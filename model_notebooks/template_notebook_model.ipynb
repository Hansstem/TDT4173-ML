{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "import warnings\n",
    "import data_func.read_data as read_data\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning, module=\"xgboost\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframes = read_data.get_training_data()\n",
    "X_frames_train = dataframes[0]\n",
    "Y_frames_train = dataframes[1]\n",
    "X_frames_test = read_data.get_test_data()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data clean up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29667\n",
      "29667\n",
      "720\n"
     ]
    }
   ],
   "source": [
    "# making shure that target values line up with x_values\n",
    "\n",
    "def data_allign(x_train, y_train):\n",
    "\n",
    "  y_train.dropna(inplace=True)\n",
    "  combined_data = pd.merge(x_train, y_train, left_on='date_forecast', right_on='time')\n",
    "  y_train = combined_data['pv_measurement']\n",
    "\n",
    "  if 'time' and 'pv_measurement' in combined_data.columns:\n",
    "    combined_data.drop(columns=['time', 'pv_measurement'], inplace=True)\n",
    "    \n",
    "  return combined_data, y_train\n",
    "\n",
    "import data_func.aggregation as data_agg\n",
    "\n",
    "for i in range(len(X_frames_train)):\n",
    "    X_frames_train[i] = data_agg.gen_agg(X_frames_train[i], 'mean')\n",
    "    X_frames_train[i], Y_frames_train[i] = data_allign(X_frames_train[i], Y_frames_train[i])\n",
    "\n",
    "\n",
    "for j in range(len(X_frames_test)):\n",
    "    X_frames_test[j] = data_agg.gen_agg(X_frames_test[j], 'mean')\n",
    "\n",
    "print(len(X_frames_train[0]))\n",
    "print(len(Y_frames_train[0]))\n",
    "print(len(X_frames_test[0]))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 0]\n"
     ]
    }
   ],
   "source": [
    "import data_func.timeseasonality as DTS\n",
    "for i in range(len(X_frames_train)):\n",
    "    X_frames_train[i] = DTS.append_seasonal_columns(X_frames_train[i])\n",
    "    X_frames_train[i].drop(columns=['date_forecast'], inplace=True)\n",
    "\n",
    "for i in range(len(X_frames_test)):\n",
    "    X_frames_test[i] = DTS.append_seasonal_columns(X_frames_test[i])\n",
    "    X_frames_test[i].drop(columns=['date_forecast'], inplace=True)\n",
    "\n",
    "\n",
    "import data_func.one_hot_encoding as OHE\n",
    "\n",
    "for i in range(len(X_frames_train)):\n",
    "    X_frames_train[i] = OHE.one_hot_encode(X_frames_train[i], ['dew_or_rime:idx', 'precip_type_5min:idx'])\n",
    "\n",
    "for i in range(len(X_frames_test)):\n",
    "    X_frames_test[i] = OHE.one_hot_encode(X_frames_test[i], ['dew_or_rime:idx', 'precip_type_5min:idx'])\n",
    "\n",
    "print(X_frames_train[2]['dew_or_rime:idx_0.0'].unique())\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_a, x_val_a, y_train_a, y_val_a = train_test_split(X_frames_train[0], Y_frames_train[0], test_size=0.17, random_state=None)\n",
    "x_train_b, x_val_b, y_train_b, y_val_b = train_test_split(X_frames_train[1], Y_frames_train[1], test_size=0.17, random_state=None)\n",
    "x_train_c, x_val_c, y_train_c, y_val_c = train_test_split(X_frames_train[2], Y_frames_train[2], test_size=0.17, random_state=None)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Make predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Do some more stuff"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE for A:  152142.9309509963\n",
      "MSE for B:  3800.655202913581\n",
      "MSE for C:  2637.166722211876\n",
      "Mean MSE:  52860.25095870725\n",
      "Score A:  0.8939208780307045\n",
      "Score B:  0.905450785281629\n",
      "Score C:  0.9149393602433711\n",
      "\n",
      "Model A\n",
      "                 Feature  Importance\n",
      "10          direct_rad:W    0.544118\n",
      "8          diffuse_rad:W    0.067302\n",
      "4        clear_sky_rad:W    0.041510\n",
      "33    snow_melt_10min:mm    0.031026\n",
      "48          cosinus_year    0.022969\n",
      "20      is_in_shadow:idx    0.020353\n",
      "23  precip_type_5min:idx    0.017036\n",
      "35         sun_azimuth:d    0.015271\n",
      "22        precip_5min:mm    0.014586\n",
      "45             sinus_day    0.013040\n",
      "\n",
      "Model B\n",
      "             Feature  Importance\n",
      "10      direct_rad:W    0.355808\n",
      "36   sun_elevation:d    0.135486\n",
      "4    clear_sky_rad:W    0.104658\n",
      "20  is_in_shadow:idx    0.094286\n",
      "48      cosinus_year    0.026637\n",
      "18  fresh_snow_6h:cm    0.024173\n",
      "8      diffuse_rad:W    0.022668\n",
      "19        is_day:idx    0.021480\n",
      "47        sinus_year    0.017070\n",
      "27   rain_water:kgm2    0.015288\n",
      "\n",
      "Model C\n",
      "                 Feature  Importance\n",
      "36       sun_elevation:d    0.622162\n",
      "4        clear_sky_rad:W    0.186129\n",
      "10          direct_rad:W    0.037790\n",
      "30     snow_density:kgm3    0.035218\n",
      "11       direct_rad_1h:J    0.017800\n",
      "14     fresh_snow_12h:cm    0.015099\n",
      "24     pressure_100m:hPa    0.007847\n",
      "16     fresh_snow_24h:cm    0.006074\n",
      "23  precip_type_5min:idx    0.005350\n",
      "38           t_1000hPa:K    0.004914\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Evaluate the model based on the validation data\n",
    "\n",
    "mse_a = mean_squared_error(y_val_a, model_a.predict(x_val_a))\n",
    "print(\"MSE for A: \", mse_a)\n",
    "mse_b = mean_squared_error(y_val_b, model_b.predict(x_val_b))\n",
    "print(\"MSE for B: \", mse_b)\n",
    "mse_c = mean_squared_error(y_val_c, model_c.predict(x_val_c))\n",
    "print(\"MSE for C: \", mse_c)\n",
    "print(\"Mean MSE: \", (mse_a + mse_b + mse_c) / 3)\n",
    "\n",
    "# Evaluate the predictions\n",
    "\n",
    "score_a = model_a.score(x_val_a, y_val_a)\n",
    "score_b = model_b.score(x_val_b, y_val_b)\n",
    "score_c = model_c.score(x_val_c, y_val_c)\n",
    "\n",
    "print(\"Score A: \", score_a)\n",
    "print(\"Score B: \", score_b)\n",
    "print(\"Score C: \", score_c)\n",
    "print('')\n",
    "\n",
    "# Get feature importance scores\n",
    "models = [(model_a, 'A'), (model_b, 'B'), (model_c, 'C')]\n",
    "for model in models:\n",
    "\n",
    "    feature_importance_scores = model[0].feature_importances_\n",
    "\n",
    "# Create a DataFrame to associate features with their importance scores\n",
    "    feature_importance_df1 = pd.DataFrame({'Feature': x_train_a.columns, 'Importance': feature_importance_scores})\n",
    "\n",
    "# Sort features by importance in descending order\n",
    "    feature_importance_df1 = feature_importance_df1.sort_values(by='Importance', ascending=False)\n",
    "\n",
    "# Print or visualize the feature importance scores\n",
    "    \n",
    "    print(f'Model {model[1]}')\n",
    "    print(feature_importance_df1.head(10))\n",
    "    print('')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_pred = y_pred\n",
    "\n",
    "test = pd.read_csv('../data/test.csv')\n",
    "test['prediction'] = y_test_pred\n",
    "sample_submission = pd.read_csv('../data/sample_submission.csv')\n",
    "submission = sample_submission[['id']].merge(test[['id', 'prediction']], on='id', how='left')\n",
    "submission.to_csv('submission.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
