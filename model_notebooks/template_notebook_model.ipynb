{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "import warnings\n",
    "import data_func.read_data as read_data\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning, module=\"xgboost\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframes = read_data.get_training_data()\n",
    "X_frames_train = dataframes[0]\n",
    "Y_frames_train = dataframes[1]\n",
    "X_frames_test = read_data.get_test_data()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "XTRA = X_frames_train[0]\n",
    "XTRB = X_frames_train[1]\n",
    "XTRC = X_frames_train[2]\n",
    "\n",
    "YA = Y_frames_train[0]\n",
    "YB = Y_frames_train[1]\n",
    "YC = Y_frames_train[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0   2019-06-02 22:00:00\n",
      "1   2019-06-02 22:15:00\n",
      "2   2019-06-02 22:30:00\n",
      "3   2019-06-02 22:45:00\n",
      "4   2019-06-02 23:00:00\n",
      "Name: date_forecast, dtype: datetime64[ns]\n",
      "0   2019-06-02 22:00:00\n",
      "1   2019-06-02 23:00:00\n",
      "2   2019-06-03 00:00:00\n",
      "3   2019-06-03 01:00:00\n",
      "4   2019-06-03 02:00:00\n",
      "Name: time, dtype: datetime64[ns]\n"
     ]
    }
   ],
   "source": [
    "print(XTRA[\"date_forecast\"].head())\n",
    "print(YA[\"time\"].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To align we can drop entry 0 for both Y and X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0   2019-01-01 00:00:00\n",
      "1   2019-01-01 00:15:00\n",
      "2   2019-01-01 00:30:00\n",
      "3   2019-01-01 00:45:00\n",
      "4   2019-01-01 01:00:00\n",
      "Name: date_forecast, dtype: datetime64[ns]\n",
      "0   2018-12-31 23:00:00\n",
      "1   2019-01-01 00:00:00\n",
      "2   2019-01-01 01:00:00\n",
      "3   2019-01-01 02:00:00\n",
      "4   2019-01-01 03:00:00\n",
      "Name: time, dtype: datetime64[ns]\n"
     ]
    }
   ],
   "source": [
    "print(XTRB[\"date_forecast\"].head())\n",
    "print(YB[\"time\"].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To align we remove 0 and 1 from Y and 0 from X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0   2019-01-01 00:00:00\n",
      "1   2019-01-01 00:15:00\n",
      "2   2019-01-01 00:30:00\n",
      "3   2019-01-01 00:45:00\n",
      "4   2019-01-01 01:00:00\n",
      "Name: date_forecast, dtype: datetime64[ns]\n",
      "0   2018-12-31 23:00:00\n",
      "1   2019-01-01 00:00:00\n",
      "2   2019-01-01 01:00:00\n",
      "3   2019-01-01 02:00:00\n",
      "4   2019-01-01 03:00:00\n",
      "Name: time, dtype: datetime64[ns]\n"
     ]
    }
   ],
   "source": [
    "print(XTRC[\"date_forecast\"].head())\n",
    "print(YC[\"time\"].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To align we remove 0 and 1 from Y and 0 from X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "XTRA = XTRA.drop([0]).reset_index(drop=True)\n",
    "XTRB = XTRB.drop([0]).reset_index(drop=True)\n",
    "XTRC = XTRC.drop([0]).reset_index(drop=True)\n",
    "\n",
    "YA = YA.drop([0]).reset_index(drop=True)\n",
    "YB = YB.drop([0, 1]).reset_index(drop=True)\n",
    "YC = YC.drop([0, 1]).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleaning Y-data\n",
    "\n",
    "### B targets:\n",
    "\n",
    "Start | End\n",
    "--- | ---\n",
    "2019-03-24 00:00:00 | 2019-03-28 00:00:00\n",
    "2019-05-31 00:00:00 | 2019-06-03 14:00:00\n",
    "2019-10-28 14:00:00 | 2019-10-30 23:00:00\n",
    "2020-02-23 17:00:00 | 2020-03-06 06:00:00\n",
    "2020-03-26 14:00:00 | 2020-03-27 22:00:00\n",
    "2020-04-02 03:00:00 | 2020-04-16 08:00:00\n",
    "2020-07-12 23:00:00 | 2020-08-25 23:00:00\n",
    "2020-09-24 14:00:00 | 2020-09-25 23:00:00\n",
    "2021-01-15 10:00:00 | 2021-04-19 09:00:00\n",
    "2021-04-29 00:00:00 | 2021-05-01 23:00:00\n",
    "2021-06-05 03:00:00 | 2021-06-07 08:00:00\n",
    "2021-06-13 04:00:00 | 2021-06-14 10:00:00\n",
    "2021-06-22 03:00:00 | 2021-06-24 08:00:00\n",
    "2021-07-03 15:00:00 | 2021-07-06 07:00:00\n",
    "2021-08-26 00:00:00 | 2021-09-03 22:00:00\n",
    "2021-09-08 15:00:00 | 2021-09-14 13:00:00\n",
    "2021-09-19 02:00:00 | 2021-09-27 10:00:00\n",
    "2021-01-30 15:00:00 | 2022-02-04 09:00:00\n",
    "2022-02-10 21:00:00 | 2022-02-13 07:00:00\n",
    "2022-02-16 14:00:00 | 2022-02-24 06:00:00\n",
    "2022-03-19 15:00:00 | 2022-04-13 06:00:00\n",
    "2022-12-05 17:00:00 | 2023-01-05 08:00:00\n",
    "2023-02-24 01:00:00 | 2023-02-27 05:00:00\n",
    "2023-03-07 10:00:00 | 2023-03-10 01:00:00\n",
    "2023-03-25 23:00:00 | 2023-03-28 02:00:00\n",
    "\n",
    "### C-targets:\n",
    "\n",
    "StartÂ | End\n",
    "---|---\n",
    "2020-02-23 17:00:00 | 2020-03-08 08:00:00"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "before B drop:  32846\n",
      "after B drop:  20626\n",
      "before C drop 32153\n",
      "after C drop 31825\n"
     ]
    }
   ],
   "source": [
    "start_times_b = [\n",
    "    '2019-03-24 00:00:00',\n",
    "'2019-05-31 00:00:00',\n",
    "'2019-10-28 14:00:00',\n",
    "'2020-02-23 17:00:00',\n",
    "'2020-03-26 14:00:00',\n",
    "'2020-04-02 03:00:00',\n",
    "'2020-07-12 23:00:00',\n",
    "'2020-09-24 14:00:00',\n",
    "'2021-01-15 10:00:00',\n",
    "'2021-04-29 00:00:00',\n",
    "'2021-06-05 03:00:00',\n",
    "'2021-06-13 04:00:00',\n",
    "'2021-06-22 03:00:00',\n",
    "'2021-07-03 15:00:00',\n",
    "'2021-08-26 00:00:00',\n",
    "'2021-09-08 15:00:00',\n",
    "'2021-09-19 02:00:00',\n",
    "'2021-01-30 15:00:00',\n",
    "'2022-02-10 21:00:00',\n",
    "'2022-02-16 14:00:00',\n",
    "'2022-03-19 15:00:00',\n",
    "'2022-12-05 17:00:00',\n",
    "'2023-02-24 01:00:00',\n",
    "'2023-03-07 10:00:00',\n",
    "'2023-03-25 23:00:00'\n",
    "]\n",
    "\n",
    "end_times_b = [\n",
    "    '2019-03-28 00:00:00',\n",
    "'2019-06-03 14:00:00',\n",
    "'2019-10-30 23:00:00',\n",
    "'2020-03-06 06:00:00',\n",
    "'2020-03-27 22:00:00',\n",
    "'2020-04-16 08:00:00',\n",
    "'2020-08-25 23:00:00',\n",
    "'2020-09-25 23:00:00',\n",
    "'2021-04-19 09:00:00',\n",
    "'2021-05-01 23:00:00',\n",
    "'2021-06-07 08:00:00',\n",
    "'2021-06-14 10:00:00',\n",
    "'2021-06-24 08:00:00',\n",
    "'2021-07-06 07:00:00',\n",
    "'2021-09-03 22:00:00',\n",
    "'2021-09-14 13:00:00',\n",
    "'2021-09-27 10:00:00',\n",
    "'2022-02-04 09:00:00',\n",
    "'2022-02-13 07:00:00',\n",
    "'2022-02-24 06:00:00',\n",
    "'2022-04-13 06:00:00',\n",
    "'2023-01-05 08:00:00',\n",
    "'2023-02-27 05:00:00',\n",
    "'2023-03-10 01:00:00',\n",
    "'2023-03-28 02:00:00'\n",
    "]\n",
    "\n",
    "print(\"before B drop: \", len(YB))\n",
    "\n",
    "for i in range(len(start_times_b)):\n",
    "    a = pd.to_datetime(start_times_b[i])\n",
    "    b = pd.to_datetime(end_times_b[i])\n",
    "    ind = YB[ (YB['time'] >= a) & (YB['time'] <= b)].index\n",
    "    \n",
    "    YB.drop(ind, inplace=True)\n",
    "\n",
    "print(\"after B drop: \", len(YB))\n",
    "\n",
    "print(\"before C drop: \", len(YC))\n",
    "\n",
    "a = pd.to_datetime(\"2020-02-23 17:00:00\")\n",
    "b = pd.to_datetime('2020-03-08 08:00:00')\n",
    "ind = YC[ (YC['time'] >= a) & (YC['time'] <= b)].index\n",
    "    \n",
    "YC.drop(ind, inplace=True)\n",
    "print(\"after C drop: \", len(YC))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Need to reset index for aggregation function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import data_func.aggregation as data_agg\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for x in X_frames_test:\n",
    "    print(x[\"date_forecast\"].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "drop 0 since we want to match on the \"whole\" hour."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(X_frames_test)):\n",
    "    X_frames_test[i] = X_frames_test[i].drop([0]).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data clean up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# making shure that target values line up with x_values\n",
    "import data_func.aggregation as data_agg\n",
    "\n",
    "categorical_col = ['dew_or_rime:idx', 'precip_type_5min:idx', 'is_day:idx', 'is_in_shadow:idx']\n",
    "\n",
    "def aggregate_correct_x(x: pd.DataFrame) -> pd.DataFrame:\n",
    "   '''\n",
    "   Takes a given dataframe and returns an aggregated dataframe based on selected categorical functions. \n",
    "   Assumes grouping of 4.\n",
    "   '''\n",
    "   categorical = x[[\"date_forecast\"] + categorical_col]\n",
    "   mean = x.drop(columns=categorical_col)\n",
    "\n",
    "   categorical = data_agg.gen_agg(categorical, agg_type=data_agg.stocastic_median, merge_on = 'last')\n",
    "   mean = data_agg.gen_agg(mean, \"mean\", merge_on = 'last')\n",
    "\n",
    "   return pd.merge(categorical, mean, on=\"date_forecast\")\n",
    "\n",
    "def data_allign(x_train, y_train):\n",
    "\n",
    "  y_train.dropna(inplace=True)\n",
    "  x_train = aggregate_correct_x(x_train)\n",
    "  combined_data = pd.merge(x_train, y_train, left_on='date_forecast', right_on='time')\n",
    "  y_train = combined_data['pv_measurement']\n",
    "\n",
    "  if 'time' and 'pv_measurement' in combined_data.columns:\n",
    "    combined_data.drop(columns=['time', 'pv_measurement'], inplace=True)\n",
    "    \n",
    "  return combined_data, y_train\n",
    "\n",
    "\n",
    "\n",
    "X_train = [XTRA, XTRB, XTRC]\n",
    "Y_train = [YA, YB, YC]\n",
    "\n",
    "for i in range(len(X_train)):\n",
    "    X_train[i], Y_train[i] = data_allign(X_train[i], Y_train[i])\n",
    "\n",
    "for j in range(len(X_frames_test)):\n",
    "    X_frames_test[j] = aggregate_correct_x(X_frames_test[j])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Verify length matches\n",
    "for x in range(len(X_train)):\n",
    "    print(\"x,y: \", len(X_train[x]), len(Y_train[x]))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import data_func.timeseasonality as DTS\n",
    "import data_func.one_hot_encoding as OHE\n",
    "for i in range(len(X_train)):\n",
    "    X_train[i] = DTS.append_seasonal_columns(X_train[i])\n",
    "    X_train[i].drop(columns=['date_forecast'], inplace=True)\n",
    "\n",
    "for i in range(len(X_frames_test)):\n",
    "    X_frames_test[i] = DTS.append_seasonal_columns(X_frames_test[i])\n",
    "    X_frames_test[i].drop(columns=['date_forecast'], inplace=True)\n",
    "\n",
    "# THIS SECTION CAN ONLY WORK IF THE PREVIOUS AGGREGATION IS DONE INDIVIDUALLY FOR CATEGORICAL DATA\n",
    "# import data_func.one_hot_encoding as OHE\n",
    "\n",
    "for i in range(len(X_train)):\n",
    "     X_train[i] = OHE.one_hot_encode(X_train[i], ['dew_or_rime:idx', 'precip_type_5min:idx'])\n",
    "\n",
    "for i in range(len(X_frames_test)):\n",
    "     X_frames_test[i] = OHE.one_hot_encode(X_frames_test[i], ['dew_or_rime:idx', 'precip_type_5min:idx'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train[0].describe().transpose()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_a, x_val_a, y_train_a, y_val_a = train_test_split(X_train[0], Y_train[0], test_size=0.17, random_state=None)\n",
    "x_train_b, x_val_b, y_train_b, y_val_b = train_test_split(X_train[1], Y_train[1], test_size=0.17, random_state=None)\n",
    "x_train_c, x_val_c, y_train_c, y_val_c = train_test_split(X_train[2], Y_train[2], test_size=0.17, random_state=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Make predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Do some more stuff"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Evaluate the model based on the validation data\n",
    "\n",
    "mse_a = mean_squared_error(y_val_a, model_a.predict(x_val_a))\n",
    "print(\"MSE for A: \", mse_a)\n",
    "mse_b = mean_squared_error(y_val_b, model_b.predict(x_val_b))\n",
    "print(\"MSE for B: \", mse_b)\n",
    "mse_c = mean_squared_error(y_val_c, model_c.predict(x_val_c))\n",
    "print(\"MSE for C: \", mse_c)\n",
    "print(\"Mean MSE: \", (mse_a + mse_b + mse_c) / 3)\n",
    "\n",
    "# Evaluate the predictions\n",
    "\n",
    "score_a = model_a.score(x_val_a, y_val_a)\n",
    "score_b = model_b.score(x_val_b, y_val_b)\n",
    "score_c = model_c.score(x_val_c, y_val_c)\n",
    "\n",
    "print(\"Score A: \", score_a)\n",
    "print(\"Score B: \", score_b)\n",
    "print(\"Score C: \", score_c)\n",
    "print('')\n",
    "\n",
    "# Get feature importance scores\n",
    "models = [(model_a, 'A'), (model_b, 'B'), (model_c, 'C')]\n",
    "for model in models:\n",
    "\n",
    "    feature_importance_scores = model[0].feature_importances_\n",
    "\n",
    "# Create a DataFrame to associate features with their importance scores\n",
    "    feature_importance_df1 = pd.DataFrame({'Feature': x_train_a.columns, 'Importance': feature_importance_scores})\n",
    "\n",
    "# Sort features by importance in descending order\n",
    "    feature_importance_df1 = feature_importance_df1.sort_values(by='Importance', ascending=False)\n",
    "\n",
    "# Print or visualize the feature importance scores\n",
    "    \n",
    "    print(f'Model {model[1]}')\n",
    "    print(feature_importance_df1.head(10))\n",
    "    print('')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_pred = y_pred\n",
    "\n",
    "test = pd.read_csv('../data/test.csv')\n",
    "test['prediction'] = y_test_pred\n",
    "sample_submission = pd.read_csv('../data/sample_submission.csv')\n",
    "submission = sample_submission[['id']].merge(test[['id', 'prediction']], on='id', how='left')\n",
    "submission.to_csv('submission.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
