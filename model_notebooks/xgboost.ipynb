{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import xgboost as xgb\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "import warnings\n",
    "import data_func.read_data as read_data\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning, module=\"xgboost\")\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning, message=\"is_sparse is deprecated\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframes = read_data.get_training_data()\n",
    "X_frames_train = dataframes[0]\n",
    "Y_frames_train = dataframes[1]\n",
    "X_frames_test = read_data.get_test_data()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "XTRA = X_frames_train[0]\n",
    "XTRB = X_frames_train[1]\n",
    "XTRC = X_frames_train[2]\n",
    "\n",
    "YA = Y_frames_train[0]\n",
    "YB = Y_frames_train[1]\n",
    "YC = Y_frames_train[2]\n",
    "\n",
    "print(XTRA.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"A: \\n\", len(XTRA))\n",
    "ind = XTRA[(XTRA['date_forecast'] == pd.to_datetime('2022-10-21 00:00:00'))].index\n",
    "print(ind)\n",
    "XTRA = XTRA.drop(ind).reset_index(drop=True)\n",
    "print(len(XTRA))\n",
    "\n",
    "print(\"B: \\n\", len(XTRB))\n",
    "ind = XTRB[(XTRB['date_forecast'] == pd.to_datetime('2022-05-02 21:00:00'))].index\n",
    "print(ind)\n",
    "XTRB = XTRB.drop(ind).reset_index(drop=True)\n",
    "print(len(XTRB))\n",
    "\n",
    "print(\"C: \\n\",len(XTRC))\n",
    "ind = XTRC[(XTRC['date_forecast'] == pd.to_datetime('2022-04-25 21:00:00'))].index\n",
    "print(ind)\n",
    "XTRC = XTRC.drop(ind).reset_index(drop=True)\n",
    "print(len(XTRC))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fix_y_holes(y: pd.DataFrame) -> pd.DataFrame:\n",
    "    Y = y\n",
    "    drop_val = None\n",
    "    index_dropper = []\n",
    "    for i in range(1, len(Y)-4): # Since we match on 4 consecutive values.\n",
    "        if Y['pv_measurement'].iloc[i] != 0:\n",
    "            if (Y['pv_measurement'].iloc[i] == Y['pv_measurement'].iloc[i+1] and Y['pv_measurement'].iloc[i+1] == Y['pv_measurement'].iloc[i+2] and Y['pv_measurement'].iloc[i+2] == Y['pv_measurement'].iloc[i+3]):\n",
    "                drop_val = Y['pv_measurement'].iloc[i]\n",
    "        if Y['pv_measurement'].iloc[i] == drop_val:\n",
    "            index_dropper.append(i)\n",
    "        else:\n",
    "            if drop_val != None:\n",
    "                drop_val = None\n",
    "    print(index_dropper)\n",
    "    return Y.drop(index_dropper)\n",
    "\n",
    "YA = fix_y_holes(YA)\n",
    "YB = fix_y_holes(YB)\n",
    "YC = fix_y_holes(YC)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data clean up an aggregation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Making sure that target values line up with x_values\n",
    "import data_func.aggregation as data_agg\n",
    "\n",
    "categorical_col = ['dew_or_rime:idx', 'precip_type_5min:idx', 'is_day:idx', 'is_in_shadow:idx']\n",
    "\n",
    "def aggregate_correct_x(x: pd.DataFrame) -> pd.DataFrame:\n",
    "   '''\n",
    "   Takes a given dataframe and returns an aggregated dataframe based on selected categorical functions. \n",
    "   Assumes grouping of 4.\n",
    "   '''\n",
    "   categorical = x[[\"date_forecast\"] + categorical_col]\n",
    "   mean = x.drop(columns=categorical_col)\n",
    "\n",
    "   categorical = data_agg.gen_agg(categorical, agg_type=data_agg.stocastic_median)\n",
    "   mean = data_agg.gen_agg(mean, \"mean\")\n",
    "\n",
    "   return pd.merge(categorical, mean, on=\"date_forecast\")\n",
    "\n",
    "def data_allign(x_train, y_train):\n",
    "\n",
    "  y_train.dropna(inplace=True)\n",
    "  x_train = aggregate_correct_x(x_train)\n",
    "  combined_data = pd.merge(x_train, y_train, left_on='date_forecast', right_on='time')\n",
    "  y_train = combined_data['pv_measurement']\n",
    "\n",
    "  if 'time' and 'pv_measurement' in combined_data.columns:\n",
    "    combined_data.drop(columns=['time', 'pv_measurement'], inplace=True)\n",
    "    \n",
    "  return combined_data, y_train\n",
    "\n",
    "\n",
    "\n",
    "X_train = [XTRA, XTRB, XTRC]\n",
    "Y_train = [YA, YB, YC]\n",
    "\n",
    "for i in range(len(X_train)):\n",
    "    X_train[i], Y_train[i] = data_allign(X_train[i], Y_train[i])\n",
    "\n",
    "for j in range(len(X_frames_test)):\n",
    "    X_frames_test[j] = aggregate_correct_x(X_frames_test[j])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import data_func.timeseasonality as DTS\n",
    "import data_func.one_hot_encoding as OHE\n",
    "import data_func.date_forecast as DTF\n",
    "import data_func.combine_columns as CC\n",
    "\n",
    "columns_to_drop = ['snow_density:kgm3', 'elevation:m', 'snow_drift:idx', 'date_forecast', 'ceiling_height_agl:m','cloud_base_agl:m']\n",
    "\n",
    "for i in range(len(X_train)):\n",
    "    X_train[i] = DTS.append_seasonal_columns(X_train[i])\n",
    "    X_train[i] = DTF.date_forecast_columns(X_train[i])\n",
    "    #X_train[i] = CC.combine_columns_division(X_train[i], 'clear_sky_total', ['clear_sky_energy_1h:J', 'clear_sky_rad:W'])\n",
    "\n",
    "\n",
    "for i in range(len(X_frames_test)):\n",
    "    X_frames_test[i] = DTS.append_seasonal_columns(X_frames_test[i])\n",
    "    X_frames_test[i] = DTF.date_forecast_columns(X_frames_test[i])\n",
    "    #X_frames_test[i] = CC.combine_columns_division(X_frames_test[i], 'clear_sky_total', ['clear_sky_energy_1h:J', 'clear_sky_rad:W'])\n",
    "\n",
    "\n",
    "# THIS SECTION CAN ONLY WORK IF THE PREVIOUS AGGREGATION IS DONE INDIVIDUALLY FOR CATEGORICAL DATA\n",
    "# import data_func.one_hot_encoding as OHE\n",
    "\n",
    "def fix_categorical(train: pd.DataFrame, test: pd.DataFrame):\n",
    "     temp = pd.concat([train, test], ignore_index=True)\n",
    "     index_train = temp[(temp['date_forecast'] < test['date_forecast'].iloc[0])].index\n",
    "     return temp.drop(index_train)\n",
    "\n",
    "OH_columns = ['dew_or_rime:idx', 'precip_type_5min:idx']\n",
    "\n",
    "for i in range(len(X_frames_test)):\n",
    "     X_train[i] = OHE.one_hot_encode(X_train[i],OH_columns)\n",
    "     X_frames_test[i] = OHE.one_hot_encode(X_frames_test[i], OH_columns)\n",
    "     X_frames_test[i] = fix_categorical(X_train[i], X_frames_test[i])\n",
    "     X_train[i].drop(columns=columns_to_drop, inplace=True)\n",
    "     X_frames_test[i].drop(columns=columns_to_drop, inplace=True)\n",
    "\n",
    "def combine_features(df, listOfFeaturesToCombine):\n",
    "    for features in listOfFeaturesToCombine:\n",
    "        new_col_name = features[0] + '_mean'\n",
    "        df[new_col_name] = df[features].mean(axis=1)\n",
    "        #df.drop(columns=features, inplace=True)\n",
    "    return df\n",
    "\n",
    "listOfFeaturesToCombine = [['msl_pressure:hPa', 'pressure_100m:hPa', 'pressure_50m:hPa', 'sfc_pressure:hPa'],\n",
    "                            [\"diffuse_rad:W\", \"direct_rad:W\"], \n",
    "                           [\"diffuse_rad_1h:J\", \"direct_rad_1h:J\"],\n",
    "                           ['effective_cloud_cover:p', 'effective_cloud_cover:p']\n",
    "                    ]\n",
    "for i in range(len(X_train)):\n",
    "    X_train[i] = combine_features(X_train[i], listOfFeaturesToCombine)\n",
    "    X_frames_test[i] = combine_features(X_frames_test[i], listOfFeaturesToCombine)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show null values for all training sets\n",
    "\n",
    "count_a = X_train[0].isna().sum()\n",
    "count_b = X_train[1].isna().sum()\n",
    "count_c = X_train[2].isna().sum()\n",
    "\n",
    "count_a.rename(\"A\", inplace=True)\n",
    "count_b.rename(\"B\", inplace=True)\n",
    "count_c.rename(\"C\", inplace=True)\n",
    "\n",
    "df = pd.merge(count_a, count_b, left_index=True, right_index=True)\n",
    "df = pd.merge(df, count_c, left_index=True, right_index=True)\n",
    "\n",
    "df[(df['A'] != 0) | (df['B'] != 0) | (df['C'] != 0)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show null values for all test sets\n",
    "\n",
    "count_a = X_frames_test[0].isna().sum()\n",
    "count_b = X_frames_test[1].isna().sum()\n",
    "count_c = X_frames_test[2].isna().sum()\n",
    "\n",
    "count_a.rename(\"A\", inplace=True)\n",
    "count_b.rename(\"B\", inplace=True)\n",
    "count_c.rename(\"C\", inplace=True)\n",
    "\n",
    "df = pd.merge(count_a, count_b, left_index=True, right_index=True)\n",
    "df = pd.merge(df, count_c, left_index=True, right_index=True)\n",
    "\n",
    "df[(df['A'] != 0) | (df['B'] != 0) | (df['C'] != 0)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removes nan or fills it\n",
    "values = {\"ceiling_height_agl:m\": 20000, \"cloud_base_agl:m\": 20000}\n",
    "\n",
    "for i in range(len(X_train)):\n",
    "    X_train[i].fillna(value=values, inplace=True)\n",
    "    X_frames_test[i].fillna(value=values, inplace=True)\n",
    "    X_frames_test[i].fillna(0, inplace=True) # fills remaining NaN vals with 0, (specifically for one-hot encoded columns with NaN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Combine datasets B and C\n",
    "\n",
    "def combine_bc(frames: [pd.DataFrame]):\n",
    "    \n",
    "    for i, frame in enumerate(frames):\n",
    "        if i == 0:\n",
    "            frame['location'] = '0'\n",
    "        elif i == 1:\n",
    "            frame['location'] = '1'\n",
    "    combined = pd.concat(frames)\n",
    "    combined = combined.reset_index(drop=True)\n",
    "    combined['location'] = combined['location'].astype('float64')\n",
    "\n",
    "    return combined\n",
    "\n",
    "X_train_bc = combine_bc([X_train[1], X_train[2]])\n",
    "X_train_bc = OHE.one_hot_encode(X_train_bc, [\"location\"])\n",
    "\n",
    "X_frames_test_bc = combine_bc([X_frames_test[1], X_frames_test[2]])\n",
    "X_frames_test_bc = OHE.one_hot_encode(X_frames_test_bc, [\"location\"])\n",
    "Y_train_bc = pd.concat([Y_train[1], Y_train[2]], ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_frames_test_bc['estimated'].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Split the data into training and validation sets\n",
    "\n",
    "x_train_a, x_val_a, y_train_a, y_val_a = train_test_split(X_train[0], Y_train[0], test_size=0.17, random_state=42)\n",
    "x_train_b, x_val_b, y_train_b, y_val_b = train_test_split(X_train_bc, Y_train_bc, test_size=0.17, random_state=42)\n",
    "#x_train_c, x_val_c, y_train_c, y_val_c = train_test_split(X_train[2], Y_train[2], test_size=0.17, random_state=42)\n",
    "\n",
    "# Use params from hyperparameter tuning using optuna\n",
    "#params_a = {'random_state': 42, 'max_depth': 8, 'learning_rate': 0.06749043102808519, 'n_estimators': 885, 'min_child_weight': 3, 'gamma': 0.09742083144148345, 'subsample': 0.8847103741988528, 'colsample_bytree': 0.8503503049152975, 'reg_alpha': 0.012108852929559821, 'reg_lambda': 0.28779285121150633}\n",
    "params_a = {'random_state': 42, 'n_estimators': 980, 'max_depth': 9, 'learning_rate': 0.029035565559484028, 'subsample': 0.8393121619033767, 'colsample_bytree': 0.7589542758688459}\n",
    "# params_b = {'random_state': 42, 'max_depth': 9, 'learning_rate': 0.04778208620335073, 'n_estimators': 998, 'min_child_weight': 4, 'gamma': 0.7276770076424136, 'subsample': 0.41548412574068205, 'colsample_bytree': 0.671005991193969, 'reg_alpha': 0.15578107366887714, 'reg_lambda': 0.11160337145958334}\n",
    "params_b = {'random_state': 42, 'n_estimators': 955, 'max_depth': 9, 'learning_rate': 0.02949625834198986, 'subsample': 0.8030196155828968, 'colsample_bytree': 0.72518389089994}\n",
    "#params_c = {'random_state': 42, 'n_estimators': 727, 'max_depth': 8, 'learning_rate': 0.08609213174337473, 'subsample': 0.8107057409889747, 'colsample_bytree': 0.8763563332327975}\n",
    "model_a = xgb.XGBRegressor(**params_a)\n",
    "model_b = xgb.XGBRegressor(**params_b)\n",
    "#model_c = xgb.XGBRegressor(**params_c)\n",
    "\n",
    "\n",
    "model_a.fit(x_train_a, y_train_a)\n",
    "model_b.fit(x_train_b, y_train_b)\n",
    "#model_c.fit(x_train_c, y_train_c)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the model based on the validation data\n",
    "\n",
    "mae_a = mean_absolute_error(y_val_a, model_a.predict(x_val_a))\n",
    "mse_a = mean_squared_error(y_val_a, model_a.predict(x_val_a))\n",
    "print(\"MAE for A: \", mae_a)\n",
    "print(\"MSE for A: \", mse_a)\n",
    "mae_b = mean_absolute_error(y_val_b, model_b.predict(x_val_b))\n",
    "mse_b = mean_squared_error(y_val_b, model_b.predict(x_val_b))\n",
    "print(\"MAE for B: \", mae_b)\n",
    "print(\"MSE for B: \", mse_b)\n",
    "#mae_c = mean_absolute_error(y_val_c, model_c.predict(x_val_c))\n",
    "#print(\"MAE for C: \", mae_c)\n",
    "print(\"Mean MAE: \", (mae_a + mae_b) / 2)\n",
    "\n",
    "# Evaluate the predictions\n",
    "\n",
    "score_a = model_a.score(x_val_a, y_val_a)\n",
    "score_b = model_b.score(x_val_b, y_val_b)\n",
    "#score_c = model_c.score(x_val_c, y_val_c)\n",
    "\n",
    "print(\"Score A: \", score_a)\n",
    "print(\"Score B: \", score_b)\n",
    "#print(\"Score C: \", score_c)\n",
    "print('')\n",
    "\n",
    "# Get feature importance scores\n",
    "models = [(model_a, 'A'), (model_b, 'B')]\n",
    "for model in models:\n",
    "\n",
    "    feature_importance_scores = model[0].feature_importances_\n",
    "\n",
    "# Create a DataFrame to associate features with their importance scores\n",
    "    feature_importance_df1 = pd.DataFrame({'Feature': x_train_a.columns, 'Importance': feature_importance_scores})\n",
    "\n",
    "# Sort features by importance in descending order\n",
    "    feature_importance_df1 = feature_importance_df1.sort_values(by='Importance', ascending=False)\n",
    "\n",
    "# Print or visualize the feature importance scores\n",
    "    pd.set_option('display.max_rows', 500)\n",
    "    feature_importance_df1.head(500)\n",
    "    print(f'Model {model[1]}')\n",
    "    print(feature_importance_df1)\n",
    "    pd.reset_option('display.max_rows')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Make predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model on the entire training data\n",
    "model_a.fit(X_train[0], Y_train[0])\n",
    "model_b.fit(X_train_bc, Y_train_bc)\n",
    "#model_c.fit(X_train[2], Y_train[2])\n",
    "\n",
    "y_pred_a = model_a.predict(X_frames_test[0])\n",
    "y_pred_b = model_b.predict(X_frames_test_bc)\n",
    "#y_pred_c = model_c.predict(X_frames_test[2])\n",
    "print(len(y_pred_a))\n",
    "\n",
    "y_pred = np.concatenate((y_pred_a, y_pred_b), axis=0)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(y_pred_a), len(X_frames_test[0]))\n",
    "print(len(y_pred_b), len(X_frames_test[1]))\n",
    "#print(len(y_pred_c), len(X_frames_test[2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(y_pred)):\n",
    "    if y_pred[i] < 10: \n",
    "        y_pred[i] = 0\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_pred = y_pred\n",
    "print(len(y_test_pred))\n",
    "\n",
    "test = pd.read_csv('../data/test.csv')\n",
    "test['prediction'] = y_test_pred\n",
    "sample_submission = pd.read_csv('../data/sample_submission.csv')\n",
    "submission = sample_submission[['id']].merge(test[['id', 'prediction']], on='id', how='left')\n",
    "submission.to_csv('submissions/submission_xg_two_models_with_estimated_feat.csv', index=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
