{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "import warnings\n",
    "import data_func.read_data as read_data\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning, module=\"xgboost\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframes = read_data.get_training_data()\n",
    "X_frames_train = dataframes[0]\n",
    "Y_frames_train = dataframes[1]\n",
    "X_frames_test = read_data.get_test_data()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "XTRA = X_frames_train[0]\n",
    "XTRB = X_frames_train[1]\n",
    "XTRC = X_frames_train[2]\n",
    "\n",
    "YA = Y_frames_train[0]\n",
    "YB = Y_frames_train[1]\n",
    "YC = Y_frames_train[2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleaning X\n",
    "\n",
    "Found a hole in the X data on location A\n",
    "\n",
    "1|2\n",
    "---|---\n",
    "![1](./feature_cleaning/img/X_A_1.png) | ![2](./feature_cleaning/img/X_A_2.png)\n",
    "\n",
    "This prevents our aggregation method to match the target data after these data points\n",
    "\n",
    "Trying to remove this point and reindex to fix the issue. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A: \n",
      " 136245\n",
      "Index([118664], dtype='int64')\n",
      "136244\n"
     ]
    }
   ],
   "source": [
    "print(\"A: \\n\", len(XTRA))\n",
    "ind = XTRA[(XTRA['date_forecast'] == pd.to_datetime('2022-10-21 00:00:00'))].index\n",
    "print(ind)\n",
    "XTRA = XTRA.drop(ind).reset_index(drop=True)\n",
    "print(len(XTRA))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Same problem for B-set at `2022-05-02 23:00:00` and C-set at `2022-04-25 21:00:00`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "B: \n",
      " 134505\n",
      "Index([116916], dtype='int64')\n",
      "134504\n",
      "C: \n",
      " 134401\n",
      "Index([116244], dtype='int64')\n",
      "134400\n"
     ]
    }
   ],
   "source": [
    "print(\"B: \\n\", len(XTRB))\n",
    "ind = XTRB[(XTRB['date_forecast'] == pd.to_datetime('2022-05-02 21:00:00'))].index\n",
    "print(ind)\n",
    "XTRB = XTRB.drop(ind).reset_index(drop=True)\n",
    "print(len(XTRB))\n",
    "\n",
    "print(\"C: \\n\",len(XTRC))\n",
    "ind = XTRC[(XTRC['date_forecast'] == pd.to_datetime('2022-04-25 21:00:00'))].index\n",
    "print(ind)\n",
    "XTRC = XTRC.drop(ind).reset_index(drop=True)\n",
    "print(len(XTRC))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleaning Y-data\n",
    "\n",
    "`B` targets and `C` targets have lots of static values that seems like invalid data. \n",
    "\n",
    "Removing them with function below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n",
      "[635, 636, 637, 638, 639, 640, 641, 642, 643, 644, 645, 646, 647, 648, 649, 650, 651, 652, 653, 654, 655, 656, 657, 658, 659, 660, 661, 662, 707, 708, 709, 710, 711, 712, 713, 1348, 1349, 1350, 1351, 1352, 3093, 3094, 3095, 3096, 3097, 3098, 3099, 3100, 3607, 3608, 3609, 3610, 3611, 3612, 3613, 3614, 3615, 3616, 3617, 3618, 3619, 3620, 3621, 3622, 3623, 3624, 3625, 3626, 3627, 3628, 3629, 3630, 3631, 3632, 3633, 3634, 3635, 3636, 3637, 3638, 3639, 3640, 3641, 3642, 3643, 3644, 3645, 3646, 3647, 3648, 3649, 3650, 3651, 3652, 3653, 3654, 3655, 3656, 3657, 3658, 3659, 3660, 3661, 3662, 3663, 3664, 3665, 3666, 3667, 3668, 3669, 3670, 3671, 3672, 3673, 3674, 3675, 3676, 3677, 3678, 3679, 3680, 3681, 3682, 3683, 3684, 7211, 7212, 7213, 7214, 7215, 7216, 7217, 7218, 7219, 7220, 7221, 7222, 7223, 7224, 7225, 7226, 7227, 7228, 7229, 7230, 7231, 7232, 7233, 7234, 7235, 7236, 7237, 7238, 7239, 7240, 7241, 7242, 7243, 7244, 7245, 7246, 7247, 7248, 7249, 7250, 7251, 7252, 7253, 7254, 7255, 7256, 7257, 7258, 7259, 7260, 7261, 7262, 7263, 7264, 7265, 7266, 7267, 7268, 8402, 8403, 8404, 8405, 8406, 8407, 8408, 10811, 10812, 10813, 10814, 10815, 10816, 10817, 10818, 10819, 10820, 10821, 10822, 10823, 10824, 10825, 10826, 10827, 10828, 10829, 10830, 10831, 10832, 10833, 10834, 10835, 10836, 10837, 10838, 10839, 10840, 10841, 10842, 10843, 10966, 10967, 10968, 10969, 10970, 10971, 10972, 10973, 10974, 10975, 10976, 10977, 10978, 10979, 10980, 10981, 10982, 10983, 10984, 10985, 10986, 10987, 10988, 10989, 10990, 10991, 10992, 10993, 10994, 10995, 10996, 10997, 10998, 10999, 11000, 11001, 11002, 11003, 11004, 11005, 11006, 11007, 11008, 11009, 11010, 11011, 11012, 11013, 11014, 11015, 11016, 11017, 11018, 11019, 11020, 11021, 11022, 11023, 11024, 11025, 11026, 11027, 11028, 11029, 11030, 11031, 11032, 11033, 11034, 11035, 11036, 11037, 11038, 11039, 11040, 11041, 11042, 11043, 11044, 11045, 11046, 11047, 11048, 11049, 11050, 11051, 11052, 11053, 11054, 11055, 11056, 11057, 11058, 11059, 11060, 11061, 11062, 11063, 11064, 11065, 11066, 11067, 11068, 11069, 11070, 11071, 11072, 11073, 11074, 11075, 11076, 11077, 11078, 11079, 11080, 11081, 11082, 11083, 11084, 11085, 11086, 11087, 11088, 11089, 11090, 11091, 11092, 11093, 11094, 11095, 11096, 11097, 11098, 11099, 11100, 11101, 11102, 11103, 11104, 11105, 11106, 11107, 11108, 11109, 11110, 11111, 11112, 11113, 11114, 11115, 11116, 11117, 11118, 11119, 11120, 11121, 11122, 11123, 11124, 11125, 11126, 11127, 11128, 11129, 11130, 11131, 11132, 11133, 11134, 11135, 11136, 11137, 11138, 11139, 11140, 11141, 11142, 11143, 11144, 11145, 11146, 11147, 11148, 11149, 11150, 11151, 11152, 11153, 11154, 11155, 11156, 11157, 11158, 11159, 11160, 11161, 11162, 11163, 11164, 11165, 11166, 11167, 11168, 11169, 11170, 11171, 11172, 11173, 11174, 11175, 11176, 11177, 11178, 11179, 11180, 11181, 11182, 11183, 11184, 11185, 11186, 11187, 11188, 11189, 11190, 11191, 11192, 11193, 11194, 11195, 11196, 11197, 11198, 11199, 11200, 11201, 11202, 11203, 11204, 11205, 11206, 11207, 11208, 11209, 11210, 11211, 11212, 11213, 11214, 11215, 11216, 11217, 11218, 11219, 11220, 11221, 11222, 11223, 11224, 11225, 11226, 11227, 11228, 11229, 11230, 11231, 11232, 11233, 11234, 11235, 11236, 11237, 11238, 11239, 11240, 11241, 11242, 11243, 11244, 11245, 11246, 11247, 11248, 11249, 11250, 11251, 11252, 11253, 11254, 11255, 11256, 11257, 11258, 11259, 11260, 11261, 11262, 11263, 11264, 11265, 11266, 11267, 11268, 11269, 11270, 11271, 11272, 11273, 11274, 11275, 11276, 11277, 11278, 11279, 11280, 11281, 11282, 11283, 11284, 11285, 11286, 11287, 11288, 11289, 11290, 11291, 11292, 11293, 11294, 11295, 11296, 11297, 11298, 11299, 11300, 11301, 11302, 11303, 11304, 11305, 11306, 11307, 13409, 13410, 13411, 13412, 13413, 13414, 13415, 13416, 13417, 13418, 13419, 13420, 13421, 13422, 13423, 13424, 13425, 13426, 13427, 13428, 13429, 13430, 13431, 13432, 13433, 13434, 13435, 13436, 13437, 13438, 13439, 13440, 13441, 13442, 13443, 13444, 13445, 13446, 13447, 13448, 13449, 13450, 13451, 13452, 13453, 13454, 13455, 13456, 13457, 13458, 13459, 13460, 13461, 13462, 13463, 13464, 13465, 13466, 13467, 13468, 13469, 13470, 13471, 13472, 13473, 13474, 13475, 13476, 13477, 13478, 13479, 13480, 13481, 13482, 13483, 13484, 13485, 13486, 13487, 13488, 13489, 13490, 13491, 13492, 13493, 13494, 13495, 13496, 13497, 13498, 13499, 13500, 13501, 13502, 13503, 13504, 13505, 13506, 13507, 13508, 13509, 13510, 13511, 13512, 13513, 13514, 13515, 13516, 13517, 13518, 13519, 13520, 13521, 13522, 13523, 13524, 13525, 13526, 13527, 13528, 13529, 13530, 13531, 13532, 13533, 13534, 13535, 13536, 13537, 13538, 13539, 13540, 13541, 13542, 13543, 13544, 13545, 13546, 13547, 13548, 13549, 13550, 13551, 13552, 13553, 13554, 13555, 13556, 13557, 13558, 13559, 13560, 13561, 13562, 13563, 13564, 13565, 13566, 13567, 13568, 13569, 13570, 13571, 13572, 13573, 13574, 13575, 13576, 13577, 13578, 13579, 13580, 13581, 13582, 13583, 13584, 13585, 13586, 13587, 13588, 13589, 13590, 13591, 13592, 13593, 13594, 13595, 13596, 13597, 13598, 13599, 13600, 13601, 13602, 13603, 13604, 13605, 13606, 13607, 13608, 13609, 13610, 13611, 13612, 13613, 13614, 13615, 13616, 13617, 13618, 13619, 13620, 13621, 13622, 13623, 13624, 13625, 13626, 13627, 13628, 13629, 13630, 13631, 13632, 13633, 13634, 13635, 13636, 13637, 13638, 13639, 13640, 13641, 13642, 13643, 13644, 13645, 13646, 13647, 13648, 13649, 13650, 13651, 13652, 13653, 13654, 13655, 13656, 13657, 13658, 13659, 13660, 13661, 13662, 13663, 13664, 13665, 13666, 13667, 13668, 13669, 13670, 13671, 13672, 13673, 13674, 13675, 13676, 13677, 13678, 13679, 13680, 13681, 13682, 13683, 13684, 13685, 13686, 13687, 13688, 13689, 13690, 13691, 13692, 13693, 13694, 13695, 13696, 13697, 13698, 13699, 13700, 13701, 13702, 13703, 13704, 13705, 13706, 13707, 13708, 13709, 13710, 13711, 13712, 13713, 13714, 13715, 13716, 13717, 13718, 13719, 13720, 13721, 13722, 13723, 13724, 13725, 13726, 13727, 13728, 13729, 13730, 13731, 13732, 13733, 13734, 13735, 13736, 13737, 13738, 13739, 13740, 13741, 13742, 13743, 13744, 13745, 13746, 13747, 13748, 13749, 13750, 13751, 13752, 13753, 13754, 13755, 13756, 13757, 13758, 13759, 13760, 13761, 13762, 13763, 13764, 13765, 13766, 13767, 13768, 13769, 13770, 13771, 13772, 13773, 13774, 13775, 13776, 13777, 13778, 13779, 13780, 13781, 13782, 13783, 13784, 13785, 13786, 13787, 13788, 13789, 13790, 13791, 13792, 13793, 13794, 13795, 13796, 13797, 13798, 13799, 13800, 13801, 13802, 13803, 13804, 13805, 13806, 13807, 13808, 13809, 13810, 13811, 13812, 13813, 13814, 13815, 13816, 13817, 13818, 13819, 13820, 13821, 13822, 13823, 13824, 13825, 13826, 13827, 13828, 13829, 13830, 13831, 13832, 13833, 13834, 13835, 13836, 13837, 13838, 13839, 13840, 13841, 13842, 13843, 13844, 13845, 13846, 13847, 13848, 13849, 13850, 13851, 13852, 13853, 13854, 13855, 13856, 13857, 13858, 13859, 13860, 13861, 13862, 13863, 13864, 13865, 13866, 13867, 13868, 13869, 13870, 13871, 13872, 13873, 13874, 13875, 13876, 13877, 13878, 13879, 13880, 13881, 13882, 13883, 13884, 13885, 13886, 13887, 13888, 13889, 13890, 13891, 13892, 13893, 13894, 13895, 13896, 13897, 13898, 13899, 13900, 13901, 13902, 13903, 13904, 13905, 13906, 13907, 13908, 13909, 13910, 13911, 13912, 13913, 13914, 13915, 13916, 13917, 13918, 13919, 13920, 13921, 13922, 13923, 13924, 13925, 13926, 13927, 13928, 13929, 13930, 13931, 13932, 13933, 13934, 13935, 13936, 13937, 13938, 13939, 13940, 13941, 13942, 13943, 13944, 13945, 13946, 13947, 13948, 13949, 13950, 13951, 13952, 13953, 13954, 13955, 13956, 13957, 13958, 13959, 13960, 13961, 13962, 13963, 13964, 13965, 13966, 13967, 13968, 13969, 13970, 13971, 13972, 13973, 13974, 13975, 13976, 13977, 13978, 13979, 13980, 13981, 13982, 13983, 13984, 13985, 13986, 13987, 13988, 13989, 13990, 13991, 13992, 13993, 13994, 13995, 13996, 13997, 13998, 13999, 14000, 14001, 14002, 14003, 14004, 14005, 14006, 14007, 14008, 14009, 14010, 14011, 14012, 14013, 14014, 14015, 14016, 14017, 14018, 14019, 14020, 14021, 14022, 14023, 14024, 14025, 14026, 14027, 14028, 14029, 14030, 14031, 14032, 14033, 14034, 14035, 14036, 14037, 14038, 14039, 14040, 14041, 14042, 14043, 14044, 14045, 14046, 14047, 14048, 14049, 14050, 14051, 14052, 14053, 14054, 14055, 14056, 14057, 14058, 14059, 14060, 14061, 14062, 14063, 14064, 14065, 14066, 14067, 14068, 14069, 14070, 14071, 14072, 14073, 14074, 14075, 14076, 14077, 14078, 14079, 14080, 14081, 14082, 14083, 14084, 14085, 14086, 14087, 14088, 14089, 14090, 14091, 14092, 14093, 14094, 14095, 14096, 14097, 14098, 14099, 14100, 14101, 14102, 14103, 14104, 14105, 14106, 14107, 14108, 14109, 14110, 14111, 14112, 14113, 14114, 14115, 14116, 14117, 14118, 14119, 14120, 14121, 14122, 14123, 14124, 14125, 14126, 14127, 14128, 14129, 14130, 14131, 14132, 14133, 14134, 14135, 14136, 14137, 14138, 14139, 14140, 14141, 14142, 14143, 14144, 14145, 14146, 14147, 14148, 14149, 14150, 14151, 14152, 14153, 14154, 14155, 14156, 14157, 14158, 14159, 14160, 14161, 14162, 14163, 14164, 14165, 14166, 14167, 14168, 14169, 14170, 14171, 14172, 14173, 14174, 14175, 14176, 14177, 14178, 14179, 14180, 14181, 14182, 14183, 14184, 14185, 14186, 14187, 14188, 14189, 14190, 14191, 14192, 14193, 14194, 14195, 14196, 14197, 14198, 14199, 14200, 14201, 14202, 14203, 14204, 14205, 14206, 14207, 14208, 14209, 14210, 14211, 14212, 14213, 14214, 14215, 14216, 14217, 14218, 14219, 14220, 14221, 14222, 14223, 14224, 14225, 14226, 14227, 14228, 14229, 14230, 14231, 14232, 14233, 14234, 14235, 14236, 14237, 14238, 14239, 14240, 14241, 14242, 14243, 14244, 14245, 14246, 14247, 14248, 14249, 14250, 14251, 14252, 14253, 14254, 14255, 14256, 14257, 14258, 14259, 14260, 14261, 14262, 14263, 14264, 14265, 14266, 14267, 14268, 14269, 14270, 14271, 14272, 14273, 14274, 14275, 14276, 14277, 14278, 14279, 14280, 14281, 14282, 14283, 14284, 14285, 14286, 14287, 14288, 14289, 14290, 14291, 14292, 14293, 14294, 14295, 14296, 14297, 14298, 14299, 14300, 14301, 14302, 14303, 14304, 14305, 14306, 14307, 14308, 14309, 14310, 14311, 14312, 14313, 14314, 14315, 14316, 14317, 14318, 14319, 14320, 14321, 14322, 14323, 14324, 14325, 14326, 14327, 14328, 14329, 14330, 14331, 14332, 14333, 14334, 14335, 14336, 14337, 14338, 14339, 14340, 14341, 14342, 14343, 14344, 14345, 14346, 14347, 14348, 14349, 14350, 14351, 14352, 14353, 14354, 14355, 14356, 14357, 14358, 14359, 14360, 14361, 14362, 14363, 14364, 14365, 14366, 14367, 14368, 14369, 14370, 14371, 14372, 14373, 14374, 14375, 14376, 14377, 14378, 14379, 14380, 14381, 14382, 14383, 14384, 14385, 14386, 14387, 14388, 14389, 14390, 14391, 14392, 14393, 14394, 14395, 14396, 14397, 14398, 14399, 14400, 14401, 14402, 14403, 14404, 14405, 14406, 14407, 14408, 14409, 14410, 14411, 14412, 14413, 14414, 14415, 14416, 14417, 14418, 14419, 14420, 14421, 14422, 14423, 14424, 14425, 14426, 14427, 14428, 14429, 14430, 14431, 14432, 14433, 14434, 14435, 14436, 14437, 14438, 14439, 14440, 14441, 14442, 14443, 14444, 14445, 14446, 14447, 14448, 14449, 14450, 14451, 14452, 14453, 14454, 14455, 14456, 14457, 14458, 14459, 14460, 14461, 14462, 14463, 14464, 14465, 14466, 14638, 14639, 14640, 14641, 14642, 14643, 14644, 15177, 15178, 15179, 15180, 15181, 15182, 15183, 15184, 15185, 15186, 15187, 15188, 15189, 15190, 15191, 15192, 15193, 15194, 15195, 15196, 15197, 15198, 15199, 15200, 15201, 15202, 15203, 15204, 15205, 15206, 15207, 15208, 15209, 15210, 16627, 16628, 16629, 16630, 16631, 16632, 16633, 16634, 16635, 16636, 16637, 16638, 18244, 18245, 18246, 18247, 18437, 18438, 18439, 18440, 18690, 18691, 18692, 18693, 18694, 18695, 18696, 18697, 18698, 18699, 18700, 18701, 18702, 18703, 18704, 18705, 18706, 18707, 18708, 18709, 18710, 18711, 18712, 18713, 18714, 18715, 18716, 18717, 18718, 18719, 18720, 18721, 18722, 18723, 18724, 18725, 18726, 18727, 18728, 18729, 18730, 18731, 18732, 18733, 18734, 18735, 18736, 18737, 18738, 18739, 18740, 18741, 18742, 18743, 18744, 18745, 18746, 18747, 18748, 18749, 18750, 18751, 18752, 18753, 18754, 18755, 18756, 18757, 18758, 18759, 18760, 18761, 18762, 18763, 18764, 18765, 18766, 18767, 18768, 18769, 18770, 18771, 18772, 18773, 18774, 18775, 18776, 18777, 18778, 18779, 18780, 18781, 18782, 18783, 18784, 18785, 18786, 18787, 18788, 18789, 18790, 18791, 18792, 18793, 18794, 18795, 18796, 18797, 18798, 18799, 18800, 18801, 18802, 18803, 18804, 18805, 18806, 18807, 18808, 18809, 18810, 18811, 18812, 18813, 18814, 18815, 18816, 18817, 18818, 18819, 18820, 18821, 18822, 18823, 18824, 18825, 18826, 18827, 18828, 18829, 18830, 18831, 18832, 18833, 18834, 18835, 18836, 18837, 18838, 18839, 18840, 18841, 18842, 18843, 18844, 18845, 18846, 18847, 18848, 18849, 18850, 18851, 18852, 18853, 18854, 18855, 18856, 18857, 18858, 18859, 18860, 18861, 18862, 18863, 18864, 18865, 18866, 18867, 18868, 18869, 18870, 18871, 18872, 18873, 18874, 18875, 18876, 18877, 18878, 18879, 18880, 18881, 18882, 18883, 18884, 18885, 18886, 18887, 18888, 18889, 18890, 18891, 18892, 18893, 18894, 18895, 18896, 18897, 18898, 18899, 18900, 18901, 18902, 18903, 18904, 18905, 18906, 18907, 18908, 18909, 18910, 18911, 18912, 18913, 18914, 18915, 18916, 18917, 18918, 18919, 18920, 18921, 18922, 18923, 18924, 18925, 18926, 18927, 18928, 18929, 18930, 18931, 18932, 18933, 18934, 18935, 18936, 18937, 18938, 18939, 18940, 18941, 18942, 18943, 18944, 18945, 18946, 18947, 18948, 18949, 18950, 18951, 18952, 18953, 18954, 18955, 18956, 18957, 18958, 18959, 18960, 18961, 18962, 18963, 18964, 18965, 18966, 18967, 18968, 18969, 18970, 18971, 18972, 18973, 18974, 18975, 18976, 18977, 18978, 18979, 18980, 18981, 18982, 18983, 18984, 18985, 18986, 18987, 18988, 18989, 18990, 18991, 18992, 18993, 18994, 18995, 18996, 18997, 18998, 18999, 19000, 19001, 19002, 19003, 19004, 19005, 19006, 19007, 19008, 19009, 19010, 19011, 19012, 19013, 19014, 19015, 19016, 19017, 19018, 19019, 19020, 19021, 19022, 19023, 19024, 19025, 19026, 19027, 19028, 19029, 19030, 19031, 19032, 19033, 19034, 19035, 19036, 19037, 19038, 19039, 19040, 19041, 19042, 19043, 19044, 19045, 19046, 19047, 19048, 19049, 19050, 19051, 19052, 19053, 19054, 19055, 19056, 19057, 19058, 19059, 19060, 19061, 19062, 19063, 19064, 19065, 19066, 19067, 19068, 19069, 19070, 19071, 19072, 19073, 19074, 19075, 19076, 19077, 19078, 19079, 19080, 19081, 19082, 19083, 19084, 19085, 19086, 19087, 19088, 19089, 19090, 19091, 19092, 19093, 19094, 19095, 19096, 19097, 19098, 19099, 19100, 19101, 19102, 19103, 19104, 19105, 19106, 19107, 19108, 19109, 19110, 19111, 19112, 19113, 19114, 19115, 19116, 19117, 19118, 19119, 19120, 19121, 19122, 19123, 19124, 19125, 19126, 19127, 19128, 19129, 19130, 19131, 19132, 19133, 19134, 19135, 19136, 19137, 20368, 20369, 20370, 20371, 20372, 20373, 20374, 20375, 20376, 20377, 20378, 20379, 20380, 20381, 20382, 20383, 20384, 20385, 20386, 20387, 20388, 20389, 20390, 20391, 20392, 20393, 20394, 20395, 20396, 20397, 20398, 20399, 20400, 20401, 20402, 20403, 20404, 20405, 20406, 20407, 20408, 20409, 20410, 20411, 20412, 20413, 20414, 20415, 20416, 20417, 20418, 20419, 20420, 20421, 20422, 20423, 20424, 20425, 20426, 20427, 20428, 20429, 20430, 20431, 20432, 20433, 20434, 20435, 20436, 20437, 20438, 20439, 21259, 21260, 21261, 21262, 21263, 21264, 21265, 21266, 21267, 21268, 21269, 21270, 21271, 21272, 21273, 21274, 21275, 21276, 21277, 21278, 21279, 21280, 21281, 21282, 21283, 21284, 21285, 21286, 21287, 21288, 21289, 21290, 21291, 21292, 21293, 21294, 21295, 21296, 21297, 21298, 21299, 21300, 21301, 21302, 21303, 21304, 21305, 21306, 21307, 21308, 21309, 21310, 21311, 21312, 21313, 21451, 21452, 21453, 21454, 21455, 21456, 21457, 21458, 21459, 21460, 21461, 21462, 21463, 21464, 21465, 21466, 21467, 21468, 21469, 21470, 21471, 21472, 21473, 21474, 21475, 21476, 21477, 21478, 21479, 21480, 21481, 21482, 21483, 21667, 21668, 21669, 21670, 21671, 21672, 21673, 21674, 21675, 21676, 21677, 21678, 21679, 21680, 21681, 21682, 21683, 21684, 21685, 21686, 21687, 21688, 21689, 21690, 21691, 21692, 21693, 21694, 21695, 21696, 21697, 21698, 21699, 21700, 21701, 21702, 21703, 21704, 21705, 21706, 21707, 21708, 21709, 21710, 21711, 21712, 21713, 21714, 21715, 21716, 21717, 21718, 21719, 21720, 21721, 21722, 21942, 21943, 21944, 21945, 21946, 21947, 21948, 21949, 21950, 21951, 21952, 21953, 21954, 21955, 21956, 21957, 21958, 21959, 21960, 21961, 21962, 21963, 21964, 21965, 21966, 21967, 21968, 21969, 21970, 21971, 21972, 21973, 21974, 21975, 21976, 21977, 21978, 21979, 21980, 21981, 21982, 21983, 21984, 21985, 21986, 21987, 21988, 21989, 21990, 21991, 21992, 21993, 21994, 21995, 21996, 21997, 21998, 21999, 22000, 22001, 22002, 22003, 22004, 22005, 22006, 22007, 22326, 22327, 22328, 22329, 22330, 22331, 22332, 22333, 22334, 22335, 23224, 23225, 23226, 23227, 23228, 23229, 23230, 23231, 23232, 23233, 23234, 23235, 23236, 23237, 23238, 23239, 23240, 23241, 23242, 23243, 23244, 23245, 23246, 23247, 23248, 23249, 23250, 23251, 23252, 23253, 23254, 23255, 23256, 23257, 23258, 23259, 23260, 23261, 23262, 23263, 23264, 23265, 23266, 23267, 23268, 23269, 23270, 23271, 23272, 23273, 23274, 23275, 23276, 23277, 23278, 23279, 23280, 23281, 23282, 23283, 23284, 23285, 23286, 23287, 23288, 23289, 23290, 23291, 23292, 23293, 23294, 23295, 23296, 23297, 23298, 23299, 23300, 23301, 23302, 23303, 23304, 23305, 23306, 23307, 23308, 23309, 23310, 23311, 23312, 23313, 23314, 23315, 23316, 23317, 23318, 23319, 23320, 23321, 23322, 23323, 23324, 23325, 23326, 23327, 23328, 23329, 23330, 23331, 23332, 23333, 23334, 23335, 23336, 23337, 23338, 23339, 23340, 23341, 23342, 23343, 23344, 23345, 23346, 23347, 23348, 23349, 23350, 23351, 23352, 23353, 23354, 23355, 23356, 23357, 23358, 23359, 23360, 23361, 23362, 23363, 23364, 23365, 23366, 23367, 23368, 23369, 23370, 23371, 23372, 23373, 23374, 23375, 23376, 23377, 23378, 23379, 23380, 23381, 23382, 23383, 23384, 23385, 23386, 23387, 23388, 23389, 23390, 23391, 23392, 23393, 23394, 23395, 23396, 23397, 23398, 23399, 23400, 23401, 23402, 23403, 23404, 23405, 23406, 23407, 23408, 23409, 23410, 23411, 23412, 23413, 23414, 23415, 23416, 23417, 23418, 23419, 23420, 23421, 23422, 23423, 23424, 23425, 23426, 23427, 23428, 23429, 23430, 23431, 23432, 23433, 23434, 23435, 23436, 23437, 23438, 23439, 23550, 23551, 23552, 23553, 23554, 23555, 23556, 23557, 23558, 23559, 23560, 23561, 23562, 23563, 23564, 23565, 23566, 23567, 23568, 23569, 23570, 23571, 23572, 23573, 23574, 23575, 23576, 23577, 23578, 23579, 23580, 23581, 23582, 23583, 23584, 23585, 23586, 23587, 23588, 23589, 23590, 23591, 23592, 23593, 23594, 23595, 23596, 23597, 23598, 23599, 23600, 23601, 23602, 23603, 23604, 23605, 23606, 23607, 23608, 23609, 23610, 23611, 23612, 23613, 23614, 23615, 23616, 23617, 23618, 23619, 23620, 23621, 23622, 23623, 23624, 23625, 23626, 23627, 23628, 23629, 23630, 23631, 23632, 23633, 23634, 23635, 23636, 23637, 23638, 23639, 23640, 23641, 23642, 23643, 23644, 23645, 23646, 23647, 23648, 23649, 23650, 23651, 23652, 23653, 23654, 23655, 23656, 23657, 23658, 23659, 23660, 23661, 23662, 23663, 23664, 23665, 23666, 23667, 23668, 23669, 23670, 23671, 23672, 23673, 23674, 23675, 23676, 23677, 23678, 23679, 23680, 23681, 23682, 23683, 23684, 23685, 23686, 23687, 23688, 23689, 23690, 23691, 23692, 23693, 23694, 23695, 23801, 23802, 23803, 23804, 23805, 23806, 23807, 23808, 23809, 23810, 23811, 23812, 23813, 23814, 23815, 23816, 23817, 23818, 23819, 23820, 23821, 23822, 23823, 23824, 23825, 23826, 23827, 23828, 23829, 23830, 23831, 23832, 23833, 23834, 23835, 23836, 23837, 23838, 23839, 23840, 23841, 23842, 23843, 23844, 23845, 23846, 23847, 23848, 23849, 23850, 23851, 23852, 23853, 23854, 23855, 23856, 23857, 23858, 23859, 23860, 23861, 23862, 23863, 23864, 23865, 23866, 23867, 23868, 23869, 23870, 23871, 23872, 23873, 23874, 23875, 23876, 23877, 23878, 23879, 23880, 23881, 23882, 23883, 23884, 23885, 23886, 23887, 23888, 23889, 23890, 23891, 23892, 23893, 23894, 23895, 23896, 23897, 23898, 23899, 23900, 23901, 23902, 23903, 23904, 23905, 23906, 23907, 23908, 23909, 23910, 23911, 23912, 23913, 23914, 23915, 23916, 23917, 23918, 23919, 23920, 23921, 23922, 23923, 23924, 23925, 23926, 23927, 23928, 23929, 23930, 23931, 23932, 23933, 23934, 23935, 23936, 23937, 23938, 23939, 23940, 23941, 23942, 23943, 23944, 23945, 23946, 23947, 23948, 23949, 23950, 23951, 23952, 23953, 23954, 23955, 23956, 23957, 23958, 23959, 23960, 23961, 23962, 23963, 23964, 23965, 23966, 23967, 23968, 23969, 23970, 23971, 23972, 23973, 23974, 23975, 23976, 23977, 23978, 23979, 23980, 23981, 23982, 23983, 23984, 23985, 23986, 23987, 23988, 23989, 23990, 23991, 23992, 23993, 23994, 23995, 23996, 23997, 23998, 23999, 24000, 24001, 24002, 24374, 24375, 24376, 24377, 24378, 24379, 24380, 24381, 24382, 24383, 24384, 24385, 24403, 24404, 24405, 24406, 24407, 24408, 24409, 24410, 24411, 24412, 24413, 28157, 28158, 28159, 28160, 28161, 28162, 28163, 28164, 28165, 28166, 28167, 28168, 28169, 28170, 28171, 28172, 28173, 28174, 28175, 28176, 28177, 28178, 28179, 28180, 28181, 28182, 28183, 28184, 28185, 28186, 28187, 28188, 28189, 28190, 28191, 28192, 28193, 28194, 28195, 28196, 28197, 28198, 28199, 28200, 28201, 28202, 28203, 28204, 28205, 28206, 28207, 28208, 28209, 28210, 28211, 28212, 28213, 28214, 28215, 28216, 28217, 28218, 28219, 28220, 28221, 28222, 28223, 28224, 28225, 28226, 28227, 28228, 28229, 28230, 28231, 28232, 28233, 28234, 28235, 28236, 28237, 28238, 28239, 28240, 28241, 28242, 28243, 28244, 28245, 28246, 28247, 28248, 28249, 28250, 28251, 28252, 28253, 28254, 28255, 28256, 28257, 28258, 28259, 28260, 28261, 28262, 28263, 28264, 28265, 28266, 28267, 28268, 28269, 28270, 28271, 28272, 28273, 28274, 28275, 28276, 28277, 28278, 28279, 28280, 28281, 28282, 28283, 28284, 28285, 28286, 28287, 28288, 28289, 28290, 28291, 28292, 28293, 28294, 28295, 28296, 28297, 28298, 28299, 28300, 28301, 28302, 28303, 28304, 28305, 28306, 28307, 28308, 28309, 28310, 28311, 28312, 28313, 28314, 28315, 28316, 28317, 28318, 28319, 28320, 28321, 28322, 28323, 28324, 28325, 28326, 28327, 28328, 28329, 28330, 28331, 28332, 28333, 28334, 28335, 28336, 28337, 28338, 28339, 28340, 28341, 28342, 28343, 28344, 28345, 28346, 28347, 28348, 28349, 28350, 28351, 28352, 28353, 28354, 28355, 28356, 28357, 28358, 28359, 28360, 28361, 28362, 28363, 28364, 28365, 28366]\n",
      "[7616, 7617, 7618, 7619, 16207, 16208, 16209, 16210, 16782, 16783, 16784, 16785, 16854, 16855, 16856, 16857, 17166, 17167, 17168, 17169, 17286, 17287, 17288, 17289, 19110, 19111, 19112, 19113, 19114, 19115, 19182, 19183, 19184, 19185, 19881, 19882, 19883, 19884, 28663, 28664, 28665, 28666]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Axes: title={'center': 'Target C Clean'}, xlabel='time'>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 2000x1000 with 6 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def fix_y_holes(y: pd.DataFrame) -> pd.DataFrame:\n",
    "    Y = y\n",
    "    drop_val = None\n",
    "    index_dropper = []\n",
    "    for i in range(1, len(Y)-4): # Since we match on 4 consecutive values.\n",
    "        if Y['pv_measurement'].iloc[i] != 0:\n",
    "            if (Y['pv_measurement'].iloc[i] == Y['pv_measurement'].iloc[i+1] and Y['pv_measurement'].iloc[i+1] == Y['pv_measurement'].iloc[i+2] and Y['pv_measurement'].iloc[i+2] == Y['pv_measurement'].iloc[i+3]):\n",
    "                drop_val = Y['pv_measurement'].iloc[i]\n",
    "        if Y['pv_measurement'].iloc[i] == drop_val:\n",
    "            index_dropper.append(i)\n",
    "        else:\n",
    "            if drop_val != None:\n",
    "                drop_val = None\n",
    "    print(index_dropper)\n",
    "    return Y.drop(index_dropper)\n",
    "    \n",
    "import matplotlib.pylab as plt\n",
    "fig, axs = plt.subplots(6, 1, figsize=(20, 10), sharex=True)\n",
    "YA[['time', 'pv_measurement']].set_index('time').plot(ax=axs[0], title='Target A', color='red')\n",
    "YB[['time', 'pv_measurement']].set_index('time').plot(ax=axs[1], title='Target B', color='red')\n",
    "YC[['time', 'pv_measurement']].set_index('time').plot(ax=axs[2], title='Target C', color='red')\n",
    "\n",
    "\n",
    "YA = fix_y_holes(YA)\n",
    "YB = fix_y_holes(YB)\n",
    "YC = fix_y_holes(YC)\n",
    "\n",
    "YA[['time', 'pv_measurement']].set_index('time').plot(ax=axs[3], title='Target A Clean', color='blue')\n",
    "YB[['time', 'pv_measurement']].set_index('time').plot(ax=axs[4], title='Target B Clean', color='blue')\n",
    "YC[['time', 'pv_measurement']].set_index('time').plot(ax=axs[5], title='Target C Clean', color='blue')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Aggregation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# making shure that target values line up with x_values\n",
    "import data_func.aggregation as data_agg\n",
    "\n",
    "categorical_col = ['dew_or_rime:idx', 'precip_type_5min:idx', 'is_day:idx', 'is_in_shadow:idx']\n",
    "\n",
    "def aggregate_correct_x(x: pd.DataFrame) -> pd.DataFrame:\n",
    "   '''\n",
    "   Takes a given dataframe and returns an aggregated dataframe based on selected categorical functions. \n",
    "   Assumes grouping of 4.\n",
    "   '''\n",
    "   categorical = x[[\"date_forecast\"] + categorical_col]\n",
    "   mean = x.drop(columns=categorical_col)\n",
    "\n",
    "   categorical = data_agg.gen_agg(categorical, agg_type=data_agg.stocastic_median, merge_on = 'first')\n",
    "   mean = data_agg.gen_agg(mean, \"mean\", merge_on = 'first')\n",
    "\n",
    "   return pd.merge(categorical, mean, on=\"date_forecast\")\n",
    "\n",
    "def data_allign(x_train, y_train):\n",
    "\n",
    "  y_train.dropna(inplace=True)\n",
    "  x_train = aggregate_correct_x(x_train)\n",
    "  combined_data = pd.merge(x_train, y_train, left_on='date_forecast', right_on='time')\n",
    "  y_train = combined_data['pv_measurement']\n",
    "\n",
    "  if 'time' and 'pv_measurement' in combined_data.columns:\n",
    "    combined_data.drop(columns=['time', 'pv_measurement'], inplace=True)\n",
    "    \n",
    "  return combined_data, y_train\n",
    "\n",
    "X_train = [XTRA, XTRB, XTRC]\n",
    "Y_train = [YA, YB, YC]\n",
    "\n",
    "for i in range(len(X_train)):\n",
    "    X_train[i], Y_train[i] = data_allign(X_train[i], Y_train[i])\n",
    "\n",
    "for j in range(len(X_frames_test)):\n",
    "    X_frames_test[j] = aggregate_correct_x(X_frames_test[j])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x,y:  34060 34060\n",
      "x,y:  29596 29596\n",
      "x,y:  26028 26028\n"
     ]
    }
   ],
   "source": [
    "#Verify length matches\n",
    "for x in range(len(X_train)):\n",
    "    print(\"x,y: \", len(X_train[x]), len(Y_train[x]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34055   2023-04-30 19:00:00\n",
      "34056   2023-04-30 20:00:00\n",
      "34057   2023-04-30 21:00:00\n",
      "34058   2023-04-30 22:00:00\n",
      "34059   2023-04-30 23:00:00\n",
      "Name: date_forecast, dtype: datetime64[us]\n",
      "29591   2023-04-30 19:00:00\n",
      "29592   2023-04-30 20:00:00\n",
      "29593   2023-04-30 21:00:00\n",
      "29594   2023-04-30 22:00:00\n",
      "29595   2023-04-30 23:00:00\n",
      "Name: date_forecast, dtype: datetime64[us]\n",
      "26023   2023-04-30 19:00:00\n",
      "26024   2023-04-30 20:00:00\n",
      "26025   2023-04-30 21:00:00\n",
      "26026   2023-04-30 22:00:00\n",
      "26027   2023-04-30 23:00:00\n",
      "Name: date_forecast, dtype: datetime64[us]\n"
     ]
    }
   ],
   "source": [
    "# Verifying that all train dataset still have their end data after aggregation in case of allignment issue\n",
    "for x in X_train:\n",
    "    print(x[\"date_forecast\"].tail())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import data_func.timeseasonality as DTS\n",
    "import data_func.one_hot_encoding as OHE\n",
    "for i in range(len(X_train)):\n",
    "    X_train[i] = DTS.append_seasonal_columns(X_train[i])\n",
    "    \n",
    "\n",
    "for i in range(len(X_frames_test)):\n",
    "    X_frames_test[i] = DTS.append_seasonal_columns(X_frames_test[i])\n",
    "    \n",
    "\n",
    "# THIS SECTION CAN ONLY WORK IF THE PREVIOUS AGGREGATION IS DONE INDIVIDUALLY FOR CATEGORICAL DATA\n",
    "# import data_func.one_hot_encoding as OHE\n",
    "\n",
    "def fix_categorical(train: pd.DataFrame, test: pd.DataFrame):\n",
    "     temp = pd.concat((train, test), ignore_index=True)\n",
    "     index_train = temp[(temp['date_forecast'] < test['date_forecast'].iloc[0])].index\n",
    "     return temp.drop(index_train)\n",
    "\n",
    "OH_columns = ['dew_or_rime:idx', 'precip_type_5min:idx']\n",
    "\n",
    "for i in range(len(X_frames_test)):\n",
    "     X_train[i] = OHE.one_hot_encode(X_train[i],OH_columns)\n",
    "     X_frames_test[i] = OHE.one_hot_encode(X_frames_test[i], OH_columns)\n",
    "     X_frames_test[i] = fix_categorical(X_train[i], X_frames_test[i])\n",
    "     X_train[i].drop(columns=['date_forecast'], inplace=True)\n",
    "     X_frames_test[i].drop(columns=['date_forecast'], inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Multiplying effective cloud coverage with clear sky radiation\n",
    "from data_func.feature_engineering.combine import multiply_columns\n",
    "\n",
    "def flip_percent(x):\n",
    "    return (x-100)*-1\n",
    "\n",
    "for i in range(len(X_train)):\n",
    "    A = X_train[i]['effective_cloud_cover:p'].apply(flip_percent)\n",
    "    B = X_train[i]['clear_sky_energy_1h:J']\n",
    "    AT = X_frames_test[i]['effective_cloud_cover:p'].apply(flip_percent)\n",
    "    BT = X_frames_test[i]['clear_sky_energy_1h:J']\n",
    "\n",
    "    X_train[i]['COMB_clear_sky_energy_X_eff_cloud_cover'] = multiply_columns(A, B)\n",
    "    X_frames_test[i]['COMB_clear_sky_energy_X_eff_cloud_cover'] =  multiply_columns(AT, BT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A</th>\n",
       "      <th>B</th>\n",
       "      <th>C</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>ceiling_height_agl:m</th>\n",
       "      <td>6126</td>\n",
       "      <td>4588</td>\n",
       "      <td>5122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cloud_base_agl:m</th>\n",
       "      <td>2362</td>\n",
       "      <td>2025</td>\n",
       "      <td>2199</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>snow_density:kgm3</th>\n",
       "      <td>32920</td>\n",
       "      <td>28040</td>\n",
       "      <td>24561</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          A      B      C\n",
       "ceiling_height_agl:m   6126   4588   5122\n",
       "cloud_base_agl:m       2362   2025   2199\n",
       "snow_density:kgm3     32920  28040  24561"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Show null values for all training sets\n",
    "\n",
    "count_a = X_train[0].isna().sum()\n",
    "count_b = X_train[1].isna().sum()\n",
    "count_c = X_train[2].isna().sum()\n",
    "\n",
    "count_a.rename(\"A\", inplace=True)\n",
    "count_b.rename(\"B\", inplace=True)\n",
    "count_c.rename(\"C\", inplace=True)\n",
    "\n",
    "df = pd.merge(count_a, count_b, left_index=True, right_index=True)\n",
    "df = pd.merge(df, count_c, left_index=True, right_index=True)\n",
    "\n",
    "df[(df['A'] != 0) | (df['B'] != 0) | (df['C'] != 0)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A</th>\n",
       "      <th>B</th>\n",
       "      <th>C</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>ceiling_height_agl:m</th>\n",
       "      <td>188</td>\n",
       "      <td>180</td>\n",
       "      <td>202</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cloud_base_agl:m</th>\n",
       "      <td>70</td>\n",
       "      <td>65</td>\n",
       "      <td>88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>snow_density:kgm3</th>\n",
       "      <td>720</td>\n",
       "      <td>720</td>\n",
       "      <td>720</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dew_or_rime:idx_-1</th>\n",
       "      <td>720</td>\n",
       "      <td>720</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>precip_type_5min:idx_2</th>\n",
       "      <td>720</td>\n",
       "      <td>720</td>\n",
       "      <td>720</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>precip_type_5min:idx_3</th>\n",
       "      <td>720</td>\n",
       "      <td>720</td>\n",
       "      <td>720</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>precip_type_5min:idx_5</th>\n",
       "      <td>720</td>\n",
       "      <td>720</td>\n",
       "      <td>720</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          A    B    C\n",
       "ceiling_height_agl:m    188  180  202\n",
       "cloud_base_agl:m         70   65   88\n",
       "snow_density:kgm3       720  720  720\n",
       "dew_or_rime:idx_-1      720  720    0\n",
       "precip_type_5min:idx_2  720  720  720\n",
       "precip_type_5min:idx_3  720  720  720\n",
       "precip_type_5min:idx_5  720  720  720"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Show null values for all test sets\n",
    "\n",
    "count_a = X_frames_test[0].isna().sum()\n",
    "count_b = X_frames_test[1].isna().sum()\n",
    "count_c = X_frames_test[2].isna().sum()\n",
    "\n",
    "count_a.rename(\"A\", inplace=True)\n",
    "count_b.rename(\"B\", inplace=True)\n",
    "count_c.rename(\"C\", inplace=True)\n",
    "\n",
    "df = pd.merge(count_a, count_b, left_index=True, right_index=True)\n",
    "df = pd.merge(df, count_c, left_index=True, right_index=True)\n",
    "\n",
    "df[(df['A'] != 0) | (df['B'] != 0) | (df['C'] != 0)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removes nan or fills it\n",
    "values = {\"ceiling_height_agl:m\": 20000, \"cloud_base_agl:m\": 20000}\n",
    "\n",
    "for i in range(len(X_train)):\n",
    "    X_train[i].drop(columns=['snow_density:kgm3', 'elevation:m'], inplace=True)\n",
    "    X_frames_test[i].drop(columns=['snow_density:kgm3', 'elevation:m'], inplace=True)\n",
    "    X_train[i].fillna(value=values, inplace=True)\n",
    "    X_frames_test[i].fillna(value=values, inplace=True)\n",
    "    X_frames_test[i].fillna(0, inplace=True) # fills remaining NaN vals with 0, (specifically for one-hot encoded columns with NaN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "drop_cols_a = [\n",
    "    #\"fresh_snow_12h:cm\", \n",
    "    #\"fresh_snow_1h:cm\",\n",
    "    #\"fresh_snow_24h:cm\",\n",
    "    #\"fresh_snow_3h:cm\",\n",
    "    #\"fresh_snow_6h:cm\",\n",
    "    #\"snow_drift:idx\",\n",
    "    #\"snow_depth:cm\",\n",
    "    #\"snow_melt_10min:mm\",\n",
    "    #\"snow_water:kgm2\"\n",
    "]\n",
    "\n",
    "#X_train[0].drop(columns=drop_cols_a, inplace=True)\n",
    "#X_frames_test[0].drop(columns=drop_cols_a, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data_func.combine_all_frames import combine_all_frames\n",
    "B=X_train[1].__deepcopy__()\n",
    "C=X_train[2].__deepcopy__()\n",
    "X_train_BC = combine_all_frames([B, C])\n",
    "YB = Y_train[1].__deepcopy__()\n",
    "YC = Y_train[2].__deepcopy__()\n",
    "Y_train_BC = pd.concat([YB, YC])\n",
    "Y_train_BC.reset_index(drop=True)\n",
    "X_frames_test = combine_all_frames([X_frames_test[1], X_frames_test[2]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import autokeras as ak"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_a, x_val_a, y_train_a, y_val_a = train_test_split(X_train[0], Y_train[0], test_size=0.17, random_state=42)\n",
    "x_train_b, x_val_b, y_train_b, y_val_b = train_test_split(X_train[1], Y_train[1], test_size=0.17, random_state=42)\n",
    "x_train_c, x_val_c, y_train_c, y_val_c = train_test_split(X_train[2], Y_train[2], test_size=0.17, random_state=42)\n",
    "x_train_bc, x_val_bc, y_train_bc, y_val_bc = train_test_split(X_train_BC, Y_train_BC, test_size=0.17, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First example: [[    0.       1.       7.7      1.23  1728.95     0.       0.    1728.95\n",
      "    280.3      0.       0.       0.       0.      99.07     0.       0.\n",
      "      0.       0.       0.    1006.3      0.     993.75   999.78     0.\n",
      "      0.      71.67  1005.8      0.       0.       0.       0.17   348.04\n",
      "     -3.77     0.     286.23   100.   40386.48     3.6     -3.57    -0.5\n",
      "      0.      -0.5      0.87     0.49    -0.87     0.       1.       0.\n",
      "      1.       0.       0.       0.       0.       0.  ]]\n",
      "\n",
      "Normalized: [[-0.97  0.95  0.49 -0.67 -0.62 -0.65 -0.65 -0.26  0.63 -0.67 -0.68 -0.46\n",
      "  -0.46  0.93 -0.15 -0.09 -0.19 -0.1  -0.12 -0.26 -0.2  -0.23 -0.24 -0.08\n",
      "  -0.25 -0.17 -0.25 -0.16  0.   -0.05  0.36  1.72 -0.15 -0.54  0.94  0.77\n",
      "   0.44  0.3  -1.46 -0.58 -0.01 -0.71  1.22  0.71 -1.25 -0.09  0.19 -0.17\n",
      "   0.24 -0.21 -0.07 -0.08 -0.01 -0.42]]\n"
     ]
    }
   ],
   "source": [
    "normalizer_A = tf.keras.layers.Normalization(axis=-1)\n",
    "normalizer_A.adapt(X_train[0])\n",
    "\n",
    "first = np.array(X_train[0][:1])\n",
    "\n",
    "with np.printoptions(precision=2, suppress=True):\n",
    "  print('First example:', first)\n",
    "  print()\n",
    "  print('Normalized:', normalizer_A(first).numpy())\n",
    "\n",
    "normalizer_B = tf.keras.layers.Normalization(axis=-1)\n",
    "normalizer_B.adapt(X_train[1])\n",
    "normalizer_C = tf.keras.layers.Normalization(axis=-1)\n",
    "normalizer_C.adapt(X_train[2])\n",
    "normalizer_BC = tf.keras.layers.Normalization(axis=-1)\n",
    "normalizer_BC.adapt(X_train_BC)\n",
    "\n",
    "early_stop = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "707/707 [==============================] - 1s 2ms/step - loss: 543091.2500 - mae: 335.6893 - mse: 543091.2500 - val_loss: 228199.1875 - val_mae: 234.2713 - val_mse: 228199.1875\n",
      "Epoch 2/1000\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 313252.4375 - mae: 266.3782 - mse: 313252.4375 - val_loss: 217488.1406 - val_mae: 223.4828 - val_mse: 217488.1406\n",
      "Epoch 3/1000\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 316214.1562 - mae: 264.6230 - mse: 316214.1562 - val_loss: 216796.5312 - val_mae: 220.9109 - val_mse: 216796.5312\n",
      "Epoch 4/1000\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 302704.0000 - mae: 259.8214 - mse: 302704.0000 - val_loss: 225230.1719 - val_mae: 225.1677 - val_mse: 225230.1719\n",
      "Epoch 5/1000\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 297787.3438 - mae: 259.0414 - mse: 297787.3438 - val_loss: 215727.0938 - val_mae: 220.4341 - val_mse: 215727.0938\n",
      "Epoch 6/1000\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 290561.4062 - mae: 254.5743 - mse: 290561.4062 - val_loss: 207873.6250 - val_mae: 213.2044 - val_mse: 207873.6250\n",
      "Epoch 7/1000\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 283471.9062 - mae: 250.4375 - mse: 283471.9062 - val_loss: 212723.0469 - val_mae: 214.2865 - val_mse: 212723.0469\n",
      "Epoch 8/1000\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 287059.4062 - mae: 249.6860 - mse: 287059.4062 - val_loss: 208501.9062 - val_mae: 212.3004 - val_mse: 208501.9062\n",
      "Epoch 9/1000\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 278994.1875 - mae: 246.4322 - mse: 278994.1875 - val_loss: 203379.4062 - val_mae: 206.3798 - val_mse: 203379.4062\n",
      "Epoch 10/1000\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 283512.7812 - mae: 246.0245 - mse: 283512.7812 - val_loss: 214875.1406 - val_mae: 212.2565 - val_mse: 214875.1406\n",
      "Epoch 11/1000\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 281810.0625 - mae: 246.0960 - mse: 281810.0625 - val_loss: 213736.0000 - val_mae: 211.5139 - val_mse: 213736.0000\n",
      "Epoch 12/1000\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 283157.1562 - mae: 243.8705 - mse: 283157.1562 - val_loss: 209492.8281 - val_mae: 208.9963 - val_mse: 209492.8281\n",
      "Epoch 13/1000\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 289088.3125 - mae: 246.9611 - mse: 289088.3125 - val_loss: 199057.3125 - val_mae: 202.6883 - val_mse: 199057.3125\n",
      "Epoch 14/1000\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 281986.6875 - mae: 244.4752 - mse: 281986.6875 - val_loss: 205341.0156 - val_mae: 204.6910 - val_mse: 205341.0156\n",
      "Epoch 15/1000\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 275609.1875 - mae: 242.6597 - mse: 275609.1875 - val_loss: 199194.0312 - val_mae: 201.3882 - val_mse: 199194.0312\n",
      "Epoch 16/1000\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 277023.8438 - mae: 242.8044 - mse: 277023.8438 - val_loss: 203726.5625 - val_mae: 206.4107 - val_mse: 203726.5625\n",
      "Epoch 17/1000\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 272282.0312 - mae: 239.9400 - mse: 272282.0312 - val_loss: 205172.3906 - val_mae: 205.4508 - val_mse: 205172.3906\n",
      "Epoch 18/1000\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 279555.5312 - mae: 241.3119 - mse: 279555.5312 - val_loss: 199640.1562 - val_mae: 200.8079 - val_mse: 199640.1562\n",
      "Epoch 19/1000\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 275516.2500 - mae: 241.1517 - mse: 275516.2500 - val_loss: 199707.4844 - val_mae: 201.6492 - val_mse: 199707.4844\n",
      "Epoch 20/1000\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 273340.8125 - mae: 241.4845 - mse: 273340.8125 - val_loss: 201822.3594 - val_mae: 200.8668 - val_mse: 201822.3594\n",
      "Epoch 21/1000\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 275619.7812 - mae: 240.7074 - mse: 275619.7812 - val_loss: 208885.7031 - val_mae: 207.5418 - val_mse: 208885.7031\n",
      "Epoch 22/1000\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 277854.6875 - mae: 241.3710 - mse: 277854.6875 - val_loss: 204940.5000 - val_mae: 206.3322 - val_mse: 204940.5000\n",
      "Epoch 23/1000\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 279594.4688 - mae: 241.5504 - mse: 279594.4688 - val_loss: 197612.9531 - val_mae: 199.8543 - val_mse: 197612.9531\n",
      "Epoch 24/1000\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 274167.5312 - mae: 241.1790 - mse: 274167.5312 - val_loss: 197192.7344 - val_mae: 199.8864 - val_mse: 197192.7344\n",
      "Epoch 25/1000\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 275772.0938 - mae: 240.9475 - mse: 275772.0938 - val_loss: 198869.0781 - val_mae: 200.1879 - val_mse: 198869.0781\n",
      "Epoch 26/1000\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 272212.8750 - mae: 240.2817 - mse: 272212.8750 - val_loss: 195413.6406 - val_mae: 196.7804 - val_mse: 195413.6406\n",
      "Epoch 27/1000\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 280033.4062 - mae: 241.9162 - mse: 280033.4062 - val_loss: 200865.8906 - val_mae: 202.9350 - val_mse: 200865.8906\n",
      "Epoch 28/1000\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 275461.8125 - mae: 241.0399 - mse: 275461.8125 - val_loss: 196901.8281 - val_mae: 199.9935 - val_mse: 196901.8281\n",
      "Epoch 29/1000\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 270366.2812 - mae: 238.4044 - mse: 270366.2812 - val_loss: 196451.0469 - val_mae: 200.4222 - val_mse: 196451.0469\n",
      "Epoch 30/1000\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 274832.6250 - mae: 240.6883 - mse: 274832.6250 - val_loss: 194728.3906 - val_mae: 198.4714 - val_mse: 194728.3906\n",
      "Epoch 31/1000\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 274558.5000 - mae: 241.1283 - mse: 274558.5000 - val_loss: 196226.4062 - val_mae: 197.4507 - val_mse: 196226.4062\n",
      "Epoch 32/1000\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 279059.0312 - mae: 240.9052 - mse: 279059.0312 - val_loss: 197099.5312 - val_mae: 199.9911 - val_mse: 197099.5312\n",
      "Epoch 33/1000\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 282744.6250 - mae: 243.0411 - mse: 282744.6250 - val_loss: 194129.4375 - val_mae: 201.4101 - val_mse: 194129.4375\n",
      "Epoch 34/1000\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 274737.9062 - mae: 240.9127 - mse: 274737.9062 - val_loss: 194508.6250 - val_mae: 195.6354 - val_mse: 194508.6250\n",
      "Epoch 35/1000\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 268119.0312 - mae: 238.0988 - mse: 268119.0312 - val_loss: 198886.9219 - val_mae: 203.3369 - val_mse: 198886.9219\n",
      "Epoch 36/1000\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 276547.0625 - mae: 240.8575 - mse: 276547.0625 - val_loss: 201440.1406 - val_mae: 206.6475 - val_mse: 201440.1406\n",
      "Epoch 37/1000\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 272264.0938 - mae: 239.5314 - mse: 272264.0938 - val_loss: 194222.4062 - val_mae: 199.6888 - val_mse: 194222.4062\n",
      "Epoch 38/1000\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 276104.4062 - mae: 242.0393 - mse: 276104.4062 - val_loss: 201078.6250 - val_mae: 205.4050 - val_mse: 201078.6250\n",
      "Epoch 39/1000\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 263939.4375 - mae: 236.3563 - mse: 263939.4375 - val_loss: 204446.4531 - val_mae: 206.9664 - val_mse: 204446.4531\n",
      "Epoch 40/1000\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 276667.9062 - mae: 240.3702 - mse: 276667.9062 - val_loss: 191691.9688 - val_mae: 197.5783 - val_mse: 191691.9688\n",
      "Epoch 41/1000\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 273221.1875 - mae: 239.3884 - mse: 273221.1875 - val_loss: 193371.6406 - val_mae: 200.0651 - val_mse: 193371.6406\n",
      "Epoch 42/1000\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 270623.5938 - mae: 238.7471 - mse: 270623.5938 - val_loss: 192210.7500 - val_mae: 198.0415 - val_mse: 192210.7500\n",
      "Epoch 43/1000\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 267596.7812 - mae: 237.3351 - mse: 267596.7812 - val_loss: 196079.3906 - val_mae: 201.0596 - val_mse: 196079.3906\n",
      "Epoch 44/1000\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 270386.6562 - mae: 237.6732 - mse: 270386.6562 - val_loss: 195615.5312 - val_mae: 204.1235 - val_mse: 195615.5312\n",
      "Epoch 45/1000\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 271642.1875 - mae: 239.4490 - mse: 271642.1875 - val_loss: 196362.2031 - val_mae: 198.9543 - val_mse: 196362.2031\n",
      "Epoch 46/1000\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 276502.3750 - mae: 240.8742 - mse: 276502.3750 - val_loss: 198394.0000 - val_mae: 205.6893 - val_mse: 198394.0000\n",
      "Epoch 47/1000\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 282504.2188 - mae: 243.6673 - mse: 282504.2188 - val_loss: 195502.3594 - val_mae: 201.0806 - val_mse: 195502.3594\n",
      "Epoch 48/1000\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 272844.3750 - mae: 239.3573 - mse: 272844.3750 - val_loss: 196152.1250 - val_mae: 198.5291 - val_mse: 196152.1250\n",
      "Epoch 49/1000\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 264893.2812 - mae: 236.4760 - mse: 264893.2812 - val_loss: 198219.5625 - val_mae: 205.2075 - val_mse: 198219.5625\n",
      "Epoch 50/1000\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 269886.9688 - mae: 239.1534 - mse: 269886.9688 - val_loss: 205428.3906 - val_mae: 206.2418 - val_mse: 205428.3906\n",
      "Epoch 51/1000\n",
      "707/707 [==============================] - 1s 2ms/step - loss: 272677.6250 - mae: 238.6864 - mse: 272677.6250 - val_loss: 207048.8281 - val_mae: 209.9303 - val_mse: 207048.8281\n",
      "Epoch 52/1000\n",
      "707/707 [==============================] - 1s 2ms/step - loss: 269747.4688 - mae: 238.5024 - mse: 269747.4688 - val_loss: 216857.3125 - val_mae: 217.4137 - val_mse: 216857.3125\n",
      "Epoch 53/1000\n",
      "707/707 [==============================] - 1s 2ms/step - loss: 270542.1250 - mae: 238.8187 - mse: 270542.1250 - val_loss: 197165.4844 - val_mae: 201.0003 - val_mse: 197165.4844\n",
      "Epoch 54/1000\n",
      "707/707 [==============================] - 1s 2ms/step - loss: 271375.5000 - mae: 240.1558 - mse: 271375.5000 - val_loss: 190070.5156 - val_mae: 197.1175 - val_mse: 190070.5156\n",
      "Epoch 55/1000\n",
      "707/707 [==============================] - 1s 2ms/step - loss: 267477.7500 - mae: 237.3307 - mse: 267477.7500 - val_loss: 191718.3906 - val_mae: 198.2773 - val_mse: 191718.3906\n",
      "Epoch 56/1000\n",
      "707/707 [==============================] - 1s 2ms/step - loss: 269731.5938 - mae: 238.7046 - mse: 269731.5938 - val_loss: 192201.7969 - val_mae: 204.2760 - val_mse: 192201.7969\n",
      "Epoch 57/1000\n",
      "707/707 [==============================] - 1s 2ms/step - loss: 274103.2812 - mae: 240.5261 - mse: 274103.2812 - val_loss: 194645.5000 - val_mae: 202.2535 - val_mse: 194645.5000\n",
      "Epoch 58/1000\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 268745.9688 - mae: 238.4790 - mse: 268745.9688 - val_loss: 190458.0000 - val_mae: 198.2101 - val_mse: 190458.0000\n",
      "Epoch 59/1000\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 273075.9688 - mae: 238.9583 - mse: 273075.9688 - val_loss: 193524.0000 - val_mae: 200.9079 - val_mse: 193524.0000\n",
      "Epoch 60/1000\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 271418.0625 - mae: 239.4182 - mse: 271418.0625 - val_loss: 192561.0312 - val_mae: 199.7980 - val_mse: 192561.0312\n",
      "Epoch 61/1000\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 265153.1562 - mae: 236.0102 - mse: 265153.1562 - val_loss: 199901.4531 - val_mae: 203.3398 - val_mse: 199901.4531\n",
      "Epoch 62/1000\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 261959.7812 - mae: 235.5982 - mse: 261959.7812 - val_loss: 189343.8906 - val_mae: 197.3604 - val_mse: 189343.8906\n",
      "Epoch 63/1000\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 262460.9375 - mae: 237.4417 - mse: 262460.9375 - val_loss: 190535.1250 - val_mae: 200.0299 - val_mse: 190535.1250\n",
      "Epoch 64/1000\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 270498.1562 - mae: 238.5058 - mse: 270498.1562 - val_loss: 190740.9844 - val_mae: 199.7414 - val_mse: 190740.9844\n",
      "Epoch 65/1000\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 267000.1250 - mae: 238.6624 - mse: 267000.1250 - val_loss: 190747.0156 - val_mae: 198.8690 - val_mse: 190747.0156\n",
      "Epoch 66/1000\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 263324.0312 - mae: 236.6839 - mse: 263324.0312 - val_loss: 196053.2969 - val_mae: 203.1339 - val_mse: 196053.2969\n",
      "Epoch 67/1000\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 266454.3125 - mae: 237.7386 - mse: 266454.3125 - val_loss: 191524.6250 - val_mae: 201.4292 - val_mse: 191524.6250\n",
      "Epoch 68/1000\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 266159.3438 - mae: 237.3280 - mse: 266159.3438 - val_loss: 187883.9375 - val_mae: 199.0149 - val_mse: 187883.9375\n",
      "Epoch 69/1000\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 279115.0625 - mae: 241.3649 - mse: 279115.0625 - val_loss: 194219.4219 - val_mae: 203.1580 - val_mse: 194219.4219\n",
      "Epoch 70/1000\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 269142.6562 - mae: 240.5406 - mse: 269142.6562 - val_loss: 196222.2500 - val_mae: 202.4390 - val_mse: 196222.2500\n",
      "Epoch 71/1000\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 260177.9062 - mae: 236.2766 - mse: 260177.9062 - val_loss: 199652.5625 - val_mae: 208.6312 - val_mse: 199652.5625\n",
      "Epoch 72/1000\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 265362.0000 - mae: 237.9079 - mse: 265362.0000 - val_loss: 193077.4219 - val_mae: 206.2871 - val_mse: 193077.4219\n",
      "Epoch 73/1000\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 270287.4688 - mae: 239.2314 - mse: 270287.4688 - val_loss: 188723.0781 - val_mae: 196.7991 - val_mse: 188723.0781\n",
      "Epoch 74/1000\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 264483.8750 - mae: 237.1720 - mse: 264483.8750 - val_loss: 192597.2812 - val_mae: 199.8567 - val_mse: 192597.2812\n",
      "Epoch 75/1000\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 265250.6250 - mae: 236.0317 - mse: 265250.6250 - val_loss: 192274.8281 - val_mae: 202.6804 - val_mse: 192274.8281\n",
      "Epoch 76/1000\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 263279.7812 - mae: 237.0813 - mse: 263279.7812 - val_loss: 195155.7656 - val_mae: 204.2031 - val_mse: 195155.7656\n",
      "Epoch 77/1000\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 265773.0312 - mae: 237.9949 - mse: 265773.0312 - val_loss: 198473.8438 - val_mae: 207.5247 - val_mse: 198473.8438\n",
      "Epoch 78/1000\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 269408.5000 - mae: 239.7028 - mse: 269408.5000 - val_loss: 197769.2656 - val_mae: 209.5068 - val_mse: 197769.2656\n",
      "Epoch 79/1000\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 265045.7812 - mae: 236.9471 - mse: 265045.7812 - val_loss: 188028.5156 - val_mae: 199.7120 - val_mse: 188028.5156\n",
      "Epoch 80/1000\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 261258.0156 - mae: 236.8385 - mse: 261258.0156 - val_loss: 196489.5312 - val_mae: 208.1152 - val_mse: 196489.5312\n",
      "Epoch 81/1000\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 272624.6250 - mae: 240.5172 - mse: 272624.6250 - val_loss: 188322.9375 - val_mae: 201.7565 - val_mse: 188322.9375\n",
      "Epoch 82/1000\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 265555.0000 - mae: 239.0266 - mse: 265555.0000 - val_loss: 187779.1406 - val_mae: 195.2510 - val_mse: 187779.1406\n",
      "Epoch 83/1000\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 261840.1562 - mae: 236.0889 - mse: 261840.1562 - val_loss: 186841.8438 - val_mae: 194.5543 - val_mse: 186841.8438\n",
      "Epoch 84/1000\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 262812.4062 - mae: 237.3665 - mse: 262812.4062 - val_loss: 186522.8438 - val_mae: 194.5845 - val_mse: 186522.8438\n",
      "Epoch 85/1000\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 260802.0156 - mae: 238.3809 - mse: 260802.0156 - val_loss: 190341.0312 - val_mae: 196.5868 - val_mse: 190341.0312\n",
      "Epoch 86/1000\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 268747.3125 - mae: 240.2647 - mse: 268747.3125 - val_loss: 192972.6719 - val_mae: 201.1539 - val_mse: 192972.6719\n",
      "Epoch 87/1000\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 261675.0156 - mae: 238.1659 - mse: 261675.0156 - val_loss: 188266.1250 - val_mae: 198.5399 - val_mse: 188266.1250\n",
      "Epoch 88/1000\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 268889.5312 - mae: 240.2436 - mse: 268889.5312 - val_loss: 196537.0312 - val_mae: 205.3853 - val_mse: 196537.0312\n",
      "Epoch 89/1000\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 261779.2344 - mae: 237.1786 - mse: 261779.2344 - val_loss: 198590.6875 - val_mae: 204.8718 - val_mse: 198590.6875\n",
      "Epoch 90/1000\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 261129.6406 - mae: 237.0388 - mse: 261129.6406 - val_loss: 186160.3750 - val_mae: 195.8846 - val_mse: 186160.3750\n",
      "Epoch 91/1000\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 263729.1250 - mae: 238.0129 - mse: 263729.1250 - val_loss: 185496.3281 - val_mae: 197.9627 - val_mse: 185496.3281\n",
      "Epoch 92/1000\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 263014.3125 - mae: 236.9002 - mse: 263014.3125 - val_loss: 206120.8125 - val_mae: 214.7611 - val_mse: 206120.8125\n",
      "Epoch 93/1000\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 252849.7188 - mae: 236.0509 - mse: 252849.7188 - val_loss: 190021.2812 - val_mae: 199.9808 - val_mse: 190021.2812\n",
      "Epoch 94/1000\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 259598.2812 - mae: 236.3948 - mse: 259598.2812 - val_loss: 192015.7188 - val_mae: 204.7800 - val_mse: 192015.7188\n",
      "Epoch 95/1000\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 261000.0938 - mae: 238.0479 - mse: 261000.0938 - val_loss: 192684.2969 - val_mae: 205.7284 - val_mse: 192684.2969\n",
      "Epoch 96/1000\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 263997.5938 - mae: 239.5138 - mse: 263997.5938 - val_loss: 191798.4688 - val_mae: 201.9526 - val_mse: 191798.4688\n",
      "Epoch 97/1000\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 264679.4688 - mae: 238.3579 - mse: 264679.4688 - val_loss: 187045.9844 - val_mae: 196.6162 - val_mse: 187045.9844\n",
      "Epoch 98/1000\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 255875.7344 - mae: 236.0339 - mse: 255875.7344 - val_loss: 186913.8438 - val_mae: 199.2969 - val_mse: 186913.8438\n",
      "Epoch 99/1000\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 265017.2812 - mae: 240.1402 - mse: 265017.2812 - val_loss: 190280.1719 - val_mae: 201.5029 - val_mse: 190280.1719\n",
      "Epoch 100/1000\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 262848.2188 - mae: 238.4749 - mse: 262848.2188 - val_loss: 201702.8750 - val_mae: 211.6865 - val_mse: 201702.8750\n",
      "Epoch 101/1000\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 255339.2188 - mae: 235.7310 - mse: 255339.2188 - val_loss: 185995.8594 - val_mae: 195.1250 - val_mse: 185995.8594\n",
      "Epoch 102/1000\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 264006.6562 - mae: 238.7512 - mse: 264006.6562 - val_loss: 185487.0938 - val_mae: 198.8180 - val_mse: 185487.0938\n",
      "Epoch 103/1000\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 256856.2812 - mae: 237.5258 - mse: 256856.2812 - val_loss: 190631.5938 - val_mae: 203.1137 - val_mse: 190631.5938\n",
      "Epoch 104/1000\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 261902.7656 - mae: 237.8588 - mse: 261902.7656 - val_loss: 186275.2344 - val_mae: 198.8364 - val_mse: 186275.2344\n",
      "Epoch 105/1000\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 259811.5781 - mae: 238.3846 - mse: 259811.5781 - val_loss: 192693.7031 - val_mae: 206.9069 - val_mse: 192693.7031\n",
      "Epoch 106/1000\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 261542.1406 - mae: 238.1229 - mse: 261542.1406 - val_loss: 190763.4688 - val_mae: 203.7869 - val_mse: 190763.4688\n",
      "Epoch 107/1000\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 256194.6875 - mae: 236.7878 - mse: 256194.6875 - val_loss: 189047.9219 - val_mae: 204.3786 - val_mse: 189047.9219\n",
      "Epoch 108/1000\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 255972.1562 - mae: 235.7122 - mse: 255972.1562 - val_loss: 193499.5000 - val_mae: 205.8035 - val_mse: 193499.5000\n",
      "Epoch 109/1000\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 255587.1562 - mae: 235.8420 - mse: 255587.1562 - val_loss: 184682.7969 - val_mae: 197.6125 - val_mse: 184682.7969\n",
      "Epoch 110/1000\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 263078.6875 - mae: 239.6412 - mse: 263078.6875 - val_loss: 186690.5938 - val_mae: 196.2909 - val_mse: 186690.5938\n",
      "Epoch 111/1000\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 252374.2500 - mae: 235.0316 - mse: 252374.2500 - val_loss: 192770.4375 - val_mae: 208.9287 - val_mse: 192770.4375\n",
      "Epoch 112/1000\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 256392.9844 - mae: 237.7710 - mse: 256392.9844 - val_loss: 185835.9062 - val_mae: 203.7037 - val_mse: 185835.9062\n",
      "Epoch 113/1000\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 257869.4375 - mae: 236.9913 - mse: 257869.4375 - val_loss: 187303.4062 - val_mae: 202.6375 - val_mse: 187303.4062\n",
      "Epoch 114/1000\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 259391.6719 - mae: 237.9653 - mse: 259391.6719 - val_loss: 192533.9375 - val_mae: 206.9888 - val_mse: 192533.9375\n",
      "Epoch 115/1000\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 260004.0156 - mae: 238.4568 - mse: 260004.0156 - val_loss: 183228.3594 - val_mae: 199.0481 - val_mse: 183228.3594\n",
      "Epoch 116/1000\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 261186.7500 - mae: 239.7712 - mse: 261186.7500 - val_loss: 191340.5156 - val_mae: 205.6293 - val_mse: 191340.5156\n",
      "Epoch 117/1000\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 260002.5625 - mae: 238.4106 - mse: 260002.5625 - val_loss: 188671.1562 - val_mae: 203.2148 - val_mse: 188671.1562\n",
      "Epoch 118/1000\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 258905.2188 - mae: 237.9885 - mse: 258905.2188 - val_loss: 182898.0781 - val_mae: 200.2627 - val_mse: 182898.0781\n",
      "Epoch 119/1000\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 248881.4688 - mae: 234.3470 - mse: 248881.4688 - val_loss: 188333.7031 - val_mae: 199.5303 - val_mse: 188333.7031\n",
      "Epoch 120/1000\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 259484.7188 - mae: 238.9700 - mse: 259484.7188 - val_loss: 190442.5625 - val_mae: 206.0611 - val_mse: 190442.5625\n",
      "Epoch 121/1000\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 248808.5938 - mae: 235.5425 - mse: 248808.5938 - val_loss: 187330.9688 - val_mae: 205.3764 - val_mse: 187330.9688\n",
      "Epoch 122/1000\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 253483.8750 - mae: 236.4067 - mse: 253483.8750 - val_loss: 186083.0938 - val_mae: 196.6167 - val_mse: 186083.0938\n",
      "Epoch 123/1000\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 256875.5000 - mae: 238.0138 - mse: 256875.5000 - val_loss: 195268.0781 - val_mae: 209.2474 - val_mse: 195268.0781\n",
      "Epoch 124/1000\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 257913.7656 - mae: 237.6565 - mse: 257913.7656 - val_loss: 184031.7500 - val_mae: 198.6385 - val_mse: 184031.7500\n",
      "Epoch 125/1000\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 253848.9688 - mae: 238.0303 - mse: 253848.9688 - val_loss: 183261.7031 - val_mae: 194.7681 - val_mse: 183261.7031\n",
      "Epoch 126/1000\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 253882.2656 - mae: 235.9786 - mse: 253882.2656 - val_loss: 184004.2500 - val_mae: 199.4416 - val_mse: 184004.2500\n",
      "Epoch 127/1000\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 256279.5781 - mae: 237.0154 - mse: 256279.5781 - val_loss: 191798.7031 - val_mae: 203.4093 - val_mse: 191798.7031\n",
      "Epoch 128/1000\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 252344.7500 - mae: 238.0303 - mse: 252344.7500 - val_loss: 188010.0469 - val_mae: 207.0725 - val_mse: 188010.0469\n",
      "Epoch 129/1000\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 257237.2188 - mae: 238.5727 - mse: 257237.2188 - val_loss: 183514.9531 - val_mae: 197.9232 - val_mse: 183514.9531\n",
      "Epoch 130/1000\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 253575.6875 - mae: 236.7615 - mse: 253575.6875 - val_loss: 185274.1250 - val_mae: 198.1170 - val_mse: 185274.1250\n",
      "Epoch 131/1000\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 261319.3906 - mae: 239.2131 - mse: 261319.3906 - val_loss: 192086.0312 - val_mae: 208.9043 - val_mse: 192086.0312\n",
      "Epoch 132/1000\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 249966.7031 - mae: 237.0661 - mse: 249966.7031 - val_loss: 182541.7031 - val_mae: 199.0143 - val_mse: 182541.7031\n",
      "Epoch 133/1000\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 256277.9062 - mae: 238.6900 - mse: 256277.9062 - val_loss: 197111.4688 - val_mae: 212.0973 - val_mse: 197111.4688\n",
      "Epoch 134/1000\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 251748.5312 - mae: 237.4876 - mse: 251748.5312 - val_loss: 183670.1875 - val_mae: 201.1659 - val_mse: 183670.1875\n",
      "Epoch 135/1000\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 257953.2500 - mae: 239.2100 - mse: 257953.2500 - val_loss: 184766.1250 - val_mae: 200.8746 - val_mse: 184766.1250\n",
      "Epoch 136/1000\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 250001.5000 - mae: 235.4620 - mse: 250001.5000 - val_loss: 186399.2031 - val_mae: 204.0070 - val_mse: 186399.2031\n",
      "Epoch 137/1000\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 251505.5156 - mae: 236.7425 - mse: 251505.5156 - val_loss: 184787.6250 - val_mae: 200.4962 - val_mse: 184787.6250\n",
      "Epoch 138/1000\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 250446.3594 - mae: 236.4776 - mse: 250446.3594 - val_loss: 183327.2969 - val_mae: 201.1566 - val_mse: 183327.2969\n",
      "Epoch 139/1000\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 255063.7500 - mae: 237.8207 - mse: 255063.7500 - val_loss: 180718.3906 - val_mae: 197.2730 - val_mse: 180718.3906\n",
      "Epoch 140/1000\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 256809.9844 - mae: 239.1755 - mse: 256809.9844 - val_loss: 181669.7500 - val_mae: 196.5684 - val_mse: 181669.7500\n",
      "Epoch 141/1000\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 254054.4375 - mae: 236.2417 - mse: 254054.4375 - val_loss: 183437.9375 - val_mae: 198.6170 - val_mse: 183437.9375\n",
      "Epoch 142/1000\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 254298.4844 - mae: 237.5533 - mse: 254298.4844 - val_loss: 186758.0938 - val_mae: 202.5274 - val_mse: 186758.0938\n",
      "Epoch 143/1000\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 254484.0156 - mae: 236.1753 - mse: 254484.0156 - val_loss: 187945.2656 - val_mae: 202.2677 - val_mse: 187945.2656\n",
      "Epoch 144/1000\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 254697.9219 - mae: 236.4303 - mse: 254697.9219 - val_loss: 193304.8750 - val_mae: 205.5651 - val_mse: 193304.8750\n",
      "Epoch 145/1000\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 260944.8594 - mae: 237.2001 - mse: 260944.8594 - val_loss: 188135.5000 - val_mae: 202.6436 - val_mse: 188135.5000\n",
      "Epoch 146/1000\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 251291.4375 - mae: 233.1539 - mse: 251291.4375 - val_loss: 187648.6094 - val_mae: 202.8842 - val_mse: 187648.6094\n",
      "Epoch 147/1000\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 258827.6875 - mae: 234.4864 - mse: 258827.6875 - val_loss: 183804.8594 - val_mae: 196.7519 - val_mse: 183804.8594\n",
      "Epoch 148/1000\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 248322.7656 - mae: 231.9294 - mse: 248322.7656 - val_loss: 203874.2969 - val_mae: 210.7172 - val_mse: 203874.2969\n",
      "Epoch 149/1000\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 256690.2031 - mae: 235.1938 - mse: 256690.2031 - val_loss: 184555.2188 - val_mae: 197.0261 - val_mse: 184555.2188\n",
      "Epoch 150/1000\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 248775.0625 - mae: 232.3404 - mse: 248775.0625 - val_loss: 184314.4062 - val_mae: 193.9853 - val_mse: 184314.4062\n",
      "Epoch 151/1000\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 244601.7188 - mae: 230.8380 - mse: 244601.7188 - val_loss: 182191.0938 - val_mae: 195.1025 - val_mse: 182191.0938\n",
      "Epoch 152/1000\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 257598.0625 - mae: 235.2217 - mse: 257598.0625 - val_loss: 183707.9844 - val_mae: 196.0895 - val_mse: 183707.9844\n",
      "Epoch 153/1000\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 252805.6719 - mae: 233.9324 - mse: 252805.6719 - val_loss: 181039.8594 - val_mae: 193.1845 - val_mse: 181039.8594\n",
      "Epoch 154/1000\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 250978.5938 - mae: 232.4689 - mse: 250978.5938 - val_loss: 187355.4219 - val_mae: 199.7524 - val_mse: 187355.4219\n",
      "Epoch 155/1000\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 254850.7500 - mae: 233.3075 - mse: 254850.7500 - val_loss: 194118.5000 - val_mae: 205.0345 - val_mse: 194118.5000\n",
      "Epoch 156/1000\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 252349.4375 - mae: 232.1677 - mse: 252349.4375 - val_loss: 183949.1094 - val_mae: 200.2787 - val_mse: 183949.1094\n",
      "Epoch 157/1000\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 259518.2031 - mae: 234.9293 - mse: 259518.2031 - val_loss: 182068.2656 - val_mae: 191.6008 - val_mse: 182068.2656\n",
      "Epoch 158/1000\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 254798.8438 - mae: 231.9397 - mse: 254798.8438 - val_loss: 180860.9688 - val_mae: 193.8128 - val_mse: 180860.9688\n",
      "Epoch 159/1000\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 248481.0625 - mae: 231.4776 - mse: 248481.0625 - val_loss: 179467.1875 - val_mae: 188.2942 - val_mse: 179467.1875\n",
      "Epoch 160/1000\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 252029.4688 - mae: 231.6821 - mse: 252029.4688 - val_loss: 184643.4688 - val_mae: 199.1996 - val_mse: 184643.4688\n",
      "Epoch 161/1000\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 250978.7500 - mae: 232.8465 - mse: 250978.7500 - val_loss: 180457.5312 - val_mae: 191.9998 - val_mse: 180457.5312\n",
      "Epoch 162/1000\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 255457.0000 - mae: 234.0272 - mse: 255457.0000 - val_loss: 182900.2031 - val_mae: 191.5471 - val_mse: 182900.2031\n",
      "Epoch 163/1000\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 247738.6250 - mae: 231.0304 - mse: 247738.6250 - val_loss: 180878.5625 - val_mae: 193.2067 - val_mse: 180878.5625\n",
      "Epoch 164/1000\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 252047.8125 - mae: 230.5929 - mse: 252047.8125 - val_loss: 185898.7344 - val_mae: 199.3354 - val_mse: 185898.7344\n",
      "Epoch 165/1000\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 249280.0938 - mae: 231.9378 - mse: 249280.0938 - val_loss: 185567.0938 - val_mae: 199.0309 - val_mse: 185567.0938\n",
      "Epoch 166/1000\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 254489.1250 - mae: 233.7803 - mse: 254489.1250 - val_loss: 185487.4219 - val_mae: 201.4593 - val_mse: 185487.4219\n",
      "Epoch 167/1000\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 254430.2031 - mae: 233.5932 - mse: 254430.2031 - val_loss: 182553.6406 - val_mae: 194.9325 - val_mse: 182553.6406\n",
      "Epoch 168/1000\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 249901.6250 - mae: 231.9666 - mse: 249901.6250 - val_loss: 181855.2344 - val_mae: 194.9000 - val_mse: 181855.2344\n",
      "Epoch 169/1000\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 252787.2969 - mae: 232.1484 - mse: 252787.2969 - val_loss: 183774.4219 - val_mae: 197.9671 - val_mse: 183774.4219\n",
      "Epoch 170/1000\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 260050.2031 - mae: 235.6118 - mse: 260050.2031 - val_loss: 183518.0156 - val_mae: 196.5507 - val_mse: 183518.0156\n",
      "Epoch 171/1000\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 246176.0000 - mae: 231.7044 - mse: 246176.0000 - val_loss: 191386.2344 - val_mae: 203.9488 - val_mse: 191386.2344\n",
      "Epoch 172/1000\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 249129.6406 - mae: 231.4395 - mse: 249129.6406 - val_loss: 183476.9531 - val_mae: 193.4257 - val_mse: 183476.9531\n",
      "Epoch 173/1000\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 254871.5000 - mae: 233.4286 - mse: 254871.5000 - val_loss: 178069.8750 - val_mae: 191.3715 - val_mse: 178069.8750\n",
      "Epoch 174/1000\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 250627.7656 - mae: 232.2710 - mse: 250627.7656 - val_loss: 179926.9062 - val_mae: 191.9939 - val_mse: 179926.9062\n",
      "Epoch 175/1000\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 251596.3438 - mae: 233.5515 - mse: 251596.3438 - val_loss: 180054.3750 - val_mae: 197.0223 - val_mse: 180054.3750\n",
      "Epoch 176/1000\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 251498.0938 - mae: 234.2103 - mse: 251498.0938 - val_loss: 179783.3750 - val_mae: 192.5301 - val_mse: 179783.3750\n",
      "Epoch 177/1000\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 253122.9219 - mae: 233.7053 - mse: 253122.9219 - val_loss: 184322.6094 - val_mae: 199.8134 - val_mse: 184322.6094\n",
      "Epoch 178/1000\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 243986.1719 - mae: 230.2948 - mse: 243986.1719 - val_loss: 177416.6562 - val_mae: 191.1480 - val_mse: 177416.6562\n",
      "Epoch 179/1000\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 241751.1406 - mae: 228.7995 - mse: 241751.1406 - val_loss: 183411.9375 - val_mae: 197.5921 - val_mse: 183411.9375\n",
      "Epoch 180/1000\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 254250.1406 - mae: 233.2277 - mse: 254250.1406 - val_loss: 182220.4219 - val_mae: 197.6719 - val_mse: 182220.4219\n",
      "Epoch 181/1000\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 244308.0469 - mae: 230.6384 - mse: 244308.0469 - val_loss: 180479.0625 - val_mae: 195.8203 - val_mse: 180479.0625\n",
      "Epoch 182/1000\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 247377.8906 - mae: 232.1712 - mse: 247377.8906 - val_loss: 184403.4844 - val_mae: 198.7601 - val_mse: 184403.4844\n",
      "Epoch 183/1000\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 249321.1562 - mae: 231.7720 - mse: 249321.1562 - val_loss: 184945.1719 - val_mae: 200.4456 - val_mse: 184945.1719\n",
      "Epoch 184/1000\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 249457.8281 - mae: 233.2870 - mse: 249457.8281 - val_loss: 186627.2812 - val_mae: 202.4906 - val_mse: 186627.2812\n",
      "Epoch 185/1000\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 248221.4688 - mae: 233.2054 - mse: 248221.4688 - val_loss: 187771.0156 - val_mae: 206.3076 - val_mse: 187771.0156\n",
      "Epoch 186/1000\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 254602.8438 - mae: 234.7878 - mse: 254602.8438 - val_loss: 180665.2031 - val_mae: 189.7446 - val_mse: 180665.2031\n",
      "Epoch 187/1000\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 243140.3438 - mae: 230.7008 - mse: 243140.3438 - val_loss: 184596.3125 - val_mae: 198.2698 - val_mse: 184596.3125\n",
      "Epoch 188/1000\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 253060.5312 - mae: 233.1472 - mse: 253060.5312 - val_loss: 187261.0625 - val_mae: 200.1705 - val_mse: 187261.0625\n",
      "Epoch 189/1000\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 253105.5156 - mae: 233.7970 - mse: 253105.5156 - val_loss: 190412.8438 - val_mae: 200.8766 - val_mse: 190412.8438\n",
      "Epoch 190/1000\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 248325.0469 - mae: 231.5540 - mse: 248325.0469 - val_loss: 176684.2344 - val_mae: 190.9750 - val_mse: 176684.2344\n",
      "Epoch 191/1000\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 249701.4375 - mae: 232.1374 - mse: 249701.4375 - val_loss: 182636.4688 - val_mae: 195.6451 - val_mse: 182636.4688\n",
      "Epoch 192/1000\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 253532.0469 - mae: 233.3626 - mse: 253532.0469 - val_loss: 181020.4375 - val_mae: 195.3554 - val_mse: 181020.4375\n",
      "Epoch 193/1000\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 240269.5625 - mae: 229.3921 - mse: 240269.5625 - val_loss: 178165.4688 - val_mae: 196.5116 - val_mse: 178165.4688\n",
      "Epoch 194/1000\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 252554.7656 - mae: 233.4387 - mse: 252554.7656 - val_loss: 191508.0625 - val_mae: 202.8596 - val_mse: 191508.0625\n",
      "Epoch 195/1000\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 245473.7344 - mae: 232.0000 - mse: 245473.7344 - val_loss: 180729.7500 - val_mae: 198.4350 - val_mse: 180729.7500\n",
      "Epoch 196/1000\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 237202.0781 - mae: 228.7516 - mse: 237202.0781 - val_loss: 178177.0781 - val_mae: 191.6349 - val_mse: 178177.0781\n",
      "Epoch 197/1000\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 248728.5625 - mae: 231.6186 - mse: 248728.5625 - val_loss: 188607.5469 - val_mae: 202.6953 - val_mse: 188607.5469\n",
      "Epoch 198/1000\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 249250.8125 - mae: 232.8979 - mse: 249250.8125 - val_loss: 181232.2969 - val_mae: 197.7203 - val_mse: 181232.2969\n",
      "Epoch 199/1000\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 244871.0000 - mae: 231.1871 - mse: 244871.0000 - val_loss: 180763.1406 - val_mae: 195.6616 - val_mse: 180763.1406\n",
      "Epoch 200/1000\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 249041.1094 - mae: 235.9394 - mse: 249041.1094 - val_loss: 184580.0312 - val_mae: 196.6177 - val_mse: 184580.0312\n",
      "Epoch 201/1000\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 243954.5156 - mae: 231.8356 - mse: 243954.5156 - val_loss: 177712.8594 - val_mae: 196.1172 - val_mse: 177712.8594\n",
      "Epoch 202/1000\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 245562.5625 - mae: 231.2441 - mse: 245562.5625 - val_loss: 181626.6719 - val_mae: 198.7287 - val_mse: 181626.6719\n",
      "Epoch 203/1000\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 242788.1875 - mae: 231.9496 - mse: 242788.1875 - val_loss: 188779.8438 - val_mae: 202.7572 - val_mse: 188779.8438\n",
      "Epoch 204/1000\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 244354.5469 - mae: 232.1860 - mse: 244354.5469 - val_loss: 178327.8906 - val_mae: 195.3174 - val_mse: 178327.8906\n",
      "Epoch 205/1000\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 245747.5938 - mae: 232.2938 - mse: 245747.5938 - val_loss: 191539.3906 - val_mae: 206.7212 - val_mse: 191539.3906\n",
      "Epoch 206/1000\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 248030.1406 - mae: 233.1676 - mse: 248030.1406 - val_loss: 178170.3594 - val_mae: 194.1475 - val_mse: 178170.3594\n",
      "Epoch 207/1000\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 246315.1719 - mae: 233.2514 - mse: 246315.1719 - val_loss: 181430.2188 - val_mae: 200.0907 - val_mse: 181430.2188\n",
      "Epoch 208/1000\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 243354.7812 - mae: 231.2124 - mse: 243354.7812 - val_loss: 191424.2969 - val_mae: 203.7631 - val_mse: 191424.2969\n",
      "Epoch 209/1000\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 247399.7188 - mae: 233.1226 - mse: 247399.7188 - val_loss: 181740.5312 - val_mae: 197.7459 - val_mse: 181740.5312\n",
      "Epoch 210/1000\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 242702.0781 - mae: 230.4763 - mse: 242702.0781 - val_loss: 178686.0469 - val_mae: 196.7344 - val_mse: 178686.0469\n",
      "Epoch 211/1000\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 239973.3281 - mae: 230.8350 - mse: 239973.3281 - val_loss: 181170.4219 - val_mae: 202.2734 - val_mse: 181170.4219\n",
      "Epoch 212/1000\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 242535.3125 - mae: 230.3111 - mse: 242535.3125 - val_loss: 185436.8438 - val_mae: 202.5312 - val_mse: 185436.8438\n",
      "Epoch 213/1000\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 241978.0312 - mae: 230.5001 - mse: 241978.0312 - val_loss: 178934.2812 - val_mae: 197.9528 - val_mse: 178934.2812\n",
      "Epoch 214/1000\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 245847.3281 - mae: 232.8935 - mse: 245847.3281 - val_loss: 179746.4219 - val_mae: 195.9371 - val_mse: 179746.4219\n",
      "Epoch 215/1000\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 245469.0625 - mae: 232.0589 - mse: 245469.0625 - val_loss: 180150.5781 - val_mae: 193.8810 - val_mse: 180150.5781\n",
      "Epoch 216/1000\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 236739.6562 - mae: 228.7965 - mse: 236739.6562 - val_loss: 180114.9219 - val_mae: 199.5998 - val_mse: 180114.9219\n",
      "Epoch 217/1000\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 250327.3906 - mae: 234.6496 - mse: 250327.3906 - val_loss: 177454.2500 - val_mae: 196.9963 - val_mse: 177454.2500\n",
      "Epoch 218/1000\n",
      "707/707 [==============================] - 1s 2ms/step - loss: 239103.2031 - mae: 230.1064 - mse: 239103.2031 - val_loss: 180120.6094 - val_mae: 197.9584 - val_mse: 180120.6094\n",
      "Epoch 219/1000\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 243006.0156 - mae: 233.0548 - mse: 243006.0156 - val_loss: 180774.2031 - val_mae: 195.5976 - val_mse: 180774.2031\n",
      "Epoch 220/1000\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 245721.5312 - mae: 232.3090 - mse: 245721.5312 - val_loss: 178469.2031 - val_mae: 196.8648 - val_mse: 178469.2031\n",
      "Epoch 221/1000\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 239468.7031 - mae: 230.7412 - mse: 239468.7031 - val_loss: 176418.4375 - val_mae: 192.4489 - val_mse: 176418.4375\n",
      "Epoch 222/1000\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 242081.1562 - mae: 231.5526 - mse: 242081.1562 - val_loss: 179857.8125 - val_mae: 199.7438 - val_mse: 179857.8125\n",
      "Epoch 223/1000\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 248936.0938 - mae: 232.9797 - mse: 248936.0938 - val_loss: 178225.6250 - val_mae: 196.4443 - val_mse: 178225.6250\n",
      "Epoch 224/1000\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 243076.5938 - mae: 231.9274 - mse: 243076.5938 - val_loss: 186627.9844 - val_mae: 204.9415 - val_mse: 186627.9844\n",
      "Epoch 225/1000\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 236052.9219 - mae: 227.9260 - mse: 236052.9219 - val_loss: 205965.2031 - val_mae: 215.4705 - val_mse: 205965.2031\n",
      "Epoch 226/1000\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 238102.2500 - mae: 229.8876 - mse: 238102.2500 - val_loss: 177038.5781 - val_mae: 199.0071 - val_mse: 177038.5781\n",
      "Epoch 227/1000\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 232354.8438 - mae: 227.8161 - mse: 232354.8438 - val_loss: 178171.3750 - val_mae: 198.1243 - val_mse: 178171.3750\n",
      "Epoch 228/1000\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 245157.4844 - mae: 232.8467 - mse: 245157.4844 - val_loss: 182116.4844 - val_mae: 202.2676 - val_mse: 182116.4844\n",
      "Epoch 229/1000\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 240566.3594 - mae: 230.8402 - mse: 240566.3594 - val_loss: 193409.7188 - val_mae: 207.6223 - val_mse: 193409.7188\n",
      "Epoch 230/1000\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 243668.0938 - mae: 232.4865 - mse: 243668.0938 - val_loss: 177900.2031 - val_mae: 195.4335 - val_mse: 177900.2031\n",
      "Epoch 231/1000\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 244750.7344 - mae: 231.4748 - mse: 244750.7344 - val_loss: 183826.4062 - val_mae: 202.5465 - val_mse: 183826.4062\n",
      "Epoch 232/1000\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 237723.6094 - mae: 230.6597 - mse: 237723.6094 - val_loss: 178299.0938 - val_mae: 196.9061 - val_mse: 178299.0938\n",
      "Epoch 233/1000\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 246279.9219 - mae: 234.8523 - mse: 246279.9219 - val_loss: 181183.9688 - val_mae: 201.6713 - val_mse: 181183.9688\n",
      "Epoch 234/1000\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 245130.4062 - mae: 233.9088 - mse: 245130.4062 - val_loss: 180776.4375 - val_mae: 198.4844 - val_mse: 180776.4375\n",
      "Epoch 235/1000\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 242670.7188 - mae: 232.7040 - mse: 242670.7188 - val_loss: 175758.5156 - val_mae: 192.4443 - val_mse: 175758.5156\n",
      "Epoch 236/1000\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 243163.2812 - mae: 230.1561 - mse: 243163.2812 - val_loss: 178284.5469 - val_mae: 198.4313 - val_mse: 178284.5469\n",
      "Epoch 237/1000\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 240084.4688 - mae: 231.9564 - mse: 240084.4688 - val_loss: 192531.9062 - val_mae: 208.9302 - val_mse: 192531.9062\n",
      "Epoch 238/1000\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 243131.6719 - mae: 233.1282 - mse: 243131.6719 - val_loss: 175786.9844 - val_mae: 192.0648 - val_mse: 175786.9844\n",
      "Epoch 239/1000\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 243965.9219 - mae: 231.7945 - mse: 243965.9219 - val_loss: 179709.3906 - val_mae: 199.4608 - val_mse: 179709.3906\n",
      "Epoch 240/1000\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 246317.5469 - mae: 233.4289 - mse: 246317.5469 - val_loss: 172848.1250 - val_mae: 192.7334 - val_mse: 172848.1250\n",
      "Epoch 241/1000\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 233187.9375 - mae: 229.9819 - mse: 233187.9375 - val_loss: 173462.9062 - val_mae: 193.9197 - val_mse: 173462.9062\n",
      "Epoch 242/1000\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 239745.3906 - mae: 231.7527 - mse: 239745.3906 - val_loss: 182842.1094 - val_mae: 201.7292 - val_mse: 182842.1094\n",
      "Epoch 243/1000\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 234619.5938 - mae: 228.3074 - mse: 234619.5938 - val_loss: 178898.8125 - val_mae: 199.9545 - val_mse: 178898.8125\n",
      "Epoch 244/1000\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 249125.3281 - mae: 234.4560 - mse: 249125.3281 - val_loss: 175926.7188 - val_mae: 191.6284 - val_mse: 175926.7188\n",
      "Epoch 245/1000\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 237572.5000 - mae: 230.3659 - mse: 237572.5000 - val_loss: 174335.5312 - val_mae: 191.6423 - val_mse: 174335.5312\n",
      "Epoch 246/1000\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 238055.1875 - mae: 230.5056 - mse: 238055.1875 - val_loss: 176959.1250 - val_mae: 194.4751 - val_mse: 176959.1250\n",
      "Epoch 247/1000\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 246173.4531 - mae: 233.6413 - mse: 246173.4531 - val_loss: 174926.4375 - val_mae: 194.5424 - val_mse: 174926.4375\n",
      "Epoch 248/1000\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 240681.8438 - mae: 232.2731 - mse: 240681.8438 - val_loss: 174649.9375 - val_mae: 196.7782 - val_mse: 174649.9375\n",
      "Epoch 249/1000\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 238088.4062 - mae: 230.1179 - mse: 238088.4062 - val_loss: 174176.7656 - val_mae: 195.3028 - val_mse: 174176.7656\n",
      "Epoch 250/1000\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 241547.4531 - mae: 233.0316 - mse: 241547.4531 - val_loss: 182492.9844 - val_mae: 199.4385 - val_mse: 182492.9844\n",
      "Epoch 251/1000\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 236544.2188 - mae: 230.4938 - mse: 236544.2188 - val_loss: 180714.9375 - val_mae: 203.2268 - val_mse: 180714.9375\n",
      "Epoch 252/1000\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 236325.5469 - mae: 229.4510 - mse: 236325.5469 - val_loss: 175297.3281 - val_mae: 197.5279 - val_mse: 175297.3281\n",
      "Epoch 253/1000\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 243894.5000 - mae: 232.8849 - mse: 243894.5000 - val_loss: 181143.6094 - val_mae: 200.8140 - val_mse: 181143.6094\n",
      "Epoch 254/1000\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 240663.5156 - mae: 231.2946 - mse: 240663.5156 - val_loss: 173808.6406 - val_mae: 194.9412 - val_mse: 173808.6406\n",
      "Epoch 255/1000\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 242207.5312 - mae: 232.4308 - mse: 242207.5312 - val_loss: 176653.6094 - val_mae: 196.7350 - val_mse: 176653.6094\n",
      "Epoch 256/1000\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 233222.3125 - mae: 229.5161 - mse: 233222.3125 - val_loss: 199073.1406 - val_mae: 211.9536 - val_mse: 199073.1406\n",
      "Epoch 257/1000\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 230499.8125 - mae: 228.8679 - mse: 230499.8125 - val_loss: 182248.9375 - val_mae: 202.7341 - val_mse: 182248.9375\n",
      "Epoch 258/1000\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 234116.3125 - mae: 229.4505 - mse: 234116.3125 - val_loss: 177811.9062 - val_mae: 198.8101 - val_mse: 177811.9062\n",
      "Epoch 259/1000\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 239694.5312 - mae: 230.0355 - mse: 239694.5312 - val_loss: 172394.5469 - val_mae: 194.3491 - val_mse: 172394.5469\n",
      "Epoch 260/1000\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 234251.2031 - mae: 229.6571 - mse: 234251.2031 - val_loss: 182945.0000 - val_mae: 202.0252 - val_mse: 182945.0000\n",
      "Epoch 261/1000\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 236246.8906 - mae: 230.7325 - mse: 236246.8906 - val_loss: 177752.1875 - val_mae: 201.9698 - val_mse: 177752.1875\n",
      "Epoch 262/1000\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 233523.1875 - mae: 230.0064 - mse: 233523.1875 - val_loss: 172240.5000 - val_mae: 193.3483 - val_mse: 172240.5000\n",
      "Epoch 263/1000\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 236867.6875 - mae: 230.9518 - mse: 236867.6875 - val_loss: 180193.7969 - val_mae: 201.6945 - val_mse: 180193.7969\n",
      "Epoch 264/1000\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 237588.6719 - mae: 231.0746 - mse: 237588.6719 - val_loss: 178899.8125 - val_mae: 197.9428 - val_mse: 178899.8125\n",
      "Epoch 265/1000\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 233190.0938 - mae: 229.5237 - mse: 233190.0938 - val_loss: 172643.0156 - val_mae: 191.5932 - val_mse: 172643.0156\n",
      "Epoch 266/1000\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 235922.3750 - mae: 230.8970 - mse: 235922.3750 - val_loss: 173356.1406 - val_mae: 194.3674 - val_mse: 173356.1406\n",
      "Epoch 267/1000\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 235580.2188 - mae: 231.2467 - mse: 235580.2188 - val_loss: 177869.8594 - val_mae: 200.5050 - val_mse: 177869.8594\n",
      "Epoch 268/1000\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 239089.5781 - mae: 230.1753 - mse: 239089.5781 - val_loss: 171922.0156 - val_mae: 194.8555 - val_mse: 171922.0156\n",
      "Epoch 269/1000\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 241797.2656 - mae: 232.7387 - mse: 241797.2656 - val_loss: 174107.5000 - val_mae: 198.1871 - val_mse: 174107.5000\n",
      "Epoch 270/1000\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 240804.5469 - mae: 232.2009 - mse: 240804.5469 - val_loss: 170032.6719 - val_mae: 191.3699 - val_mse: 170032.6719\n",
      "Epoch 271/1000\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 230260.0781 - mae: 227.7260 - mse: 230260.0781 - val_loss: 184173.2031 - val_mae: 201.9092 - val_mse: 184173.2031\n",
      "Epoch 272/1000\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 240397.9531 - mae: 232.1357 - mse: 240397.9531 - val_loss: 174629.8594 - val_mae: 197.9459 - val_mse: 174629.8594\n",
      "Epoch 273/1000\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 231566.6250 - mae: 228.8871 - mse: 231566.6250 - val_loss: 178049.2031 - val_mae: 200.5305 - val_mse: 178049.2031\n",
      "Epoch 274/1000\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 235197.8125 - mae: 230.3176 - mse: 235197.8125 - val_loss: 169204.6406 - val_mae: 193.5408 - val_mse: 169204.6406\n",
      "Epoch 275/1000\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 240486.5000 - mae: 234.0906 - mse: 240486.5000 - val_loss: 185468.5625 - val_mae: 204.3368 - val_mse: 185468.5625\n",
      "Epoch 276/1000\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 239572.1719 - mae: 232.1432 - mse: 239572.1719 - val_loss: 179571.3125 - val_mae: 198.4531 - val_mse: 179571.3125\n",
      "Epoch 277/1000\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 235384.6875 - mae: 229.3648 - mse: 235384.6875 - val_loss: 172328.2188 - val_mae: 191.4239 - val_mse: 172328.2188\n",
      "Epoch 278/1000\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 230705.6875 - mae: 229.9826 - mse: 230705.6875 - val_loss: 180910.1094 - val_mae: 206.7939 - val_mse: 180910.1094\n",
      "Epoch 279/1000\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 231665.6875 - mae: 229.9058 - mse: 231665.6875 - val_loss: 180893.6719 - val_mae: 203.6027 - val_mse: 180893.6719\n",
      "Epoch 280/1000\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 228993.7656 - mae: 228.0078 - mse: 228993.7656 - val_loss: 172550.8750 - val_mae: 196.3240 - val_mse: 172550.8750\n",
      "Epoch 281/1000\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 237042.7344 - mae: 232.9630 - mse: 237042.7344 - val_loss: 182903.2344 - val_mae: 203.6679 - val_mse: 182903.2344\n",
      "Epoch 282/1000\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 234308.9688 - mae: 231.0967 - mse: 234308.9688 - val_loss: 184251.8750 - val_mae: 205.3105 - val_mse: 184251.8750\n",
      "Epoch 283/1000\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 229833.4375 - mae: 229.2002 - mse: 229833.4375 - val_loss: 188112.8438 - val_mae: 208.9067 - val_mse: 188112.8438\n",
      "Epoch 284/1000\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 237621.9062 - mae: 231.4964 - mse: 237621.9062 - val_loss: 178775.7812 - val_mae: 201.8339 - val_mse: 178775.7812\n",
      "Epoch 285/1000\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 236669.6250 - mae: 231.4109 - mse: 236669.6250 - val_loss: 171301.4844 - val_mae: 194.4452 - val_mse: 171301.4844\n",
      "Epoch 286/1000\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 240260.2188 - mae: 233.0307 - mse: 240260.2188 - val_loss: 172016.1250 - val_mae: 196.5201 - val_mse: 172016.1250\n",
      "Epoch 287/1000\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 242168.5469 - mae: 233.7330 - mse: 242168.5469 - val_loss: 176401.2656 - val_mae: 194.7788 - val_mse: 176401.2656\n",
      "Epoch 288/1000\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 232311.5469 - mae: 229.9032 - mse: 232311.5469 - val_loss: 170919.6250 - val_mae: 195.9182 - val_mse: 170919.6250\n",
      "Epoch 289/1000\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 235984.4844 - mae: 231.6493 - mse: 235984.4844 - val_loss: 177805.9844 - val_mae: 201.8309 - val_mse: 177805.9844\n",
      "Epoch 290/1000\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 238603.1562 - mae: 233.2267 - mse: 238603.1562 - val_loss: 174585.2812 - val_mae: 200.2339 - val_mse: 174585.2812\n",
      "Epoch 291/1000\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 241910.9062 - mae: 234.2783 - mse: 241910.9062 - val_loss: 183623.6250 - val_mae: 202.4959 - val_mse: 183623.6250\n",
      "Epoch 292/1000\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 235863.5625 - mae: 231.2737 - mse: 235863.5625 - val_loss: 174500.2031 - val_mae: 198.2483 - val_mse: 174500.2031\n",
      "Epoch 293/1000\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 236489.8438 - mae: 232.2872 - mse: 236489.8438 - val_loss: 170330.1406 - val_mae: 194.1160 - val_mse: 170330.1406\n",
      "Epoch 294/1000\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 230376.9375 - mae: 230.2128 - mse: 230376.9375 - val_loss: 191553.0938 - val_mae: 209.2891 - val_mse: 191553.0938\n",
      "Epoch 295/1000\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 235222.0312 - mae: 231.4138 - mse: 235222.0312 - val_loss: 182598.9375 - val_mae: 201.8623 - val_mse: 182598.9375\n",
      "Epoch 296/1000\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 239082.0469 - mae: 232.8678 - mse: 239082.0469 - val_loss: 182498.3906 - val_mae: 201.6040 - val_mse: 182498.3906\n",
      "Epoch 297/1000\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 238423.4062 - mae: 233.7560 - mse: 238423.4062 - val_loss: 176915.3750 - val_mae: 195.9581 - val_mse: 176915.3750\n",
      "Epoch 298/1000\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 235730.4375 - mae: 231.1116 - mse: 235730.4375 - val_loss: 174684.6875 - val_mae: 199.0296 - val_mse: 174684.6875\n",
      "Epoch 299/1000\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 242875.7500 - mae: 235.2808 - mse: 242875.7500 - val_loss: 182978.6719 - val_mae: 203.4919 - val_mse: 182978.6719\n",
      "Epoch 300/1000\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 230734.5000 - mae: 229.9975 - mse: 230734.5000 - val_loss: 173432.5312 - val_mae: 198.9257 - val_mse: 173432.5312\n",
      "Epoch 301/1000\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 236138.2656 - mae: 231.3959 - mse: 236138.2656 - val_loss: 170747.1094 - val_mae: 195.8020 - val_mse: 170747.1094\n",
      "Epoch 302/1000\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 237237.2500 - mae: 231.7651 - mse: 237237.2500 - val_loss: 168433.0625 - val_mae: 193.7775 - val_mse: 168433.0625\n",
      "Epoch 303/1000\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 237769.0469 - mae: 232.9846 - mse: 237769.0469 - val_loss: 174520.4219 - val_mae: 196.0428 - val_mse: 174520.4219\n",
      "Epoch 304/1000\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 238980.5469 - mae: 231.8007 - mse: 238980.5469 - val_loss: 182521.8281 - val_mae: 206.4834 - val_mse: 182521.8281\n",
      "Epoch 305/1000\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 238168.0000 - mae: 232.4616 - mse: 238168.0000 - val_loss: 188828.0781 - val_mae: 208.3718 - val_mse: 188828.0781\n",
      "Epoch 306/1000\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 229100.2969 - mae: 229.4348 - mse: 229100.2969 - val_loss: 171364.6562 - val_mae: 195.9914 - val_mse: 171364.6562\n",
      "Epoch 307/1000\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 231527.2344 - mae: 230.0290 - mse: 231527.2344 - val_loss: 173873.6094 - val_mae: 197.1524 - val_mse: 173873.6094\n",
      "Epoch 308/1000\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 232570.4062 - mae: 230.0798 - mse: 232570.4062 - val_loss: 182072.6250 - val_mae: 208.2169 - val_mse: 182072.6250\n",
      "Epoch 309/1000\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 231275.3750 - mae: 230.7009 - mse: 231275.3750 - val_loss: 171869.2812 - val_mae: 194.9490 - val_mse: 171869.2812\n",
      "Epoch 310/1000\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 233973.7188 - mae: 230.9797 - mse: 233973.7188 - val_loss: 171617.6719 - val_mae: 196.3321 - val_mse: 171617.6719\n",
      "Epoch 311/1000\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 228674.0000 - mae: 228.8465 - mse: 228674.0000 - val_loss: 177967.7812 - val_mae: 204.1152 - val_mse: 177967.7812\n",
      "Epoch 312/1000\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 223239.7031 - mae: 227.8890 - mse: 223239.7031 - val_loss: 169430.6875 - val_mae: 196.2487 - val_mse: 169430.6875\n",
      "Epoch 313/1000\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 238643.7500 - mae: 232.9727 - mse: 238643.7500 - val_loss: 175211.9219 - val_mae: 199.7422 - val_mse: 175211.9219\n",
      "Epoch 314/1000\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 231239.7969 - mae: 231.3273 - mse: 231239.7969 - val_loss: 170579.4219 - val_mae: 195.9429 - val_mse: 170579.4219\n",
      "Epoch 315/1000\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 233479.6250 - mae: 231.2376 - mse: 233479.6250 - val_loss: 185914.5312 - val_mae: 203.7715 - val_mse: 185914.5312\n",
      "Epoch 316/1000\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 231765.9531 - mae: 230.6504 - mse: 231765.9531 - val_loss: 170205.6406 - val_mae: 194.9900 - val_mse: 170205.6406\n",
      "Epoch 317/1000\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 238135.1250 - mae: 232.5270 - mse: 238135.1250 - val_loss: 177896.9062 - val_mae: 200.5147 - val_mse: 177896.9062\n",
      "Epoch 318/1000\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 233762.6094 - mae: 232.8078 - mse: 233762.6094 - val_loss: 170659.3438 - val_mae: 198.1263 - val_mse: 170659.3438\n",
      "Epoch 319/1000\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 231534.3438 - mae: 231.7486 - mse: 231534.3438 - val_loss: 186685.5312 - val_mae: 203.8306 - val_mse: 186685.5312\n",
      "Epoch 320/1000\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 233268.0000 - mae: 231.8074 - mse: 233268.0000 - val_loss: 174439.2031 - val_mae: 197.3725 - val_mse: 174439.2031\n",
      "Epoch 321/1000\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 236128.5312 - mae: 232.3133 - mse: 236128.5312 - val_loss: 171284.9219 - val_mae: 200.5687 - val_mse: 171284.9219\n",
      "Epoch 322/1000\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 236633.8594 - mae: 234.1178 - mse: 236633.8594 - val_loss: 177036.0156 - val_mae: 198.9534 - val_mse: 177036.0156\n",
      "Epoch 323/1000\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 232010.3750 - mae: 229.7459 - mse: 232010.3750 - val_loss: 169625.7969 - val_mae: 196.1856 - val_mse: 169625.7969\n",
      "Epoch 324/1000\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 233869.7969 - mae: 232.0556 - mse: 233869.7969 - val_loss: 176021.6875 - val_mae: 201.8595 - val_mse: 176021.6875\n",
      "Epoch 325/1000\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 226427.5156 - mae: 228.7410 - mse: 226427.5156 - val_loss: 168916.2969 - val_mae: 195.2655 - val_mse: 168916.2969\n",
      "Epoch 326/1000\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 224005.4375 - mae: 228.3394 - mse: 224005.4375 - val_loss: 177252.0938 - val_mae: 200.6322 - val_mse: 177252.0938\n",
      "Epoch 327/1000\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 231124.3438 - mae: 229.8954 - mse: 231124.3438 - val_loss: 173169.5625 - val_mae: 199.7828 - val_mse: 173169.5625\n",
      "Epoch 328/1000\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 225562.0938 - mae: 228.4567 - mse: 225562.0938 - val_loss: 175649.5312 - val_mae: 203.5705 - val_mse: 175649.5312\n",
      "Epoch 329/1000\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 229933.4844 - mae: 230.4537 - mse: 229933.4844 - val_loss: 173913.6094 - val_mae: 200.8620 - val_mse: 173913.6094\n",
      "Epoch 330/1000\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 227175.0156 - mae: 229.5757 - mse: 227175.0156 - val_loss: 178368.3281 - val_mae: 203.8541 - val_mse: 178368.3281\n",
      "Epoch 331/1000\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 231088.7500 - mae: 230.6665 - mse: 231088.7500 - val_loss: 170290.5312 - val_mae: 199.6699 - val_mse: 170290.5312\n",
      "Epoch 332/1000\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 237369.7031 - mae: 232.6045 - mse: 237369.7031 - val_loss: 171386.4844 - val_mae: 198.7799 - val_mse: 171386.4844\n",
      "Epoch 333/1000\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 231364.9844 - mae: 230.6881 - mse: 231364.9844 - val_loss: 173124.6406 - val_mae: 199.1601 - val_mse: 173124.6406\n",
      "Epoch 334/1000\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 226879.6406 - mae: 230.2944 - mse: 226879.6406 - val_loss: 174652.0781 - val_mae: 202.2811 - val_mse: 174652.0781\n",
      "Epoch 335/1000\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 230947.6094 - mae: 231.3330 - mse: 230947.6094 - val_loss: 168079.8438 - val_mae: 193.0006 - val_mse: 168079.8438\n",
      "Epoch 336/1000\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 225285.3906 - mae: 229.0030 - mse: 225285.3906 - val_loss: 172809.0156 - val_mae: 196.2082 - val_mse: 172809.0156\n",
      "Epoch 337/1000\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 243540.8125 - mae: 234.5694 - mse: 243540.8125 - val_loss: 181215.3281 - val_mae: 203.2473 - val_mse: 181215.3281\n",
      "Epoch 338/1000\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 234727.3281 - mae: 232.3179 - mse: 234727.3281 - val_loss: 165808.6562 - val_mae: 192.9342 - val_mse: 165808.6562\n",
      "Epoch 339/1000\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 229358.0625 - mae: 231.0724 - mse: 229358.0625 - val_loss: 176533.9062 - val_mae: 204.9414 - val_mse: 176533.9062\n",
      "Epoch 340/1000\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 232908.6719 - mae: 231.1877 - mse: 232908.6719 - val_loss: 169089.9688 - val_mae: 195.7629 - val_mse: 169089.9688\n",
      "Epoch 341/1000\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 234885.6250 - mae: 233.7486 - mse: 234885.6250 - val_loss: 169780.5469 - val_mae: 196.1931 - val_mse: 169780.5469\n",
      "Epoch 342/1000\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 238000.3594 - mae: 233.6324 - mse: 238000.3594 - val_loss: 167386.1094 - val_mae: 195.5820 - val_mse: 167386.1094\n",
      "Epoch 343/1000\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 226076.9688 - mae: 230.3969 - mse: 226076.9688 - val_loss: 170595.2656 - val_mae: 199.4501 - val_mse: 170595.2656\n",
      "Epoch 344/1000\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 223611.8281 - mae: 227.9298 - mse: 223611.8281 - val_loss: 170582.9375 - val_mae: 197.0134 - val_mse: 170582.9375\n",
      "Epoch 345/1000\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 232339.6719 - mae: 231.8181 - mse: 232339.6719 - val_loss: 165096.6406 - val_mae: 193.0584 - val_mse: 165096.6406\n",
      "Epoch 346/1000\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 228338.6406 - mae: 231.5269 - mse: 228338.6406 - val_loss: 183969.4531 - val_mae: 208.4841 - val_mse: 183969.4531\n",
      "Epoch 347/1000\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 226660.4844 - mae: 229.9225 - mse: 226660.4844 - val_loss: 181313.3438 - val_mae: 208.5120 - val_mse: 181313.3438\n",
      "Epoch 348/1000\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 224158.6562 - mae: 228.9278 - mse: 224158.6562 - val_loss: 170060.1875 - val_mae: 200.0816 - val_mse: 170060.1875\n",
      "Epoch 349/1000\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 227517.5156 - mae: 230.9828 - mse: 227517.5156 - val_loss: 176186.4531 - val_mae: 200.4835 - val_mse: 176186.4531\n",
      "Epoch 350/1000\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 232897.7188 - mae: 231.8105 - mse: 232897.7188 - val_loss: 171193.0000 - val_mae: 196.9631 - val_mse: 171193.0000\n",
      "Epoch 351/1000\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 227918.8594 - mae: 230.1541 - mse: 227918.8594 - val_loss: 167327.7344 - val_mae: 195.7391 - val_mse: 167327.7344\n",
      "Epoch 352/1000\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 230090.7188 - mae: 232.0933 - mse: 230090.7188 - val_loss: 177245.1094 - val_mae: 201.4074 - val_mse: 177245.1094\n",
      "Epoch 353/1000\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 229178.9219 - mae: 231.1035 - mse: 229178.9219 - val_loss: 172126.9062 - val_mae: 200.3370 - val_mse: 172126.9062\n",
      "Epoch 354/1000\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 228892.6094 - mae: 230.0887 - mse: 228892.6094 - val_loss: 165910.0781 - val_mae: 193.9834 - val_mse: 165910.0781\n",
      "Epoch 355/1000\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 228103.5938 - mae: 230.8629 - mse: 228103.5938 - val_loss: 170826.3750 - val_mae: 197.1574 - val_mse: 170826.3750\n",
      "Epoch 356/1000\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 225467.0000 - mae: 229.8841 - mse: 225467.0000 - val_loss: 172906.4688 - val_mae: 199.1487 - val_mse: 172906.4688\n",
      "Epoch 357/1000\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 227651.9062 - mae: 230.4089 - mse: 227651.9062 - val_loss: 177917.9531 - val_mae: 203.8897 - val_mse: 177917.9531\n",
      "Epoch 358/1000\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 231088.8594 - mae: 231.6721 - mse: 231088.8594 - val_loss: 175867.1562 - val_mae: 202.9990 - val_mse: 175867.1562\n",
      "Epoch 359/1000\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 222757.9688 - mae: 227.9714 - mse: 222757.9688 - val_loss: 172887.3906 - val_mae: 198.6945 - val_mse: 172887.3906\n",
      "Epoch 360/1000\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 225500.5312 - mae: 230.0420 - mse: 225500.5312 - val_loss: 169666.2812 - val_mae: 198.2099 - val_mse: 169666.2812\n",
      "Epoch 361/1000\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 226078.3281 - mae: 230.8104 - mse: 226078.3281 - val_loss: 182904.5000 - val_mae: 205.6031 - val_mse: 182904.5000\n",
      "Epoch 362/1000\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 223004.5000 - mae: 228.7702 - mse: 223004.5000 - val_loss: 167312.9531 - val_mae: 197.9239 - val_mse: 167312.9531\n",
      "Epoch 363/1000\n",
      "707/707 [==============================] - 1s 2ms/step - loss: 221987.8750 - mae: 228.7773 - mse: 221987.8750 - val_loss: 170315.9844 - val_mae: 202.6924 - val_mse: 170315.9844\n",
      "Epoch 364/1000\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 232348.2969 - mae: 233.9693 - mse: 232348.2969 - val_loss: 175039.9844 - val_mae: 203.1702 - val_mse: 175039.9844\n",
      "Epoch 365/1000\n",
      "707/707 [==============================] - 1s 2ms/step - loss: 225979.5781 - mae: 229.4052 - mse: 225979.5781 - val_loss: 168760.7031 - val_mae: 196.1727 - val_mse: 168760.7031\n",
      "Epoch 366/1000\n",
      "707/707 [==============================] - 2s 3ms/step - loss: 225295.9844 - mae: 231.6165 - mse: 225295.9844 - val_loss: 165947.9531 - val_mae: 193.0789 - val_mse: 165947.9531\n",
      "Epoch 367/1000\n",
      "707/707 [==============================] - 2s 3ms/step - loss: 229014.8281 - mae: 230.8114 - mse: 229014.8281 - val_loss: 183897.5000 - val_mae: 209.2556 - val_mse: 183897.5000\n",
      "Epoch 368/1000\n",
      "707/707 [==============================] - 2s 2ms/step - loss: 228399.2344 - mae: 230.1802 - mse: 228399.2344 - val_loss: 186713.6562 - val_mae: 208.3434 - val_mse: 186713.6562\n",
      "Epoch 369/1000\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 229918.5938 - mae: 232.3592 - mse: 229918.5938 - val_loss: 169676.2344 - val_mae: 197.2748 - val_mse: 169676.2344\n",
      "Epoch 370/1000\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 226380.8438 - mae: 231.2421 - mse: 226380.8438 - val_loss: 171359.3438 - val_mae: 199.2548 - val_mse: 171359.3438\n",
      "Epoch 371/1000\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 232555.5625 - mae: 231.9881 - mse: 232555.5625 - val_loss: 166640.4844 - val_mae: 197.0578 - val_mse: 166640.4844\n",
      "Epoch 372/1000\n",
      "707/707 [==============================] - 1s 2ms/step - loss: 224416.5000 - mae: 230.7779 - mse: 224416.5000 - val_loss: 187715.3906 - val_mae: 210.7522 - val_mse: 187715.3906\n",
      "Epoch 373/1000\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 227633.4375 - mae: 230.7560 - mse: 227633.4375 - val_loss: 169105.0781 - val_mae: 196.6695 - val_mse: 169105.0781\n",
      "Epoch 374/1000\n",
      "707/707 [==============================] - 1s 2ms/step - loss: 227874.7031 - mae: 230.7105 - mse: 227874.7031 - val_loss: 173758.2188 - val_mae: 200.8496 - val_mse: 173758.2188\n",
      "Epoch 375/1000\n",
      "707/707 [==============================] - 1s 2ms/step - loss: 223276.9844 - mae: 230.6096 - mse: 223276.9844 - val_loss: 170799.6719 - val_mae: 195.3690 - val_mse: 170799.6719\n",
      "Epoch 376/1000\n",
      "707/707 [==============================] - 1s 2ms/step - loss: 228973.3438 - mae: 230.6562 - mse: 228973.3438 - val_loss: 170865.7344 - val_mae: 194.2881 - val_mse: 170865.7344\n",
      "Epoch 377/1000\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 235490.9688 - mae: 233.8124 - mse: 235490.9688 - val_loss: 168184.8125 - val_mae: 198.7446 - val_mse: 168184.8125\n",
      "Epoch 378/1000\n",
      "707/707 [==============================] - 1s 2ms/step - loss: 231097.6406 - mae: 231.4894 - mse: 231097.6406 - val_loss: 164199.3438 - val_mae: 193.6324 - val_mse: 164199.3438\n",
      "Epoch 379/1000\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 225178.3438 - mae: 228.2324 - mse: 225178.3438 - val_loss: 169330.7969 - val_mae: 199.0946 - val_mse: 169330.7969\n",
      "Epoch 380/1000\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 228986.9531 - mae: 231.2885 - mse: 228986.9531 - val_loss: 166949.9062 - val_mae: 194.1205 - val_mse: 166949.9062\n",
      "Epoch 381/1000\n",
      "707/707 [==============================] - 1s 2ms/step - loss: 227632.0469 - mae: 231.1754 - mse: 227632.0469 - val_loss: 169112.7656 - val_mae: 197.3976 - val_mse: 169112.7656\n",
      "Epoch 382/1000\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 227034.0938 - mae: 230.7448 - mse: 227034.0938 - val_loss: 175565.2500 - val_mae: 198.9938 - val_mse: 175565.2500\n",
      "Epoch 383/1000\n",
      "707/707 [==============================] - 1s 2ms/step - loss: 227558.5938 - mae: 230.6431 - mse: 227558.5938 - val_loss: 167598.0938 - val_mae: 196.7410 - val_mse: 167598.0938\n",
      "Epoch 384/1000\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 225028.9688 - mae: 231.7993 - mse: 225028.9688 - val_loss: 174373.1406 - val_mae: 203.2589 - val_mse: 174373.1406\n",
      "Epoch 385/1000\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 221530.4062 - mae: 229.1108 - mse: 221530.4062 - val_loss: 163336.5000 - val_mae: 196.6837 - val_mse: 163336.5000\n",
      "Epoch 386/1000\n",
      "707/707 [==============================] - 1s 2ms/step - loss: 226092.9531 - mae: 231.5383 - mse: 226092.9531 - val_loss: 165023.1250 - val_mae: 194.1475 - val_mse: 165023.1250\n",
      "Epoch 387/1000\n",
      "707/707 [==============================] - 1s 2ms/step - loss: 224810.1562 - mae: 230.3858 - mse: 224810.1562 - val_loss: 165744.5156 - val_mae: 193.8461 - val_mse: 165744.5156\n",
      "Epoch 388/1000\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 227391.5312 - mae: 231.6247 - mse: 227391.5312 - val_loss: 172457.0781 - val_mae: 200.3020 - val_mse: 172457.0781\n",
      "Epoch 389/1000\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 230672.2188 - mae: 232.2500 - mse: 230672.2188 - val_loss: 171615.4062 - val_mae: 199.2706 - val_mse: 171615.4062\n",
      "Epoch 390/1000\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 221581.6406 - mae: 230.0717 - mse: 221581.6406 - val_loss: 173156.7500 - val_mae: 201.2775 - val_mse: 173156.7500\n",
      "Epoch 391/1000\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 221898.7188 - mae: 229.4192 - mse: 221898.7188 - val_loss: 168558.7344 - val_mae: 198.5767 - val_mse: 168558.7344\n",
      "Epoch 392/1000\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 217526.3281 - mae: 226.9872 - mse: 217526.3281 - val_loss: 167675.0781 - val_mae: 199.5315 - val_mse: 167675.0781\n",
      "Epoch 393/1000\n",
      "707/707 [==============================] - 1s 2ms/step - loss: 217307.9844 - mae: 228.4474 - mse: 217307.9844 - val_loss: 169953.7812 - val_mae: 200.9767 - val_mse: 169953.7812\n",
      "Epoch 394/1000\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 222778.2812 - mae: 230.4899 - mse: 222778.2812 - val_loss: 175857.3281 - val_mae: 201.1224 - val_mse: 175857.3281\n",
      "Epoch 395/1000\n",
      "707/707 [==============================] - 1s 2ms/step - loss: 220302.1406 - mae: 228.8360 - mse: 220302.1406 - val_loss: 176794.9531 - val_mae: 204.0305 - val_mse: 176794.9531\n",
      "Epoch 396/1000\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 218066.0469 - mae: 228.2003 - mse: 218066.0469 - val_loss: 173481.8906 - val_mae: 205.1589 - val_mse: 173481.8906\n",
      "Epoch 397/1000\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 228115.1719 - mae: 233.7126 - mse: 228115.1719 - val_loss: 176661.6250 - val_mae: 201.3046 - val_mse: 176661.6250\n",
      "Epoch 398/1000\n",
      "707/707 [==============================] - 1s 2ms/step - loss: 226873.7031 - mae: 230.6512 - mse: 226873.7031 - val_loss: 167218.5000 - val_mae: 198.2974 - val_mse: 167218.5000\n",
      "Epoch 399/1000\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 220762.8281 - mae: 228.8822 - mse: 220762.8281 - val_loss: 163951.6719 - val_mae: 196.4698 - val_mse: 163951.6719\n",
      "Epoch 400/1000\n",
      "707/707 [==============================] - 1s 2ms/step - loss: 226507.5156 - mae: 232.1946 - mse: 226507.5156 - val_loss: 175338.8594 - val_mae: 205.3499 - val_mse: 175338.8594\n",
      "Epoch 401/1000\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 226300.1094 - mae: 231.3474 - mse: 226300.1094 - val_loss: 189607.3906 - val_mae: 212.2502 - val_mse: 189607.3906\n",
      "Epoch 402/1000\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 228456.4219 - mae: 232.5416 - mse: 228456.4219 - val_loss: 170417.6094 - val_mae: 200.9836 - val_mse: 170417.6094\n",
      "Epoch 403/1000\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 222492.5312 - mae: 229.8125 - mse: 222492.5312 - val_loss: 181612.7031 - val_mae: 209.5864 - val_mse: 181612.7031\n",
      "Epoch 404/1000\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 225537.1875 - mae: 232.5469 - mse: 225537.1875 - val_loss: 171064.6250 - val_mae: 197.8878 - val_mse: 171064.6250\n",
      "Epoch 405/1000\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 219944.0781 - mae: 229.8550 - mse: 219944.0781 - val_loss: 165682.3750 - val_mae: 196.6322 - val_mse: 165682.3750\n",
      "Epoch 406/1000\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 224899.3594 - mae: 230.8383 - mse: 224899.3594 - val_loss: 177719.7969 - val_mae: 205.4241 - val_mse: 177719.7969\n",
      "Epoch 407/1000\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 233243.4688 - mae: 235.2191 - mse: 233243.4688 - val_loss: 168100.9844 - val_mae: 200.4710 - val_mse: 168100.9844\n",
      "Epoch 408/1000\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 226454.3281 - mae: 231.2455 - mse: 226454.3281 - val_loss: 176382.1875 - val_mae: 205.4038 - val_mse: 176382.1875\n",
      "Epoch 409/1000\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 223708.5938 - mae: 231.4803 - mse: 223708.5938 - val_loss: 170868.7969 - val_mae: 197.8618 - val_mse: 170868.7969\n",
      "Epoch 410/1000\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 219364.4062 - mae: 228.1730 - mse: 219364.4062 - val_loss: 163820.3281 - val_mae: 194.9430 - val_mse: 163820.3281\n",
      "Epoch 411/1000\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 225078.1406 - mae: 232.3435 - mse: 225078.1406 - val_loss: 169841.6094 - val_mae: 197.3736 - val_mse: 169841.6094\n",
      "Epoch 412/1000\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 222834.9688 - mae: 229.6629 - mse: 222834.9688 - val_loss: 172971.1250 - val_mae: 203.5078 - val_mse: 172971.1250\n",
      "Epoch 413/1000\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 219084.7500 - mae: 228.7333 - mse: 219084.7500 - val_loss: 172129.9844 - val_mae: 200.8254 - val_mse: 172129.9844\n",
      "Epoch 414/1000\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 223359.1719 - mae: 231.3067 - mse: 223359.1719 - val_loss: 186463.8281 - val_mae: 207.3512 - val_mse: 186463.8281\n",
      "Epoch 415/1000\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 227187.9219 - mae: 232.8746 - mse: 227187.9219 - val_loss: 173167.5312 - val_mae: 203.5500 - val_mse: 173167.5312\n",
      "Epoch 416/1000\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 215145.2344 - mae: 227.5985 - mse: 215145.2344 - val_loss: 164989.4375 - val_mae: 197.3359 - val_mse: 164989.4375\n",
      "Epoch 417/1000\n",
      "707/707 [==============================] - 1s 2ms/step - loss: 220977.4844 - mae: 230.5368 - mse: 220977.4844 - val_loss: 164273.7656 - val_mae: 194.2846 - val_mse: 164273.7656\n",
      "Epoch 418/1000\n",
      "707/707 [==============================] - 1s 2ms/step - loss: 228539.2031 - mae: 232.3884 - mse: 228539.2031 - val_loss: 167444.9375 - val_mae: 199.0501 - val_mse: 167444.9375\n",
      "Epoch 419/1000\n",
      "707/707 [==============================] - 1s 2ms/step - loss: 222256.7656 - mae: 229.3199 - mse: 222256.7656 - val_loss: 164380.7031 - val_mae: 195.4401 - val_mse: 164380.7031\n",
      "Epoch 420/1000\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 218425.3281 - mae: 229.0131 - mse: 218425.3281 - val_loss: 170046.6250 - val_mae: 198.6534 - val_mse: 170046.6250\n",
      "Epoch 421/1000\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 218905.3281 - mae: 229.6511 - mse: 218905.3281 - val_loss: 164368.8594 - val_mae: 196.7013 - val_mse: 164368.8594\n",
      "Epoch 422/1000\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 220646.3750 - mae: 229.4683 - mse: 220646.3750 - val_loss: 166829.2812 - val_mae: 199.3678 - val_mse: 166829.2812\n",
      "Epoch 423/1000\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 221415.2188 - mae: 230.0466 - mse: 221415.2188 - val_loss: 163863.3906 - val_mae: 192.4435 - val_mse: 163863.3906\n",
      "Epoch 424/1000\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 225057.0156 - mae: 230.7554 - mse: 225057.0156 - val_loss: 165272.0312 - val_mae: 197.4384 - val_mse: 165272.0312\n",
      "Epoch 425/1000\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 226882.5312 - mae: 232.8931 - mse: 226882.5312 - val_loss: 166556.7188 - val_mae: 197.4678 - val_mse: 166556.7188\n",
      "Epoch 426/1000\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 225975.5469 - mae: 230.5469 - mse: 225975.5469 - val_loss: 185086.0625 - val_mae: 212.4269 - val_mse: 185086.0625\n",
      "Epoch 427/1000\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 217539.5938 - mae: 228.1398 - mse: 217539.5938 - val_loss: 167052.1562 - val_mae: 199.3177 - val_mse: 167052.1562\n",
      "Epoch 428/1000\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 220763.2656 - mae: 230.7572 - mse: 220763.2656 - val_loss: 179619.1719 - val_mae: 206.1812 - val_mse: 179619.1719\n",
      "Epoch 429/1000\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 226251.9062 - mae: 232.0386 - mse: 226251.9062 - val_loss: 166904.1250 - val_mae: 199.8084 - val_mse: 166904.1250\n",
      "Epoch 430/1000\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 221156.0156 - mae: 231.0763 - mse: 221156.0156 - val_loss: 180247.6406 - val_mae: 207.3116 - val_mse: 180247.6406\n",
      "Epoch 431/1000\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 220797.9844 - mae: 230.4478 - mse: 220797.9844 - val_loss: 175960.0000 - val_mae: 204.4971 - val_mse: 175960.0000\n",
      "Epoch 432/1000\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 228460.3125 - mae: 233.1920 - mse: 228460.3125 - val_loss: 177262.7656 - val_mae: 204.2052 - val_mse: 177262.7656\n",
      "Epoch 433/1000\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 224920.6562 - mae: 230.6695 - mse: 224920.6562 - val_loss: 168405.7500 - val_mae: 197.1503 - val_mse: 168405.7500\n",
      "Epoch 434/1000\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 225457.5625 - mae: 231.8670 - mse: 225457.5625 - val_loss: 167651.7188 - val_mae: 200.8845 - val_mse: 167651.7188\n",
      "Epoch 435/1000\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 226688.8125 - mae: 232.5779 - mse: 226688.8125 - val_loss: 170206.4219 - val_mae: 198.6857 - val_mse: 170206.4219\n",
      "Epoch 436/1000\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 217185.9219 - mae: 227.5856 - mse: 217185.9219 - val_loss: 179083.0781 - val_mae: 209.8778 - val_mse: 179083.0781\n",
      "Epoch 437/1000\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 221506.5938 - mae: 230.4711 - mse: 221506.5938 - val_loss: 168783.5156 - val_mae: 200.4967 - val_mse: 168783.5156\n",
      "Epoch 438/1000\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 220372.7031 - mae: 229.4262 - mse: 220372.7031 - val_loss: 162541.7344 - val_mae: 193.7280 - val_mse: 162541.7344\n",
      "Epoch 439/1000\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 219116.5781 - mae: 229.6055 - mse: 219116.5781 - val_loss: 163211.0781 - val_mae: 193.8233 - val_mse: 163211.0781\n",
      "Epoch 440/1000\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 216753.7031 - mae: 229.1632 - mse: 216753.7031 - val_loss: 166569.9219 - val_mae: 198.0187 - val_mse: 166569.9219\n",
      "Epoch 441/1000\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 220525.2188 - mae: 231.5756 - mse: 220525.2188 - val_loss: 168430.1094 - val_mae: 196.8681 - val_mse: 168430.1094\n",
      "Epoch 442/1000\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 217795.3125 - mae: 228.7057 - mse: 217795.3125 - val_loss: 163960.9531 - val_mae: 198.7199 - val_mse: 163960.9531\n",
      "Epoch 443/1000\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 220035.9844 - mae: 230.4605 - mse: 220035.9844 - val_loss: 169846.6562 - val_mae: 200.5065 - val_mse: 169846.6562\n",
      "Epoch 444/1000\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 219707.6562 - mae: 229.3612 - mse: 219707.6562 - val_loss: 165292.4844 - val_mae: 195.2447 - val_mse: 165292.4844\n",
      "Epoch 445/1000\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 217048.2031 - mae: 228.8527 - mse: 217048.2031 - val_loss: 165679.4844 - val_mae: 196.7903 - val_mse: 165679.4844\n",
      "Epoch 446/1000\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 212672.0312 - mae: 228.1441 - mse: 212672.0312 - val_loss: 163937.6250 - val_mae: 195.2191 - val_mse: 163937.6250\n",
      "Epoch 447/1000\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 219936.2656 - mae: 229.2237 - mse: 219936.2656 - val_loss: 168099.6406 - val_mae: 200.4777 - val_mse: 168099.6406\n",
      "Epoch 448/1000\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 218395.7656 - mae: 230.2663 - mse: 218395.7656 - val_loss: 169558.4531 - val_mae: 201.0908 - val_mse: 169558.4531\n",
      "Epoch 449/1000\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 220657.3125 - mae: 229.9814 - mse: 220657.3125 - val_loss: 176741.7031 - val_mae: 206.3742 - val_mse: 176741.7031\n",
      "Epoch 450/1000\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 218257.9844 - mae: 229.6212 - mse: 218257.9844 - val_loss: 168464.4688 - val_mae: 197.7303 - val_mse: 168464.4688\n",
      "Epoch 451/1000\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 224742.4688 - mae: 231.5617 - mse: 224742.4688 - val_loss: 166300.0781 - val_mae: 199.7531 - val_mse: 166300.0781\n",
      "Epoch 452/1000\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 219575.9219 - mae: 230.0204 - mse: 219575.9219 - val_loss: 167164.8125 - val_mae: 198.8931 - val_mse: 167164.8125\n",
      "Epoch 453/1000\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 221758.6250 - mae: 231.1559 - mse: 221758.6250 - val_loss: 171370.5938 - val_mae: 204.1120 - val_mse: 171370.5938\n",
      "Epoch 454/1000\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 219404.8750 - mae: 229.3778 - mse: 219404.8750 - val_loss: 170055.0938 - val_mae: 201.7825 - val_mse: 170055.0938\n",
      "Epoch 455/1000\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 214863.4531 - mae: 228.1952 - mse: 214863.4531 - val_loss: 166093.4375 - val_mae: 197.8921 - val_mse: 166093.4375\n",
      "Epoch 456/1000\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 224151.5156 - mae: 232.5713 - mse: 224151.5156 - val_loss: 162727.7656 - val_mae: 195.3436 - val_mse: 162727.7656\n",
      "Epoch 457/1000\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 221894.9062 - mae: 230.6927 - mse: 221894.9062 - val_loss: 172522.5312 - val_mae: 202.0572 - val_mse: 172522.5312\n",
      "Epoch 458/1000\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 220533.4219 - mae: 230.8123 - mse: 220533.4219 - val_loss: 165914.3750 - val_mae: 200.3134 - val_mse: 165914.3750\n",
      "Epoch 459/1000\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 224147.6875 - mae: 233.1843 - mse: 224147.6875 - val_loss: 164526.9375 - val_mae: 197.7031 - val_mse: 164526.9375\n",
      "Epoch 460/1000\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 215822.4531 - mae: 229.7773 - mse: 215822.4531 - val_loss: 163374.7031 - val_mae: 199.2381 - val_mse: 163374.7031\n",
      "Epoch 461/1000\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 222968.6719 - mae: 229.6827 - mse: 222968.6719 - val_loss: 168851.0938 - val_mae: 200.8670 - val_mse: 168851.0938\n",
      "Epoch 462/1000\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 220138.5781 - mae: 232.2339 - mse: 220138.5781 - val_loss: 164506.6719 - val_mae: 197.5030 - val_mse: 164506.6719\n",
      "Epoch 463/1000\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 221524.2344 - mae: 230.5388 - mse: 221524.2344 - val_loss: 172240.7969 - val_mae: 205.9873 - val_mse: 172240.7969\n",
      "Epoch 464/1000\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 222597.9688 - mae: 231.1986 - mse: 222597.9688 - val_loss: 162454.2656 - val_mae: 196.9209 - val_mse: 162454.2656\n",
      "Epoch 465/1000\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 219386.8750 - mae: 229.7815 - mse: 219386.8750 - val_loss: 169586.1719 - val_mae: 201.7032 - val_mse: 169586.1719\n",
      "Epoch 466/1000\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 218083.1719 - mae: 230.9074 - mse: 218083.1719 - val_loss: 161962.0781 - val_mae: 196.3599 - val_mse: 161962.0781\n",
      "Epoch 467/1000\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 219752.1875 - mae: 228.7217 - mse: 219752.1875 - val_loss: 169858.4531 - val_mae: 205.9818 - val_mse: 169858.4531\n",
      "Epoch 468/1000\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 218800.8906 - mae: 229.6570 - mse: 218800.8906 - val_loss: 170169.9688 - val_mae: 201.5004 - val_mse: 170169.9688\n",
      "Epoch 469/1000\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 223865.5469 - mae: 232.2080 - mse: 223865.5469 - val_loss: 170848.8750 - val_mae: 202.9208 - val_mse: 170848.8750\n",
      "Epoch 470/1000\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 214101.3750 - mae: 229.2550 - mse: 214101.3750 - val_loss: 168121.9062 - val_mae: 201.4087 - val_mse: 168121.9062\n",
      "Epoch 471/1000\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 214425.4375 - mae: 226.8231 - mse: 214425.4375 - val_loss: 168069.9531 - val_mae: 204.6043 - val_mse: 168069.9531\n",
      "Epoch 472/1000\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 215305.1406 - mae: 229.5520 - mse: 215305.1406 - val_loss: 172954.5625 - val_mae: 207.7037 - val_mse: 172954.5625\n",
      "Epoch 473/1000\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 219858.5469 - mae: 230.9289 - mse: 219858.5469 - val_loss: 168541.1094 - val_mae: 198.6312 - val_mse: 168541.1094\n",
      "Epoch 474/1000\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 216436.5625 - mae: 228.5359 - mse: 216436.5625 - val_loss: 167485.1250 - val_mae: 201.9027 - val_mse: 167485.1250\n",
      "Epoch 475/1000\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 220844.3281 - mae: 230.5402 - mse: 220844.3281 - val_loss: 168821.4062 - val_mae: 200.1259 - val_mse: 168821.4062\n",
      "Epoch 476/1000\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 215290.3125 - mae: 228.2814 - mse: 215290.3125 - val_loss: 168475.0938 - val_mae: 199.1560 - val_mse: 168475.0938\n",
      "Epoch 477/1000\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 215428.1875 - mae: 229.0280 - mse: 215428.1875 - val_loss: 171002.1094 - val_mae: 201.9567 - val_mse: 171002.1094\n",
      "Epoch 478/1000\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 224360.0312 - mae: 232.3085 - mse: 224360.0312 - val_loss: 172335.1094 - val_mae: 203.4850 - val_mse: 172335.1094\n",
      "Epoch 479/1000\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 209512.2812 - mae: 227.0221 - mse: 209512.2812 - val_loss: 168349.3750 - val_mae: 202.0559 - val_mse: 168349.3750\n",
      "Epoch 480/1000\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 216566.6875 - mae: 228.1652 - mse: 216566.6875 - val_loss: 166753.3594 - val_mae: 198.3083 - val_mse: 166753.3594\n",
      "Epoch 481/1000\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 224335.6406 - mae: 231.4015 - mse: 224335.6406 - val_loss: 185477.3438 - val_mae: 212.6528 - val_mse: 185477.3438\n",
      "Epoch 482/1000\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 217542.7656 - mae: 230.4999 - mse: 217542.7656 - val_loss: 175292.2500 - val_mae: 207.1017 - val_mse: 175292.2500\n",
      "Epoch 483/1000\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 214375.5000 - mae: 228.9120 - mse: 214375.5000 - val_loss: 164400.1406 - val_mae: 198.6965 - val_mse: 164400.1406\n",
      "Epoch 484/1000\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 216611.2031 - mae: 230.1618 - mse: 216611.2031 - val_loss: 170261.0625 - val_mae: 202.1248 - val_mse: 170261.0625\n",
      "Epoch 485/1000\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 215384.0156 - mae: 231.2970 - mse: 215384.0156 - val_loss: 163426.2031 - val_mae: 196.2732 - val_mse: 163426.2031\n",
      "Epoch 486/1000\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 219517.5312 - mae: 231.9020 - mse: 219517.5312 - val_loss: 163348.8438 - val_mae: 200.7570 - val_mse: 163348.8438\n",
      "Epoch 487/1000\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 212882.5312 - mae: 228.5924 - mse: 212882.5312 - val_loss: 172480.6719 - val_mae: 201.6568 - val_mse: 172480.6719\n",
      "Epoch 488/1000\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 218920.6562 - mae: 230.6797 - mse: 218920.6562 - val_loss: 167061.1562 - val_mae: 199.7079 - val_mse: 167061.1562\n",
      "Epoch 489/1000\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 216126.3125 - mae: 231.3337 - mse: 216126.3125 - val_loss: 165398.2500 - val_mae: 197.8165 - val_mse: 165398.2500\n",
      "Epoch 490/1000\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 213822.1094 - mae: 227.4650 - mse: 213822.1094 - val_loss: 164069.7344 - val_mae: 201.6011 - val_mse: 164069.7344\n",
      "Epoch 491/1000\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 217749.2031 - mae: 230.5038 - mse: 217749.2031 - val_loss: 171526.2344 - val_mae: 204.9390 - val_mse: 171526.2344\n",
      "Epoch 492/1000\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 213055.5938 - mae: 228.7245 - mse: 213055.5938 - val_loss: 177734.8281 - val_mae: 211.5930 - val_mse: 177734.8281\n",
      "Epoch 493/1000\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 220479.1562 - mae: 229.8882 - mse: 220479.1562 - val_loss: 168284.3906 - val_mae: 203.9839 - val_mse: 168284.3906\n",
      "Epoch 494/1000\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 220788.3281 - mae: 231.6157 - mse: 220788.3281 - val_loss: 175183.8594 - val_mae: 207.2757 - val_mse: 175183.8594\n",
      "Epoch 495/1000\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 213124.5781 - mae: 228.3740 - mse: 213124.5781 - val_loss: 170718.0938 - val_mae: 201.5967 - val_mse: 170718.0938\n",
      "Epoch 496/1000\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 220171.5312 - mae: 232.0360 - mse: 220171.5312 - val_loss: 173824.5000 - val_mae: 206.8841 - val_mse: 173824.5000\n",
      "Epoch 497/1000\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 209966.5469 - mae: 227.6995 - mse: 209966.5469 - val_loss: 162548.5469 - val_mae: 194.0100 - val_mse: 162548.5469\n",
      "Epoch 498/1000\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 215243.9688 - mae: 229.4135 - mse: 215243.9688 - val_loss: 165347.0625 - val_mae: 196.1047 - val_mse: 165347.0625\n",
      "Epoch 499/1000\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 220010.7812 - mae: 230.2143 - mse: 220010.7812 - val_loss: 161778.5156 - val_mae: 196.7385 - val_mse: 161778.5156\n",
      "Epoch 500/1000\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 214095.8438 - mae: 228.5730 - mse: 214095.8438 - val_loss: 168823.3125 - val_mae: 200.4639 - val_mse: 168823.3125\n",
      "Epoch 501/1000\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 219663.4688 - mae: 230.8727 - mse: 219663.4688 - val_loss: 174546.2188 - val_mae: 209.0822 - val_mse: 174546.2188\n",
      "Epoch 502/1000\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 213842.7188 - mae: 229.4881 - mse: 213842.7188 - val_loss: 172486.0000 - val_mae: 204.2655 - val_mse: 172486.0000\n",
      "Epoch 503/1000\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 216233.5000 - mae: 229.0130 - mse: 216233.5000 - val_loss: 162531.4844 - val_mae: 199.0396 - val_mse: 162531.4844\n",
      "Epoch 504/1000\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 218299.0000 - mae: 231.7490 - mse: 218299.0000 - val_loss: 165601.7031 - val_mae: 200.1286 - val_mse: 165601.7031\n",
      "Epoch 505/1000\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 216797.0156 - mae: 229.7263 - mse: 216797.0156 - val_loss: 165170.5469 - val_mae: 198.5369 - val_mse: 165170.5469\n",
      "Epoch 506/1000\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 220074.2812 - mae: 231.5569 - mse: 220074.2812 - val_loss: 167109.2812 - val_mae: 200.2506 - val_mse: 167109.2812\n",
      "Epoch 507/1000\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 209171.1406 - mae: 228.0940 - mse: 209171.1406 - val_loss: 162899.2812 - val_mae: 200.5875 - val_mse: 162899.2812\n",
      "Epoch 508/1000\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 214727.2500 - mae: 230.4059 - mse: 214727.2500 - val_loss: 165904.0781 - val_mae: 198.1317 - val_mse: 165904.0781\n",
      "Epoch 509/1000\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 216621.7031 - mae: 230.9214 - mse: 216621.7031 - val_loss: 166654.6250 - val_mae: 200.4905 - val_mse: 166654.6250\n",
      "Epoch 510/1000\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 216294.6562 - mae: 230.0373 - mse: 216294.6562 - val_loss: 162391.1875 - val_mae: 200.6249 - val_mse: 162391.1875\n",
      "Epoch 511/1000\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 213229.7812 - mae: 228.6494 - mse: 213229.7812 - val_loss: 170633.8438 - val_mae: 204.8432 - val_mse: 170633.8438\n",
      "Epoch 512/1000\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 210106.7031 - mae: 228.2427 - mse: 210106.7031 - val_loss: 160892.1094 - val_mae: 195.7118 - val_mse: 160892.1094\n",
      "Epoch 513/1000\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 214513.2656 - mae: 228.5886 - mse: 214513.2656 - val_loss: 162249.1406 - val_mae: 199.5448 - val_mse: 162249.1406\n",
      "Epoch 514/1000\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 213663.2656 - mae: 228.5528 - mse: 213663.2656 - val_loss: 163562.0312 - val_mae: 201.1778 - val_mse: 163562.0312\n",
      "Epoch 515/1000\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 215768.6250 - mae: 230.7414 - mse: 215768.6250 - val_loss: 173499.4219 - val_mae: 207.3160 - val_mse: 173499.4219\n",
      "Epoch 516/1000\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 214678.0781 - mae: 229.5443 - mse: 214678.0781 - val_loss: 168449.6250 - val_mae: 201.3288 - val_mse: 168449.6250\n",
      "Epoch 517/1000\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 216922.2812 - mae: 230.7652 - mse: 216922.2812 - val_loss: 160565.7344 - val_mae: 195.2460 - val_mse: 160565.7344\n",
      "Epoch 518/1000\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 214819.1250 - mae: 229.4199 - mse: 214819.1250 - val_loss: 169277.3125 - val_mae: 206.3526 - val_mse: 169277.3125\n",
      "Epoch 519/1000\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 221593.5156 - mae: 233.1863 - mse: 221593.5156 - val_loss: 165370.1406 - val_mae: 200.0831 - val_mse: 165370.1406\n",
      "Epoch 520/1000\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 217763.0312 - mae: 229.0738 - mse: 217763.0312 - val_loss: 169395.2969 - val_mae: 202.8633 - val_mse: 169395.2969\n",
      "Epoch 521/1000\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 209310.1719 - mae: 227.5051 - mse: 209310.1719 - val_loss: 162364.2656 - val_mae: 196.2432 - val_mse: 162364.2656\n",
      "Epoch 522/1000\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 214071.5312 - mae: 230.7069 - mse: 214071.5312 - val_loss: 178854.4219 - val_mae: 214.0901 - val_mse: 178854.4219\n",
      "Epoch 523/1000\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 211851.7656 - mae: 229.1326 - mse: 211851.7656 - val_loss: 163572.8438 - val_mae: 199.9628 - val_mse: 163572.8438\n",
      "Epoch 524/1000\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 212696.7031 - mae: 228.7989 - mse: 212696.7031 - val_loss: 166156.3594 - val_mae: 203.1292 - val_mse: 166156.3594\n",
      "Epoch 525/1000\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 217539.1250 - mae: 230.7580 - mse: 217539.1250 - val_loss: 165262.5625 - val_mae: 202.9221 - val_mse: 165262.5625\n",
      "Epoch 526/1000\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 215723.0156 - mae: 229.8547 - mse: 215723.0156 - val_loss: 164495.6250 - val_mae: 197.8973 - val_mse: 164495.6250\n",
      "Epoch 527/1000\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 218626.6562 - mae: 231.3022 - mse: 218626.6562 - val_loss: 163068.4531 - val_mae: 200.3954 - val_mse: 163068.4531\n",
      "Epoch 528/1000\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 207057.5312 - mae: 226.1771 - mse: 207057.5312 - val_loss: 163628.7188 - val_mae: 201.3753 - val_mse: 163628.7188\n",
      "Epoch 529/1000\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 220966.6406 - mae: 232.5860 - mse: 220966.6406 - val_loss: 166549.7812 - val_mae: 201.0859 - val_mse: 166549.7812\n",
      "Epoch 530/1000\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 211099.9219 - mae: 229.9444 - mse: 211099.9219 - val_loss: 165712.2031 - val_mae: 200.1308 - val_mse: 165712.2031\n",
      "Epoch 531/1000\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 222837.3594 - mae: 231.8373 - mse: 222837.3594 - val_loss: 173006.8906 - val_mae: 206.5463 - val_mse: 173006.8906\n",
      "Epoch 532/1000\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 218510.4844 - mae: 231.4967 - mse: 218510.4844 - val_loss: 163372.6562 - val_mae: 201.1393 - val_mse: 163372.6562\n",
      "Epoch 533/1000\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 216412.7188 - mae: 230.4186 - mse: 216412.7188 - val_loss: 159540.9844 - val_mae: 198.3934 - val_mse: 159540.9844\n",
      "Epoch 534/1000\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 213191.0312 - mae: 228.4003 - mse: 213191.0312 - val_loss: 162735.7812 - val_mae: 201.5788 - val_mse: 162735.7812\n",
      "Epoch 535/1000\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 214540.1094 - mae: 229.7478 - mse: 214540.1094 - val_loss: 170192.3125 - val_mae: 206.6669 - val_mse: 170192.3125\n",
      "Epoch 536/1000\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 212466.5469 - mae: 228.9846 - mse: 212466.5469 - val_loss: 165869.6250 - val_mae: 203.7221 - val_mse: 165869.6250\n",
      "Epoch 537/1000\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 214566.5938 - mae: 230.8845 - mse: 214566.5938 - val_loss: 167044.2500 - val_mae: 203.6805 - val_mse: 167044.2500\n",
      "Epoch 538/1000\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 207100.4531 - mae: 226.9632 - mse: 207100.4531 - val_loss: 170153.4844 - val_mae: 202.9664 - val_mse: 170153.4844\n",
      "Epoch 539/1000\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 211959.2344 - mae: 230.0001 - mse: 211959.2344 - val_loss: 165763.4375 - val_mae: 198.9610 - val_mse: 165763.4375\n",
      "Epoch 540/1000\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 213025.7812 - mae: 230.5700 - mse: 213025.7812 - val_loss: 166219.4375 - val_mae: 200.5468 - val_mse: 166219.4375\n",
      "Epoch 541/1000\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 212711.3750 - mae: 229.9770 - mse: 212711.3750 - val_loss: 162840.9531 - val_mae: 200.1270 - val_mse: 162840.9531\n",
      "Epoch 542/1000\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 212114.1406 - mae: 229.4866 - mse: 212114.1406 - val_loss: 172083.6406 - val_mae: 207.0020 - val_mse: 172083.6406\n",
      "Epoch 543/1000\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 214722.1562 - mae: 229.7875 - mse: 214722.1562 - val_loss: 173086.3438 - val_mae: 203.9823 - val_mse: 173086.3438\n",
      "Epoch 544/1000\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 213289.7812 - mae: 229.0307 - mse: 213289.7812 - val_loss: 161732.2656 - val_mae: 198.3077 - val_mse: 161732.2656\n",
      "Epoch 545/1000\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 212314.1562 - mae: 229.0996 - mse: 212314.1562 - val_loss: 164321.1250 - val_mae: 200.1180 - val_mse: 164321.1250\n",
      "Epoch 546/1000\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 217654.4531 - mae: 231.2298 - mse: 217654.4531 - val_loss: 190687.4219 - val_mae: 214.8237 - val_mse: 190687.4219\n",
      "Epoch 547/1000\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 210711.8125 - mae: 227.6420 - mse: 210711.8125 - val_loss: 175397.3438 - val_mae: 208.4198 - val_mse: 175397.3438\n",
      "Epoch 548/1000\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 211002.2812 - mae: 229.3091 - mse: 211002.2812 - val_loss: 160957.7656 - val_mae: 197.1519 - val_mse: 160957.7656\n",
      "Epoch 549/1000\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 209819.8438 - mae: 228.9386 - mse: 209819.8438 - val_loss: 164116.0156 - val_mae: 201.7619 - val_mse: 164116.0156\n",
      "Epoch 550/1000\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 210593.8750 - mae: 227.8645 - mse: 210593.8750 - val_loss: 165434.7656 - val_mae: 199.1235 - val_mse: 165434.7656\n",
      "Epoch 551/1000\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 212187.3594 - mae: 228.7384 - mse: 212187.3594 - val_loss: 169422.0312 - val_mae: 201.5841 - val_mse: 169422.0312\n",
      "Epoch 552/1000\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 202709.5469 - mae: 225.3504 - mse: 202709.5469 - val_loss: 160895.9844 - val_mae: 195.6892 - val_mse: 160895.9844\n",
      "Epoch 553/1000\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 209138.6250 - mae: 227.4553 - mse: 209138.6250 - val_loss: 159124.4375 - val_mae: 196.7158 - val_mse: 159124.4375\n",
      "Epoch 554/1000\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 210091.0938 - mae: 229.4067 - mse: 210091.0938 - val_loss: 170162.6094 - val_mae: 206.9321 - val_mse: 170162.6094\n",
      "Epoch 555/1000\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 214904.5625 - mae: 230.0675 - mse: 214904.5625 - val_loss: 161326.7031 - val_mae: 201.5092 - val_mse: 161326.7031\n",
      "Epoch 556/1000\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 210190.9375 - mae: 228.4766 - mse: 210190.9375 - val_loss: 158832.7812 - val_mae: 194.9974 - val_mse: 158832.7812\n",
      "Epoch 557/1000\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 210434.9844 - mae: 228.7356 - mse: 210434.9844 - val_loss: 169733.3125 - val_mae: 208.1782 - val_mse: 169733.3125\n",
      "Epoch 558/1000\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 217694.4062 - mae: 231.2476 - mse: 217694.4062 - val_loss: 164793.5781 - val_mae: 204.7534 - val_mse: 164793.5781\n",
      "Epoch 559/1000\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 211062.7500 - mae: 229.6942 - mse: 211062.7500 - val_loss: 168266.9375 - val_mae: 205.3534 - val_mse: 168266.9375\n",
      "Epoch 560/1000\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 214963.2500 - mae: 230.4887 - mse: 214963.2500 - val_loss: 161634.5625 - val_mae: 200.9894 - val_mse: 161634.5625\n",
      "Epoch 561/1000\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 208984.8438 - mae: 227.2952 - mse: 208984.8438 - val_loss: 165342.6719 - val_mae: 201.9878 - val_mse: 165342.6719\n",
      "Epoch 562/1000\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 214489.6406 - mae: 230.1732 - mse: 214489.6406 - val_loss: 164291.5938 - val_mae: 198.5585 - val_mse: 164291.5938\n",
      "Epoch 563/1000\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 207712.4062 - mae: 228.8499 - mse: 207712.4062 - val_loss: 162552.9062 - val_mae: 201.6888 - val_mse: 162552.9062\n",
      "Epoch 564/1000\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 210074.8750 - mae: 228.3515 - mse: 210074.8750 - val_loss: 163473.8594 - val_mae: 199.1604 - val_mse: 163473.8594\n",
      "Epoch 565/1000\n",
      "707/707 [==============================] - 1s 2ms/step - loss: 214697.0781 - mae: 230.7635 - mse: 214697.0781 - val_loss: 164326.6406 - val_mae: 201.1200 - val_mse: 164326.6406\n",
      "Epoch 566/1000\n",
      "707/707 [==============================] - 1s 2ms/step - loss: 214667.6406 - mae: 230.5861 - mse: 214667.6406 - val_loss: 165302.4531 - val_mae: 204.6588 - val_mse: 165302.4531\n",
      "Epoch 567/1000\n",
      "707/707 [==============================] - 1s 2ms/step - loss: 211124.9219 - mae: 227.8896 - mse: 211124.9219 - val_loss: 158498.5312 - val_mae: 195.8997 - val_mse: 158498.5312\n",
      "Epoch 568/1000\n",
      "707/707 [==============================] - 1s 2ms/step - loss: 213350.0469 - mae: 230.5218 - mse: 213350.0469 - val_loss: 159397.2344 - val_mae: 195.4003 - val_mse: 159397.2344\n",
      "Epoch 569/1000\n",
      "707/707 [==============================] - 1s 2ms/step - loss: 211051.6562 - mae: 230.2982 - mse: 211051.6562 - val_loss: 162234.5625 - val_mae: 201.8486 - val_mse: 162234.5625\n",
      "Epoch 570/1000\n",
      "707/707 [==============================] - 1s 2ms/step - loss: 213326.4375 - mae: 230.8358 - mse: 213326.4375 - val_loss: 160801.6562 - val_mae: 199.5752 - val_mse: 160801.6562\n",
      "Epoch 571/1000\n",
      "707/707 [==============================] - 1s 2ms/step - loss: 210057.5156 - mae: 228.4760 - mse: 210057.5156 - val_loss: 159286.2812 - val_mae: 198.3910 - val_mse: 159286.2812\n",
      "Epoch 572/1000\n",
      "707/707 [==============================] - 1s 2ms/step - loss: 209440.9844 - mae: 229.2660 - mse: 209440.9844 - val_loss: 162402.5781 - val_mae: 200.7429 - val_mse: 162402.5781\n",
      "Epoch 573/1000\n",
      "707/707 [==============================] - 1s 2ms/step - loss: 217034.8906 - mae: 230.4907 - mse: 217034.8906 - val_loss: 166103.0312 - val_mae: 202.7671 - val_mse: 166103.0312\n",
      "Epoch 574/1000\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 212950.7344 - mae: 231.1199 - mse: 212950.7344 - val_loss: 164877.7812 - val_mae: 202.2236 - val_mse: 164877.7812\n",
      "Epoch 575/1000\n",
      "707/707 [==============================] - 1s 2ms/step - loss: 210835.2188 - mae: 229.3380 - mse: 210835.2188 - val_loss: 160371.2656 - val_mae: 200.3563 - val_mse: 160371.2656\n",
      "Epoch 576/1000\n",
      "707/707 [==============================] - 1s 2ms/step - loss: 214303.5312 - mae: 229.7235 - mse: 214303.5312 - val_loss: 157909.3750 - val_mae: 197.4201 - val_mse: 157909.3750\n",
      "Epoch 577/1000\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 216185.5938 - mae: 231.3955 - mse: 216185.5938 - val_loss: 177813.0156 - val_mae: 209.8194 - val_mse: 177813.0156\n",
      "Epoch 578/1000\n",
      "707/707 [==============================] - 1s 2ms/step - loss: 208318.4531 - mae: 229.2812 - mse: 208318.4531 - val_loss: 166374.5156 - val_mae: 204.5766 - val_mse: 166374.5156\n",
      "Epoch 579/1000\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 207100.7969 - mae: 228.8964 - mse: 207100.7969 - val_loss: 171357.0625 - val_mae: 206.4777 - val_mse: 171357.0625\n",
      "Epoch 580/1000\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 203709.5781 - mae: 227.3210 - mse: 203709.5781 - val_loss: 177181.6406 - val_mae: 212.7950 - val_mse: 177181.6406\n",
      "Epoch 581/1000\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 213404.0469 - mae: 230.9754 - mse: 213404.0469 - val_loss: 165021.2969 - val_mae: 203.7222 - val_mse: 165021.2969\n",
      "Epoch 582/1000\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 209603.2031 - mae: 230.2166 - mse: 209603.2031 - val_loss: 171674.6406 - val_mae: 205.9081 - val_mse: 171674.6406\n",
      "Epoch 583/1000\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 215587.2656 - mae: 231.3628 - mse: 215587.2656 - val_loss: 165144.8750 - val_mae: 201.9238 - val_mse: 165144.8750\n",
      "Epoch 584/1000\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 218180.0781 - mae: 232.8757 - mse: 218180.0781 - val_loss: 167306.4844 - val_mae: 204.2178 - val_mse: 167306.4844\n",
      "Epoch 585/1000\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 209799.9844 - mae: 230.4337 - mse: 209799.9844 - val_loss: 170239.3906 - val_mae: 205.7309 - val_mse: 170239.3906\n",
      "Epoch 586/1000\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 205964.2500 - mae: 227.6754 - mse: 205964.2500 - val_loss: 162207.0625 - val_mae: 200.6918 - val_mse: 162207.0625\n",
      "Epoch 587/1000\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 215279.3438 - mae: 230.9301 - mse: 215279.3438 - val_loss: 161660.3281 - val_mae: 199.2271 - val_mse: 161660.3281\n",
      "Epoch 588/1000\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 210139.2656 - mae: 230.1134 - mse: 210139.2656 - val_loss: 162141.5625 - val_mae: 199.0349 - val_mse: 162141.5625\n",
      "Epoch 589/1000\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 208933.9375 - mae: 228.7751 - mse: 208933.9375 - val_loss: 171586.8594 - val_mae: 210.7337 - val_mse: 171586.8594\n",
      "Epoch 590/1000\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 211143.6094 - mae: 229.8551 - mse: 211143.6094 - val_loss: 162110.4531 - val_mae: 199.5723 - val_mse: 162110.4531\n",
      "Epoch 591/1000\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 206515.1562 - mae: 227.2962 - mse: 206515.1562 - val_loss: 161187.6719 - val_mae: 200.8574 - val_mse: 161187.6719\n",
      "Epoch 592/1000\n",
      "707/707 [==============================] - 1s 2ms/step - loss: 214109.1406 - mae: 229.6077 - mse: 214109.1406 - val_loss: 167050.7969 - val_mae: 204.8141 - val_mse: 167050.7969\n",
      "Epoch 593/1000\n",
      "707/707 [==============================] - 1s 2ms/step - loss: 210074.7500 - mae: 228.3465 - mse: 210074.7500 - val_loss: 161754.2188 - val_mae: 197.2222 - val_mse: 161754.2188\n",
      "Epoch 594/1000\n",
      "707/707 [==============================] - 1s 2ms/step - loss: 215820.5312 - mae: 231.3074 - mse: 215820.5312 - val_loss: 166941.4062 - val_mae: 203.7444 - val_mse: 166941.4062\n",
      "Epoch 595/1000\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 212207.6719 - mae: 229.9802 - mse: 212207.6719 - val_loss: 165418.6094 - val_mae: 203.0459 - val_mse: 165418.6094\n",
      "Epoch 596/1000\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 208773.4688 - mae: 228.6945 - mse: 208773.4688 - val_loss: 161992.7812 - val_mae: 196.5641 - val_mse: 161992.7812\n",
      "Epoch 597/1000\n",
      "707/707 [==============================] - 1s 2ms/step - loss: 206387.7969 - mae: 228.0225 - mse: 206387.7969 - val_loss: 167038.1562 - val_mae: 203.5695 - val_mse: 167038.1562\n",
      "Epoch 598/1000\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 206627.5312 - mae: 228.0796 - mse: 206627.5312 - val_loss: 165867.2188 - val_mae: 203.1293 - val_mse: 165867.2188\n",
      "Epoch 599/1000\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 215881.2500 - mae: 230.5481 - mse: 215881.2500 - val_loss: 175777.6562 - val_mae: 210.8711 - val_mse: 175777.6562\n",
      "Epoch 600/1000\n",
      "707/707 [==============================] - 1s 2ms/step - loss: 209129.4844 - mae: 229.4642 - mse: 209129.4844 - val_loss: 158604.5469 - val_mae: 197.6432 - val_mse: 158604.5469\n",
      "Epoch 601/1000\n",
      "707/707 [==============================] - 1s 2ms/step - loss: 211830.9219 - mae: 230.0420 - mse: 211830.9219 - val_loss: 159693.0781 - val_mae: 197.1157 - val_mse: 159693.0781\n",
      "Epoch 602/1000\n",
      "707/707 [==============================] - 1s 2ms/step - loss: 205204.7500 - mae: 228.3798 - mse: 205204.7500 - val_loss: 160133.4844 - val_mae: 198.7145 - val_mse: 160133.4844\n",
      "Epoch 603/1000\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 208743.3594 - mae: 229.4718 - mse: 208743.3594 - val_loss: 165257.1875 - val_mae: 201.1023 - val_mse: 165257.1875\n",
      "Epoch 604/1000\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 211880.1094 - mae: 230.4666 - mse: 211880.1094 - val_loss: 166069.4688 - val_mae: 203.1260 - val_mse: 166069.4688\n",
      "Epoch 605/1000\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 211906.1406 - mae: 230.5017 - mse: 211906.1406 - val_loss: 159177.2656 - val_mae: 198.6392 - val_mse: 159177.2656\n",
      "Epoch 606/1000\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 213740.2188 - mae: 230.9502 - mse: 213740.2188 - val_loss: 156622.5781 - val_mae: 196.1760 - val_mse: 156622.5781\n",
      "Epoch 607/1000\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 210971.9844 - mae: 229.7770 - mse: 210971.9844 - val_loss: 163272.3438 - val_mae: 200.7315 - val_mse: 163272.3438\n",
      "Epoch 608/1000\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 211348.2188 - mae: 230.1761 - mse: 211348.2188 - val_loss: 161089.7812 - val_mae: 199.8584 - val_mse: 161089.7812\n",
      "Epoch 609/1000\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 207939.6094 - mae: 228.3956 - mse: 207939.6094 - val_loss: 169096.0781 - val_mae: 205.5226 - val_mse: 169096.0781\n",
      "Epoch 610/1000\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 212904.9219 - mae: 229.8376 - mse: 212904.9219 - val_loss: 163830.0156 - val_mae: 200.8991 - val_mse: 163830.0156\n",
      "Epoch 611/1000\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 213306.8906 - mae: 231.6729 - mse: 213306.8906 - val_loss: 158749.9219 - val_mae: 196.3073 - val_mse: 158749.9219\n",
      "Epoch 612/1000\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 210716.6562 - mae: 229.3327 - mse: 210716.6562 - val_loss: 159615.7812 - val_mae: 200.7918 - val_mse: 159615.7812\n",
      "Epoch 613/1000\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 205851.1406 - mae: 228.7742 - mse: 205851.1406 - val_loss: 158871.4375 - val_mae: 196.0871 - val_mse: 158871.4375\n",
      "Epoch 614/1000\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 203568.8750 - mae: 227.2489 - mse: 203568.8750 - val_loss: 157919.7344 - val_mae: 197.1631 - val_mse: 157919.7344\n",
      "Epoch 615/1000\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 207066.7500 - mae: 229.1277 - mse: 207066.7500 - val_loss: 162000.7031 - val_mae: 202.5790 - val_mse: 162000.7031\n",
      "Epoch 616/1000\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 207662.8281 - mae: 230.2274 - mse: 207662.8281 - val_loss: 168962.6094 - val_mae: 202.1565 - val_mse: 168962.6094\n",
      "Epoch 617/1000\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 206567.2656 - mae: 227.7382 - mse: 206567.2656 - val_loss: 164781.1250 - val_mae: 204.4427 - val_mse: 164781.1250\n",
      "Epoch 618/1000\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 211075.0156 - mae: 230.3220 - mse: 211075.0156 - val_loss: 181265.8750 - val_mae: 213.5760 - val_mse: 181265.8750\n",
      "Epoch 619/1000\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 207204.6406 - mae: 228.3758 - mse: 207204.6406 - val_loss: 160742.4219 - val_mae: 199.2636 - val_mse: 160742.4219\n",
      "Epoch 620/1000\n",
      "707/707 [==============================] - 2s 2ms/step - loss: 210550.1094 - mae: 228.5584 - mse: 210550.1094 - val_loss: 159716.9844 - val_mae: 201.7416 - val_mse: 159716.9844\n",
      "Epoch 621/1000\n",
      "707/707 [==============================] - 2s 3ms/step - loss: 208931.6406 - mae: 229.1109 - mse: 208931.6406 - val_loss: 163924.9688 - val_mae: 202.9950 - val_mse: 163924.9688\n",
      "Epoch 622/1000\n",
      "707/707 [==============================] - 2s 3ms/step - loss: 205400.8438 - mae: 228.0090 - mse: 205400.8438 - val_loss: 161663.9844 - val_mae: 200.4388 - val_mse: 161663.9844\n",
      "Epoch 623/1000\n",
      "707/707 [==============================] - 2s 2ms/step - loss: 209157.1562 - mae: 229.5163 - mse: 209157.1562 - val_loss: 165549.7812 - val_mae: 204.7942 - val_mse: 165549.7812\n",
      "Epoch 624/1000\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 203683.4219 - mae: 225.8303 - mse: 203683.4219 - val_loss: 168662.3281 - val_mae: 206.3661 - val_mse: 168662.3281\n",
      "Epoch 625/1000\n",
      "707/707 [==============================] - 2s 3ms/step - loss: 206524.4375 - mae: 228.2621 - mse: 206524.4375 - val_loss: 167330.1250 - val_mae: 207.8179 - val_mse: 167330.1250\n",
      "Epoch 626/1000\n",
      "707/707 [==============================] - 2s 2ms/step - loss: 212615.8594 - mae: 231.4630 - mse: 212615.8594 - val_loss: 162094.5156 - val_mae: 201.3064 - val_mse: 162094.5156\n",
      "Epoch 627/1000\n",
      "707/707 [==============================] - 2s 2ms/step - loss: 203125.3281 - mae: 228.8621 - mse: 203125.3281 - val_loss: 167359.1250 - val_mae: 206.2091 - val_mse: 167359.1250\n",
      "Epoch 628/1000\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 203174.3750 - mae: 227.8611 - mse: 203174.3750 - val_loss: 169725.3281 - val_mae: 204.1232 - val_mse: 169725.3281\n",
      "Epoch 629/1000\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 206886.0156 - mae: 227.3414 - mse: 206886.0156 - val_loss: 164136.1406 - val_mae: 203.8323 - val_mse: 164136.1406\n",
      "Epoch 630/1000\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 205894.1562 - mae: 226.5989 - mse: 205894.1562 - val_loss: 157412.6406 - val_mae: 197.9507 - val_mse: 157412.6406\n",
      "Epoch 631/1000\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 212154.7969 - mae: 231.4411 - mse: 212154.7969 - val_loss: 169393.6875 - val_mae: 206.4496 - val_mse: 169393.6875\n",
      "Epoch 632/1000\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 204442.3750 - mae: 227.6656 - mse: 204442.3750 - val_loss: 163641.6562 - val_mae: 204.3148 - val_mse: 163641.6562\n",
      "Epoch 633/1000\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 206666.9219 - mae: 228.8066 - mse: 206666.9219 - val_loss: 170393.2031 - val_mae: 206.5175 - val_mse: 170393.2031\n",
      "Epoch 634/1000\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 208373.9531 - mae: 229.3694 - mse: 208373.9531 - val_loss: 163417.9844 - val_mae: 202.6928 - val_mse: 163417.9844\n",
      "Epoch 635/1000\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 204407.7812 - mae: 227.2663 - mse: 204407.7812 - val_loss: 165798.0781 - val_mae: 205.0140 - val_mse: 165798.0781\n",
      "Epoch 636/1000\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 208669.5312 - mae: 229.9244 - mse: 208669.5312 - val_loss: 161084.3281 - val_mae: 199.3038 - val_mse: 161084.3281\n",
      "Epoch 637/1000\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 210490.9375 - mae: 230.7672 - mse: 210490.9375 - val_loss: 164929.0156 - val_mae: 202.1582 - val_mse: 164929.0156\n",
      "Epoch 638/1000\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 210580.5781 - mae: 230.2170 - mse: 210580.5781 - val_loss: 169413.2344 - val_mae: 208.3015 - val_mse: 169413.2344\n",
      "Epoch 639/1000\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 205544.9844 - mae: 229.0550 - mse: 205544.9844 - val_loss: 163873.6406 - val_mae: 201.5161 - val_mse: 163873.6406\n",
      "Epoch 640/1000\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 210747.8906 - mae: 231.2125 - mse: 210747.8906 - val_loss: 162635.4219 - val_mae: 202.8123 - val_mse: 162635.4219\n",
      "Epoch 641/1000\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 206091.3125 - mae: 228.6331 - mse: 206091.3125 - val_loss: 162770.9531 - val_mae: 201.2393 - val_mse: 162770.9531\n",
      "Epoch 642/1000\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 213366.5469 - mae: 231.3568 - mse: 213366.5469 - val_loss: 175065.1094 - val_mae: 209.6937 - val_mse: 175065.1094\n",
      "Epoch 643/1000\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 203436.9219 - mae: 227.8278 - mse: 203436.9219 - val_loss: 170753.4531 - val_mae: 205.1608 - val_mse: 170753.4531\n",
      "Epoch 644/1000\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 208773.6562 - mae: 228.9554 - mse: 208773.6562 - val_loss: 173135.9219 - val_mae: 209.0920 - val_mse: 173135.9219\n",
      "Epoch 645/1000\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 213777.7812 - mae: 232.8696 - mse: 213777.7812 - val_loss: 166080.5625 - val_mae: 204.2760 - val_mse: 166080.5625\n",
      "Epoch 646/1000\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 206045.3906 - mae: 228.5725 - mse: 206045.3906 - val_loss: 158824.9844 - val_mae: 196.6515 - val_mse: 158824.9844\n",
      "Epoch 647/1000\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 202649.3438 - mae: 227.7806 - mse: 202649.3438 - val_loss: 164809.0312 - val_mae: 204.9387 - val_mse: 164809.0312\n",
      "Epoch 648/1000\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 211740.9375 - mae: 229.4929 - mse: 211740.9375 - val_loss: 169732.2969 - val_mae: 210.2493 - val_mse: 169732.2969\n",
      "Epoch 649/1000\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 204962.7969 - mae: 228.8382 - mse: 204962.7969 - val_loss: 163861.2656 - val_mae: 204.8944 - val_mse: 163861.2656\n",
      "Epoch 650/1000\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 208230.4531 - mae: 230.4397 - mse: 208230.4531 - val_loss: 175306.3125 - val_mae: 212.3305 - val_mse: 175306.3125\n",
      "Epoch 651/1000\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 204724.5156 - mae: 228.6089 - mse: 204724.5156 - val_loss: 169734.6094 - val_mae: 209.0373 - val_mse: 169734.6094\n",
      "Epoch 652/1000\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 207581.8906 - mae: 228.4368 - mse: 207581.8906 - val_loss: 161622.6719 - val_mae: 199.8277 - val_mse: 161622.6719\n",
      "Epoch 653/1000\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 206999.9062 - mae: 229.0560 - mse: 206999.9062 - val_loss: 163743.5312 - val_mae: 202.7534 - val_mse: 163743.5312\n",
      "Epoch 654/1000\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 204925.9688 - mae: 228.1638 - mse: 204925.9688 - val_loss: 164820.6094 - val_mae: 202.9866 - val_mse: 164820.6094\n",
      "Epoch 655/1000\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 209259.2500 - mae: 228.7412 - mse: 209259.2500 - val_loss: 185894.9219 - val_mae: 217.5570 - val_mse: 185894.9219\n",
      "Epoch 656/1000\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 204864.3438 - mae: 228.2689 - mse: 204864.3438 - val_loss: 158643.6094 - val_mae: 197.6920 - val_mse: 158643.6094\n",
      "Epoch 657/1000\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 208408.9219 - mae: 229.9141 - mse: 208408.9219 - val_loss: 169734.7500 - val_mae: 207.2926 - val_mse: 169734.7500\n",
      "Epoch 658/1000\n",
      "707/707 [==============================] - 1s 2ms/step - loss: 207996.6562 - mae: 229.6927 - mse: 207996.6562 - val_loss: 166180.6875 - val_mae: 205.2046 - val_mse: 166180.6875\n",
      "Epoch 659/1000\n",
      "707/707 [==============================] - 2s 2ms/step - loss: 204947.7500 - mae: 229.6353 - mse: 204947.7500 - val_loss: 172200.9844 - val_mae: 210.0994 - val_mse: 172200.9844\n",
      "Epoch 660/1000\n",
      "707/707 [==============================] - 2s 3ms/step - loss: 207360.5625 - mae: 229.0074 - mse: 207360.5625 - val_loss: 167148.2969 - val_mae: 204.0367 - val_mse: 167148.2969\n",
      "Epoch 661/1000\n",
      "707/707 [==============================] - 2s 3ms/step - loss: 206790.0156 - mae: 229.4551 - mse: 206790.0156 - val_loss: 161727.3594 - val_mae: 202.8153 - val_mse: 161727.3594\n",
      "Epoch 662/1000\n",
      "707/707 [==============================] - 2s 3ms/step - loss: 206412.9531 - mae: 230.4492 - mse: 206412.9531 - val_loss: 156824.0938 - val_mae: 196.8500 - val_mse: 156824.0938\n",
      "Epoch 663/1000\n",
      "707/707 [==============================] - 2s 2ms/step - loss: 200820.5000 - mae: 226.4721 - mse: 200820.5000 - val_loss: 162733.5625 - val_mae: 204.5139 - val_mse: 162733.5625\n",
      "Epoch 664/1000\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 216865.1562 - mae: 233.5937 - mse: 216865.1562 - val_loss: 172668.5156 - val_mae: 211.4036 - val_mse: 172668.5156\n",
      "Epoch 665/1000\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 208177.9531 - mae: 229.2767 - mse: 208177.9531 - val_loss: 160056.7656 - val_mae: 198.1387 - val_mse: 160056.7656\n",
      "Epoch 666/1000\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 204410.7500 - mae: 228.4682 - mse: 204410.7500 - val_loss: 170185.7656 - val_mae: 203.6578 - val_mse: 170185.7656\n",
      "Epoch 667/1000\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 200545.9219 - mae: 225.0260 - mse: 200545.9219 - val_loss: 162011.4844 - val_mae: 202.6330 - val_mse: 162011.4844\n",
      "Epoch 668/1000\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 211591.2031 - mae: 230.5123 - mse: 211591.2031 - val_loss: 161604.7188 - val_mae: 203.7179 - val_mse: 161604.7188\n",
      "Epoch 669/1000\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 197006.0156 - mae: 224.8618 - mse: 197006.0156 - val_loss: 162140.4219 - val_mae: 200.1648 - val_mse: 162140.4219\n",
      "Epoch 670/1000\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 202492.4531 - mae: 227.9773 - mse: 202492.4531 - val_loss: 155976.5469 - val_mae: 199.4449 - val_mse: 155976.5469\n",
      "Epoch 671/1000\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 204578.5625 - mae: 228.3906 - mse: 204578.5625 - val_loss: 162705.0312 - val_mae: 205.4218 - val_mse: 162705.0312\n",
      "Epoch 672/1000\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 200477.2812 - mae: 226.6824 - mse: 200477.2812 - val_loss: 155695.5000 - val_mae: 198.3888 - val_mse: 155695.5000\n",
      "Epoch 673/1000\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 203397.0469 - mae: 227.6505 - mse: 203397.0469 - val_loss: 162717.1719 - val_mae: 204.1295 - val_mse: 162717.1719\n",
      "Epoch 674/1000\n",
      "707/707 [==============================] - 1s 2ms/step - loss: 207511.6250 - mae: 229.7931 - mse: 207511.6250 - val_loss: 165812.5938 - val_mae: 201.1405 - val_mse: 165812.5938\n",
      "Epoch 675/1000\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 203419.9844 - mae: 227.9047 - mse: 203419.9844 - val_loss: 161240.4531 - val_mae: 201.6023 - val_mse: 161240.4531\n",
      "Epoch 676/1000\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 205277.9062 - mae: 229.4657 - mse: 205277.9062 - val_loss: 169567.2344 - val_mae: 208.3012 - val_mse: 169567.2344\n",
      "Epoch 677/1000\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 204131.7812 - mae: 226.1354 - mse: 204131.7812 - val_loss: 160744.1562 - val_mae: 202.7923 - val_mse: 160744.1562\n",
      "Epoch 678/1000\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 200802.9531 - mae: 228.1000 - mse: 200802.9531 - val_loss: 164687.1406 - val_mae: 204.4496 - val_mse: 164687.1406\n",
      "Epoch 679/1000\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 205826.1719 - mae: 228.1755 - mse: 205826.1719 - val_loss: 167683.4844 - val_mae: 208.2727 - val_mse: 167683.4844\n",
      "Epoch 680/1000\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 195565.4062 - mae: 225.8126 - mse: 195565.4062 - val_loss: 182577.4219 - val_mae: 217.0845 - val_mse: 182577.4219\n",
      "Epoch 681/1000\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 205315.4688 - mae: 228.6395 - mse: 205315.4688 - val_loss: 159987.4531 - val_mae: 200.8460 - val_mse: 159987.4531\n",
      "Epoch 682/1000\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 206859.0312 - mae: 229.6589 - mse: 206859.0312 - val_loss: 182720.9062 - val_mae: 214.8419 - val_mse: 182720.9062\n",
      "Epoch 683/1000\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 208381.6719 - mae: 230.2672 - mse: 208381.6719 - val_loss: 174823.0469 - val_mae: 211.4361 - val_mse: 174823.0469\n",
      "Epoch 684/1000\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 203014.7969 - mae: 228.7440 - mse: 203014.7969 - val_loss: 162340.5469 - val_mae: 204.6413 - val_mse: 162340.5469\n",
      "Epoch 685/1000\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 210638.6719 - mae: 232.4107 - mse: 210638.6719 - val_loss: 160205.1719 - val_mae: 198.8986 - val_mse: 160205.1719\n",
      "Epoch 686/1000\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 211219.7344 - mae: 231.9496 - mse: 211219.7344 - val_loss: 166668.2656 - val_mae: 209.2158 - val_mse: 166668.2656\n",
      "Epoch 687/1000\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 203236.5000 - mae: 227.8205 - mse: 203236.5000 - val_loss: 167196.7344 - val_mae: 208.1165 - val_mse: 167196.7344\n",
      "Epoch 688/1000\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 200794.4688 - mae: 227.4140 - mse: 200794.4688 - val_loss: 162786.6406 - val_mae: 205.4813 - val_mse: 162786.6406\n",
      "Epoch 689/1000\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 202892.2500 - mae: 227.0472 - mse: 202892.2500 - val_loss: 156257.5000 - val_mae: 198.0232 - val_mse: 156257.5000\n",
      "Epoch 690/1000\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 205700.2969 - mae: 229.0636 - mse: 205700.2969 - val_loss: 164000.3906 - val_mae: 204.3190 - val_mse: 164000.3906\n",
      "Epoch 691/1000\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 204292.1406 - mae: 228.3289 - mse: 204292.1406 - val_loss: 157999.4688 - val_mae: 200.8500 - val_mse: 157999.4688\n",
      "Epoch 692/1000\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 206286.3281 - mae: 228.8326 - mse: 206286.3281 - val_loss: 160963.5469 - val_mae: 202.6149 - val_mse: 160963.5469\n",
      "Epoch 693/1000\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 206771.9531 - mae: 229.6461 - mse: 206771.9531 - val_loss: 170141.1875 - val_mae: 208.3322 - val_mse: 170141.1875\n",
      "Epoch 694/1000\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 208902.6094 - mae: 230.1695 - mse: 208902.6094 - val_loss: 161442.1875 - val_mae: 202.5598 - val_mse: 161442.1875\n",
      "Epoch 695/1000\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 205148.5625 - mae: 228.1568 - mse: 205148.5625 - val_loss: 170297.4219 - val_mae: 210.3165 - val_mse: 170297.4219\n",
      "Epoch 696/1000\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 208309.7656 - mae: 231.2245 - mse: 208309.7656 - val_loss: 160958.1562 - val_mae: 201.0680 - val_mse: 160958.1562\n",
      "Epoch 697/1000\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 208886.1094 - mae: 230.3492 - mse: 208886.1094 - val_loss: 156976.9375 - val_mae: 201.4950 - val_mse: 156976.9375\n",
      "Epoch 698/1000\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 209338.7656 - mae: 229.6055 - mse: 209338.7656 - val_loss: 163649.7344 - val_mae: 202.4590 - val_mse: 163649.7344\n",
      "Epoch 699/1000\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 207771.0469 - mae: 229.9026 - mse: 207771.0469 - val_loss: 157900.9375 - val_mae: 199.3974 - val_mse: 157900.9375\n",
      "Epoch 700/1000\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 208414.7969 - mae: 230.8728 - mse: 208414.7969 - val_loss: 162425.7656 - val_mae: 205.8226 - val_mse: 162425.7656\n",
      "Epoch 701/1000\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 200070.2812 - mae: 227.6949 - mse: 200070.2812 - val_loss: 161607.4219 - val_mae: 204.0833 - val_mse: 161607.4219\n",
      "Epoch 702/1000\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 203040.5469 - mae: 228.1953 - mse: 203040.5469 - val_loss: 158160.8438 - val_mae: 204.0884 - val_mse: 158160.8438\n",
      "Epoch 703/1000\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 207816.5938 - mae: 230.3756 - mse: 207816.5938 - val_loss: 161096.6562 - val_mae: 205.2237 - val_mse: 161096.6562\n",
      "Epoch 704/1000\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 210459.7344 - mae: 229.8088 - mse: 210459.7344 - val_loss: 165439.1406 - val_mae: 204.1762 - val_mse: 165439.1406\n",
      "Epoch 705/1000\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 201586.6875 - mae: 227.1580 - mse: 201586.6875 - val_loss: 173047.1875 - val_mae: 213.6088 - val_mse: 173047.1875\n",
      "Epoch 706/1000\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 203866.5781 - mae: 228.2868 - mse: 203866.5781 - val_loss: 164621.5312 - val_mae: 204.6032 - val_mse: 164621.5312\n",
      "Epoch 707/1000\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 204338.3750 - mae: 227.6814 - mse: 204338.3750 - val_loss: 168497.4375 - val_mae: 207.1570 - val_mse: 168497.4375\n",
      "Epoch 708/1000\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 211646.1094 - mae: 231.2562 - mse: 211646.1094 - val_loss: 160437.7344 - val_mae: 201.8443 - val_mse: 160437.7344\n",
      "Epoch 709/1000\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 208523.0312 - mae: 230.4012 - mse: 208523.0312 - val_loss: 158201.4531 - val_mae: 198.0603 - val_mse: 158201.4531\n",
      "Epoch 710/1000\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 203550.3438 - mae: 227.9538 - mse: 203550.3438 - val_loss: 163698.3906 - val_mae: 202.6237 - val_mse: 163698.3906\n",
      "Epoch 711/1000\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 200803.2344 - mae: 226.5513 - mse: 200803.2344 - val_loss: 162623.2344 - val_mae: 205.2065 - val_mse: 162623.2344\n",
      "Epoch 712/1000\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 207042.7656 - mae: 228.2330 - mse: 207042.7656 - val_loss: 164873.1406 - val_mae: 204.2986 - val_mse: 164873.1406\n",
      "Epoch 713/1000\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 204592.5781 - mae: 229.3258 - mse: 204592.5781 - val_loss: 165301.5938 - val_mae: 203.7765 - val_mse: 165301.5938\n",
      "Epoch 714/1000\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 206087.9062 - mae: 229.1087 - mse: 206087.9062 - val_loss: 163802.8438 - val_mae: 204.1883 - val_mse: 163802.8438\n",
      "Epoch 715/1000\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 207302.3750 - mae: 230.3403 - mse: 207302.3750 - val_loss: 155447.2656 - val_mae: 197.6751 - val_mse: 155447.2656\n",
      "Epoch 716/1000\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 205859.3906 - mae: 229.0854 - mse: 205859.3906 - val_loss: 167401.8281 - val_mae: 208.4787 - val_mse: 167401.8281\n",
      "Epoch 717/1000\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 208228.7344 - mae: 230.1428 - mse: 208228.7344 - val_loss: 166149.1562 - val_mae: 206.3366 - val_mse: 166149.1562\n",
      "Epoch 718/1000\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 202243.6406 - mae: 229.4331 - mse: 202243.6406 - val_loss: 159486.7344 - val_mae: 199.4584 - val_mse: 159486.7344\n",
      "Epoch 719/1000\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 202989.5625 - mae: 226.1827 - mse: 202989.5625 - val_loss: 177720.9844 - val_mae: 215.4816 - val_mse: 177720.9844\n",
      "Epoch 720/1000\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 203282.1094 - mae: 227.3769 - mse: 203282.1094 - val_loss: 159677.0156 - val_mae: 199.8078 - val_mse: 159677.0156\n",
      "Epoch 721/1000\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 205814.1094 - mae: 229.6496 - mse: 205814.1094 - val_loss: 165703.7656 - val_mae: 206.6251 - val_mse: 165703.7656\n",
      "Epoch 722/1000\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 202250.5312 - mae: 228.0336 - mse: 202250.5312 - val_loss: 160054.7812 - val_mae: 205.0519 - val_mse: 160054.7812\n",
      "Epoch 723/1000\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 206120.6250 - mae: 228.0300 - mse: 206120.6250 - val_loss: 158285.6094 - val_mae: 199.1559 - val_mse: 158285.6094\n",
      "Epoch 724/1000\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 209077.3438 - mae: 232.0058 - mse: 209077.3438 - val_loss: 164206.9062 - val_mae: 205.2453 - val_mse: 164206.9062\n",
      "Epoch 725/1000\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 208542.1875 - mae: 230.5772 - mse: 208542.1875 - val_loss: 163645.2188 - val_mae: 206.9694 - val_mse: 163645.2188\n",
      "Epoch 726/1000\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 205391.1719 - mae: 229.3652 - mse: 205391.1719 - val_loss: 161884.5469 - val_mae: 200.7884 - val_mse: 161884.5469\n",
      "Epoch 727/1000\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 199751.3906 - mae: 227.6032 - mse: 199751.3906 - val_loss: 171912.3594 - val_mae: 213.3496 - val_mse: 171912.3594\n",
      "Epoch 728/1000\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 203131.8438 - mae: 228.1172 - mse: 203131.8438 - val_loss: 164442.6406 - val_mae: 205.2590 - val_mse: 164442.6406\n",
      "Epoch 729/1000\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 205556.2656 - mae: 230.7646 - mse: 205556.2656 - val_loss: 162333.8438 - val_mae: 200.8033 - val_mse: 162333.8438\n",
      "Epoch 730/1000\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 201582.9531 - mae: 226.2765 - mse: 201582.9531 - val_loss: 161880.2500 - val_mae: 203.3893 - val_mse: 161880.2500\n",
      "Epoch 731/1000\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 209951.2500 - mae: 229.9562 - mse: 209951.2500 - val_loss: 160233.6719 - val_mae: 203.6840 - val_mse: 160233.6719\n",
      "Epoch 732/1000\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 202229.0000 - mae: 228.9290 - mse: 202229.0000 - val_loss: 180032.9531 - val_mae: 212.8849 - val_mse: 180032.9531\n",
      "Epoch 733/1000\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 204178.0312 - mae: 229.1007 - mse: 204178.0312 - val_loss: 177295.4688 - val_mae: 214.9219 - val_mse: 177295.4688\n",
      "Epoch 734/1000\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 203255.7969 - mae: 229.7128 - mse: 203255.7969 - val_loss: 170043.6406 - val_mae: 209.2839 - val_mse: 170043.6406\n",
      "Epoch 735/1000\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 198263.4531 - mae: 226.2242 - mse: 198263.4531 - val_loss: 163154.5469 - val_mae: 201.8135 - val_mse: 163154.5469\n",
      "Epoch 736/1000\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 197214.7500 - mae: 225.3452 - mse: 197214.7500 - val_loss: 161019.7969 - val_mae: 200.4382 - val_mse: 161019.7969\n",
      "Epoch 737/1000\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 207833.2812 - mae: 229.3259 - mse: 207833.2812 - val_loss: 165285.5625 - val_mae: 202.7131 - val_mse: 165285.5625\n",
      "Epoch 738/1000\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 198457.9531 - mae: 225.2206 - mse: 198457.9531 - val_loss: 172978.3750 - val_mae: 210.1560 - val_mse: 172978.3750\n",
      "Epoch 739/1000\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 199118.1250 - mae: 227.1890 - mse: 199118.1250 - val_loss: 162764.1406 - val_mae: 204.0194 - val_mse: 162764.1406\n",
      "Epoch 740/1000\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 203763.2031 - mae: 229.4380 - mse: 203763.2031 - val_loss: 165842.0469 - val_mae: 207.7239 - val_mse: 165842.0469\n",
      "Epoch 741/1000\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 199667.3906 - mae: 226.4557 - mse: 199667.3906 - val_loss: 163422.0469 - val_mae: 204.4440 - val_mse: 163422.0469\n",
      "Epoch 742/1000\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 200588.3594 - mae: 226.3954 - mse: 200588.3594 - val_loss: 159053.6562 - val_mae: 201.6458 - val_mse: 159053.6562\n",
      "Epoch 743/1000\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 201960.5781 - mae: 228.1607 - mse: 201960.5781 - val_loss: 160062.8594 - val_mae: 205.4350 - val_mse: 160062.8594\n",
      "Epoch 744/1000\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 201711.3438 - mae: 227.7977 - mse: 201711.3438 - val_loss: 159000.6250 - val_mae: 201.0757 - val_mse: 159000.6250\n",
      "Epoch 745/1000\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 197190.2812 - mae: 226.9018 - mse: 197190.2812 - val_loss: 162518.2031 - val_mae: 204.3783 - val_mse: 162518.2031\n",
      "Epoch 746/1000\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 208902.6719 - mae: 231.2071 - mse: 208902.6719 - val_loss: 161706.8906 - val_mae: 203.4653 - val_mse: 161706.8906\n",
      "Epoch 747/1000\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 198661.1094 - mae: 225.6879 - mse: 198661.1094 - val_loss: 165196.1562 - val_mae: 205.6577 - val_mse: 165196.1562\n",
      "Epoch 748/1000\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 201812.8594 - mae: 228.7883 - mse: 201812.8594 - val_loss: 159490.2500 - val_mae: 202.7463 - val_mse: 159490.2500\n",
      "Epoch 749/1000\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 199632.0781 - mae: 227.9202 - mse: 199632.0781 - val_loss: 162135.8906 - val_mae: 207.0526 - val_mse: 162135.8906\n",
      "Epoch 750/1000\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 204600.3438 - mae: 228.7149 - mse: 204600.3438 - val_loss: 166420.8125 - val_mae: 203.5908 - val_mse: 166420.8125\n",
      "Epoch 751/1000\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 204428.3594 - mae: 230.2041 - mse: 204428.3594 - val_loss: 172155.3906 - val_mae: 207.7133 - val_mse: 172155.3906\n",
      "Epoch 752/1000\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 199677.8438 - mae: 227.6500 - mse: 199677.8438 - val_loss: 163420.9688 - val_mae: 206.0289 - val_mse: 163420.9688\n",
      "Epoch 753/1000\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 197618.0938 - mae: 226.9070 - mse: 197618.0938 - val_loss: 164177.5156 - val_mae: 205.5967 - val_mse: 164177.5156\n",
      "Epoch 754/1000\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 197673.0000 - mae: 225.8714 - mse: 197673.0000 - val_loss: 165429.1719 - val_mae: 206.7327 - val_mse: 165429.1719\n",
      "Epoch 755/1000\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 205625.4688 - mae: 229.6993 - mse: 205625.4688 - val_loss: 160303.2656 - val_mae: 201.6143 - val_mse: 160303.2656\n",
      "Epoch 756/1000\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 206049.6094 - mae: 229.8082 - mse: 206049.6094 - val_loss: 162177.6875 - val_mae: 203.2199 - val_mse: 162177.6875\n",
      "Epoch 757/1000\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 203118.3750 - mae: 228.3103 - mse: 203118.3750 - val_loss: 159547.4219 - val_mae: 200.8487 - val_mse: 159547.4219\n",
      "Epoch 758/1000\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 203169.5312 - mae: 228.5525 - mse: 203169.5312 - val_loss: 175591.7812 - val_mae: 212.2311 - val_mse: 175591.7812\n",
      "Epoch 759/1000\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 206915.0781 - mae: 230.1328 - mse: 206915.0781 - val_loss: 162821.7344 - val_mae: 203.8585 - val_mse: 162821.7344\n",
      "Epoch 760/1000\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 196271.0469 - mae: 225.6646 - mse: 196271.0469 - val_loss: 157746.3906 - val_mae: 196.4787 - val_mse: 157746.3906\n",
      "Epoch 761/1000\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 205203.4219 - mae: 229.3396 - mse: 205203.4219 - val_loss: 156892.3281 - val_mae: 199.9969 - val_mse: 156892.3281\n",
      "Epoch 762/1000\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 204976.7969 - mae: 228.1763 - mse: 204976.7969 - val_loss: 170690.6406 - val_mae: 210.5036 - val_mse: 170690.6406\n",
      "Epoch 763/1000\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 205626.2812 - mae: 229.5902 - mse: 205626.2812 - val_loss: 163546.7656 - val_mae: 204.3848 - val_mse: 163546.7656\n",
      "Epoch 764/1000\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 196612.6406 - mae: 225.5482 - mse: 196612.6406 - val_loss: 162758.3906 - val_mae: 204.8434 - val_mse: 162758.3906\n",
      "Epoch 765/1000\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 202905.4062 - mae: 229.4549 - mse: 202905.4062 - val_loss: 158274.5000 - val_mae: 200.5800 - val_mse: 158274.5000\n",
      "Epoch 766/1000\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 204213.1562 - mae: 229.1574 - mse: 204213.1562 - val_loss: 155989.7031 - val_mae: 198.6548 - val_mse: 155989.7031\n",
      "Epoch 767/1000\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 198038.4375 - mae: 227.3385 - mse: 198038.4375 - val_loss: 156879.9219 - val_mae: 198.1670 - val_mse: 156879.9219\n",
      "Epoch 768/1000\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 202431.0156 - mae: 229.7656 - mse: 202431.0156 - val_loss: 168823.3438 - val_mae: 210.2016 - val_mse: 168823.3438\n",
      "Epoch 769/1000\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 210449.0938 - mae: 232.8726 - mse: 210449.0938 - val_loss: 156746.0781 - val_mae: 200.9562 - val_mse: 156746.0781\n",
      "Epoch 770/1000\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 203220.6250 - mae: 228.8375 - mse: 203220.6250 - val_loss: 162619.8438 - val_mae: 206.5901 - val_mse: 162619.8438\n",
      "Epoch 771/1000\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 208840.3438 - mae: 231.3639 - mse: 208840.3438 - val_loss: 158789.1719 - val_mae: 200.3518 - val_mse: 158789.1719\n",
      "Epoch 772/1000\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 202334.6562 - mae: 227.7863 - mse: 202334.6562 - val_loss: 167089.9219 - val_mae: 207.8391 - val_mse: 167089.9219\n",
      "Epoch 773/1000\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 203382.4688 - mae: 229.1782 - mse: 203382.4688 - val_loss: 160663.8438 - val_mae: 204.3080 - val_mse: 160663.8438\n",
      "Epoch 774/1000\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 204699.0312 - mae: 229.3432 - mse: 204699.0312 - val_loss: 160608.6406 - val_mae: 201.6184 - val_mse: 160608.6406\n",
      "Epoch 775/1000\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 203095.2031 - mae: 229.4892 - mse: 203095.2031 - val_loss: 167083.4375 - val_mae: 206.7565 - val_mse: 167083.4375\n",
      "Epoch 776/1000\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 202482.8125 - mae: 227.4907 - mse: 202482.8125 - val_loss: 156115.3594 - val_mae: 198.6454 - val_mse: 156115.3594\n",
      "Epoch 777/1000\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 197402.0312 - mae: 226.6946 - mse: 197402.0312 - val_loss: 154728.5000 - val_mae: 197.5972 - val_mse: 154728.5000\n",
      "Epoch 778/1000\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 198907.2969 - mae: 227.6213 - mse: 198907.2969 - val_loss: 164214.9844 - val_mae: 205.4939 - val_mse: 164214.9844\n",
      "Epoch 779/1000\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 204405.1562 - mae: 229.1037 - mse: 204405.1562 - val_loss: 154421.4219 - val_mae: 196.7272 - val_mse: 154421.4219\n",
      "Epoch 780/1000\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 195821.7031 - mae: 226.4804 - mse: 195821.7031 - val_loss: 168177.3906 - val_mae: 208.0102 - val_mse: 168177.3906\n",
      "Epoch 781/1000\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 204153.1875 - mae: 229.9711 - mse: 204153.1875 - val_loss: 164770.6719 - val_mae: 203.7081 - val_mse: 164770.6719\n",
      "Epoch 782/1000\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 198921.7500 - mae: 225.9437 - mse: 198921.7500 - val_loss: 159701.4844 - val_mae: 203.2262 - val_mse: 159701.4844\n",
      "Epoch 783/1000\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 203318.3750 - mae: 228.8023 - mse: 203318.3750 - val_loss: 160858.7969 - val_mae: 201.7554 - val_mse: 160858.7969\n",
      "Epoch 784/1000\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 199046.4531 - mae: 226.0780 - mse: 199046.4531 - val_loss: 155091.7969 - val_mae: 200.2795 - val_mse: 155091.7969\n",
      "Epoch 785/1000\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 198805.6719 - mae: 226.9998 - mse: 198805.6719 - val_loss: 172487.2656 - val_mae: 210.8791 - val_mse: 172487.2656\n",
      "Epoch 786/1000\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 212901.6719 - mae: 233.0983 - mse: 212901.6719 - val_loss: 175341.8281 - val_mae: 212.6512 - val_mse: 175341.8281\n",
      "Epoch 787/1000\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 199389.1875 - mae: 227.5018 - mse: 199389.1875 - val_loss: 159309.4531 - val_mae: 201.5688 - val_mse: 159309.4531\n",
      "Epoch 788/1000\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 204173.5312 - mae: 228.9779 - mse: 204173.5312 - val_loss: 162726.5625 - val_mae: 203.6112 - val_mse: 162726.5625\n",
      "Epoch 789/1000\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 202183.9688 - mae: 228.6021 - mse: 202183.9688 - val_loss: 172310.4844 - val_mae: 210.6614 - val_mse: 172310.4844\n",
      "Epoch 790/1000\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 197810.7344 - mae: 226.9077 - mse: 197810.7344 - val_loss: 176793.0312 - val_mae: 214.8674 - val_mse: 176793.0312\n",
      "Epoch 791/1000\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 204250.1250 - mae: 228.6308 - mse: 204250.1250 - val_loss: 161686.0000 - val_mae: 203.2232 - val_mse: 161686.0000\n",
      "Epoch 792/1000\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 201835.5469 - mae: 227.5270 - mse: 201835.5469 - val_loss: 169119.2031 - val_mae: 209.6360 - val_mse: 169119.2031\n",
      "Epoch 793/1000\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 201193.6562 - mae: 229.3166 - mse: 201193.6562 - val_loss: 165095.6250 - val_mae: 206.1240 - val_mse: 165095.6250\n",
      "Epoch 794/1000\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 200396.0781 - mae: 228.7045 - mse: 200396.0781 - val_loss: 166432.4219 - val_mae: 209.9991 - val_mse: 166432.4219\n",
      "Epoch 795/1000\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 200274.0625 - mae: 228.2142 - mse: 200274.0625 - val_loss: 159982.8438 - val_mae: 203.7041 - val_mse: 159982.8438\n",
      "Epoch 796/1000\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 203434.7344 - mae: 228.7023 - mse: 203434.7344 - val_loss: 161367.7188 - val_mae: 206.4120 - val_mse: 161367.7188\n",
      "Epoch 797/1000\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 202826.6719 - mae: 228.2596 - mse: 202826.6719 - val_loss: 160991.7344 - val_mae: 205.6684 - val_mse: 160991.7344\n",
      "Epoch 798/1000\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 205413.2500 - mae: 229.5217 - mse: 205413.2500 - val_loss: 179549.0938 - val_mae: 217.8164 - val_mse: 179549.0938\n",
      "Epoch 799/1000\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 198160.2812 - mae: 227.7030 - mse: 198160.2812 - val_loss: 154582.2969 - val_mae: 198.2023 - val_mse: 154582.2969\n",
      "Epoch 800/1000\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 197541.7812 - mae: 228.3738 - mse: 197541.7812 - val_loss: 169962.8281 - val_mae: 209.9647 - val_mse: 169962.8281\n",
      "Epoch 801/1000\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 201261.7812 - mae: 228.6126 - mse: 201261.7812 - val_loss: 167194.4688 - val_mae: 207.1788 - val_mse: 167194.4688\n",
      "Epoch 802/1000\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 197214.2344 - mae: 226.3797 - mse: 197214.2344 - val_loss: 157523.2500 - val_mae: 199.5515 - val_mse: 157523.2500\n",
      "Epoch 803/1000\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 194617.5000 - mae: 225.1161 - mse: 194617.5000 - val_loss: 158211.8750 - val_mae: 201.6051 - val_mse: 158211.8750\n",
      "Epoch 804/1000\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 196835.7188 - mae: 225.1779 - mse: 196835.7188 - val_loss: 160229.9062 - val_mae: 205.6236 - val_mse: 160229.9062\n",
      "Epoch 805/1000\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 198164.4219 - mae: 227.4438 - mse: 198164.4219 - val_loss: 159126.8750 - val_mae: 203.0128 - val_mse: 159126.8750\n",
      "Epoch 806/1000\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 199926.8594 - mae: 227.0583 - mse: 199926.8594 - val_loss: 159753.6875 - val_mae: 203.7730 - val_mse: 159753.6875\n",
      "Epoch 807/1000\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 200190.4219 - mae: 226.1045 - mse: 200190.4219 - val_loss: 157515.6406 - val_mae: 202.5278 - val_mse: 157515.6406\n",
      "Epoch 808/1000\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 200498.3906 - mae: 227.8036 - mse: 200498.3906 - val_loss: 170429.7969 - val_mae: 205.5517 - val_mse: 170429.7969\n",
      "Epoch 809/1000\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 204339.5469 - mae: 229.7715 - mse: 204339.5469 - val_loss: 161167.8750 - val_mae: 204.9723 - val_mse: 161167.8750\n",
      "Epoch 810/1000\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 199604.8750 - mae: 225.9409 - mse: 199604.8750 - val_loss: 162552.2656 - val_mae: 203.5247 - val_mse: 162552.2656\n",
      "Epoch 811/1000\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 202943.5938 - mae: 230.1709 - mse: 202943.5938 - val_loss: 156458.5781 - val_mae: 198.4807 - val_mse: 156458.5781\n",
      "Epoch 812/1000\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 199933.2500 - mae: 227.9751 - mse: 199933.2500 - val_loss: 171690.8281 - val_mae: 211.1448 - val_mse: 171690.8281\n",
      "Epoch 813/1000\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 195545.6094 - mae: 226.4460 - mse: 195545.6094 - val_loss: 166242.0781 - val_mae: 207.9060 - val_mse: 166242.0781\n",
      "Epoch 814/1000\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 202599.9062 - mae: 228.5370 - mse: 202599.9062 - val_loss: 163992.5156 - val_mae: 202.8673 - val_mse: 163992.5156\n",
      "Epoch 815/1000\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 202966.5156 - mae: 227.7883 - mse: 202966.5156 - val_loss: 168626.5469 - val_mae: 208.4859 - val_mse: 168626.5469\n",
      "Epoch 816/1000\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 201891.6562 - mae: 228.2090 - mse: 201891.6562 - val_loss: 167948.5625 - val_mae: 211.9012 - val_mse: 167948.5625\n",
      "Epoch 817/1000\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 205238.9375 - mae: 229.2413 - mse: 205238.9375 - val_loss: 165594.7500 - val_mae: 206.4337 - val_mse: 165594.7500\n",
      "Epoch 818/1000\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 202559.8750 - mae: 229.8660 - mse: 202559.8750 - val_loss: 166180.6719 - val_mae: 209.4053 - val_mse: 166180.6719\n",
      "Epoch 819/1000\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 206117.8438 - mae: 227.1653 - mse: 206117.8438 - val_loss: 163934.4688 - val_mae: 208.4984 - val_mse: 163934.4688\n",
      "Epoch 820/1000\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 196951.2656 - mae: 226.6361 - mse: 196951.2656 - val_loss: 157862.8281 - val_mae: 203.3236 - val_mse: 157862.8281\n",
      "Epoch 821/1000\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 199707.8750 - mae: 227.8749 - mse: 199707.8750 - val_loss: 179700.2656 - val_mae: 215.0663 - val_mse: 179700.2656\n",
      "Epoch 822/1000\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 203478.0781 - mae: 227.5522 - mse: 203478.0781 - val_loss: 166812.5312 - val_mae: 207.5665 - val_mse: 166812.5312\n",
      "Epoch 823/1000\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 195917.3750 - mae: 225.5672 - mse: 195917.3750 - val_loss: 163587.5469 - val_mae: 204.8054 - val_mse: 163587.5469\n",
      "Epoch 824/1000\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 197918.2969 - mae: 225.8325 - mse: 197918.2969 - val_loss: 166111.1875 - val_mae: 209.8470 - val_mse: 166111.1875\n",
      "Epoch 825/1000\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 208914.0625 - mae: 232.3906 - mse: 208914.0625 - val_loss: 168280.9531 - val_mae: 208.1084 - val_mse: 168280.9531\n",
      "Epoch 826/1000\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 200519.4844 - mae: 228.0264 - mse: 200519.4844 - val_loss: 163228.7812 - val_mae: 205.8994 - val_mse: 163228.7812\n",
      "Epoch 827/1000\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 195922.4844 - mae: 225.8885 - mse: 195922.4844 - val_loss: 160287.1719 - val_mae: 202.2117 - val_mse: 160287.1719\n",
      "Epoch 828/1000\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 196193.3438 - mae: 224.7674 - mse: 196193.3438 - val_loss: 154680.3906 - val_mae: 199.5393 - val_mse: 154680.3906\n",
      "Epoch 829/1000\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 198321.5469 - mae: 225.9383 - mse: 198321.5469 - val_loss: 155433.9844 - val_mae: 197.5224 - val_mse: 155433.9844\n",
      "Epoch 830/1000\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 201043.3438 - mae: 228.5557 - mse: 201043.3438 - val_loss: 158458.7656 - val_mae: 200.4168 - val_mse: 158458.7656\n",
      "Epoch 831/1000\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 198472.6875 - mae: 225.1856 - mse: 198472.6875 - val_loss: 155291.3594 - val_mae: 203.2004 - val_mse: 155291.3594\n",
      "Epoch 832/1000\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 196565.5000 - mae: 227.5781 - mse: 196565.5000 - val_loss: 158255.4219 - val_mae: 201.2622 - val_mse: 158255.4219\n",
      "Epoch 833/1000\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 201529.3594 - mae: 227.7692 - mse: 201529.3594 - val_loss: 157887.6875 - val_mae: 200.5833 - val_mse: 157887.6875\n",
      "Epoch 834/1000\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 199342.3750 - mae: 226.9624 - mse: 199342.3750 - val_loss: 167545.9219 - val_mae: 209.7721 - val_mse: 167545.9219\n",
      "Epoch 835/1000\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 196213.1094 - mae: 226.1081 - mse: 196213.1094 - val_loss: 157584.7031 - val_mae: 200.7595 - val_mse: 157584.7031\n",
      "Epoch 836/1000\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 200931.4688 - mae: 228.2583 - mse: 200931.4688 - val_loss: 160039.8906 - val_mae: 199.5849 - val_mse: 160039.8906\n",
      "Epoch 837/1000\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 191897.9844 - mae: 224.7105 - mse: 191897.9844 - val_loss: 161082.6406 - val_mae: 206.8983 - val_mse: 161082.6406\n",
      "Epoch 838/1000\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 197538.0625 - mae: 228.1225 - mse: 197538.0625 - val_loss: 164535.7188 - val_mae: 205.9978 - val_mse: 164535.7188\n",
      "Epoch 839/1000\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 198389.8281 - mae: 227.0347 - mse: 198389.8281 - val_loss: 159032.9688 - val_mae: 202.3051 - val_mse: 159032.9688\n",
      "Epoch 840/1000\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 196628.3750 - mae: 227.7151 - mse: 196628.3750 - val_loss: 156402.6094 - val_mae: 199.3955 - val_mse: 156402.6094\n",
      "Epoch 841/1000\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 193396.8594 - mae: 225.5920 - mse: 193396.8594 - val_loss: 163370.6562 - val_mae: 203.8830 - val_mse: 163370.6562\n",
      "Epoch 842/1000\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 203908.3125 - mae: 230.2380 - mse: 203908.3125 - val_loss: 161977.5156 - val_mae: 204.2057 - val_mse: 161977.5156\n",
      "Epoch 843/1000\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 203039.8438 - mae: 228.9846 - mse: 203039.8438 - val_loss: 162913.5938 - val_mae: 206.1909 - val_mse: 162913.5938\n",
      "Epoch 844/1000\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 198344.1875 - mae: 228.4163 - mse: 198344.1875 - val_loss: 161217.0469 - val_mae: 205.4360 - val_mse: 161217.0469\n",
      "Epoch 845/1000\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 197711.8438 - mae: 227.2357 - mse: 197711.8438 - val_loss: 156585.5938 - val_mae: 197.8934 - val_mse: 156585.5938\n",
      "Epoch 846/1000\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 199236.7812 - mae: 227.2711 - mse: 199236.7812 - val_loss: 165228.3281 - val_mae: 208.0546 - val_mse: 165228.3281\n",
      "Epoch 847/1000\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 201627.7031 - mae: 229.0555 - mse: 201627.7031 - val_loss: 158035.2188 - val_mae: 199.7936 - val_mse: 158035.2188\n",
      "Epoch 848/1000\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 193818.4375 - mae: 225.6459 - mse: 193818.4375 - val_loss: 164728.6562 - val_mae: 206.2766 - val_mse: 164728.6562\n",
      "Epoch 849/1000\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 195724.4062 - mae: 227.4569 - mse: 195724.4062 - val_loss: 162465.3438 - val_mae: 205.4809 - val_mse: 162465.3438\n",
      "Epoch 850/1000\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 197550.3125 - mae: 227.2011 - mse: 197550.3125 - val_loss: 162936.1562 - val_mae: 202.1697 - val_mse: 162936.1562\n",
      "Epoch 851/1000\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 194908.5625 - mae: 225.3271 - mse: 194908.5625 - val_loss: 163112.6562 - val_mae: 204.5989 - val_mse: 163112.6562\n",
      "Epoch 852/1000\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 200095.9219 - mae: 228.2116 - mse: 200095.9219 - val_loss: 164669.4219 - val_mae: 202.3723 - val_mse: 164669.4219\n",
      "Epoch 853/1000\n",
      "707/707 [==============================] - 1s 2ms/step - loss: 201543.7344 - mae: 228.8297 - mse: 201543.7344 - val_loss: 166094.8750 - val_mae: 204.9620 - val_mse: 166094.8750\n",
      "Epoch 854/1000\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 202061.2188 - mae: 228.9770 - mse: 202061.2188 - val_loss: 157485.4844 - val_mae: 203.5663 - val_mse: 157485.4844\n",
      "Epoch 855/1000\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 194809.9688 - mae: 225.5793 - mse: 194809.9688 - val_loss: 159837.7500 - val_mae: 202.9326 - val_mse: 159837.7500\n",
      "Epoch 856/1000\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 192299.3594 - mae: 224.2634 - mse: 192299.3594 - val_loss: 156927.3281 - val_mae: 202.4489 - val_mse: 156927.3281\n",
      "Epoch 857/1000\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 197166.7812 - mae: 227.2211 - mse: 197166.7812 - val_loss: 167081.5469 - val_mae: 211.7111 - val_mse: 167081.5469\n",
      "Epoch 858/1000\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 197905.0781 - mae: 228.6452 - mse: 197905.0781 - val_loss: 168633.1250 - val_mae: 208.5531 - val_mse: 168633.1250\n",
      "Epoch 859/1000\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 203926.9375 - mae: 230.5692 - mse: 203926.9375 - val_loss: 172542.4219 - val_mae: 210.7528 - val_mse: 172542.4219\n",
      "Epoch 860/1000\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 197953.6406 - mae: 227.6256 - mse: 197953.6406 - val_loss: 166073.8438 - val_mae: 207.2328 - val_mse: 166073.8438\n",
      "Epoch 861/1000\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 200807.7969 - mae: 228.3305 - mse: 200807.7969 - val_loss: 165258.6719 - val_mae: 208.5322 - val_mse: 165258.6719\n",
      "Epoch 862/1000\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 198370.8438 - mae: 227.4658 - mse: 198370.8438 - val_loss: 164743.3281 - val_mae: 204.3369 - val_mse: 164743.3281\n",
      "Epoch 863/1000\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 194649.5000 - mae: 225.4019 - mse: 194649.5000 - val_loss: 161089.6406 - val_mae: 206.6581 - val_mse: 161089.6406\n",
      "Epoch 864/1000\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 193245.4375 - mae: 226.0706 - mse: 193245.4375 - val_loss: 167246.5781 - val_mae: 209.9863 - val_mse: 167246.5781\n",
      "Epoch 865/1000\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 203245.5938 - mae: 229.5377 - mse: 203245.5938 - val_loss: 159248.5625 - val_mae: 204.3931 - val_mse: 159248.5625\n",
      "Epoch 866/1000\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 202609.8594 - mae: 227.3929 - mse: 202609.8594 - val_loss: 161225.3438 - val_mae: 203.6258 - val_mse: 161225.3438\n",
      "Epoch 867/1000\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 191824.3125 - mae: 225.4780 - mse: 191824.3125 - val_loss: 165714.4688 - val_mae: 208.2591 - val_mse: 165714.4688\n",
      "Epoch 868/1000\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 198815.7188 - mae: 228.0769 - mse: 198815.7188 - val_loss: 161322.2500 - val_mae: 209.1304 - val_mse: 161322.2500\n",
      "Epoch 869/1000\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 199609.4375 - mae: 226.5215 - mse: 199609.4375 - val_loss: 159220.5625 - val_mae: 203.3593 - val_mse: 159220.5625\n",
      "Epoch 870/1000\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 196133.1250 - mae: 226.4757 - mse: 196133.1250 - val_loss: 158717.9844 - val_mae: 203.9882 - val_mse: 158717.9844\n",
      "Epoch 871/1000\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 199586.2656 - mae: 228.8517 - mse: 199586.2656 - val_loss: 162400.5625 - val_mae: 206.5496 - val_mse: 162400.5625\n",
      "Epoch 872/1000\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 200219.0312 - mae: 228.7566 - mse: 200219.0312 - val_loss: 164201.9219 - val_mae: 207.3678 - val_mse: 164201.9219\n",
      "Epoch 873/1000\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 194177.4531 - mae: 226.6098 - mse: 194177.4531 - val_loss: 164075.8125 - val_mae: 207.1115 - val_mse: 164075.8125\n",
      "Epoch 874/1000\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 197906.7188 - mae: 227.0095 - mse: 197906.7188 - val_loss: 159984.4375 - val_mae: 201.4417 - val_mse: 159984.4375\n",
      "Epoch 875/1000\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 192534.4844 - mae: 225.7028 - mse: 192534.4844 - val_loss: 165660.1875 - val_mae: 207.4512 - val_mse: 165660.1875\n",
      "Epoch 876/1000\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 200964.4219 - mae: 228.6930 - mse: 200964.4219 - val_loss: 168311.7656 - val_mae: 209.9500 - val_mse: 168311.7656\n",
      "Epoch 877/1000\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 194901.2344 - mae: 226.3165 - mse: 194901.2344 - val_loss: 153715.9688 - val_mae: 197.6312 - val_mse: 153715.9688\n",
      "Epoch 878/1000\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 202655.8750 - mae: 230.5753 - mse: 202655.8750 - val_loss: 159895.4375 - val_mae: 203.9771 - val_mse: 159895.4375\n",
      "Epoch 879/1000\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 200095.5938 - mae: 228.3528 - mse: 200095.5938 - val_loss: 159291.4531 - val_mae: 204.2340 - val_mse: 159291.4531\n",
      "Epoch 880/1000\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 196055.5625 - mae: 225.4275 - mse: 196055.5625 - val_loss: 161027.3906 - val_mae: 207.8961 - val_mse: 161027.3906\n",
      "Epoch 881/1000\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 198755.9375 - mae: 227.1934 - mse: 198755.9375 - val_loss: 156837.8906 - val_mae: 201.6488 - val_mse: 156837.8906\n",
      "Epoch 882/1000\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 197573.2500 - mae: 226.9435 - mse: 197573.2500 - val_loss: 158815.8594 - val_mae: 202.4609 - val_mse: 158815.8594\n",
      "Epoch 883/1000\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 195833.6875 - mae: 226.7507 - mse: 195833.6875 - val_loss: 163132.7188 - val_mae: 205.1560 - val_mse: 163132.7188\n",
      "Epoch 884/1000\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 193361.6094 - mae: 225.8144 - mse: 193361.6094 - val_loss: 158119.8594 - val_mae: 201.1766 - val_mse: 158119.8594\n",
      "Epoch 885/1000\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 202007.0625 - mae: 227.8159 - mse: 202007.0625 - val_loss: 161673.0938 - val_mae: 206.7574 - val_mse: 161673.0938\n",
      "Epoch 886/1000\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 197324.2500 - mae: 227.1749 - mse: 197324.2500 - val_loss: 162792.1719 - val_mae: 204.0580 - val_mse: 162792.1719\n",
      "Epoch 887/1000\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 194083.4844 - mae: 226.9893 - mse: 194083.4844 - val_loss: 168794.1094 - val_mae: 207.6899 - val_mse: 168794.1094\n",
      "Epoch 888/1000\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 199697.6406 - mae: 227.7277 - mse: 199697.6406 - val_loss: 158424.4688 - val_mae: 205.5533 - val_mse: 158424.4688\n",
      "Epoch 889/1000\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 198486.3594 - mae: 226.7168 - mse: 198486.3594 - val_loss: 166373.8594 - val_mae: 207.9318 - val_mse: 166373.8594\n",
      "Epoch 890/1000\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 194992.9844 - mae: 225.8855 - mse: 194992.9844 - val_loss: 158767.1875 - val_mae: 204.5419 - val_mse: 158767.1875\n",
      "Epoch 891/1000\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 196882.0938 - mae: 228.2255 - mse: 196882.0938 - val_loss: 171890.2500 - val_mae: 213.5522 - val_mse: 171890.2500\n",
      "Epoch 892/1000\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 199469.0000 - mae: 227.2920 - mse: 199469.0000 - val_loss: 155787.6406 - val_mae: 202.3667 - val_mse: 155787.6406\n",
      "Epoch 893/1000\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 201624.0781 - mae: 227.6981 - mse: 201624.0781 - val_loss: 172235.9219 - val_mae: 211.1797 - val_mse: 172235.9219\n",
      "Epoch 894/1000\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 193173.9844 - mae: 222.8914 - mse: 193173.9844 - val_loss: 160100.8281 - val_mae: 203.3555 - val_mse: 160100.8281\n",
      "Epoch 895/1000\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 201852.6094 - mae: 227.3265 - mse: 201852.6094 - val_loss: 158522.6094 - val_mae: 205.6345 - val_mse: 158522.6094\n",
      "Epoch 896/1000\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 201717.2500 - mae: 230.8992 - mse: 201717.2500 - val_loss: 159235.4531 - val_mae: 202.2999 - val_mse: 159235.4531\n",
      "Epoch 897/1000\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 197313.1562 - mae: 227.8236 - mse: 197313.1562 - val_loss: 164965.7656 - val_mae: 208.9823 - val_mse: 164965.7656\n",
      "Epoch 898/1000\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 196976.2812 - mae: 227.1470 - mse: 196976.2812 - val_loss: 156486.9531 - val_mae: 200.4221 - val_mse: 156486.9531\n",
      "Epoch 899/1000\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 190150.7031 - mae: 224.2913 - mse: 190150.7031 - val_loss: 168921.3125 - val_mae: 210.2805 - val_mse: 168921.3125\n",
      "Epoch 900/1000\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 194187.3906 - mae: 225.7356 - mse: 194187.3906 - val_loss: 165339.4531 - val_mae: 208.5898 - val_mse: 165339.4531\n",
      "Epoch 901/1000\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 198278.1250 - mae: 228.1445 - mse: 198278.1250 - val_loss: 167254.9688 - val_mae: 209.6902 - val_mse: 167254.9688\n",
      "Epoch 902/1000\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 195390.5469 - mae: 225.8845 - mse: 195390.5469 - val_loss: 156427.9375 - val_mae: 200.2475 - val_mse: 156427.9375\n",
      "Epoch 903/1000\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 195527.8125 - mae: 227.8704 - mse: 195527.8125 - val_loss: 155939.8281 - val_mae: 200.8904 - val_mse: 155939.8281\n",
      "Epoch 904/1000\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 198439.7656 - mae: 226.6798 - mse: 198439.7656 - val_loss: 163538.7344 - val_mae: 205.4223 - val_mse: 163538.7344\n",
      "Epoch 905/1000\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 188889.1406 - mae: 224.0397 - mse: 188889.1406 - val_loss: 168543.9219 - val_mae: 208.0328 - val_mse: 168543.9219\n",
      "Epoch 906/1000\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 195261.6719 - mae: 226.4876 - mse: 195261.6719 - val_loss: 163152.0625 - val_mae: 203.1930 - val_mse: 163152.0625\n",
      "Epoch 907/1000\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 199958.6250 - mae: 228.6477 - mse: 199958.6250 - val_loss: 161137.9531 - val_mae: 201.2348 - val_mse: 161137.9531\n",
      "Epoch 908/1000\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 192815.1719 - mae: 225.0598 - mse: 192815.1719 - val_loss: 166421.3281 - val_mae: 206.4778 - val_mse: 166421.3281\n",
      "Epoch 909/1000\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 195993.9375 - mae: 226.4505 - mse: 195993.9375 - val_loss: 166222.5469 - val_mae: 207.1002 - val_mse: 166222.5469\n",
      "Epoch 910/1000\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 191959.2031 - mae: 225.3694 - mse: 191959.2031 - val_loss: 157306.2656 - val_mae: 202.8790 - val_mse: 157306.2656\n",
      "Epoch 911/1000\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 195685.1562 - mae: 226.2909 - mse: 195685.1562 - val_loss: 172934.5000 - val_mae: 215.2043 - val_mse: 172934.5000\n",
      "Epoch 912/1000\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 192578.3750 - mae: 225.0838 - mse: 192578.3750 - val_loss: 170067.9844 - val_mae: 211.3495 - val_mse: 170067.9844\n",
      "Epoch 913/1000\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 198334.4531 - mae: 227.7627 - mse: 198334.4531 - val_loss: 177119.9531 - val_mae: 215.9865 - val_mse: 177119.9531\n",
      "Epoch 914/1000\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 196919.9375 - mae: 227.3819 - mse: 196919.9375 - val_loss: 166748.0156 - val_mae: 209.6197 - val_mse: 166748.0156\n",
      "Epoch 915/1000\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 190269.0000 - mae: 223.8671 - mse: 190269.0000 - val_loss: 162000.2812 - val_mae: 202.5317 - val_mse: 162000.2812\n",
      "Epoch 916/1000\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 197069.5156 - mae: 227.4937 - mse: 197069.5156 - val_loss: 160446.7500 - val_mae: 203.4475 - val_mse: 160446.7500\n",
      "Epoch 917/1000\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 200726.6406 - mae: 228.2345 - mse: 200726.6406 - val_loss: 160994.4219 - val_mae: 203.7630 - val_mse: 160994.4219\n",
      "Epoch 918/1000\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 195846.8281 - mae: 225.8728 - mse: 195846.8281 - val_loss: 164568.1406 - val_mae: 208.4697 - val_mse: 164568.1406\n",
      "Epoch 919/1000\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 193783.8906 - mae: 226.2783 - mse: 193783.8906 - val_loss: 160830.3594 - val_mae: 202.6216 - val_mse: 160830.3594\n",
      "Epoch 920/1000\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 193494.5312 - mae: 224.3817 - mse: 193494.5312 - val_loss: 168314.1562 - val_mae: 209.2560 - val_mse: 168314.1562\n",
      "Epoch 921/1000\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 194341.0312 - mae: 226.0296 - mse: 194341.0312 - val_loss: 162695.1250 - val_mae: 205.7762 - val_mse: 162695.1250\n",
      "Epoch 922/1000\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 193788.8438 - mae: 225.1462 - mse: 193788.8438 - val_loss: 160407.4375 - val_mae: 202.7910 - val_mse: 160407.4375\n",
      "Epoch 923/1000\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 189977.2812 - mae: 225.0641 - mse: 189977.2812 - val_loss: 172838.1250 - val_mae: 213.9965 - val_mse: 172838.1250\n",
      "Epoch 924/1000\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 202695.6094 - mae: 228.3632 - mse: 202695.6094 - val_loss: 162555.2812 - val_mae: 204.5930 - val_mse: 162555.2812\n",
      "Epoch 925/1000\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 201857.2812 - mae: 229.3852 - mse: 201857.2812 - val_loss: 159635.0469 - val_mae: 206.0203 - val_mse: 159635.0469\n",
      "Epoch 926/1000\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 204010.0938 - mae: 228.9805 - mse: 204010.0938 - val_loss: 171542.2969 - val_mae: 214.3334 - val_mse: 171542.2969\n",
      "Epoch 927/1000\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 191079.1875 - mae: 224.6832 - mse: 191079.1875 - val_loss: 163125.2812 - val_mae: 207.3990 - val_mse: 163125.2812\n",
      "Epoch 928/1000\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 196407.1562 - mae: 226.4574 - mse: 196407.1562 - val_loss: 160160.2656 - val_mae: 206.7795 - val_mse: 160160.2656\n",
      "Epoch 929/1000\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 200715.2500 - mae: 228.3812 - mse: 200715.2500 - val_loss: 156778.3750 - val_mae: 199.7555 - val_mse: 156778.3750\n",
      "Epoch 930/1000\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 188705.2188 - mae: 223.3118 - mse: 188705.2188 - val_loss: 162585.7812 - val_mae: 203.4937 - val_mse: 162585.7812\n",
      "Epoch 931/1000\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 190257.9062 - mae: 223.9504 - mse: 190257.9062 - val_loss: 163884.5156 - val_mae: 204.6526 - val_mse: 163884.5156\n",
      "Epoch 932/1000\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 186949.3281 - mae: 222.4980 - mse: 186949.3281 - val_loss: 158435.7344 - val_mae: 202.4046 - val_mse: 158435.7344\n",
      "Epoch 933/1000\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 194032.7188 - mae: 225.4299 - mse: 194032.7188 - val_loss: 166794.7656 - val_mae: 209.6577 - val_mse: 166794.7656\n",
      "Epoch 934/1000\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 193246.1406 - mae: 226.5678 - mse: 193246.1406 - val_loss: 157686.5625 - val_mae: 201.7702 - val_mse: 157686.5625\n",
      "Epoch 935/1000\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 198191.7500 - mae: 226.8077 - mse: 198191.7500 - val_loss: 157599.7188 - val_mae: 201.6817 - val_mse: 157599.7188\n",
      "Epoch 936/1000\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 197418.4219 - mae: 227.4663 - mse: 197418.4219 - val_loss: 166012.8125 - val_mae: 208.5100 - val_mse: 166012.8125\n",
      "Epoch 937/1000\n",
      "707/707 [==============================] - 1s 2ms/step - loss: 193771.8438 - mae: 226.7232 - mse: 193771.8438 - val_loss: 165107.6094 - val_mae: 206.7359 - val_mse: 165107.6094\n",
      "Epoch 938/1000\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 185391.1250 - mae: 223.1984 - mse: 185391.1250 - val_loss: 164622.3438 - val_mae: 206.5942 - val_mse: 164622.3438\n",
      "Epoch 939/1000\n",
      "707/707 [==============================] - 1s 2ms/step - loss: 189260.4844 - mae: 223.8436 - mse: 189260.4844 - val_loss: 155737.7656 - val_mae: 197.8147 - val_mse: 155737.7656\n",
      "Epoch 940/1000\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 199540.8125 - mae: 227.6493 - mse: 199540.8125 - val_loss: 159217.7188 - val_mae: 204.7640 - val_mse: 159217.7188\n",
      "Epoch 941/1000\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 189995.2188 - mae: 225.0074 - mse: 189995.2188 - val_loss: 165107.5781 - val_mae: 210.5948 - val_mse: 165107.5781\n",
      "Epoch 942/1000\n",
      "707/707 [==============================] - 1s 2ms/step - loss: 196028.8750 - mae: 226.5845 - mse: 196028.8750 - val_loss: 158233.5938 - val_mae: 202.7923 - val_mse: 158233.5938\n",
      "Epoch 943/1000\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 197192.5000 - mae: 226.2761 - mse: 197192.5000 - val_loss: 167321.0000 - val_mae: 207.3199 - val_mse: 167321.0000\n",
      "Epoch 944/1000\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 194027.1719 - mae: 225.6416 - mse: 194027.1719 - val_loss: 170478.3750 - val_mae: 213.5006 - val_mse: 170478.3750\n",
      "Epoch 945/1000\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 198039.3438 - mae: 227.6766 - mse: 198039.3438 - val_loss: 153649.9375 - val_mae: 199.9532 - val_mse: 153649.9375\n",
      "Epoch 946/1000\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 190359.9531 - mae: 224.1089 - mse: 190359.9531 - val_loss: 158786.6406 - val_mae: 202.0530 - val_mse: 158786.6406\n",
      "Epoch 947/1000\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 193189.0156 - mae: 226.1806 - mse: 193189.0156 - val_loss: 166471.8281 - val_mae: 211.1093 - val_mse: 166471.8281\n",
      "Epoch 948/1000\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 196492.2812 - mae: 226.3119 - mse: 196492.2812 - val_loss: 160341.8281 - val_mae: 207.3365 - val_mse: 160341.8281\n",
      "Epoch 949/1000\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 199663.7031 - mae: 227.3014 - mse: 199663.7031 - val_loss: 157689.9219 - val_mae: 200.9341 - val_mse: 157689.9219\n",
      "Epoch 950/1000\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 201773.5000 - mae: 228.7098 - mse: 201773.5000 - val_loss: 162406.1094 - val_mae: 206.3826 - val_mse: 162406.1094\n",
      "Epoch 951/1000\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 189324.8281 - mae: 224.6646 - mse: 189324.8281 - val_loss: 157884.0469 - val_mae: 203.2494 - val_mse: 157884.0469\n",
      "Epoch 952/1000\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 193569.3906 - mae: 226.3400 - mse: 193569.3906 - val_loss: 157757.9219 - val_mae: 203.8879 - val_mse: 157757.9219\n",
      "Epoch 953/1000\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 191969.0781 - mae: 224.5478 - mse: 191969.0781 - val_loss: 162260.4375 - val_mae: 206.4160 - val_mse: 162260.4375\n",
      "Epoch 954/1000\n",
      "707/707 [==============================] - 1s 2ms/step - loss: 193436.9219 - mae: 225.4926 - mse: 193436.9219 - val_loss: 162856.7031 - val_mae: 205.3443 - val_mse: 162856.7031\n",
      "Epoch 955/1000\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 197731.1562 - mae: 227.0477 - mse: 197731.1562 - val_loss: 165745.1875 - val_mae: 205.9777 - val_mse: 165745.1875\n",
      "Epoch 956/1000\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 191693.5625 - mae: 225.1382 - mse: 191693.5625 - val_loss: 155282.1719 - val_mae: 200.4407 - val_mse: 155282.1719\n",
      "Epoch 957/1000\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 189096.7188 - mae: 222.9637 - mse: 189096.7188 - val_loss: 165288.5312 - val_mae: 207.0759 - val_mse: 165288.5312\n",
      "Epoch 958/1000\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 198270.8438 - mae: 228.6287 - mse: 198270.8438 - val_loss: 174293.3750 - val_mae: 215.4695 - val_mse: 174293.3750\n",
      "Epoch 959/1000\n",
      "707/707 [==============================] - 1s 2ms/step - loss: 199384.8438 - mae: 228.3757 - mse: 199384.8438 - val_loss: 161759.4844 - val_mae: 204.5435 - val_mse: 161759.4844\n",
      "Epoch 960/1000\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 197142.3281 - mae: 226.5296 - mse: 197142.3281 - val_loss: 160712.4844 - val_mae: 206.8771 - val_mse: 160712.4844\n",
      "Epoch 961/1000\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 192247.6562 - mae: 225.1053 - mse: 192247.6562 - val_loss: 165183.6875 - val_mae: 209.2620 - val_mse: 165183.6875\n",
      "Epoch 962/1000\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 196827.2969 - mae: 228.2818 - mse: 196827.2969 - val_loss: 161838.8125 - val_mae: 207.7735 - val_mse: 161838.8125\n",
      "Epoch 963/1000\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 194692.4375 - mae: 224.7314 - mse: 194692.4375 - val_loss: 157805.2031 - val_mae: 203.7598 - val_mse: 157805.2031\n",
      "Epoch 964/1000\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 194874.2344 - mae: 227.4085 - mse: 194874.2344 - val_loss: 165077.6562 - val_mae: 209.2844 - val_mse: 165077.6562\n",
      "Epoch 965/1000\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 192612.2656 - mae: 224.9786 - mse: 192612.2656 - val_loss: 160561.7656 - val_mae: 201.8987 - val_mse: 160561.7656\n",
      "Epoch 966/1000\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 197342.7969 - mae: 228.4700 - mse: 197342.7969 - val_loss: 157636.0000 - val_mae: 204.2830 - val_mse: 157636.0000\n",
      "Epoch 967/1000\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 195125.3594 - mae: 225.7727 - mse: 195125.3594 - val_loss: 162225.6875 - val_mae: 204.9325 - val_mse: 162225.6875\n",
      "Epoch 968/1000\n",
      "707/707 [==============================] - 1s 2ms/step - loss: 193518.2656 - mae: 226.4618 - mse: 193518.2656 - val_loss: 165124.6250 - val_mae: 209.1738 - val_mse: 165124.6250\n",
      "Epoch 969/1000\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 189337.6719 - mae: 225.1549 - mse: 189337.6719 - val_loss: 159854.4219 - val_mae: 205.9090 - val_mse: 159854.4219\n",
      "Epoch 970/1000\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 200212.8750 - mae: 228.7264 - mse: 200212.8750 - val_loss: 161184.8125 - val_mae: 207.0477 - val_mse: 161184.8125\n",
      "Epoch 971/1000\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 199285.7031 - mae: 228.5107 - mse: 199285.7031 - val_loss: 171014.7031 - val_mae: 212.8727 - val_mse: 171014.7031\n",
      "Epoch 972/1000\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 190569.0938 - mae: 225.1553 - mse: 190569.0938 - val_loss: 163306.3281 - val_mae: 208.9682 - val_mse: 163306.3281\n",
      "Epoch 973/1000\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 189139.8125 - mae: 223.5539 - mse: 189139.8125 - val_loss: 160039.1719 - val_mae: 206.1604 - val_mse: 160039.1719\n",
      "Epoch 974/1000\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 199117.0312 - mae: 225.8824 - mse: 199117.0312 - val_loss: 159625.0469 - val_mae: 209.6892 - val_mse: 159625.0469\n",
      "Epoch 975/1000\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 196831.7344 - mae: 225.7070 - mse: 196831.7344 - val_loss: 157667.6406 - val_mae: 202.8935 - val_mse: 157667.6406\n",
      "Epoch 976/1000\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 197918.3906 - mae: 227.4405 - mse: 197918.3906 - val_loss: 168607.0156 - val_mae: 210.8519 - val_mse: 168607.0156\n",
      "Epoch 977/1000\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 194805.5938 - mae: 226.5705 - mse: 194805.5938 - val_loss: 162114.1094 - val_mae: 205.5391 - val_mse: 162114.1094\n",
      "Epoch 978/1000\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 194771.8438 - mae: 225.9850 - mse: 194771.8438 - val_loss: 156345.0156 - val_mae: 200.5156 - val_mse: 156345.0156\n",
      "Epoch 979/1000\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 190267.8281 - mae: 223.3809 - mse: 190267.8281 - val_loss: 159305.2344 - val_mae: 200.3040 - val_mse: 159305.2344\n",
      "Epoch 980/1000\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 192555.6562 - mae: 225.9620 - mse: 192555.6562 - val_loss: 158225.6094 - val_mae: 201.7873 - val_mse: 158225.6094\n",
      "Epoch 981/1000\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 191592.8906 - mae: 225.4119 - mse: 191592.8906 - val_loss: 153682.7344 - val_mae: 200.0201 - val_mse: 153682.7344\n",
      "Epoch 982/1000\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 191428.7812 - mae: 224.2792 - mse: 191428.7812 - val_loss: 165003.7500 - val_mae: 208.2410 - val_mse: 165003.7500\n",
      "Epoch 983/1000\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 194400.5312 - mae: 226.3700 - mse: 194400.5312 - val_loss: 156307.3750 - val_mae: 202.9976 - val_mse: 156307.3750\n",
      "Epoch 984/1000\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 195948.8906 - mae: 227.2724 - mse: 195948.8906 - val_loss: 161517.3750 - val_mae: 204.0608 - val_mse: 161517.3750\n",
      "Epoch 985/1000\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 189958.0000 - mae: 224.9899 - mse: 189958.0000 - val_loss: 154401.9844 - val_mae: 197.7545 - val_mse: 154401.9844\n",
      "Epoch 986/1000\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 189914.1562 - mae: 224.1259 - mse: 189914.1562 - val_loss: 159784.2812 - val_mae: 207.2067 - val_mse: 159784.2812\n",
      "Epoch 987/1000\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 196146.5312 - mae: 226.0833 - mse: 196146.5312 - val_loss: 155868.9531 - val_mae: 200.7635 - val_mse: 155868.9531\n",
      "Epoch 988/1000\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 188977.1875 - mae: 223.5616 - mse: 188977.1875 - val_loss: 164178.7188 - val_mae: 206.2467 - val_mse: 164178.7188\n",
      "Epoch 989/1000\n",
      "707/707 [==============================] - 1s 2ms/step - loss: 192662.1094 - mae: 223.2798 - mse: 192662.1094 - val_loss: 166031.3125 - val_mae: 205.3024 - val_mse: 166031.3125\n",
      "Epoch 990/1000\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 193005.0781 - mae: 225.5358 - mse: 193005.0781 - val_loss: 162037.6719 - val_mae: 207.1509 - val_mse: 162037.6719\n",
      "Epoch 991/1000\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 194987.5469 - mae: 225.5256 - mse: 194987.5469 - val_loss: 169345.6250 - val_mae: 212.3664 - val_mse: 169345.6250\n",
      "Epoch 992/1000\n",
      "707/707 [==============================] - 1s 2ms/step - loss: 189309.4062 - mae: 223.6344 - mse: 189309.4062 - val_loss: 157334.5938 - val_mae: 204.2885 - val_mse: 157334.5938\n",
      "Epoch 993/1000\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 194508.4531 - mae: 225.3007 - mse: 194508.4531 - val_loss: 163178.5000 - val_mae: 204.8328 - val_mse: 163178.5000\n",
      "Epoch 994/1000\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 195292.7188 - mae: 227.6841 - mse: 195292.7188 - val_loss: 177534.2188 - val_mae: 215.9131 - val_mse: 177534.2188\n",
      "Epoch 995/1000\n",
      "707/707 [==============================] - 1s 2ms/step - loss: 192232.7188 - mae: 226.6951 - mse: 192232.7188 - val_loss: 160281.7344 - val_mae: 207.5491 - val_mse: 160281.7344\n",
      "Epoch 996/1000\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 188348.8438 - mae: 225.0870 - mse: 188348.8438 - val_loss: 165822.6719 - val_mae: 208.5813 - val_mse: 165822.6719\n",
      "Epoch 997/1000\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 189223.8281 - mae: 225.0084 - mse: 189223.8281 - val_loss: 161395.5312 - val_mae: 204.7197 - val_mse: 161395.5312\n",
      "Epoch 998/1000\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 190906.3125 - mae: 223.3917 - mse: 190906.3125 - val_loss: 159861.3281 - val_mae: 203.8431 - val_mse: 159861.3281\n",
      "Epoch 999/1000\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 186141.6250 - mae: 222.7885 - mse: 186141.6250 - val_loss: 169219.2969 - val_mae: 213.0715 - val_mse: 169219.2969\n",
      "Epoch 1000/1000\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 192112.4688 - mae: 225.6969 - mse: 192112.4688 - val_loss: 156690.1406 - val_mae: 201.4388 - val_mse: 156690.1406\n"
     ]
    }
   ],
   "source": [
    "model_a = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.InputLayer(input_shape=54),\n",
    "    #ak.MultiCategoryEncoding(encoding=['int','int','int','int','none','none','none','none','none',\n",
    "    #                                   'none','none','none','none','none','int','int','int','int',\n",
    "    #                                   'int','none','int','none','none','int','int','none','none',\n",
    "    #                                   'int','int','int','int','none','none','int','none','none',\n",
    "    #                                   'none','int','int','int','int','int','int','none','none',\n",
    "    #                                   'int','int','int','int','int','int','int','int']),\n",
    "    normalizer_A, \n",
    "    tf.keras.layers.Dense(1024, activation='linear'),\n",
    "    tf.keras.layers.ReLU(),\n",
    "    tf.keras.layers.Dropout(0.5),\n",
    "    tf.keras.layers.Dense(32, activation='linear'),\n",
    "    tf.keras.layers.ReLU(),\n",
    "    tf.keras.layers.Dropout(0.5),\n",
    "    tf.keras.layers.Dense(1)\n",
    "])\n",
    "\n",
    "model_a.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.001), \n",
    "                loss=\"mse\", \n",
    "                metrics=[\"mae\", \"mse\"])\n",
    "\n",
    "history_a = model_a.fit(x=x_train_a, y=y_train_a, epochs=1000, callbacks=[early_stop], validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:Skipping variable loading for optimizer 'Adam', because it has 13 variables whereas the saved optimizer has 1 variables. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 53)]              0         \n",
      "                                                                 \n",
      " multi_category_encoding (M  (None, 53)                0         \n",
      " ultiCategoryEncoding)                                           \n",
      "                                                                 \n",
      " normalization (Normalizati  (None, 53)                107       \n",
      " on)                                                             \n",
      "                                                                 \n",
      " dense (Dense)               (None, 1024)              55296     \n",
      "                                                                 \n",
      " re_lu (ReLU)                (None, 1024)              0         \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 1024)              0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 32)                32800     \n",
      "                                                                 \n",
      " re_lu_1 (ReLU)              (None, 32)                0         \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 32)                0         \n",
      "                                                                 \n",
      " regression_head_1 (Dense)   (None, 1)                 33        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 88236 (344.68 KB)\n",
      "Trainable params: 88129 (344.25 KB)\n",
      "Non-trainable params: 107 (432.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "a = tf.keras.models.load_model(\"./tensorflow_models/best_a_01_11.keras\")\n",
    "a.get_config()\n",
    "a.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "181/181 [==============================] - 0s 504us/step - loss: 138797.0312 - mae: 194.6623 - mse: 138797.0312\n",
      "[138797.03125, 194.6622772216797, 138797.03125]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "in user code:\n\n    File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/keras/src/engine/training.py\", line 2042, in test_function  *\n        return step_function(self, iterator)\n    File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/keras/src/engine/training.py\", line 2025, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/keras/src/engine/training.py\", line 2013, in run_step  **\n        outputs = model.test_step(data)\n    File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/keras/src/engine/training.py\", line 1893, in test_step\n        y_pred = self(x, training=False)\n    File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/keras/src/utils/traceback_utils.py\", line 70, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/keras/src/engine/input_spec.py\", line 298, in assert_input_compatibility\n        raise ValueError(\n\n    ValueError: Input 0 of layer \"model\" is incompatible with the layer: expected shape=(None, 53), found shape=(None, 54)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m/Users/peterlawrence/Repos/TDT4173-ML/model_notebooks/TF_AK_architecture.ipynb Cell 32\u001b[0m line \u001b[0;36m2\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/peterlawrence/Repos/TDT4173-ML/model_notebooks/TF_AK_architecture.ipynb#X36sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mprint\u001b[39m(model_a\u001b[39m.\u001b[39mevaluate(x_val_a, y_val_a))\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/peterlawrence/Repos/TDT4173-ML/model_notebooks/TF_AK_architecture.ipynb#X36sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m \u001b[39mprint\u001b[39m(a\u001b[39m.\u001b[39;49mevaluate(x_val_a, y_val_a))\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/keras/src/utils/traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n\u001b[1;32m     68\u001b[0m     \u001b[39m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m     69\u001b[0m     \u001b[39m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m---> 70\u001b[0m     \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39mwith_traceback(filtered_tb) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m     71\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m     72\u001b[0m     \u001b[39mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m/var/folders/94/wm45lcfj7sv746_0rnyvdk840000gn/T/__autograph_generated_file0d5y1po2.py:15\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__test_function\u001b[0;34m(iterator)\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m     14\u001b[0m     do_return \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[0;32m---> 15\u001b[0m     retval_ \u001b[39m=\u001b[39m ag__\u001b[39m.\u001b[39mconverted_call(ag__\u001b[39m.\u001b[39mld(step_function), (ag__\u001b[39m.\u001b[39mld(\u001b[39mself\u001b[39m), ag__\u001b[39m.\u001b[39mld(iterator)), \u001b[39mNone\u001b[39;00m, fscope)\n\u001b[1;32m     16\u001b[0m \u001b[39mexcept\u001b[39;00m:\n\u001b[1;32m     17\u001b[0m     do_return \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n",
      "\u001b[0;31mValueError\u001b[0m: in user code:\n\n    File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/keras/src/engine/training.py\", line 2042, in test_function  *\n        return step_function(self, iterator)\n    File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/keras/src/engine/training.py\", line 2025, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/keras/src/engine/training.py\", line 2013, in run_step  **\n        outputs = model.test_step(data)\n    File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/keras/src/engine/training.py\", line 1893, in test_step\n        y_pred = self(x, training=False)\n    File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/keras/src/utils/traceback_utils.py\", line 70, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/keras/src/engine/input_spec.py\", line 298, in assert_input_compatibility\n        raise ValueError(\n\n    ValueError: Input 0 of layer \"model\" is incompatible with the layer: expected shape=(None, 53), found shape=(None, 54)\n"
     ]
    }
   ],
   "source": [
    "print(model_a.evaluate(x_val_a, y_val_a))\n",
    "print(a.evaluate(x_val_a, y_val_a))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:Skipping variable loading for optimizer 'Adam', because it has 17 variables whereas the saved optimizer has 1 variables. \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'name': 'model',\n",
       " 'trainable': True,\n",
       " 'layers': [{'module': 'keras.layers',\n",
       "   'class_name': 'InputLayer',\n",
       "   'config': {'batch_input_shape': (None, 53),\n",
       "    'dtype': 'float32',\n",
       "    'sparse': False,\n",
       "    'ragged': False,\n",
       "    'name': 'input_1'},\n",
       "   'registered_name': None,\n",
       "   'name': 'input_1',\n",
       "   'inbound_nodes': []},\n",
       "  {'module': 'autokeras.keras_layers',\n",
       "   'class_name': 'MultiCategoryEncoding',\n",
       "   'config': {'name': 'multi_category_encoding',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'encoding': ['int',\n",
       "     'int',\n",
       "     'int',\n",
       "     'int',\n",
       "     'none',\n",
       "     'none',\n",
       "     'none',\n",
       "     'none',\n",
       "     'none',\n",
       "     'none',\n",
       "     'none',\n",
       "     'none',\n",
       "     'none',\n",
       "     'none',\n",
       "     'int',\n",
       "     'int',\n",
       "     'int',\n",
       "     'int',\n",
       "     'int',\n",
       "     'none',\n",
       "     'int',\n",
       "     'none',\n",
       "     'none',\n",
       "     'int',\n",
       "     'int',\n",
       "     'none',\n",
       "     'none',\n",
       "     'int',\n",
       "     'int',\n",
       "     'int',\n",
       "     'int',\n",
       "     'none',\n",
       "     'none',\n",
       "     'int',\n",
       "     'none',\n",
       "     'none',\n",
       "     'none',\n",
       "     'int',\n",
       "     'int',\n",
       "     'int',\n",
       "     'int',\n",
       "     'int',\n",
       "     'int',\n",
       "     'none',\n",
       "     'none',\n",
       "     'int',\n",
       "     'int',\n",
       "     'int',\n",
       "     'int',\n",
       "     'int',\n",
       "     'int',\n",
       "     'int',\n",
       "     'int']},\n",
       "   'registered_name': 'Custom>MultiCategoryEncoding',\n",
       "   'build_config': {'input_shape': (None, 53)},\n",
       "   'name': 'multi_category_encoding',\n",
       "   'inbound_nodes': [[['input_1', 0, 0, {}]]]},\n",
       "  {'module': 'keras.layers',\n",
       "   'class_name': 'Normalization',\n",
       "   'config': {'name': 'normalization',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': (-1,),\n",
       "    'invert': False,\n",
       "    'mean': None,\n",
       "    'variance': None},\n",
       "   'registered_name': None,\n",
       "   'build_config': {'input_shape': (None, 53)},\n",
       "   'name': 'normalization',\n",
       "   'inbound_nodes': [[['multi_category_encoding', 0, 0, {}]]]},\n",
       "  {'module': 'keras.layers',\n",
       "   'class_name': 'Dense',\n",
       "   'config': {'name': 'dense',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'units': 32,\n",
       "    'activation': 'linear',\n",
       "    'use_bias': True,\n",
       "    'kernel_initializer': {'module': 'keras.initializers',\n",
       "     'class_name': 'GlorotUniform',\n",
       "     'config': {'seed': None},\n",
       "     'registered_name': None},\n",
       "    'bias_initializer': {'module': 'keras.initializers',\n",
       "     'class_name': 'Zeros',\n",
       "     'config': {},\n",
       "     'registered_name': None},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'registered_name': None,\n",
       "   'build_config': {'input_shape': (None, 53)},\n",
       "   'name': 'dense',\n",
       "   'inbound_nodes': [[['normalization', 0, 0, {}]]]},\n",
       "  {'module': 'keras.layers',\n",
       "   'class_name': 'ReLU',\n",
       "   'config': {'name': 're_lu',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'max_value': None,\n",
       "    'negative_slope': 0.0,\n",
       "    'threshold': 0.0},\n",
       "   'registered_name': None,\n",
       "   'build_config': {'input_shape': (None, 32)},\n",
       "   'name': 're_lu',\n",
       "   'inbound_nodes': [[['dense', 0, 0, {}]]]},\n",
       "  {'module': 'keras.layers',\n",
       "   'class_name': 'Dense',\n",
       "   'config': {'name': 'dense_1',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'units': 32,\n",
       "    'activation': 'linear',\n",
       "    'use_bias': True,\n",
       "    'kernel_initializer': {'module': 'keras.initializers',\n",
       "     'class_name': 'GlorotUniform',\n",
       "     'config': {'seed': None},\n",
       "     'registered_name': None},\n",
       "    'bias_initializer': {'module': 'keras.initializers',\n",
       "     'class_name': 'Zeros',\n",
       "     'config': {},\n",
       "     'registered_name': None},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'registered_name': None,\n",
       "   'build_config': {'input_shape': (None, 32)},\n",
       "   'name': 'dense_1',\n",
       "   'inbound_nodes': [[['re_lu', 0, 0, {}]]]},\n",
       "  {'module': 'keras.layers',\n",
       "   'class_name': 'ReLU',\n",
       "   'config': {'name': 're_lu_1',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'max_value': None,\n",
       "    'negative_slope': 0.0,\n",
       "    'threshold': 0.0},\n",
       "   'registered_name': None,\n",
       "   'build_config': {'input_shape': (None, 32)},\n",
       "   'name': 're_lu_1',\n",
       "   'inbound_nodes': [[['dense_1', 0, 0, {}]]]},\n",
       "  {'module': 'keras.layers',\n",
       "   'class_name': 'Dense',\n",
       "   'config': {'name': 'dense_2',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'units': 256,\n",
       "    'activation': 'linear',\n",
       "    'use_bias': True,\n",
       "    'kernel_initializer': {'module': 'keras.initializers',\n",
       "     'class_name': 'GlorotUniform',\n",
       "     'config': {'seed': None},\n",
       "     'registered_name': None},\n",
       "    'bias_initializer': {'module': 'keras.initializers',\n",
       "     'class_name': 'Zeros',\n",
       "     'config': {},\n",
       "     'registered_name': None},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'registered_name': None,\n",
       "   'build_config': {'input_shape': (None, 32)},\n",
       "   'name': 'dense_2',\n",
       "   'inbound_nodes': [[['re_lu_1', 0, 0, {}]]]},\n",
       "  {'module': 'keras.layers',\n",
       "   'class_name': 'ReLU',\n",
       "   'config': {'name': 're_lu_2',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'max_value': None,\n",
       "    'negative_slope': 0.0,\n",
       "    'threshold': 0.0},\n",
       "   'registered_name': None,\n",
       "   'build_config': {'input_shape': (None, 256)},\n",
       "   'name': 're_lu_2',\n",
       "   'inbound_nodes': [[['dense_2', 0, 0, {}]]]},\n",
       "  {'module': 'keras.layers',\n",
       "   'class_name': 'Dense',\n",
       "   'config': {'name': 'regression_head_1',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'units': 1,\n",
       "    'activation': 'linear',\n",
       "    'use_bias': True,\n",
       "    'kernel_initializer': {'module': 'keras.initializers',\n",
       "     'class_name': 'GlorotUniform',\n",
       "     'config': {'seed': None},\n",
       "     'registered_name': None},\n",
       "    'bias_initializer': {'module': 'keras.initializers',\n",
       "     'class_name': 'Zeros',\n",
       "     'config': {},\n",
       "     'registered_name': None},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'registered_name': None,\n",
       "   'build_config': {'input_shape': (None, 256)},\n",
       "   'name': 'regression_head_1',\n",
       "   'inbound_nodes': [[['re_lu_2', 0, 0, {}]]]}],\n",
       " 'input_layers': [['input_1', 0, 0]],\n",
       " 'output_layers': [['regression_head_1', 0, 0]]}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b = tf.keras.models.load_model(\"./tensorflow_models/best_b_01_11.keras\")\n",
    "b.get_config()\n",
    "#b.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.AdamW` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.AdamW`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "615/615 [==============================] - 1s 856us/step - loss: 10784.1299 - mae: 42.7548 - mse: 10784.1299 - val_loss: 5326.5811 - val_mae: 31.7971 - val_mse: 5326.5811\n",
      "Epoch 2/1000\n",
      "615/615 [==============================] - 0s 770us/step - loss: 5561.2759 - mae: 31.9690 - mse: 5561.2759 - val_loss: 5188.5996 - val_mae: 31.1913 - val_mse: 5188.5996\n",
      "Epoch 3/1000\n",
      "615/615 [==============================] - 0s 707us/step - loss: 5415.5459 - mae: 31.3328 - mse: 5415.5459 - val_loss: 5279.7803 - val_mae: 31.4478 - val_mse: 5279.7803\n",
      "Epoch 4/1000\n",
      "615/615 [==============================] - 0s 708us/step - loss: 5310.7026 - mae: 30.6929 - mse: 5310.7026 - val_loss: 4984.0649 - val_mae: 30.3500 - val_mse: 4984.0649\n",
      "Epoch 5/1000\n",
      "615/615 [==============================] - 0s 661us/step - loss: 5181.3271 - mae: 30.1725 - mse: 5181.3271 - val_loss: 4955.7109 - val_mae: 29.7903 - val_mse: 4955.7109\n",
      "Epoch 6/1000\n",
      "615/615 [==============================] - 0s 658us/step - loss: 5131.5625 - mae: 30.1301 - mse: 5131.5625 - val_loss: 4881.1245 - val_mae: 29.9528 - val_mse: 4881.1245\n",
      "Epoch 7/1000\n",
      "615/615 [==============================] - 0s 664us/step - loss: 5120.8770 - mae: 29.7406 - mse: 5120.8770 - val_loss: 4754.9336 - val_mae: 29.1396 - val_mse: 4754.9336\n",
      "Epoch 8/1000\n",
      "615/615 [==============================] - 0s 661us/step - loss: 4999.9243 - mae: 29.3833 - mse: 4999.9243 - val_loss: 4921.5869 - val_mae: 29.6412 - val_mse: 4921.5869\n",
      "Epoch 9/1000\n",
      "615/615 [==============================] - 0s 666us/step - loss: 4951.1025 - mae: 29.2933 - mse: 4951.1025 - val_loss: 4850.6260 - val_mae: 29.1960 - val_mse: 4850.6260\n",
      "Epoch 10/1000\n",
      "615/615 [==============================] - 0s 659us/step - loss: 4911.3135 - mae: 29.2062 - mse: 4911.3135 - val_loss: 5035.5498 - val_mae: 29.8876 - val_mse: 5035.5498\n",
      "Epoch 11/1000\n",
      "615/615 [==============================] - 0s 679us/step - loss: 4862.3027 - mae: 28.8991 - mse: 4862.3027 - val_loss: 4704.7871 - val_mae: 28.7326 - val_mse: 4704.7871\n",
      "Epoch 12/1000\n",
      "615/615 [==============================] - 0s 659us/step - loss: 4778.9072 - mae: 28.7576 - mse: 4778.9072 - val_loss: 4684.0225 - val_mae: 28.7969 - val_mse: 4684.0225\n",
      "Epoch 13/1000\n",
      "615/615 [==============================] - 0s 658us/step - loss: 4827.2075 - mae: 28.8787 - mse: 4827.2075 - val_loss: 4676.5396 - val_mae: 28.5885 - val_mse: 4676.5396\n",
      "Epoch 14/1000\n",
      "615/615 [==============================] - 0s 661us/step - loss: 4742.5752 - mae: 28.5648 - mse: 4742.5752 - val_loss: 4670.5068 - val_mae: 28.9811 - val_mse: 4670.5068\n",
      "Epoch 15/1000\n",
      "615/615 [==============================] - 0s 660us/step - loss: 4721.1660 - mae: 28.6455 - mse: 4721.1660 - val_loss: 4865.3896 - val_mae: 29.0035 - val_mse: 4865.3896\n",
      "Epoch 16/1000\n",
      "615/615 [==============================] - 0s 706us/step - loss: 4738.9189 - mae: 28.5994 - mse: 4738.9189 - val_loss: 4591.6099 - val_mae: 28.4261 - val_mse: 4591.6099\n",
      "Epoch 17/1000\n",
      "615/615 [==============================] - 0s 667us/step - loss: 4639.1465 - mae: 28.5007 - mse: 4639.1465 - val_loss: 4993.1699 - val_mae: 29.1784 - val_mse: 4993.1699\n",
      "Epoch 18/1000\n",
      "615/615 [==============================] - 0s 663us/step - loss: 4604.0928 - mae: 28.1904 - mse: 4604.0928 - val_loss: 4555.4482 - val_mae: 28.7373 - val_mse: 4555.4482\n",
      "Epoch 19/1000\n",
      "615/615 [==============================] - 0s 691us/step - loss: 4591.1934 - mae: 28.2273 - mse: 4591.1934 - val_loss: 4595.1611 - val_mae: 28.1159 - val_mse: 4595.1611\n",
      "Epoch 20/1000\n",
      "615/615 [==============================] - 0s 679us/step - loss: 4562.6729 - mae: 28.2948 - mse: 4562.6729 - val_loss: 4623.7651 - val_mae: 27.9796 - val_mse: 4623.7651\n",
      "Epoch 21/1000\n",
      "615/615 [==============================] - 0s 665us/step - loss: 4541.3325 - mae: 28.1741 - mse: 4541.3325 - val_loss: 4667.6392 - val_mae: 28.6691 - val_mse: 4667.6392\n",
      "Epoch 22/1000\n",
      "615/615 [==============================] - 0s 663us/step - loss: 4490.8198 - mae: 27.9721 - mse: 4490.8198 - val_loss: 4519.9707 - val_mae: 28.0996 - val_mse: 4519.9707\n",
      "Epoch 23/1000\n",
      "615/615 [==============================] - 0s 665us/step - loss: 4441.9541 - mae: 28.0857 - mse: 4441.9541 - val_loss: 4516.3096 - val_mae: 28.3457 - val_mse: 4516.3096\n",
      "Epoch 24/1000\n",
      "615/615 [==============================] - 0s 668us/step - loss: 4454.6865 - mae: 27.8862 - mse: 4454.6865 - val_loss: 4594.5322 - val_mae: 28.3623 - val_mse: 4594.5322\n",
      "Epoch 25/1000\n",
      "615/615 [==============================] - 0s 667us/step - loss: 4458.9868 - mae: 27.9150 - mse: 4458.9868 - val_loss: 4890.0098 - val_mae: 29.8209 - val_mse: 4890.0098\n",
      "Epoch 26/1000\n",
      "615/615 [==============================] - 0s 664us/step - loss: 4462.0933 - mae: 28.0442 - mse: 4462.0933 - val_loss: 4612.3828 - val_mae: 29.7345 - val_mse: 4612.3828\n",
      "Epoch 27/1000\n",
      "615/615 [==============================] - 0s 693us/step - loss: 4395.1987 - mae: 27.7821 - mse: 4395.1987 - val_loss: 4664.6899 - val_mae: 28.7083 - val_mse: 4664.6899\n",
      "Epoch 28/1000\n",
      "615/615 [==============================] - 0s 664us/step - loss: 4378.0249 - mae: 27.7640 - mse: 4378.0249 - val_loss: 4617.9399 - val_mae: 28.8489 - val_mse: 4617.9399\n",
      "Epoch 29/1000\n",
      "615/615 [==============================] - 0s 665us/step - loss: 4369.6045 - mae: 27.6030 - mse: 4369.6045 - val_loss: 4504.7437 - val_mae: 28.5643 - val_mse: 4504.7437\n",
      "Epoch 30/1000\n",
      "615/615 [==============================] - 0s 658us/step - loss: 4313.2427 - mae: 27.5017 - mse: 4313.2427 - val_loss: 4652.4785 - val_mae: 29.2405 - val_mse: 4652.4785\n",
      "Epoch 31/1000\n",
      "615/615 [==============================] - 0s 663us/step - loss: 4332.0010 - mae: 27.7537 - mse: 4332.0010 - val_loss: 4514.0786 - val_mae: 28.7093 - val_mse: 4514.0786\n",
      "Epoch 32/1000\n",
      "615/615 [==============================] - 0s 665us/step - loss: 4321.1953 - mae: 27.6044 - mse: 4321.1953 - val_loss: 4538.0068 - val_mae: 27.9488 - val_mse: 4538.0068\n",
      "Epoch 33/1000\n",
      "615/615 [==============================] - 0s 664us/step - loss: 4316.0928 - mae: 27.7833 - mse: 4316.0928 - val_loss: 4752.0835 - val_mae: 28.9094 - val_mse: 4752.0835\n",
      "Epoch 34/1000\n",
      "615/615 [==============================] - 0s 693us/step - loss: 4253.4824 - mae: 27.4329 - mse: 4253.4824 - val_loss: 4416.3442 - val_mae: 28.3759 - val_mse: 4416.3442\n",
      "Epoch 35/1000\n",
      "615/615 [==============================] - 0s 672us/step - loss: 4224.0947 - mae: 27.3388 - mse: 4224.0947 - val_loss: 4466.4287 - val_mae: 29.2861 - val_mse: 4466.4287\n",
      "Epoch 36/1000\n",
      "615/615 [==============================] - 0s 661us/step - loss: 4191.6553 - mae: 27.2663 - mse: 4191.6553 - val_loss: 4418.2231 - val_mae: 27.8105 - val_mse: 4418.2231\n",
      "Epoch 37/1000\n",
      "615/615 [==============================] - 0s 665us/step - loss: 4184.8057 - mae: 27.1524 - mse: 4184.8057 - val_loss: 4474.2578 - val_mae: 28.1157 - val_mse: 4474.2578\n",
      "Epoch 38/1000\n",
      "615/615 [==============================] - 0s 660us/step - loss: 4177.7310 - mae: 27.3135 - mse: 4177.7310 - val_loss: 4507.5728 - val_mae: 27.8856 - val_mse: 4507.5728\n",
      "Epoch 39/1000\n",
      "615/615 [==============================] - 0s 655us/step - loss: 4167.2295 - mae: 27.2312 - mse: 4167.2295 - val_loss: 4301.5850 - val_mae: 27.5929 - val_mse: 4301.5850\n",
      "Epoch 40/1000\n",
      "615/615 [==============================] - 0s 665us/step - loss: 4094.2356 - mae: 26.9616 - mse: 4094.2356 - val_loss: 4505.2329 - val_mae: 29.0732 - val_mse: 4505.2329\n",
      "Epoch 41/1000\n",
      "615/615 [==============================] - 0s 676us/step - loss: 4067.5623 - mae: 26.9862 - mse: 4067.5623 - val_loss: 4389.5391 - val_mae: 28.1351 - val_mse: 4389.5391\n",
      "Epoch 42/1000\n",
      "615/615 [==============================] - 0s 660us/step - loss: 4053.0256 - mae: 26.9519 - mse: 4053.0256 - val_loss: 4366.7568 - val_mae: 28.0422 - val_mse: 4366.7568\n",
      "Epoch 43/1000\n",
      "615/615 [==============================] - 0s 658us/step - loss: 4026.3860 - mae: 26.8564 - mse: 4026.3860 - val_loss: 4422.5161 - val_mae: 28.5347 - val_mse: 4422.5161\n",
      "Epoch 44/1000\n",
      "615/615 [==============================] - 0s 660us/step - loss: 4002.2031 - mae: 26.9744 - mse: 4002.2031 - val_loss: 4458.7100 - val_mae: 28.3697 - val_mse: 4458.7100\n",
      "Epoch 45/1000\n",
      "615/615 [==============================] - 0s 661us/step - loss: 4012.2864 - mae: 26.7391 - mse: 4012.2864 - val_loss: 4501.4126 - val_mae: 28.8893 - val_mse: 4501.4126\n",
      "Epoch 46/1000\n",
      "615/615 [==============================] - 0s 660us/step - loss: 4003.4229 - mae: 26.6996 - mse: 4003.4229 - val_loss: 4466.1455 - val_mae: 27.7989 - val_mse: 4466.1455\n",
      "Epoch 47/1000\n",
      "615/615 [==============================] - 0s 660us/step - loss: 3962.2932 - mae: 26.7523 - mse: 3962.2932 - val_loss: 4296.7446 - val_mae: 27.3368 - val_mse: 4296.7446\n",
      "Epoch 48/1000\n",
      "615/615 [==============================] - 0s 707us/step - loss: 3986.4102 - mae: 26.8292 - mse: 3986.4102 - val_loss: 4407.4521 - val_mae: 27.7587 - val_mse: 4407.4521\n",
      "Epoch 49/1000\n",
      "615/615 [==============================] - 0s 660us/step - loss: 3913.2302 - mae: 26.6901 - mse: 3913.2302 - val_loss: 4332.4282 - val_mae: 27.7655 - val_mse: 4332.4282\n",
      "Epoch 50/1000\n",
      "615/615 [==============================] - 0s 659us/step - loss: 3945.7839 - mae: 26.4940 - mse: 3945.7839 - val_loss: 4331.1411 - val_mae: 28.3532 - val_mse: 4331.1411\n",
      "Epoch 51/1000\n",
      "615/615 [==============================] - 0s 654us/step - loss: 3868.1895 - mae: 26.4880 - mse: 3868.1895 - val_loss: 4616.2061 - val_mae: 28.0318 - val_mse: 4616.2061\n",
      "Epoch 52/1000\n",
      "615/615 [==============================] - 0s 656us/step - loss: 3897.6951 - mae: 26.6516 - mse: 3897.6951 - val_loss: 4838.8774 - val_mae: 29.6746 - val_mse: 4838.8774\n",
      "Epoch 53/1000\n",
      "615/615 [==============================] - 0s 652us/step - loss: 3859.1130 - mae: 26.5592 - mse: 3859.1130 - val_loss: 4409.7754 - val_mae: 28.6387 - val_mse: 4409.7754\n",
      "Epoch 54/1000\n",
      "615/615 [==============================] - 0s 702us/step - loss: 3861.6282 - mae: 26.5714 - mse: 3861.6282 - val_loss: 4445.5200 - val_mae: 30.4830 - val_mse: 4445.5200\n",
      "Epoch 55/1000\n",
      "615/615 [==============================] - 0s 654us/step - loss: 3801.5225 - mae: 26.2645 - mse: 3801.5225 - val_loss: 4333.4131 - val_mae: 28.0883 - val_mse: 4333.4131\n",
      "Epoch 56/1000\n",
      "615/615 [==============================] - 0s 655us/step - loss: 3773.8000 - mae: 26.2266 - mse: 3773.8000 - val_loss: 4357.7554 - val_mae: 27.9746 - val_mse: 4357.7554\n",
      "Epoch 57/1000\n",
      "615/615 [==============================] - 0s 656us/step - loss: 3758.1460 - mae: 26.1631 - mse: 3758.1460 - val_loss: 4386.9609 - val_mae: 28.5177 - val_mse: 4386.9609\n",
      "Epoch 58/1000\n",
      "615/615 [==============================] - 0s 654us/step - loss: 3765.6812 - mae: 26.2972 - mse: 3765.6812 - val_loss: 4455.4766 - val_mae: 28.8133 - val_mse: 4455.4766\n",
      "Epoch 59/1000\n",
      "615/615 [==============================] - 0s 653us/step - loss: 3735.3120 - mae: 25.9879 - mse: 3735.3120 - val_loss: 4295.7383 - val_mae: 27.4500 - val_mse: 4295.7383\n",
      "Epoch 60/1000\n",
      "615/615 [==============================] - 0s 653us/step - loss: 3743.8315 - mae: 26.1139 - mse: 3743.8315 - val_loss: 4290.8594 - val_mae: 27.6357 - val_mse: 4290.8594\n",
      "Epoch 61/1000\n",
      "615/615 [==============================] - 0s 674us/step - loss: 3766.8857 - mae: 26.3222 - mse: 3766.8857 - val_loss: 4653.5103 - val_mae: 28.9449 - val_mse: 4653.5103\n",
      "Epoch 62/1000\n",
      "615/615 [==============================] - 0s 666us/step - loss: 3662.3684 - mae: 26.0604 - mse: 3662.3684 - val_loss: 4227.4473 - val_mae: 27.2202 - val_mse: 4227.4473\n",
      "Epoch 63/1000\n",
      "615/615 [==============================] - 0s 691us/step - loss: 3668.6533 - mae: 25.8275 - mse: 3668.6533 - val_loss: 4457.0908 - val_mae: 28.9441 - val_mse: 4457.0908\n",
      "Epoch 64/1000\n",
      "615/615 [==============================] - 0s 656us/step - loss: 3612.2180 - mae: 25.6695 - mse: 3612.2180 - val_loss: 4390.8994 - val_mae: 27.9636 - val_mse: 4390.8994\n",
      "Epoch 65/1000\n",
      "615/615 [==============================] - 0s 657us/step - loss: 3655.5449 - mae: 25.6755 - mse: 3655.5449 - val_loss: 4299.1377 - val_mae: 27.6718 - val_mse: 4299.1377\n",
      "Epoch 66/1000\n",
      "615/615 [==============================] - 0s 649us/step - loss: 3646.6782 - mae: 25.5722 - mse: 3646.6782 - val_loss: 4400.4102 - val_mae: 29.4473 - val_mse: 4400.4102\n",
      "Epoch 67/1000\n",
      "615/615 [==============================] - 0s 661us/step - loss: 3608.0933 - mae: 25.6017 - mse: 3608.0933 - val_loss: 4539.3452 - val_mae: 29.0215 - val_mse: 4539.3452\n",
      "Epoch 68/1000\n",
      "615/615 [==============================] - 0s 810us/step - loss: 3551.5303 - mae: 25.5536 - mse: 3551.5303 - val_loss: 4265.8716 - val_mae: 27.4457 - val_mse: 4265.8716\n",
      "Epoch 69/1000\n",
      "615/615 [==============================] - 0s 678us/step - loss: 3597.6855 - mae: 25.6738 - mse: 3597.6855 - val_loss: 4448.0063 - val_mae: 29.0297 - val_mse: 4448.0063\n",
      "Epoch 70/1000\n",
      "615/615 [==============================] - 0s 651us/step - loss: 3539.1106 - mae: 25.4322 - mse: 3539.1106 - val_loss: 4303.9702 - val_mae: 27.7079 - val_mse: 4303.9702\n",
      "Epoch 71/1000\n",
      "615/615 [==============================] - 0s 702us/step - loss: 3572.6572 - mae: 25.8808 - mse: 3572.6572 - val_loss: 4345.9546 - val_mae: 28.6323 - val_mse: 4345.9546\n",
      "Epoch 72/1000\n",
      "615/615 [==============================] - 0s 676us/step - loss: 3568.2793 - mae: 25.5260 - mse: 3568.2793 - val_loss: 4346.6899 - val_mae: 27.5986 - val_mse: 4346.6899\n",
      "Epoch 73/1000\n",
      "615/615 [==============================] - 0s 731us/step - loss: 3521.4822 - mae: 25.4304 - mse: 3521.4822 - val_loss: 4259.8203 - val_mae: 27.9062 - val_mse: 4259.8203\n",
      "Epoch 74/1000\n",
      "615/615 [==============================] - 0s 701us/step - loss: 3510.5276 - mae: 25.5149 - mse: 3510.5276 - val_loss: 4339.3301 - val_mae: 27.4380 - val_mse: 4339.3301\n",
      "Epoch 75/1000\n",
      "615/615 [==============================] - 0s 684us/step - loss: 3491.5959 - mae: 25.1062 - mse: 3491.5959 - val_loss: 4360.5127 - val_mae: 28.8663 - val_mse: 4360.5127\n",
      "Epoch 76/1000\n",
      "615/615 [==============================] - 0s 654us/step - loss: 3507.7734 - mae: 25.5552 - mse: 3507.7734 - val_loss: 4304.7627 - val_mae: 28.1956 - val_mse: 4304.7627\n",
      "Epoch 77/1000\n",
      "615/615 [==============================] - 0s 655us/step - loss: 3502.8499 - mae: 25.5084 - mse: 3502.8499 - val_loss: 4232.4375 - val_mae: 28.6120 - val_mse: 4232.4375\n",
      "Epoch 78/1000\n",
      "615/615 [==============================] - 0s 654us/step - loss: 3452.3350 - mae: 25.1428 - mse: 3452.3350 - val_loss: 4382.6011 - val_mae: 27.9085 - val_mse: 4382.6011\n",
      "Epoch 79/1000\n",
      "615/615 [==============================] - 0s 663us/step - loss: 3439.4187 - mae: 25.3079 - mse: 3439.4187 - val_loss: 4255.8887 - val_mae: 27.1913 - val_mse: 4255.8887\n",
      "Epoch 80/1000\n",
      "615/615 [==============================] - 0s 691us/step - loss: 3454.1050 - mae: 25.3984 - mse: 3454.1050 - val_loss: 4198.7510 - val_mae: 29.0320 - val_mse: 4198.7510\n",
      "Epoch 81/1000\n",
      "615/615 [==============================] - 0s 654us/step - loss: 3424.4939 - mae: 25.1429 - mse: 3424.4939 - val_loss: 4283.3188 - val_mae: 27.8843 - val_mse: 4283.3188\n",
      "Epoch 82/1000\n",
      "615/615 [==============================] - 0s 666us/step - loss: 3437.4910 - mae: 25.3972 - mse: 3437.4910 - val_loss: 4324.4072 - val_mae: 28.8326 - val_mse: 4324.4072\n",
      "Epoch 83/1000\n",
      "615/615 [==============================] - 0s 654us/step - loss: 3418.9104 - mae: 25.2972 - mse: 3418.9104 - val_loss: 4176.9438 - val_mae: 28.0026 - val_mse: 4176.9438\n",
      "Epoch 84/1000\n",
      "615/615 [==============================] - 0s 654us/step - loss: 3344.2542 - mae: 24.9373 - mse: 3344.2542 - val_loss: 4429.1323 - val_mae: 29.4497 - val_mse: 4429.1323\n",
      "Epoch 85/1000\n",
      "615/615 [==============================] - 0s 661us/step - loss: 3390.6062 - mae: 25.0584 - mse: 3390.6062 - val_loss: 4237.1807 - val_mae: 28.1534 - val_mse: 4237.1807\n",
      "Epoch 86/1000\n",
      "615/615 [==============================] - 0s 684us/step - loss: 3372.8647 - mae: 25.0222 - mse: 3372.8647 - val_loss: 4363.9512 - val_mae: 29.2046 - val_mse: 4363.9512\n",
      "Epoch 87/1000\n",
      "615/615 [==============================] - 0s 657us/step - loss: 3313.6497 - mae: 24.8386 - mse: 3313.6497 - val_loss: 4303.3765 - val_mae: 27.7896 - val_mse: 4303.3765\n",
      "Epoch 88/1000\n",
      "615/615 [==============================] - 0s 672us/step - loss: 3352.4050 - mae: 25.0644 - mse: 3352.4050 - val_loss: 4140.3584 - val_mae: 27.8916 - val_mse: 4140.3584\n",
      "Epoch 89/1000\n",
      "615/615 [==============================] - 0s 660us/step - loss: 3353.9485 - mae: 24.9613 - mse: 3353.9485 - val_loss: 4249.0918 - val_mae: 28.8684 - val_mse: 4249.0918\n",
      "Epoch 90/1000\n",
      "615/615 [==============================] - 0s 666us/step - loss: 3281.1443 - mae: 24.6936 - mse: 3281.1443 - val_loss: 4225.6025 - val_mae: 27.9325 - val_mse: 4225.6025\n",
      "Epoch 91/1000\n",
      "615/615 [==============================] - 0s 749us/step - loss: 3335.9966 - mae: 25.1702 - mse: 3335.9966 - val_loss: 4270.4150 - val_mae: 28.0793 - val_mse: 4270.4150\n",
      "Epoch 92/1000\n",
      "615/615 [==============================] - 0s 663us/step - loss: 3270.2769 - mae: 24.9201 - mse: 3270.2769 - val_loss: 4469.8149 - val_mae: 28.3292 - val_mse: 4469.8149\n",
      "Epoch 93/1000\n",
      "615/615 [==============================] - 0s 662us/step - loss: 3326.1589 - mae: 25.0515 - mse: 3326.1589 - val_loss: 4362.6846 - val_mae: 28.2929 - val_mse: 4362.6846\n",
      "Epoch 94/1000\n",
      "615/615 [==============================] - 0s 709us/step - loss: 3235.3308 - mae: 24.7266 - mse: 3235.3308 - val_loss: 4226.1655 - val_mae: 27.9852 - val_mse: 4226.1655\n",
      "Epoch 95/1000\n",
      "615/615 [==============================] - 0s 701us/step - loss: 3283.6011 - mae: 24.6745 - mse: 3283.6011 - val_loss: 4203.0820 - val_mae: 28.5892 - val_mse: 4203.0820\n",
      "Epoch 96/1000\n",
      "615/615 [==============================] - 0s 712us/step - loss: 3256.2571 - mae: 24.7726 - mse: 3256.2571 - val_loss: 4387.8491 - val_mae: 28.3591 - val_mse: 4387.8491\n",
      "Epoch 97/1000\n",
      "615/615 [==============================] - 0s 682us/step - loss: 3261.1682 - mae: 25.0024 - mse: 3261.1682 - val_loss: 4416.5176 - val_mae: 29.5393 - val_mse: 4416.5176\n",
      "Epoch 98/1000\n",
      "615/615 [==============================] - 0s 660us/step - loss: 3236.2251 - mae: 24.6614 - mse: 3236.2251 - val_loss: 4412.2617 - val_mae: 29.2619 - val_mse: 4412.2617\n",
      "Epoch 99/1000\n",
      "615/615 [==============================] - 0s 671us/step - loss: 3208.8606 - mae: 24.7320 - mse: 3208.8606 - val_loss: 4544.2832 - val_mae: 28.8875 - val_mse: 4544.2832\n",
      "Epoch 100/1000\n",
      "615/615 [==============================] - 0s 661us/step - loss: 3200.8147 - mae: 24.6783 - mse: 3200.8147 - val_loss: 4325.5610 - val_mae: 28.0443 - val_mse: 4325.5610\n",
      "Epoch 101/1000\n",
      "615/615 [==============================] - 0s 659us/step - loss: 3168.7439 - mae: 24.5382 - mse: 3168.7439 - val_loss: 4637.7495 - val_mae: 29.8498 - val_mse: 4637.7495\n",
      "Epoch 102/1000\n",
      "615/615 [==============================] - 0s 654us/step - loss: 3175.6401 - mae: 24.5420 - mse: 3175.6401 - val_loss: 4282.8643 - val_mae: 27.2228 - val_mse: 4282.8643\n",
      "Epoch 103/1000\n",
      "615/615 [==============================] - 0s 679us/step - loss: 3154.9836 - mae: 24.3556 - mse: 3154.9836 - val_loss: 4584.4717 - val_mae: 28.6737 - val_mse: 4584.4717\n",
      "Epoch 104/1000\n",
      "615/615 [==============================] - 0s 667us/step - loss: 3160.1267 - mae: 24.4150 - mse: 3160.1267 - val_loss: 4292.7451 - val_mae: 27.5540 - val_mse: 4292.7451\n",
      "Epoch 105/1000\n",
      "615/615 [==============================] - 0s 658us/step - loss: 3122.0706 - mae: 24.4069 - mse: 3122.0706 - val_loss: 4453.4424 - val_mae: 30.0996 - val_mse: 4453.4424\n",
      "Epoch 106/1000\n",
      "615/615 [==============================] - 0s 660us/step - loss: 3103.2825 - mae: 24.3808 - mse: 3103.2825 - val_loss: 4297.0928 - val_mae: 27.9851 - val_mse: 4297.0928\n",
      "Epoch 107/1000\n",
      "615/615 [==============================] - 0s 661us/step - loss: 3119.3088 - mae: 24.3863 - mse: 3119.3088 - val_loss: 4587.0220 - val_mae: 29.6617 - val_mse: 4587.0220\n",
      "Epoch 108/1000\n",
      "615/615 [==============================] - 0s 653us/step - loss: 3144.0298 - mae: 24.7476 - mse: 3144.0298 - val_loss: 4320.9448 - val_mae: 28.2200 - val_mse: 4320.9448\n",
      "Epoch 109/1000\n",
      "615/615 [==============================] - 0s 689us/step - loss: 3076.1125 - mae: 24.2696 - mse: 3076.1125 - val_loss: 4203.0566 - val_mae: 27.7802 - val_mse: 4203.0566\n",
      "Epoch 110/1000\n",
      "615/615 [==============================] - 0s 657us/step - loss: 3056.0459 - mae: 24.3212 - mse: 3056.0459 - val_loss: 4915.7515 - val_mae: 31.4633 - val_mse: 4915.7515\n",
      "Epoch 111/1000\n",
      "615/615 [==============================] - 0s 667us/step - loss: 3123.9043 - mae: 24.4188 - mse: 3123.9043 - val_loss: 4228.1108 - val_mae: 28.6920 - val_mse: 4228.1108\n",
      "Epoch 112/1000\n",
      "615/615 [==============================] - 0s 659us/step - loss: 3084.2844 - mae: 24.3088 - mse: 3084.2844 - val_loss: 4056.5000 - val_mae: 27.6328 - val_mse: 4056.5000\n",
      "Epoch 113/1000\n",
      "615/615 [==============================] - 0s 656us/step - loss: 3066.5679 - mae: 24.0814 - mse: 3066.5679 - val_loss: 4222.2549 - val_mae: 27.7542 - val_mse: 4222.2549\n",
      "Epoch 114/1000\n",
      "615/615 [==============================] - 0s 665us/step - loss: 3088.8086 - mae: 24.5380 - mse: 3088.8086 - val_loss: 4199.4526 - val_mae: 28.6278 - val_mse: 4199.4526\n",
      "Epoch 115/1000\n",
      "615/615 [==============================] - 0s 677us/step - loss: 3049.6394 - mae: 24.2223 - mse: 3049.6394 - val_loss: 4352.2544 - val_mae: 31.5100 - val_mse: 4352.2544\n",
      "Epoch 116/1000\n",
      "615/615 [==============================] - 0s 668us/step - loss: 3055.9070 - mae: 24.1204 - mse: 3055.9070 - val_loss: 4193.2319 - val_mae: 28.5566 - val_mse: 4193.2319\n",
      "Epoch 117/1000\n",
      "615/615 [==============================] - 0s 658us/step - loss: 3015.3284 - mae: 24.1546 - mse: 3015.3284 - val_loss: 4478.6011 - val_mae: 30.3209 - val_mse: 4478.6011\n",
      "Epoch 118/1000\n",
      "615/615 [==============================] - 0s 654us/step - loss: 3053.9783 - mae: 24.2012 - mse: 3053.9783 - val_loss: 4438.1724 - val_mae: 29.3022 - val_mse: 4438.1724\n",
      "Epoch 119/1000\n",
      "615/615 [==============================] - 0s 668us/step - loss: 3037.6267 - mae: 24.3710 - mse: 3037.6267 - val_loss: 4186.5864 - val_mae: 27.9005 - val_mse: 4186.5864\n",
      "Epoch 120/1000\n",
      "615/615 [==============================] - 0s 690us/step - loss: 2953.4612 - mae: 23.6826 - mse: 2953.4612 - val_loss: 4277.9370 - val_mae: 29.3315 - val_mse: 4277.9370\n",
      "Epoch 121/1000\n",
      "615/615 [==============================] - 0s 654us/step - loss: 3067.9626 - mae: 24.4733 - mse: 3067.9626 - val_loss: 4281.8462 - val_mae: 29.4689 - val_mse: 4281.8462\n",
      "Epoch 122/1000\n",
      "615/615 [==============================] - 0s 655us/step - loss: 2999.2087 - mae: 24.1510 - mse: 2999.2087 - val_loss: 4232.0098 - val_mae: 29.0354 - val_mse: 4232.0098\n",
      "Epoch 123/1000\n",
      "615/615 [==============================] - 0s 665us/step - loss: 2992.5449 - mae: 24.4118 - mse: 2992.5449 - val_loss: 4094.0811 - val_mae: 28.9437 - val_mse: 4094.0811\n",
      "Epoch 124/1000\n",
      "615/615 [==============================] - 0s 655us/step - loss: 2981.1482 - mae: 24.0462 - mse: 2981.1482 - val_loss: 4130.4365 - val_mae: 27.3568 - val_mse: 4130.4365\n",
      "Epoch 125/1000\n",
      "615/615 [==============================] - 0s 676us/step - loss: 2955.8792 - mae: 24.0232 - mse: 2955.8792 - val_loss: 4243.5469 - val_mae: 28.4465 - val_mse: 4243.5469\n",
      "Epoch 126/1000\n",
      "615/615 [==============================] - 0s 659us/step - loss: 2933.9048 - mae: 23.8508 - mse: 2933.9048 - val_loss: 4164.7578 - val_mae: 27.3996 - val_mse: 4164.7578\n",
      "Epoch 127/1000\n",
      "615/615 [==============================] - 0s 654us/step - loss: 2951.0164 - mae: 24.2053 - mse: 2951.0164 - val_loss: 4272.5293 - val_mae: 29.4115 - val_mse: 4272.5293\n",
      "Epoch 128/1000\n",
      "615/615 [==============================] - 0s 664us/step - loss: 2920.6528 - mae: 23.8463 - mse: 2920.6528 - val_loss: 4081.2107 - val_mae: 29.0103 - val_mse: 4081.2107\n",
      "Epoch 129/1000\n",
      "615/615 [==============================] - 0s 654us/step - loss: 2929.2800 - mae: 24.0204 - mse: 2929.2800 - val_loss: 4067.3054 - val_mae: 26.8240 - val_mse: 4067.3054\n",
      "Epoch 130/1000\n",
      "615/615 [==============================] - 0s 655us/step - loss: 2951.7759 - mae: 24.1811 - mse: 2951.7759 - val_loss: 4365.2271 - val_mae: 27.8954 - val_mse: 4365.2271\n",
      "Epoch 131/1000\n",
      "615/615 [==============================] - 0s 693us/step - loss: 2903.5891 - mae: 23.7161 - mse: 2903.5891 - val_loss: 4083.1719 - val_mae: 27.9496 - val_mse: 4083.1719\n",
      "Epoch 132/1000\n",
      "615/615 [==============================] - 0s 761us/step - loss: 2886.2026 - mae: 23.8315 - mse: 2886.2026 - val_loss: 4096.2412 - val_mae: 29.1021 - val_mse: 4096.2412\n",
      "Epoch 133/1000\n",
      "615/615 [==============================] - 0s 657us/step - loss: 2851.5562 - mae: 23.5785 - mse: 2851.5562 - val_loss: 4347.2251 - val_mae: 28.1430 - val_mse: 4347.2251\n",
      "Epoch 134/1000\n",
      "615/615 [==============================] - 0s 662us/step - loss: 2880.6799 - mae: 23.9098 - mse: 2880.6799 - val_loss: 4741.8228 - val_mae: 29.3609 - val_mse: 4741.8228\n",
      "Epoch 135/1000\n",
      "615/615 [==============================] - 0s 654us/step - loss: 2874.4663 - mae: 23.7524 - mse: 2874.4663 - val_loss: 4272.1191 - val_mae: 29.4711 - val_mse: 4272.1191\n",
      "Epoch 136/1000\n",
      "615/615 [==============================] - 0s 697us/step - loss: 2867.4546 - mae: 23.9123 - mse: 2867.4546 - val_loss: 4382.5679 - val_mae: 29.4211 - val_mse: 4382.5679\n",
      "Epoch 137/1000\n",
      "615/615 [==============================] - 0s 659us/step - loss: 2806.1780 - mae: 23.4204 - mse: 2806.1780 - val_loss: 4106.8540 - val_mae: 28.1212 - val_mse: 4106.8540\n",
      "Epoch 138/1000\n",
      "615/615 [==============================] - 0s 660us/step - loss: 2862.2896 - mae: 23.8190 - mse: 2862.2896 - val_loss: 4136.3833 - val_mae: 27.9704 - val_mse: 4136.3833\n",
      "Epoch 139/1000\n",
      "615/615 [==============================] - 0s 655us/step - loss: 2818.5613 - mae: 23.5825 - mse: 2818.5613 - val_loss: 4151.2031 - val_mae: 27.8681 - val_mse: 4151.2031\n",
      "Epoch 140/1000\n",
      "615/615 [==============================] - 0s 662us/step - loss: 2859.4470 - mae: 23.6543 - mse: 2859.4470 - val_loss: 4017.5503 - val_mae: 27.8842 - val_mse: 4017.5503\n",
      "Epoch 141/1000\n",
      "615/615 [==============================] - 0s 688us/step - loss: 2831.0796 - mae: 23.6827 - mse: 2831.0796 - val_loss: 4039.2083 - val_mae: 29.1491 - val_mse: 4039.2083\n",
      "Epoch 142/1000\n",
      "615/615 [==============================] - 0s 654us/step - loss: 2792.0405 - mae: 23.1997 - mse: 2792.0405 - val_loss: 4100.3296 - val_mae: 29.5941 - val_mse: 4100.3296\n",
      "Epoch 143/1000\n",
      "615/615 [==============================] - 0s 654us/step - loss: 2779.8989 - mae: 23.4624 - mse: 2779.8989 - val_loss: 4141.9033 - val_mae: 27.0638 - val_mse: 4141.9033\n",
      "Epoch 144/1000\n",
      "615/615 [==============================] - 0s 663us/step - loss: 2841.3020 - mae: 23.8861 - mse: 2841.3020 - val_loss: 4179.5391 - val_mae: 29.1300 - val_mse: 4179.5391\n",
      "Epoch 145/1000\n",
      "615/615 [==============================] - 0s 653us/step - loss: 2748.1394 - mae: 23.4806 - mse: 2748.1394 - val_loss: 4134.4077 - val_mae: 27.5988 - val_mse: 4134.4077\n",
      "Epoch 146/1000\n",
      "615/615 [==============================] - 0s 675us/step - loss: 2746.0796 - mae: 23.1890 - mse: 2746.0796 - val_loss: 4182.5171 - val_mae: 28.5527 - val_mse: 4182.5171\n",
      "Epoch 147/1000\n",
      "615/615 [==============================] - 0s 655us/step - loss: 2795.5022 - mae: 23.4334 - mse: 2795.5022 - val_loss: 4119.4922 - val_mae: 27.9527 - val_mse: 4119.4922\n",
      "Epoch 148/1000\n",
      "615/615 [==============================] - 0s 666us/step - loss: 2769.8809 - mae: 23.3372 - mse: 2769.8809 - val_loss: 4041.4309 - val_mae: 28.9280 - val_mse: 4041.4309\n",
      "Epoch 149/1000\n",
      "615/615 [==============================] - 0s 655us/step - loss: 2737.1536 - mae: 23.3180 - mse: 2737.1536 - val_loss: 4169.5117 - val_mae: 27.2996 - val_mse: 4169.5117\n",
      "Epoch 150/1000\n",
      "615/615 [==============================] - 0s 654us/step - loss: 2713.5898 - mae: 23.2901 - mse: 2713.5898 - val_loss: 4013.2046 - val_mae: 27.4311 - val_mse: 4013.2046\n",
      "Epoch 151/1000\n",
      "615/615 [==============================] - 0s 656us/step - loss: 2747.5146 - mae: 23.4128 - mse: 2747.5146 - val_loss: 4099.5312 - val_mae: 27.3988 - val_mse: 4099.5312\n",
      "Epoch 152/1000\n",
      "615/615 [==============================] - 0s 689us/step - loss: 2677.2881 - mae: 23.0652 - mse: 2677.2881 - val_loss: 4193.4536 - val_mae: 28.0194 - val_mse: 4193.4536\n",
      "Epoch 153/1000\n",
      "615/615 [==============================] - 0s 653us/step - loss: 2706.1724 - mae: 23.0573 - mse: 2706.1724 - val_loss: 4145.6191 - val_mae: 27.7511 - val_mse: 4145.6191\n",
      "Epoch 154/1000\n",
      "615/615 [==============================] - 0s 654us/step - loss: 2754.3391 - mae: 23.5062 - mse: 2754.3391 - val_loss: 4065.3499 - val_mae: 27.3161 - val_mse: 4065.3499\n",
      "Epoch 155/1000\n",
      "615/615 [==============================] - 0s 668us/step - loss: 2672.5134 - mae: 22.9053 - mse: 2672.5134 - val_loss: 4057.6553 - val_mae: 28.5951 - val_mse: 4057.6553\n",
      "Epoch 156/1000\n",
      "615/615 [==============================] - 0s 657us/step - loss: 2683.1399 - mae: 23.3053 - mse: 2683.1399 - val_loss: 4172.6934 - val_mae: 28.9966 - val_mse: 4172.6934\n",
      "Epoch 157/1000\n",
      "615/615 [==============================] - 0s 687us/step - loss: 2622.3462 - mae: 22.9226 - mse: 2622.3462 - val_loss: 5113.6743 - val_mae: 31.1484 - val_mse: 5113.6743\n",
      "Epoch 158/1000\n",
      "615/615 [==============================] - 0s 658us/step - loss: 2727.0103 - mae: 23.3895 - mse: 2727.0103 - val_loss: 4308.5679 - val_mae: 28.4555 - val_mse: 4308.5679\n",
      "Epoch 159/1000\n",
      "615/615 [==============================] - 0s 661us/step - loss: 2694.9404 - mae: 23.3362 - mse: 2694.9404 - val_loss: 3962.0891 - val_mae: 26.7500 - val_mse: 3962.0891\n",
      "Epoch 160/1000\n",
      "615/615 [==============================] - 0s 655us/step - loss: 2646.7329 - mae: 23.0047 - mse: 2646.7329 - val_loss: 4075.5042 - val_mae: 27.4468 - val_mse: 4075.5042\n",
      "Epoch 161/1000\n",
      "615/615 [==============================] - 0s 652us/step - loss: 2633.6475 - mae: 22.8990 - mse: 2633.6475 - val_loss: 4085.2307 - val_mae: 27.8894 - val_mse: 4085.2307\n",
      "Epoch 162/1000\n",
      "615/615 [==============================] - 0s 693us/step - loss: 2572.5662 - mae: 22.6991 - mse: 2572.5662 - val_loss: 4294.2217 - val_mae: 27.8594 - val_mse: 4294.2217\n",
      "Epoch 163/1000\n",
      "615/615 [==============================] - 0s 662us/step - loss: 2645.7446 - mae: 23.2166 - mse: 2645.7446 - val_loss: 4262.0459 - val_mae: 29.7516 - val_mse: 4262.0459\n",
      "Epoch 164/1000\n",
      "615/615 [==============================] - 0s 656us/step - loss: 2628.7227 - mae: 23.0909 - mse: 2628.7227 - val_loss: 3988.7820 - val_mae: 26.9090 - val_mse: 3988.7820\n",
      "Epoch 165/1000\n",
      "615/615 [==============================] - 0s 660us/step - loss: 2628.1506 - mae: 23.0938 - mse: 2628.1506 - val_loss: 4001.4585 - val_mae: 27.0560 - val_mse: 4001.4585\n",
      "Epoch 166/1000\n",
      "615/615 [==============================] - 0s 694us/step - loss: 2613.1538 - mae: 22.9600 - mse: 2613.1538 - val_loss: 4235.4380 - val_mae: 28.0578 - val_mse: 4235.4380\n",
      "Epoch 167/1000\n",
      "615/615 [==============================] - 0s 653us/step - loss: 2566.7534 - mae: 22.8005 - mse: 2566.7534 - val_loss: 4057.8975 - val_mae: 28.4792 - val_mse: 4057.8975\n",
      "Epoch 168/1000\n",
      "615/615 [==============================] - 0s 656us/step - loss: 2598.8960 - mae: 22.7858 - mse: 2598.8960 - val_loss: 4039.2759 - val_mae: 27.4774 - val_mse: 4039.2759\n",
      "Epoch 169/1000\n",
      "615/615 [==============================] - 0s 664us/step - loss: 2516.8130 - mae: 22.5453 - mse: 2516.8130 - val_loss: 4242.7334 - val_mae: 29.5158 - val_mse: 4242.7334\n",
      "Epoch 170/1000\n",
      "615/615 [==============================] - 0s 650us/step - loss: 2588.9033 - mae: 22.9433 - mse: 2588.9033 - val_loss: 4151.1909 - val_mae: 27.9468 - val_mse: 4151.1909\n",
      "Epoch 171/1000\n",
      "615/615 [==============================] - 0s 678us/step - loss: 2503.6609 - mae: 22.3732 - mse: 2503.6609 - val_loss: 4048.7124 - val_mae: 27.5980 - val_mse: 4048.7124\n",
      "Epoch 172/1000\n",
      "615/615 [==============================] - 0s 666us/step - loss: 2543.5059 - mae: 22.6111 - mse: 2543.5059 - val_loss: 4086.1482 - val_mae: 27.2238 - val_mse: 4086.1482\n",
      "Epoch 173/1000\n",
      "615/615 [==============================] - 0s 659us/step - loss: 2519.6948 - mae: 22.4834 - mse: 2519.6948 - val_loss: 4212.8433 - val_mae: 27.8664 - val_mse: 4212.8433\n",
      "Epoch 174/1000\n",
      "615/615 [==============================] - 0s 655us/step - loss: 2538.4702 - mae: 22.7453 - mse: 2538.4702 - val_loss: 4066.0044 - val_mae: 27.8238 - val_mse: 4066.0044\n",
      "Epoch 175/1000\n",
      "615/615 [==============================] - 0s 657us/step - loss: 2491.7410 - mae: 22.5113 - mse: 2491.7410 - val_loss: 4335.0117 - val_mae: 28.3474 - val_mse: 4335.0117\n",
      "Epoch 176/1000\n",
      "615/615 [==============================] - 0s 696us/step - loss: 2508.4136 - mae: 22.4401 - mse: 2508.4136 - val_loss: 4098.4492 - val_mae: 27.6737 - val_mse: 4098.4492\n",
      "Epoch 177/1000\n",
      "615/615 [==============================] - 0s 656us/step - loss: 2535.7305 - mae: 22.6290 - mse: 2535.7305 - val_loss: 4321.3560 - val_mae: 28.2521 - val_mse: 4321.3560\n",
      "Epoch 178/1000\n",
      "615/615 [==============================] - 0s 660us/step - loss: 2512.2751 - mae: 22.5699 - mse: 2512.2751 - val_loss: 4308.4399 - val_mae: 28.1544 - val_mse: 4308.4399\n",
      "Epoch 179/1000\n",
      "615/615 [==============================] - 0s 659us/step - loss: 2485.1851 - mae: 22.4948 - mse: 2485.1851 - val_loss: 4015.6443 - val_mae: 28.4854 - val_mse: 4015.6443\n",
      "Epoch 180/1000\n",
      "615/615 [==============================] - 0s 659us/step - loss: 2456.0288 - mae: 22.2625 - mse: 2456.0288 - val_loss: 4314.2285 - val_mae: 28.8070 - val_mse: 4314.2285\n",
      "Epoch 181/1000\n",
      "615/615 [==============================] - 0s 676us/step - loss: 2463.4961 - mae: 22.4490 - mse: 2463.4961 - val_loss: 4443.4248 - val_mae: 30.5223 - val_mse: 4443.4248\n",
      "Epoch 182/1000\n",
      "615/615 [==============================] - 0s 663us/step - loss: 2529.0784 - mae: 22.6131 - mse: 2529.0784 - val_loss: 4062.9521 - val_mae: 28.0093 - val_mse: 4062.9521\n",
      "Epoch 183/1000\n",
      "615/615 [==============================] - 0s 653us/step - loss: 2469.9678 - mae: 22.2838 - mse: 2469.9678 - val_loss: 4119.5356 - val_mae: 28.1821 - val_mse: 4119.5356\n",
      "Epoch 184/1000\n",
      "615/615 [==============================] - 0s 659us/step - loss: 2432.7349 - mae: 22.3552 - mse: 2432.7349 - val_loss: 4199.4185 - val_mae: 28.7832 - val_mse: 4199.4185\n",
      "Epoch 185/1000\n",
      "615/615 [==============================] - 0s 661us/step - loss: 2441.3816 - mae: 22.3258 - mse: 2441.3816 - val_loss: 4291.0557 - val_mae: 27.7271 - val_mse: 4291.0557\n",
      "Epoch 186/1000\n",
      "615/615 [==============================] - 0s 684us/step - loss: 2388.8115 - mae: 22.1706 - mse: 2388.8115 - val_loss: 4119.5308 - val_mae: 28.1551 - val_mse: 4119.5308\n",
      "Epoch 187/1000\n",
      "615/615 [==============================] - 0s 662us/step - loss: 2462.5293 - mae: 22.4548 - mse: 2462.5293 - val_loss: 4321.8691 - val_mae: 28.8452 - val_mse: 4321.8691\n",
      "Epoch 188/1000\n",
      "615/615 [==============================] - 0s 666us/step - loss: 2420.5183 - mae: 22.1010 - mse: 2420.5183 - val_loss: 4750.4775 - val_mae: 30.1833 - val_mse: 4750.4775\n",
      "Epoch 189/1000\n",
      "615/615 [==============================] - 0s 651us/step - loss: 2432.0569 - mae: 22.1727 - mse: 2432.0569 - val_loss: 4221.8833 - val_mae: 28.1757 - val_mse: 4221.8833\n",
      "Epoch 190/1000\n",
      "615/615 [==============================] - 0s 681us/step - loss: 2436.6851 - mae: 22.2561 - mse: 2436.6851 - val_loss: 4028.4634 - val_mae: 27.6005 - val_mse: 4028.4634\n",
      "Epoch 191/1000\n",
      "615/615 [==============================] - 0s 672us/step - loss: 2420.1555 - mae: 22.1977 - mse: 2420.1555 - val_loss: 4259.4268 - val_mae: 28.0346 - val_mse: 4259.4268\n",
      "Epoch 192/1000\n",
      "615/615 [==============================] - 0s 649us/step - loss: 2372.3816 - mae: 21.8876 - mse: 2372.3816 - val_loss: 4409.0405 - val_mae: 29.0009 - val_mse: 4409.0405\n",
      "Epoch 193/1000\n",
      "615/615 [==============================] - 0s 655us/step - loss: 2411.5449 - mae: 22.3455 - mse: 2411.5449 - val_loss: 4143.2856 - val_mae: 28.8786 - val_mse: 4143.2856\n",
      "Epoch 194/1000\n",
      "615/615 [==============================] - 0s 670us/step - loss: 2363.8818 - mae: 21.9960 - mse: 2363.8818 - val_loss: 4172.9404 - val_mae: 28.2547 - val_mse: 4172.9404\n",
      "Epoch 195/1000\n",
      "615/615 [==============================] - 0s 686us/step - loss: 2443.6570 - mae: 22.5397 - mse: 2443.6570 - val_loss: 4302.0972 - val_mae: 29.1431 - val_mse: 4302.0972\n",
      "Epoch 196/1000\n",
      "615/615 [==============================] - 0s 660us/step - loss: 2392.3203 - mae: 22.4395 - mse: 2392.3203 - val_loss: 3969.1082 - val_mae: 27.8701 - val_mse: 3969.1082\n",
      "Epoch 197/1000\n",
      "615/615 [==============================] - 0s 665us/step - loss: 2383.2053 - mae: 22.1134 - mse: 2383.2053 - val_loss: 4372.7358 - val_mae: 28.4691 - val_mse: 4372.7358\n",
      "Epoch 198/1000\n",
      "615/615 [==============================] - 0s 653us/step - loss: 2421.9495 - mae: 22.3980 - mse: 2421.9495 - val_loss: 4115.4233 - val_mae: 28.0454 - val_mse: 4115.4233\n",
      "Epoch 199/1000\n",
      "615/615 [==============================] - 0s 655us/step - loss: 2360.6287 - mae: 22.0475 - mse: 2360.6287 - val_loss: 4111.6753 - val_mae: 27.9691 - val_mse: 4111.6753\n",
      "Epoch 200/1000\n",
      "615/615 [==============================] - 0s 689us/step - loss: 2339.0588 - mae: 21.8839 - mse: 2339.0588 - val_loss: 4175.6240 - val_mae: 28.5292 - val_mse: 4175.6240\n",
      "Epoch 201/1000\n",
      "615/615 [==============================] - 0s 657us/step - loss: 2335.1399 - mae: 21.9705 - mse: 2335.1399 - val_loss: 4115.4858 - val_mae: 27.5622 - val_mse: 4115.4858\n",
      "Epoch 202/1000\n",
      "615/615 [==============================] - 0s 665us/step - loss: 2390.1470 - mae: 22.0241 - mse: 2390.1470 - val_loss: 4021.4797 - val_mae: 26.9474 - val_mse: 4021.4797\n",
      "Epoch 203/1000\n",
      "615/615 [==============================] - 0s 655us/step - loss: 2288.4519 - mae: 21.7442 - mse: 2288.4519 - val_loss: 4510.4507 - val_mae: 29.6780 - val_mse: 4510.4507\n",
      "Epoch 204/1000\n",
      "615/615 [==============================] - 0s 680us/step - loss: 2300.3242 - mae: 21.9494 - mse: 2300.3242 - val_loss: 4032.4055 - val_mae: 29.3019 - val_mse: 4032.4055\n",
      "Epoch 205/1000\n",
      "615/615 [==============================] - 0s 668us/step - loss: 2325.1646 - mae: 21.9611 - mse: 2325.1646 - val_loss: 4081.5994 - val_mae: 27.5559 - val_mse: 4081.5994\n",
      "Epoch 206/1000\n",
      "615/615 [==============================] - 0s 656us/step - loss: 2308.9299 - mae: 21.7384 - mse: 2308.9299 - val_loss: 4077.2856 - val_mae: 27.5867 - val_mse: 4077.2856\n",
      "Epoch 207/1000\n",
      "615/615 [==============================] - 0s 657us/step - loss: 2348.9165 - mae: 21.8335 - mse: 2348.9165 - val_loss: 4205.6821 - val_mae: 27.7549 - val_mse: 4205.6821\n",
      "Epoch 208/1000\n",
      "615/615 [==============================] - 0s 690us/step - loss: 2401.5769 - mae: 22.2868 - mse: 2401.5769 - val_loss: 4022.1829 - val_mae: 27.3756 - val_mse: 4022.1829\n",
      "Epoch 209/1000\n",
      "615/615 [==============================] - 0s 651us/step - loss: 2289.0405 - mae: 21.7975 - mse: 2289.0405 - val_loss: 4276.4243 - val_mae: 28.2294 - val_mse: 4276.4243\n",
      "Epoch 210/1000\n",
      "615/615 [==============================] - 0s 658us/step - loss: 2324.6221 - mae: 21.8425 - mse: 2324.6221 - val_loss: 4055.0735 - val_mae: 27.4501 - val_mse: 4055.0735\n",
      "Epoch 211/1000\n",
      "615/615 [==============================] - 0s 669us/step - loss: 2229.9097 - mae: 21.4825 - mse: 2229.9097 - val_loss: 4306.7642 - val_mae: 29.3229 - val_mse: 4306.7642\n",
      "Epoch 212/1000\n",
      "615/615 [==============================] - 0s 655us/step - loss: 2285.5237 - mae: 21.7827 - mse: 2285.5237 - val_loss: 4008.6497 - val_mae: 28.0504 - val_mse: 4008.6497\n",
      "Epoch 213/1000\n",
      "615/615 [==============================] - 0s 677us/step - loss: 2264.4182 - mae: 21.5772 - mse: 2264.4182 - val_loss: 4356.6353 - val_mae: 30.0782 - val_mse: 4356.6353\n",
      "Epoch 214/1000\n",
      "615/615 [==============================] - 0s 666us/step - loss: 2334.0979 - mae: 22.0120 - mse: 2334.0979 - val_loss: 4200.4302 - val_mae: 28.2311 - val_mse: 4200.4302\n",
      "Epoch 215/1000\n",
      "615/615 [==============================] - 0s 661us/step - loss: 2210.1848 - mae: 21.5587 - mse: 2210.1848 - val_loss: 3969.6956 - val_mae: 27.8970 - val_mse: 3969.6956\n",
      "Epoch 216/1000\n",
      "615/615 [==============================] - 0s 666us/step - loss: 2267.6926 - mae: 21.5235 - mse: 2267.6926 - val_loss: 3996.5330 - val_mae: 27.6053 - val_mse: 3996.5330\n",
      "Epoch 217/1000\n",
      "615/615 [==============================] - 0s 676us/step - loss: 2260.0508 - mae: 21.7157 - mse: 2260.0508 - val_loss: 4071.8977 - val_mae: 28.3178 - val_mse: 4071.8977\n",
      "Epoch 218/1000\n",
      "615/615 [==============================] - 0s 658us/step - loss: 2229.2393 - mae: 21.6017 - mse: 2229.2393 - val_loss: 3986.8618 - val_mae: 27.0847 - val_mse: 3986.8618\n",
      "Epoch 219/1000\n",
      "615/615 [==============================] - 0s 673us/step - loss: 2277.3164 - mae: 21.8428 - mse: 2277.3164 - val_loss: 3928.3130 - val_mae: 27.0767 - val_mse: 3928.3130\n",
      "Epoch 220/1000\n",
      "615/615 [==============================] - 0s 658us/step - loss: 2208.7283 - mae: 21.2570 - mse: 2208.7283 - val_loss: 4044.8672 - val_mae: 27.5517 - val_mse: 4044.8672\n",
      "Epoch 221/1000\n",
      "615/615 [==============================] - 0s 697us/step - loss: 2215.9880 - mae: 21.5295 - mse: 2215.9880 - val_loss: 4217.3135 - val_mae: 28.4487 - val_mse: 4217.3135\n",
      "Epoch 222/1000\n",
      "615/615 [==============================] - 0s 660us/step - loss: 2256.5945 - mae: 21.7202 - mse: 2256.5945 - val_loss: 4164.2026 - val_mae: 28.5326 - val_mse: 4164.2026\n",
      "Epoch 223/1000\n",
      "615/615 [==============================] - 0s 659us/step - loss: 2266.8445 - mae: 21.7414 - mse: 2266.8445 - val_loss: 4027.3777 - val_mae: 27.9081 - val_mse: 4027.3777\n",
      "Epoch 224/1000\n",
      "615/615 [==============================] - 0s 665us/step - loss: 2352.5564 - mae: 21.7055 - mse: 2352.5564 - val_loss: 4138.8813 - val_mae: 27.8774 - val_mse: 4138.8813\n",
      "Epoch 225/1000\n",
      "615/615 [==============================] - 0s 661us/step - loss: 2176.5115 - mae: 21.1945 - mse: 2176.5115 - val_loss: 4120.6304 - val_mae: 27.8462 - val_mse: 4120.6304\n",
      "Epoch 226/1000\n",
      "615/615 [==============================] - 0s 678us/step - loss: 2155.1990 - mae: 21.2705 - mse: 2155.1990 - val_loss: 4092.7869 - val_mae: 27.9976 - val_mse: 4092.7869\n",
      "Epoch 227/1000\n",
      "615/615 [==============================] - 0s 662us/step - loss: 2193.7722 - mae: 21.4786 - mse: 2193.7722 - val_loss: 4310.8872 - val_mae: 28.8386 - val_mse: 4310.8872\n",
      "Epoch 228/1000\n",
      "615/615 [==============================] - 0s 654us/step - loss: 2153.8130 - mae: 21.2841 - mse: 2153.8130 - val_loss: 3968.2007 - val_mae: 27.4445 - val_mse: 3968.2007\n",
      "Epoch 229/1000\n",
      "615/615 [==============================] - 0s 656us/step - loss: 2199.8589 - mae: 21.3270 - mse: 2199.8589 - val_loss: 4315.6978 - val_mae: 28.8295 - val_mse: 4315.6978\n",
      "Epoch 230/1000\n",
      "615/615 [==============================] - 0s 697us/step - loss: 2203.7737 - mae: 21.4459 - mse: 2203.7737 - val_loss: 4412.7207 - val_mae: 30.8373 - val_mse: 4412.7207\n",
      "Epoch 231/1000\n",
      "615/615 [==============================] - 0s 658us/step - loss: 2209.7295 - mae: 21.7514 - mse: 2209.7295 - val_loss: 3982.6677 - val_mae: 27.3114 - val_mse: 3982.6677\n",
      "Epoch 232/1000\n",
      "615/615 [==============================] - 0s 673us/step - loss: 2158.4746 - mae: 21.2298 - mse: 2158.4746 - val_loss: 3982.7568 - val_mae: 27.3653 - val_mse: 3982.7568\n",
      "Epoch 233/1000\n",
      "615/615 [==============================] - 0s 652us/step - loss: 2182.0688 - mae: 21.5827 - mse: 2182.0688 - val_loss: 4154.7646 - val_mae: 29.5358 - val_mse: 4154.7646\n",
      "Epoch 234/1000\n",
      "615/615 [==============================] - 0s 679us/step - loss: 2267.1667 - mae: 21.9573 - mse: 2267.1667 - val_loss: 4191.6543 - val_mae: 28.9557 - val_mse: 4191.6543\n",
      "Epoch 235/1000\n",
      "615/615 [==============================] - 0s 671us/step - loss: 2176.8098 - mae: 21.3290 - mse: 2176.8098 - val_loss: 4095.0967 - val_mae: 28.4562 - val_mse: 4095.0967\n",
      "Epoch 236/1000\n",
      "615/615 [==============================] - 0s 658us/step - loss: 2137.3044 - mae: 21.2110 - mse: 2137.3044 - val_loss: 4270.2085 - val_mae: 29.0992 - val_mse: 4270.2085\n",
      "Epoch 237/1000\n",
      "615/615 [==============================] - 0s 653us/step - loss: 2124.1653 - mae: 21.4649 - mse: 2124.1653 - val_loss: 4030.7563 - val_mae: 27.8309 - val_mse: 4030.7563\n",
      "Epoch 238/1000\n",
      "615/615 [==============================] - 0s 692us/step - loss: 2192.1848 - mae: 21.2060 - mse: 2192.1848 - val_loss: 4344.9976 - val_mae: 28.6420 - val_mse: 4344.9976\n",
      "Epoch 239/1000\n",
      "615/615 [==============================] - 0s 655us/step - loss: 2162.0654 - mae: 21.3655 - mse: 2162.0654 - val_loss: 4340.0991 - val_mae: 28.1509 - val_mse: 4340.0991\n",
      "Epoch 240/1000\n",
      "615/615 [==============================] - 0s 665us/step - loss: 2213.8167 - mae: 21.3371 - mse: 2213.8167 - val_loss: 4460.2598 - val_mae: 28.9378 - val_mse: 4460.2598\n",
      "Epoch 241/1000\n",
      "615/615 [==============================] - 0s 652us/step - loss: 2135.0017 - mae: 21.2429 - mse: 2135.0017 - val_loss: 4015.1760 - val_mae: 27.6373 - val_mse: 4015.1760\n",
      "Epoch 242/1000\n",
      "615/615 [==============================] - 0s 691us/step - loss: 2130.5583 - mae: 21.2698 - mse: 2130.5583 - val_loss: 3925.5498 - val_mae: 28.0135 - val_mse: 3925.5498\n",
      "Epoch 243/1000\n",
      "615/615 [==============================] - 0s 661us/step - loss: 2105.9014 - mae: 21.1880 - mse: 2105.9014 - val_loss: 4440.6328 - val_mae: 30.6391 - val_mse: 4440.6328\n",
      "Epoch 244/1000\n",
      "615/615 [==============================] - 0s 657us/step - loss: 2160.2896 - mae: 21.2349 - mse: 2160.2896 - val_loss: 4222.7368 - val_mae: 28.3251 - val_mse: 4222.7368\n",
      "Epoch 245/1000\n",
      "615/615 [==============================] - 0s 659us/step - loss: 2134.5498 - mae: 21.3536 - mse: 2134.5498 - val_loss: 4702.1997 - val_mae: 32.0174 - val_mse: 4702.1997\n",
      "Epoch 246/1000\n",
      "615/615 [==============================] - 0s 698us/step - loss: 2086.3853 - mae: 20.9448 - mse: 2086.3853 - val_loss: 4170.9951 - val_mae: 27.6768 - val_mse: 4170.9951\n",
      "Epoch 247/1000\n",
      "615/615 [==============================] - 0s 661us/step - loss: 2077.5479 - mae: 21.1047 - mse: 2077.5479 - val_loss: 4467.8384 - val_mae: 28.9141 - val_mse: 4467.8384\n",
      "Epoch 248/1000\n",
      "615/615 [==============================] - 0s 658us/step - loss: 2059.6401 - mae: 20.8862 - mse: 2059.6401 - val_loss: 4403.9268 - val_mae: 29.2579 - val_mse: 4403.9268\n",
      "Epoch 249/1000\n",
      "615/615 [==============================] - 0s 657us/step - loss: 2070.3064 - mae: 21.0974 - mse: 2070.3064 - val_loss: 4255.1333 - val_mae: 28.8211 - val_mse: 4255.1333\n",
      "Epoch 250/1000\n",
      "615/615 [==============================] - 0s 696us/step - loss: 2066.3352 - mae: 21.1205 - mse: 2066.3352 - val_loss: 4134.2290 - val_mae: 27.7605 - val_mse: 4134.2290\n",
      "Epoch 251/1000\n",
      "615/615 [==============================] - 0s 656us/step - loss: 2074.4587 - mae: 20.9510 - mse: 2074.4587 - val_loss: 4106.2656 - val_mae: 27.9229 - val_mse: 4106.2656\n",
      "Epoch 252/1000\n",
      "615/615 [==============================] - 0s 662us/step - loss: 2071.0334 - mae: 20.9134 - mse: 2071.0334 - val_loss: 3992.4148 - val_mae: 27.1421 - val_mse: 3992.4148\n",
      "Epoch 253/1000\n",
      "615/615 [==============================] - 0s 666us/step - loss: 2110.9280 - mae: 20.9691 - mse: 2110.9280 - val_loss: 4675.9932 - val_mae: 29.0569 - val_mse: 4675.9932\n",
      "Epoch 254/1000\n",
      "615/615 [==============================] - 0s 657us/step - loss: 2113.5430 - mae: 21.3868 - mse: 2113.5430 - val_loss: 4329.0161 - val_mae: 29.6705 - val_mse: 4329.0161\n",
      "Epoch 255/1000\n",
      "615/615 [==============================] - 0s 684us/step - loss: 2022.7817 - mae: 20.7832 - mse: 2022.7817 - val_loss: 4224.9229 - val_mae: 28.0768 - val_mse: 4224.9229\n",
      "Epoch 256/1000\n",
      "615/615 [==============================] - 0s 666us/step - loss: 2046.3311 - mae: 20.7907 - mse: 2046.3311 - val_loss: 4239.7725 - val_mae: 27.6586 - val_mse: 4239.7725\n",
      "Epoch 257/1000\n",
      "615/615 [==============================] - 0s 656us/step - loss: 2023.0559 - mae: 20.7167 - mse: 2023.0559 - val_loss: 4123.9111 - val_mae: 27.8262 - val_mse: 4123.9111\n",
      "Epoch 258/1000\n",
      "615/615 [==============================] - 0s 655us/step - loss: 2036.3452 - mae: 21.0176 - mse: 2036.3452 - val_loss: 4008.5442 - val_mae: 28.3102 - val_mse: 4008.5442\n",
      "Epoch 259/1000\n",
      "615/615 [==============================] - 0s 690us/step - loss: 2032.0970 - mae: 20.9230 - mse: 2032.0970 - val_loss: 3968.4587 - val_mae: 27.3791 - val_mse: 3968.4587\n",
      "Epoch 260/1000\n",
      "615/615 [==============================] - 0s 657us/step - loss: 2083.5952 - mae: 20.8492 - mse: 2083.5952 - val_loss: 4535.1323 - val_mae: 28.9840 - val_mse: 4535.1323\n",
      "Epoch 261/1000\n",
      "615/615 [==============================] - 0s 654us/step - loss: 2055.9612 - mae: 21.0044 - mse: 2055.9612 - val_loss: 4095.3801 - val_mae: 27.8707 - val_mse: 4095.3801\n",
      "Epoch 262/1000\n",
      "615/615 [==============================] - 0s 664us/step - loss: 2040.2538 - mae: 21.0540 - mse: 2040.2538 - val_loss: 4249.7856 - val_mae: 29.5553 - val_mse: 4249.7856\n",
      "Epoch 263/1000\n",
      "615/615 [==============================] - 0s 679us/step - loss: 2039.3602 - mae: 21.0018 - mse: 2039.3602 - val_loss: 4064.9138 - val_mae: 30.1089 - val_mse: 4064.9138\n",
      "Epoch 264/1000\n",
      "615/615 [==============================] - 0s 650us/step - loss: 2047.5178 - mae: 21.0683 - mse: 2047.5178 - val_loss: 4111.6479 - val_mae: 28.0773 - val_mse: 4111.6479\n",
      "Epoch 265/1000\n",
      "615/615 [==============================] - 0s 660us/step - loss: 2010.9908 - mae: 20.6537 - mse: 2010.9908 - val_loss: 4031.6846 - val_mae: 27.6003 - val_mse: 4031.6846\n",
      "Epoch 266/1000\n",
      "615/615 [==============================] - 0s 655us/step - loss: 2031.2847 - mae: 20.8719 - mse: 2031.2847 - val_loss: 4098.3374 - val_mae: 28.5290 - val_mse: 4098.3374\n",
      "Epoch 267/1000\n",
      "615/615 [==============================] - 0s 696us/step - loss: 1967.4755 - mae: 20.6040 - mse: 1967.4755 - val_loss: 3980.0969 - val_mae: 27.1966 - val_mse: 3980.0969\n",
      "Epoch 268/1000\n",
      "615/615 [==============================] - 0s 655us/step - loss: 2004.0784 - mae: 20.6861 - mse: 2004.0784 - val_loss: 4075.0168 - val_mae: 28.4773 - val_mse: 4075.0168\n",
      "Epoch 269/1000\n",
      "615/615 [==============================] - 0s 665us/step - loss: 1996.5303 - mae: 20.8228 - mse: 1996.5303 - val_loss: 4097.9277 - val_mae: 27.3896 - val_mse: 4097.9277\n",
      "Epoch 270/1000\n",
      "615/615 [==============================] - 0s 666us/step - loss: 2031.2617 - mae: 20.7624 - mse: 2031.2617 - val_loss: 4064.5916 - val_mae: 27.3948 - val_mse: 4064.5916\n",
      "Epoch 271/1000\n",
      "615/615 [==============================] - 0s 659us/step - loss: 1966.5226 - mae: 20.5989 - mse: 1966.5226 - val_loss: 4174.3145 - val_mae: 27.7523 - val_mse: 4174.3145\n",
      "Epoch 272/1000\n",
      "615/615 [==============================] - 0s 666us/step - loss: 2083.6094 - mae: 21.0839 - mse: 2083.6094 - val_loss: 4005.7798 - val_mae: 27.8309 - val_mse: 4005.7798\n",
      "Epoch 273/1000\n",
      "615/615 [==============================] - 0s 655us/step - loss: 1994.5090 - mae: 20.6313 - mse: 1994.5090 - val_loss: 4278.3745 - val_mae: 29.6154 - val_mse: 4278.3745\n",
      "Epoch 274/1000\n",
      "615/615 [==============================] - 0s 665us/step - loss: 2012.4631 - mae: 20.7224 - mse: 2012.4631 - val_loss: 3999.2693 - val_mae: 27.9184 - val_mse: 3999.2693\n",
      "Epoch 275/1000\n",
      "615/615 [==============================] - 0s 656us/step - loss: 1957.0857 - mae: 20.3930 - mse: 1957.0857 - val_loss: 4243.5923 - val_mae: 28.0036 - val_mse: 4243.5923\n",
      "Epoch 276/1000\n",
      "615/615 [==============================] - 0s 685us/step - loss: 1984.5111 - mae: 20.7996 - mse: 1984.5111 - val_loss: 4176.3955 - val_mae: 28.2472 - val_mse: 4176.3955\n",
      "Epoch 277/1000\n",
      "615/615 [==============================] - 0s 670us/step - loss: 2027.8842 - mae: 20.7949 - mse: 2027.8842 - val_loss: 4330.2773 - val_mae: 30.1318 - val_mse: 4330.2773\n",
      "Epoch 278/1000\n",
      "615/615 [==============================] - 0s 679us/step - loss: 2036.2198 - mae: 21.0487 - mse: 2036.2198 - val_loss: 4105.5352 - val_mae: 27.6680 - val_mse: 4105.5352\n",
      "Epoch 279/1000\n",
      "615/615 [==============================] - 0s 705us/step - loss: 1960.1552 - mae: 20.6054 - mse: 1960.1552 - val_loss: 4233.6714 - val_mae: 29.4870 - val_mse: 4233.6714\n",
      "Epoch 280/1000\n",
      "615/615 [==============================] - 0s 671us/step - loss: 1924.5776 - mae: 20.1782 - mse: 1924.5776 - val_loss: 4314.4961 - val_mae: 28.3931 - val_mse: 4314.4961\n",
      "Epoch 281/1000\n",
      "615/615 [==============================] - 0s 657us/step - loss: 1917.5674 - mae: 20.4208 - mse: 1917.5674 - val_loss: 4321.9243 - val_mae: 28.1776 - val_mse: 4321.9243\n",
      "Epoch 282/1000\n",
      "615/615 [==============================] - 0s 665us/step - loss: 1912.3639 - mae: 20.3719 - mse: 1912.3639 - val_loss: 4110.8560 - val_mae: 28.3980 - val_mse: 4110.8560\n",
      "Epoch 283/1000\n",
      "615/615 [==============================] - 0s 700us/step - loss: 1996.3811 - mae: 20.4222 - mse: 1996.3811 - val_loss: 4032.9260 - val_mae: 27.9935 - val_mse: 4032.9260\n",
      "Epoch 284/1000\n",
      "615/615 [==============================] - 0s 661us/step - loss: 2127.7986 - mae: 21.0131 - mse: 2127.7986 - val_loss: 4297.4644 - val_mae: 29.0753 - val_mse: 4297.4644\n",
      "Epoch 285/1000\n",
      "615/615 [==============================] - 0s 655us/step - loss: 1880.6914 - mae: 20.1517 - mse: 1880.6914 - val_loss: 4139.8984 - val_mae: 27.9750 - val_mse: 4139.8984\n",
      "Epoch 286/1000\n",
      "615/615 [==============================] - 0s 666us/step - loss: 1891.8307 - mae: 20.0992 - mse: 1891.8307 - val_loss: 4552.4321 - val_mae: 30.0173 - val_mse: 4552.4321\n",
      "Epoch 287/1000\n",
      "615/615 [==============================] - 0s 690us/step - loss: 1932.5641 - mae: 20.5345 - mse: 1932.5641 - val_loss: 3991.1118 - val_mae: 27.6771 - val_mse: 3991.1118\n",
      "Epoch 288/1000\n",
      "615/615 [==============================] - 0s 670us/step - loss: 1931.3112 - mae: 20.4226 - mse: 1931.3112 - val_loss: 4511.1284 - val_mae: 28.7763 - val_mse: 4511.1284\n",
      "Epoch 289/1000\n",
      "615/615 [==============================] - 0s 658us/step - loss: 1975.8799 - mae: 20.5694 - mse: 1975.8799 - val_loss: 4331.6440 - val_mae: 28.6137 - val_mse: 4331.6440\n",
      "Epoch 290/1000\n",
      "615/615 [==============================] - 0s 681us/step - loss: 1860.3657 - mae: 20.1783 - mse: 1860.3657 - val_loss: 3945.7695 - val_mae: 27.3057 - val_mse: 3945.7695\n",
      "Epoch 291/1000\n",
      "615/615 [==============================] - 0s 660us/step - loss: 1925.5494 - mae: 20.6865 - mse: 1925.5494 - val_loss: 4047.3169 - val_mae: 27.9861 - val_mse: 4047.3169\n",
      "Epoch 292/1000\n",
      "615/615 [==============================] - 0s 652us/step - loss: 1867.4390 - mae: 20.1380 - mse: 1867.4390 - val_loss: 4183.9634 - val_mae: 29.4079 - val_mse: 4183.9634\n",
      "Epoch 293/1000\n",
      "615/615 [==============================] - 0s 656us/step - loss: 1910.3710 - mae: 20.5489 - mse: 1910.3710 - val_loss: 4386.7681 - val_mae: 29.0771 - val_mse: 4386.7681\n",
      "Epoch 294/1000\n",
      "615/615 [==============================] - 0s 698us/step - loss: 1955.3618 - mae: 20.4780 - mse: 1955.3618 - val_loss: 4097.4141 - val_mae: 28.4227 - val_mse: 4097.4141\n",
      "Epoch 295/1000\n",
      "615/615 [==============================] - 0s 654us/step - loss: 1831.4526 - mae: 20.0965 - mse: 1831.4526 - val_loss: 4299.6577 - val_mae: 28.4930 - val_mse: 4299.6577\n",
      "Epoch 296/1000\n",
      "615/615 [==============================] - 0s 672us/step - loss: 1892.5355 - mae: 20.5507 - mse: 1892.5355 - val_loss: 4250.4795 - val_mae: 28.0223 - val_mse: 4250.4795\n",
      "Epoch 297/1000\n",
      "615/615 [==============================] - 0s 658us/step - loss: 1927.1046 - mae: 20.3973 - mse: 1927.1046 - val_loss: 4153.2578 - val_mae: 28.2370 - val_mse: 4153.2578\n",
      "Epoch 298/1000\n",
      "615/615 [==============================] - 0s 680us/step - loss: 1900.4742 - mae: 20.2785 - mse: 1900.4742 - val_loss: 4010.6099 - val_mae: 27.6050 - val_mse: 4010.6099\n",
      "Epoch 299/1000\n",
      "615/615 [==============================] - 0s 708us/step - loss: 1889.4525 - mae: 20.1516 - mse: 1889.4525 - val_loss: 4078.8965 - val_mae: 28.8830 - val_mse: 4078.8965\n",
      "Epoch 300/1000\n",
      "615/615 [==============================] - 0s 673us/step - loss: 1868.4248 - mae: 19.9258 - mse: 1868.4248 - val_loss: 4098.0894 - val_mae: 27.5000 - val_mse: 4098.0894\n",
      "Epoch 301/1000\n",
      "615/615 [==============================] - 0s 664us/step - loss: 1882.0261 - mae: 20.0363 - mse: 1882.0261 - val_loss: 4026.6594 - val_mae: 28.0136 - val_mse: 4026.6594\n",
      "Epoch 302/1000\n",
      "615/615 [==============================] - 0s 729us/step - loss: 1903.2179 - mae: 20.3895 - mse: 1903.2179 - val_loss: 4024.5867 - val_mae: 28.1218 - val_mse: 4024.5867\n",
      "Epoch 303/1000\n",
      "615/615 [==============================] - 0s 681us/step - loss: 1861.5128 - mae: 20.1764 - mse: 1861.5128 - val_loss: 4263.9302 - val_mae: 29.0437 - val_mse: 4263.9302\n",
      "Epoch 304/1000\n",
      "615/615 [==============================] - 0s 670us/step - loss: 1840.8789 - mae: 20.0654 - mse: 1840.8789 - val_loss: 4208.1685 - val_mae: 27.6257 - val_mse: 4208.1685\n",
      "Epoch 305/1000\n",
      "615/615 [==============================] - 0s 669us/step - loss: 2004.7554 - mae: 20.6530 - mse: 2004.7554 - val_loss: 4190.8306 - val_mae: 28.4739 - val_mse: 4190.8306\n",
      "Epoch 306/1000\n",
      "615/615 [==============================] - 0s 690us/step - loss: 1861.2155 - mae: 20.2253 - mse: 1861.2155 - val_loss: 4098.8989 - val_mae: 27.8545 - val_mse: 4098.8989\n",
      "Epoch 307/1000\n",
      "615/615 [==============================] - 0s 659us/step - loss: 1841.2844 - mae: 19.9588 - mse: 1841.2844 - val_loss: 4224.1543 - val_mae: 30.0974 - val_mse: 4224.1543\n",
      "Epoch 308/1000\n",
      "615/615 [==============================] - 0s 672us/step - loss: 1818.0608 - mae: 20.1448 - mse: 1818.0608 - val_loss: 4173.8887 - val_mae: 27.9533 - val_mse: 4173.8887\n",
      "Epoch 309/1000\n",
      "615/615 [==============================] - 0s 657us/step - loss: 1868.3489 - mae: 20.0082 - mse: 1868.3489 - val_loss: 3896.2551 - val_mae: 27.4515 - val_mse: 3896.2551\n",
      "Epoch 310/1000\n",
      "615/615 [==============================] - 0s 740us/step - loss: 1801.4794 - mae: 19.8611 - mse: 1801.4794 - val_loss: 4074.4363 - val_mae: 27.6540 - val_mse: 4074.4363\n",
      "Epoch 311/1000\n",
      "615/615 [==============================] - 0s 667us/step - loss: 1815.4681 - mae: 19.8395 - mse: 1815.4681 - val_loss: 4169.0830 - val_mae: 28.3049 - val_mse: 4169.0830\n",
      "Epoch 312/1000\n",
      "615/615 [==============================] - 0s 686us/step - loss: 1877.7983 - mae: 20.3627 - mse: 1877.7983 - val_loss: 4399.1406 - val_mae: 28.7934 - val_mse: 4399.1406\n",
      "Epoch 313/1000\n",
      "615/615 [==============================] - 0s 707us/step - loss: 1818.7378 - mae: 19.8988 - mse: 1818.7378 - val_loss: 4225.2671 - val_mae: 28.7343 - val_mse: 4225.2671\n",
      "Epoch 314/1000\n",
      "615/615 [==============================] - 0s 668us/step - loss: 1800.7100 - mae: 20.0389 - mse: 1800.7100 - val_loss: 4599.5049 - val_mae: 28.9830 - val_mse: 4599.5049\n",
      "Epoch 315/1000\n",
      "615/615 [==============================] - 0s 671us/step - loss: 1822.6914 - mae: 19.9314 - mse: 1822.6914 - val_loss: 4720.1411 - val_mae: 30.4570 - val_mse: 4720.1411\n",
      "Epoch 316/1000\n",
      "615/615 [==============================] - 0s 658us/step - loss: 1861.6793 - mae: 20.1232 - mse: 1861.6793 - val_loss: 5425.9053 - val_mae: 33.3917 - val_mse: 5425.9053\n",
      "Epoch 317/1000\n",
      "615/615 [==============================] - 0s 745us/step - loss: 1816.2135 - mae: 20.1323 - mse: 1816.2135 - val_loss: 4145.3154 - val_mae: 27.8952 - val_mse: 4145.3154\n",
      "Epoch 318/1000\n",
      "615/615 [==============================] - 0s 790us/step - loss: 1793.2823 - mae: 19.6149 - mse: 1793.2823 - val_loss: 4116.5723 - val_mae: 27.5187 - val_mse: 4116.5723\n",
      "Epoch 319/1000\n",
      "615/615 [==============================] - 0s 690us/step - loss: 1795.7767 - mae: 19.8674 - mse: 1795.7767 - val_loss: 4085.3926 - val_mae: 27.7939 - val_mse: 4085.3926\n",
      "Epoch 320/1000\n",
      "615/615 [==============================] - 0s 691us/step - loss: 1847.3702 - mae: 19.7834 - mse: 1847.3702 - val_loss: 4125.5703 - val_mae: 27.5667 - val_mse: 4125.5703\n",
      "Epoch 321/1000\n",
      "615/615 [==============================] - 1s 839us/step - loss: 1798.4396 - mae: 19.7838 - mse: 1798.4396 - val_loss: 4025.1411 - val_mae: 27.5853 - val_mse: 4025.1411\n",
      "Epoch 322/1000\n",
      "615/615 [==============================] - 0s 730us/step - loss: 1833.8583 - mae: 20.0912 - mse: 1833.8583 - val_loss: 4606.6699 - val_mae: 30.0674 - val_mse: 4606.6699\n",
      "Epoch 323/1000\n",
      "615/615 [==============================] - 0s 678us/step - loss: 1783.8180 - mae: 19.7735 - mse: 1783.8180 - val_loss: 4193.1260 - val_mae: 28.8102 - val_mse: 4193.1260\n",
      "Epoch 324/1000\n",
      "615/615 [==============================] - 0s 695us/step - loss: 1771.5353 - mae: 19.7381 - mse: 1771.5353 - val_loss: 4162.8936 - val_mae: 28.4734 - val_mse: 4162.8936\n",
      "Epoch 325/1000\n",
      "615/615 [==============================] - 0s 668us/step - loss: 1842.5554 - mae: 19.9247 - mse: 1842.5554 - val_loss: 4302.1172 - val_mae: 28.9617 - val_mse: 4302.1172\n",
      "Epoch 326/1000\n",
      "615/615 [==============================] - 0s 680us/step - loss: 1803.4136 - mae: 19.9457 - mse: 1803.4136 - val_loss: 4164.1489 - val_mae: 28.2886 - val_mse: 4164.1489\n",
      "Epoch 327/1000\n",
      "615/615 [==============================] - 0s 786us/step - loss: 1751.8545 - mae: 19.6088 - mse: 1751.8545 - val_loss: 4120.7031 - val_mae: 27.7539 - val_mse: 4120.7031\n",
      "Epoch 328/1000\n",
      "615/615 [==============================] - 0s 719us/step - loss: 1742.2155 - mae: 19.7250 - mse: 1742.2155 - val_loss: 4326.7256 - val_mae: 29.1052 - val_mse: 4326.7256\n",
      "Epoch 329/1000\n",
      "615/615 [==============================] - 0s 763us/step - loss: 1733.7955 - mae: 19.5421 - mse: 1733.7955 - val_loss: 3999.5554 - val_mae: 28.9870 - val_mse: 3999.5554\n",
      "Epoch 330/1000\n",
      "615/615 [==============================] - 0s 696us/step - loss: 1782.1975 - mae: 20.0047 - mse: 1782.1975 - val_loss: 4323.9658 - val_mae: 28.5493 - val_mse: 4323.9658\n",
      "Epoch 331/1000\n",
      "615/615 [==============================] - 0s 711us/step - loss: 1791.7163 - mae: 19.6715 - mse: 1791.7163 - val_loss: 3960.7959 - val_mae: 27.8515 - val_mse: 3960.7959\n",
      "Epoch 332/1000\n",
      "615/615 [==============================] - 0s 679us/step - loss: 1745.5796 - mae: 19.5119 - mse: 1745.5796 - val_loss: 3950.3887 - val_mae: 27.2748 - val_mse: 3950.3887\n",
      "Epoch 333/1000\n",
      "615/615 [==============================] - 0s 738us/step - loss: 1755.7054 - mae: 19.6446 - mse: 1755.7054 - val_loss: 4418.8320 - val_mae: 28.6071 - val_mse: 4418.8320\n",
      "Epoch 334/1000\n",
      "615/615 [==============================] - 0s 692us/step - loss: 1739.6807 - mae: 19.6383 - mse: 1739.6807 - val_loss: 4250.2021 - val_mae: 27.8849 - val_mse: 4250.2021\n",
      "Epoch 335/1000\n",
      "615/615 [==============================] - 0s 662us/step - loss: 1799.7244 - mae: 19.8660 - mse: 1799.7244 - val_loss: 3945.8708 - val_mae: 26.9854 - val_mse: 3945.8708\n",
      "Epoch 336/1000\n",
      "615/615 [==============================] - 0s 677us/step - loss: 1729.4613 - mae: 19.6084 - mse: 1729.4613 - val_loss: 4082.2207 - val_mae: 27.3316 - val_mse: 4082.2207\n",
      "Epoch 337/1000\n",
      "615/615 [==============================] - 0s 670us/step - loss: 1754.1200 - mae: 19.6059 - mse: 1754.1200 - val_loss: 4285.9175 - val_mae: 29.1718 - val_mse: 4285.9175\n",
      "Epoch 338/1000\n",
      "615/615 [==============================] - 0s 705us/step - loss: 1737.0560 - mae: 19.6562 - mse: 1737.0560 - val_loss: 4089.2668 - val_mae: 27.4347 - val_mse: 4089.2668\n",
      "Epoch 339/1000\n",
      "615/615 [==============================] - 0s 678us/step - loss: 1729.9368 - mae: 19.7196 - mse: 1729.9368 - val_loss: 4291.4033 - val_mae: 28.3846 - val_mse: 4291.4033\n",
      "Epoch 340/1000\n",
      "615/615 [==============================] - 0s 666us/step - loss: 1744.8950 - mae: 19.5407 - mse: 1744.8950 - val_loss: 3958.7339 - val_mae: 27.9998 - val_mse: 3958.7339\n",
      "Epoch 341/1000\n",
      "615/615 [==============================] - 0s 666us/step - loss: 1704.2926 - mae: 19.2866 - mse: 1704.2926 - val_loss: 4010.0908 - val_mae: 27.8138 - val_mse: 4010.0908\n",
      "Epoch 342/1000\n",
      "615/615 [==============================] - 0s 702us/step - loss: 1680.1001 - mae: 19.2554 - mse: 1680.1001 - val_loss: 4159.1987 - val_mae: 29.6497 - val_mse: 4159.1987\n",
      "Epoch 343/1000\n",
      "615/615 [==============================] - 0s 675us/step - loss: 1725.2692 - mae: 19.5795 - mse: 1725.2692 - val_loss: 4217.0928 - val_mae: 28.0677 - val_mse: 4217.0928\n",
      "Epoch 344/1000\n",
      "615/615 [==============================] - 0s 669us/step - loss: 1743.7726 - mae: 19.5547 - mse: 1743.7726 - val_loss: 4009.1484 - val_mae: 27.2902 - val_mse: 4009.1484\n",
      "Epoch 345/1000\n",
      "615/615 [==============================] - 0s 710us/step - loss: 1713.7982 - mae: 19.5039 - mse: 1713.7982 - val_loss: 4038.5015 - val_mae: 27.3822 - val_mse: 4038.5015\n",
      "Epoch 346/1000\n",
      "615/615 [==============================] - 0s 670us/step - loss: 1744.8599 - mae: 19.5422 - mse: 1744.8599 - val_loss: 4087.2026 - val_mae: 30.6322 - val_mse: 4087.2026\n",
      "Epoch 347/1000\n",
      "615/615 [==============================] - 0s 807us/step - loss: 1705.5375 - mae: 19.5816 - mse: 1705.5375 - val_loss: 4087.4468 - val_mae: 30.7137 - val_mse: 4087.4468\n",
      "Epoch 348/1000\n",
      "615/615 [==============================] - 1s 817us/step - loss: 1807.5835 - mae: 19.9530 - mse: 1807.5835 - val_loss: 4081.8682 - val_mae: 29.6766 - val_mse: 4081.8682\n",
      "Epoch 349/1000\n",
      "615/615 [==============================] - 0s 681us/step - loss: 1683.5399 - mae: 19.3126 - mse: 1683.5399 - val_loss: 4067.7065 - val_mae: 28.6347 - val_mse: 4067.7065\n",
      "Epoch 350/1000\n",
      "615/615 [==============================] - 0s 798us/step - loss: 1705.2957 - mae: 19.4894 - mse: 1705.2957 - val_loss: 4076.5879 - val_mae: 27.2441 - val_mse: 4076.5879\n",
      "Epoch 351/1000\n",
      "615/615 [==============================] - 0s 714us/step - loss: 1641.3496 - mae: 19.0532 - mse: 1641.3496 - val_loss: 3941.7092 - val_mae: 27.6171 - val_mse: 3941.7092\n",
      "Epoch 352/1000\n",
      "615/615 [==============================] - 0s 717us/step - loss: 1683.0527 - mae: 19.2883 - mse: 1683.0527 - val_loss: 4117.0757 - val_mae: 28.6209 - val_mse: 4117.0757\n",
      "Epoch 353/1000\n",
      "615/615 [==============================] - 1s 837us/step - loss: 1692.7053 - mae: 19.3106 - mse: 1692.7053 - val_loss: 3948.9143 - val_mae: 27.0616 - val_mse: 3948.9143\n",
      "Epoch 354/1000\n",
      "615/615 [==============================] - 0s 701us/step - loss: 1657.0823 - mae: 19.1312 - mse: 1657.0823 - val_loss: 4063.0483 - val_mae: 27.7803 - val_mse: 4063.0483\n",
      "Epoch 355/1000\n",
      "615/615 [==============================] - 0s 700us/step - loss: 1704.8688 - mae: 19.2509 - mse: 1704.8688 - val_loss: 3978.9636 - val_mae: 27.3895 - val_mse: 3978.9636\n",
      "Epoch 356/1000\n",
      "615/615 [==============================] - 0s 717us/step - loss: 1673.6213 - mae: 19.6070 - mse: 1673.6213 - val_loss: 4276.8052 - val_mae: 29.3980 - val_mse: 4276.8052\n",
      "Epoch 357/1000\n",
      "615/615 [==============================] - 0s 680us/step - loss: 1644.7126 - mae: 18.9946 - mse: 1644.7126 - val_loss: 3903.3801 - val_mae: 26.7924 - val_mse: 3903.3801\n",
      "Epoch 358/1000\n",
      "615/615 [==============================] - 0s 698us/step - loss: 1728.2268 - mae: 19.5777 - mse: 1728.2268 - val_loss: 4103.0688 - val_mae: 29.2461 - val_mse: 4103.0688\n",
      "Epoch 359/1000\n",
      "615/615 [==============================] - 0s 702us/step - loss: 1613.9832 - mae: 19.1511 - mse: 1613.9832 - val_loss: 4315.9067 - val_mae: 28.9830 - val_mse: 4315.9067\n",
      "Epoch 360/1000\n",
      "615/615 [==============================] - 0s 711us/step - loss: 1714.5334 - mae: 19.5236 - mse: 1714.5334 - val_loss: 4313.4810 - val_mae: 28.6549 - val_mse: 4313.4810\n",
      "Epoch 361/1000\n",
      "615/615 [==============================] - 0s 682us/step - loss: 1625.4352 - mae: 19.0641 - mse: 1625.4352 - val_loss: 4163.8711 - val_mae: 28.4198 - val_mse: 4163.8711\n",
      "Epoch 362/1000\n",
      "615/615 [==============================] - 0s 665us/step - loss: 1700.8867 - mae: 19.5988 - mse: 1700.8867 - val_loss: 4505.3950 - val_mae: 30.0669 - val_mse: 4505.3950\n",
      "Epoch 363/1000\n",
      "615/615 [==============================] - 0s 705us/step - loss: 1644.4933 - mae: 19.2044 - mse: 1644.4933 - val_loss: 4161.6885 - val_mae: 28.0401 - val_mse: 4161.6885\n",
      "Epoch 364/1000\n",
      "615/615 [==============================] - 0s 680us/step - loss: 1691.3868 - mae: 19.4608 - mse: 1691.3868 - val_loss: 3944.5015 - val_mae: 27.9683 - val_mse: 3944.5015\n",
      "Epoch 365/1000\n",
      "615/615 [==============================] - 0s 803us/step - loss: 1665.2417 - mae: 19.2148 - mse: 1665.2417 - val_loss: 4528.4438 - val_mae: 29.4339 - val_mse: 4528.4438\n",
      "Epoch 366/1000\n",
      "615/615 [==============================] - 0s 749us/step - loss: 1616.0262 - mae: 18.8992 - mse: 1616.0262 - val_loss: 4056.9685 - val_mae: 27.8821 - val_mse: 4056.9685\n",
      "Epoch 367/1000\n",
      "615/615 [==============================] - 0s 721us/step - loss: 1698.5732 - mae: 19.3406 - mse: 1698.5732 - val_loss: 4027.9736 - val_mae: 28.0208 - val_mse: 4027.9736\n",
      "Epoch 368/1000\n",
      "615/615 [==============================] - 0s 795us/step - loss: 1636.8400 - mae: 19.2124 - mse: 1636.8400 - val_loss: 3963.5620 - val_mae: 27.2362 - val_mse: 3963.5620\n",
      "Epoch 369/1000\n",
      "615/615 [==============================] - 0s 671us/step - loss: 1628.6697 - mae: 19.1234 - mse: 1628.6697 - val_loss: 4044.1958 - val_mae: 27.8466 - val_mse: 4044.1958\n",
      "Epoch 370/1000\n",
      "615/615 [==============================] - 0s 668us/step - loss: 1622.8663 - mae: 19.0266 - mse: 1622.8663 - val_loss: 4194.1792 - val_mae: 28.6922 - val_mse: 4194.1792\n",
      "Epoch 371/1000\n",
      "615/615 [==============================] - 1s 835us/step - loss: 1641.7863 - mae: 19.0155 - mse: 1641.7863 - val_loss: 4092.0012 - val_mae: 27.7056 - val_mse: 4092.0012\n",
      "Epoch 372/1000\n",
      "615/615 [==============================] - 0s 751us/step - loss: 1662.8213 - mae: 19.3519 - mse: 1662.8213 - val_loss: 4389.7969 - val_mae: 28.7620 - val_mse: 4389.7969\n",
      "Epoch 373/1000\n",
      "615/615 [==============================] - 0s 775us/step - loss: 1605.3430 - mae: 19.0193 - mse: 1605.3430 - val_loss: 4178.0146 - val_mae: 27.5109 - val_mse: 4178.0146\n",
      "Epoch 374/1000\n",
      "615/615 [==============================] - 1s 853us/step - loss: 1614.9390 - mae: 18.9692 - mse: 1614.9390 - val_loss: 4026.5161 - val_mae: 27.7284 - val_mse: 4026.5161\n",
      "Epoch 375/1000\n",
      "615/615 [==============================] - 0s 680us/step - loss: 1685.0276 - mae: 19.2688 - mse: 1685.0276 - val_loss: 4010.6936 - val_mae: 27.4985 - val_mse: 4010.6936\n",
      "Epoch 376/1000\n",
      "615/615 [==============================] - 1s 831us/step - loss: 1637.3967 - mae: 19.0087 - mse: 1637.3967 - val_loss: 4287.6309 - val_mae: 29.0148 - val_mse: 4287.6309\n",
      "Epoch 377/1000\n",
      "615/615 [==============================] - 0s 689us/step - loss: 1609.6974 - mae: 18.9149 - mse: 1609.6974 - val_loss: 4008.5662 - val_mae: 29.7760 - val_mse: 4008.5662\n",
      "Epoch 378/1000\n",
      "615/615 [==============================] - 0s 810us/step - loss: 1633.0637 - mae: 19.1306 - mse: 1633.0637 - val_loss: 4096.8159 - val_mae: 27.7009 - val_mse: 4096.8159\n",
      "Epoch 379/1000\n",
      "615/615 [==============================] - 0s 728us/step - loss: 1579.1052 - mae: 18.8464 - mse: 1579.1052 - val_loss: 3901.5151 - val_mae: 27.2293 - val_mse: 3901.5151\n",
      "Epoch 380/1000\n",
      "615/615 [==============================] - 0s 674us/step - loss: 1597.4652 - mae: 19.1254 - mse: 1597.4652 - val_loss: 4042.7168 - val_mae: 27.7859 - val_mse: 4042.7168\n",
      "Epoch 381/1000\n",
      "615/615 [==============================] - 0s 688us/step - loss: 1574.8093 - mae: 18.8575 - mse: 1574.8093 - val_loss: 4064.0098 - val_mae: 27.5136 - val_mse: 4064.0098\n",
      "Epoch 382/1000\n",
      "615/615 [==============================] - 0s 715us/step - loss: 1652.4828 - mae: 19.2282 - mse: 1652.4828 - val_loss: 4030.4287 - val_mae: 28.1945 - val_mse: 4030.4287\n",
      "Epoch 383/1000\n",
      "615/615 [==============================] - 0s 655us/step - loss: 1599.8307 - mae: 18.9302 - mse: 1599.8307 - val_loss: 4139.8315 - val_mae: 27.9301 - val_mse: 4139.8315\n",
      "Epoch 384/1000\n",
      "615/615 [==============================] - 0s 642us/step - loss: 1626.6418 - mae: 18.9418 - mse: 1626.6418 - val_loss: 4008.6562 - val_mae: 27.3853 - val_mse: 4008.6562\n",
      "Epoch 385/1000\n",
      "615/615 [==============================] - 0s 643us/step - loss: 1608.4753 - mae: 19.0685 - mse: 1608.4753 - val_loss: 4127.4136 - val_mae: 28.9145 - val_mse: 4127.4136\n",
      "Epoch 386/1000\n",
      "615/615 [==============================] - 0s 700us/step - loss: 1592.7487 - mae: 18.8039 - mse: 1592.7487 - val_loss: 4220.8149 - val_mae: 28.0926 - val_mse: 4220.8149\n",
      "Epoch 387/1000\n",
      "615/615 [==============================] - 0s 744us/step - loss: 1571.1761 - mae: 18.7524 - mse: 1571.1761 - val_loss: 4080.2124 - val_mae: 27.9640 - val_mse: 4080.2124\n",
      "Epoch 388/1000\n",
      "615/615 [==============================] - 0s 708us/step - loss: 1559.0059 - mae: 18.5897 - mse: 1559.0059 - val_loss: 4149.4199 - val_mae: 28.4978 - val_mse: 4149.4199\n",
      "Epoch 389/1000\n",
      "615/615 [==============================] - 0s 695us/step - loss: 1566.3259 - mae: 18.8042 - mse: 1566.3259 - val_loss: 4051.3079 - val_mae: 29.0036 - val_mse: 4051.3079\n",
      "Epoch 390/1000\n",
      "615/615 [==============================] - 0s 714us/step - loss: 1708.5077 - mae: 19.4333 - mse: 1708.5077 - val_loss: 4011.4065 - val_mae: 28.0173 - val_mse: 4011.4065\n",
      "Epoch 391/1000\n",
      "615/615 [==============================] - 0s 810us/step - loss: 1668.7120 - mae: 19.2695 - mse: 1668.7120 - val_loss: 4493.0732 - val_mae: 28.1061 - val_mse: 4493.0732\n",
      "Epoch 392/1000\n",
      "615/615 [==============================] - 0s 735us/step - loss: 1577.1484 - mae: 18.9953 - mse: 1577.1484 - val_loss: 3965.4548 - val_mae: 28.3470 - val_mse: 3965.4548\n",
      "Epoch 393/1000\n",
      "615/615 [==============================] - 0s 737us/step - loss: 1587.5668 - mae: 19.0349 - mse: 1587.5668 - val_loss: 4094.9778 - val_mae: 28.2149 - val_mse: 4094.9778\n",
      "Epoch 394/1000\n",
      "615/615 [==============================] - 0s 770us/step - loss: 1567.4539 - mae: 18.7156 - mse: 1567.4539 - val_loss: 4193.9785 - val_mae: 28.4488 - val_mse: 4193.9785\n",
      "Epoch 395/1000\n",
      "615/615 [==============================] - 0s 781us/step - loss: 1574.5446 - mae: 18.9453 - mse: 1574.5446 - val_loss: 4123.3862 - val_mae: 27.8993 - val_mse: 4123.3862\n",
      "Epoch 396/1000\n",
      "615/615 [==============================] - 0s 724us/step - loss: 1596.9995 - mae: 19.0543 - mse: 1596.9995 - val_loss: 4243.3184 - val_mae: 27.6936 - val_mse: 4243.3184\n",
      "Epoch 397/1000\n",
      "615/615 [==============================] - 1s 814us/step - loss: 1561.7856 - mae: 18.8181 - mse: 1561.7856 - val_loss: 4272.2563 - val_mae: 28.4336 - val_mse: 4272.2563\n",
      "Epoch 398/1000\n",
      "615/615 [==============================] - 0s 782us/step - loss: 1560.6207 - mae: 18.6984 - mse: 1560.6207 - val_loss: 3914.5430 - val_mae: 27.2505 - val_mse: 3914.5430\n",
      "Epoch 399/1000\n",
      "615/615 [==============================] - 1s 828us/step - loss: 1580.8445 - mae: 18.7841 - mse: 1580.8445 - val_loss: 4125.1274 - val_mae: 27.8673 - val_mse: 4125.1274\n",
      "Epoch 400/1000\n",
      "615/615 [==============================] - 0s 694us/step - loss: 1533.8804 - mae: 18.6195 - mse: 1533.8804 - val_loss: 4060.7380 - val_mae: 27.9300 - val_mse: 4060.7380\n",
      "Epoch 401/1000\n",
      "615/615 [==============================] - 0s 677us/step - loss: 1571.8927 - mae: 18.7362 - mse: 1571.8927 - val_loss: 4378.1592 - val_mae: 28.6738 - val_mse: 4378.1592\n",
      "Epoch 402/1000\n",
      "615/615 [==============================] - 0s 664us/step - loss: 1532.1748 - mae: 18.5395 - mse: 1532.1748 - val_loss: 4094.3359 - val_mae: 27.5334 - val_mse: 4094.3359\n",
      "Epoch 403/1000\n",
      "615/615 [==============================] - 0s 682us/step - loss: 1551.4185 - mae: 18.7877 - mse: 1551.4185 - val_loss: 4042.5190 - val_mae: 27.6187 - val_mse: 4042.5190\n",
      "Epoch 404/1000\n",
      "615/615 [==============================] - 0s 693us/step - loss: 1644.3933 - mae: 19.0705 - mse: 1644.3933 - val_loss: 4066.8997 - val_mae: 27.5680 - val_mse: 4066.8997\n",
      "Epoch 405/1000\n",
      "615/615 [==============================] - 0s 666us/step - loss: 1505.1726 - mae: 18.3114 - mse: 1505.1726 - val_loss: 3920.4648 - val_mae: 27.0954 - val_mse: 3920.4648\n",
      "Epoch 406/1000\n",
      "615/615 [==============================] - 0s 677us/step - loss: 1587.2449 - mae: 18.9176 - mse: 1587.2449 - val_loss: 4244.0156 - val_mae: 29.3981 - val_mse: 4244.0156\n",
      "Epoch 407/1000\n",
      "615/615 [==============================] - 0s 686us/step - loss: 1536.3577 - mae: 18.6762 - mse: 1536.3577 - val_loss: 3996.8174 - val_mae: 29.4135 - val_mse: 3996.8174\n",
      "Epoch 408/1000\n",
      "615/615 [==============================] - 0s 674us/step - loss: 1565.6355 - mae: 18.7737 - mse: 1565.6355 - val_loss: 3935.7720 - val_mae: 27.7685 - val_mse: 3935.7720\n",
      "Epoch 409/1000\n",
      "615/615 [==============================] - 0s 671us/step - loss: 1475.2253 - mae: 18.3266 - mse: 1475.2253 - val_loss: 4089.8237 - val_mae: 27.0649 - val_mse: 4089.8237\n"
     ]
    }
   ],
   "source": [
    "model_b = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.InputLayer(input_shape=54),\n",
    "    #ak.MultiCategoryEncoding(encoding=['int','int','int','int','none','none','none','none','none',\n",
    "    #                                   'none','none','none','none','none','int','int','int','int',\n",
    "    #                                   'int','none','int','none','none','int','int','none','none',\n",
    "    #                                   'int','int','int','int','none','none','int','none','none',\n",
    "    #                                   'none','int','int','int','int','int','int','none','none',\n",
    "    #                                   'int','int','int','int','int','int','int','int']),\n",
    "    normalizer_B, \n",
    "    tf.keras.layers.Dense(32, activation='linear'),\n",
    "    tf.keras.layers.ReLU(),\n",
    "    tf.keras.layers.Dense(32, activation='linear'),\n",
    "    tf.keras.layers.ReLU(),\n",
    "    tf.keras.layers.Dense(256, activation='linear'),\n",
    "    tf.keras.layers.ReLU(),\n",
    "    tf.keras.layers.Dense(1)\n",
    "])\n",
    "\n",
    "model_b.compile(optimizer=tf.keras.optimizers.AdamW(learning_rate=0.001), \n",
    "                loss=\"mse\", \n",
    "                metrics=[\"mae\", \"mse\"])\n",
    "\n",
    "history_b = model_b.fit(x=x_train_b, y=y_train_b, epochs=1000, callbacks=[early_stop], validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "158/158 [==============================] - 0s 438us/step - loss: 80426.7734 - mae: 31.7840 - mse: 80426.7734\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[80426.7734375, 31.78400993347168, 80426.7734375]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_b.evaluate(x_val_b, y_val_b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:Skipping variable loading for optimizer 'Adam', because it has 13 variables whereas the saved optimizer has 1 variables. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 53)]              0         \n",
      "                                                                 \n",
      " multi_category_encoding (M  (None, 53)                0         \n",
      " ultiCategoryEncoding)                                           \n",
      "                                                                 \n",
      " normalization (Normalizati  (None, 53)                107       \n",
      " on)                                                             \n",
      "                                                                 \n",
      " dense (Dense)               (None, 32)                1728      \n",
      "                                                                 \n",
      " re_lu (ReLU)                (None, 32)                0         \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 32)                0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 32)                1056      \n",
      "                                                                 \n",
      " re_lu_1 (ReLU)              (None, 32)                0         \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 32)                0         \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 32)                0         \n",
      "                                                                 \n",
      " regression_head_1 (Dense)   (None, 1)                 33        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2924 (11.43 KB)\n",
      "Trainable params: 2817 (11.00 KB)\n",
      "Non-trainable params: 107 (432.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'name': 'model',\n",
       " 'trainable': True,\n",
       " 'layers': [{'module': 'keras.layers',\n",
       "   'class_name': 'InputLayer',\n",
       "   'config': {'batch_input_shape': (None, 53),\n",
       "    'dtype': 'float32',\n",
       "    'sparse': False,\n",
       "    'ragged': False,\n",
       "    'name': 'input_1'},\n",
       "   'registered_name': None,\n",
       "   'name': 'input_1',\n",
       "   'inbound_nodes': []},\n",
       "  {'module': 'autokeras.keras_layers',\n",
       "   'class_name': 'MultiCategoryEncoding',\n",
       "   'config': {'name': 'multi_category_encoding',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'encoding': ['int',\n",
       "     'int',\n",
       "     'int',\n",
       "     'int',\n",
       "     'none',\n",
       "     'none',\n",
       "     'none',\n",
       "     'none',\n",
       "     'none',\n",
       "     'none',\n",
       "     'none',\n",
       "     'none',\n",
       "     'none',\n",
       "     'none',\n",
       "     'int',\n",
       "     'int',\n",
       "     'int',\n",
       "     'int',\n",
       "     'int',\n",
       "     'none',\n",
       "     'int',\n",
       "     'none',\n",
       "     'none',\n",
       "     'none',\n",
       "     'int',\n",
       "     'none',\n",
       "     'none',\n",
       "     'int',\n",
       "     'int',\n",
       "     'int',\n",
       "     'int',\n",
       "     'none',\n",
       "     'none',\n",
       "     'int',\n",
       "     'none',\n",
       "     'none',\n",
       "     'none',\n",
       "     'int',\n",
       "     'int',\n",
       "     'int',\n",
       "     'int',\n",
       "     'int',\n",
       "     'int',\n",
       "     'none',\n",
       "     'none',\n",
       "     'int',\n",
       "     'int',\n",
       "     'int',\n",
       "     'int',\n",
       "     'int',\n",
       "     'int',\n",
       "     'int',\n",
       "     'int']},\n",
       "   'registered_name': 'Custom>MultiCategoryEncoding',\n",
       "   'build_config': {'input_shape': (None, 53)},\n",
       "   'name': 'multi_category_encoding',\n",
       "   'inbound_nodes': [[['input_1', 0, 0, {}]]]},\n",
       "  {'module': 'keras.layers',\n",
       "   'class_name': 'Normalization',\n",
       "   'config': {'name': 'normalization',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'axis': (-1,),\n",
       "    'invert': False,\n",
       "    'mean': None,\n",
       "    'variance': None},\n",
       "   'registered_name': None,\n",
       "   'build_config': {'input_shape': (None, 53)},\n",
       "   'name': 'normalization',\n",
       "   'inbound_nodes': [[['multi_category_encoding', 0, 0, {}]]]},\n",
       "  {'module': 'keras.layers',\n",
       "   'class_name': 'Dense',\n",
       "   'config': {'name': 'dense',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'units': 32,\n",
       "    'activation': 'linear',\n",
       "    'use_bias': True,\n",
       "    'kernel_initializer': {'module': 'keras.initializers',\n",
       "     'class_name': 'GlorotUniform',\n",
       "     'config': {'seed': None},\n",
       "     'registered_name': None},\n",
       "    'bias_initializer': {'module': 'keras.initializers',\n",
       "     'class_name': 'Zeros',\n",
       "     'config': {},\n",
       "     'registered_name': None},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'registered_name': None,\n",
       "   'build_config': {'input_shape': (None, 53)},\n",
       "   'name': 'dense',\n",
       "   'inbound_nodes': [[['normalization', 0, 0, {}]]]},\n",
       "  {'module': 'keras.layers',\n",
       "   'class_name': 'ReLU',\n",
       "   'config': {'name': 're_lu',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'max_value': None,\n",
       "    'negative_slope': 0.0,\n",
       "    'threshold': 0.0},\n",
       "   'registered_name': None,\n",
       "   'build_config': {'input_shape': (None, 32)},\n",
       "   'name': 're_lu',\n",
       "   'inbound_nodes': [[['dense', 0, 0, {}]]]},\n",
       "  {'module': 'keras.layers',\n",
       "   'class_name': 'Dropout',\n",
       "   'config': {'name': 'dropout',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'rate': 0.25,\n",
       "    'noise_shape': None,\n",
       "    'seed': None},\n",
       "   'registered_name': None,\n",
       "   'build_config': {'input_shape': (None, 32)},\n",
       "   'name': 'dropout',\n",
       "   'inbound_nodes': [[['re_lu', 0, 0, {}]]]},\n",
       "  {'module': 'keras.layers',\n",
       "   'class_name': 'Dense',\n",
       "   'config': {'name': 'dense_1',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'units': 32,\n",
       "    'activation': 'linear',\n",
       "    'use_bias': True,\n",
       "    'kernel_initializer': {'module': 'keras.initializers',\n",
       "     'class_name': 'GlorotUniform',\n",
       "     'config': {'seed': None},\n",
       "     'registered_name': None},\n",
       "    'bias_initializer': {'module': 'keras.initializers',\n",
       "     'class_name': 'Zeros',\n",
       "     'config': {},\n",
       "     'registered_name': None},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'registered_name': None,\n",
       "   'build_config': {'input_shape': (None, 32)},\n",
       "   'name': 'dense_1',\n",
       "   'inbound_nodes': [[['dropout', 0, 0, {}]]]},\n",
       "  {'module': 'keras.layers',\n",
       "   'class_name': 'ReLU',\n",
       "   'config': {'name': 're_lu_1',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'max_value': None,\n",
       "    'negative_slope': 0.0,\n",
       "    'threshold': 0.0},\n",
       "   'registered_name': None,\n",
       "   'build_config': {'input_shape': (None, 32)},\n",
       "   'name': 're_lu_1',\n",
       "   'inbound_nodes': [[['dense_1', 0, 0, {}]]]},\n",
       "  {'module': 'keras.layers',\n",
       "   'class_name': 'Dropout',\n",
       "   'config': {'name': 'dropout_1',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'rate': 0.25,\n",
       "    'noise_shape': None,\n",
       "    'seed': None},\n",
       "   'registered_name': None,\n",
       "   'build_config': {'input_shape': (None, 32)},\n",
       "   'name': 'dropout_1',\n",
       "   'inbound_nodes': [[['re_lu_1', 0, 0, {}]]]},\n",
       "  {'module': 'keras.layers',\n",
       "   'class_name': 'Dropout',\n",
       "   'config': {'name': 'dropout_2',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'rate': 0.25,\n",
       "    'noise_shape': None,\n",
       "    'seed': None},\n",
       "   'registered_name': None,\n",
       "   'build_config': {'input_shape': (None, 32)},\n",
       "   'name': 'dropout_2',\n",
       "   'inbound_nodes': [[['dropout_1', 0, 0, {}]]]},\n",
       "  {'module': 'keras.layers',\n",
       "   'class_name': 'Dense',\n",
       "   'config': {'name': 'regression_head_1',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'units': 1,\n",
       "    'activation': 'linear',\n",
       "    'use_bias': True,\n",
       "    'kernel_initializer': {'module': 'keras.initializers',\n",
       "     'class_name': 'GlorotUniform',\n",
       "     'config': {'seed': None},\n",
       "     'registered_name': None},\n",
       "    'bias_initializer': {'module': 'keras.initializers',\n",
       "     'class_name': 'Zeros',\n",
       "     'config': {},\n",
       "     'registered_name': None},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'registered_name': None,\n",
       "   'build_config': {'input_shape': (None, 32)},\n",
       "   'name': 'regression_head_1',\n",
       "   'inbound_nodes': [[['dropout_2', 0, 0, {}]]]}],\n",
       " 'input_layers': [['input_1', 0, 0]],\n",
       " 'output_layers': [['regression_head_1', 0, 0]]}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c = tf.keras.models.load_model(\"./tensorflow_models/best_c_01_11.keras\")\n",
    "c.summary()\n",
    "c.get_config()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.RMSprop` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.RMSprop`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "541/541 [==============================] - 1s 783us/step - loss: 53.5021 - mae: 53.5021 - mse: 17938.8262 - accuracy: 0.4644 - val_loss: 28.2628 - val_mae: 28.2628 - val_mse: 4447.3589 - val_accuracy: 0.5707\n",
      "Epoch 2/1000\n",
      "541/541 [==============================] - 0s 630us/step - loss: 32.1141 - mae: 32.1141 - mse: 5978.6694 - accuracy: 0.5685 - val_loss: 26.0969 - val_mae: 26.0969 - val_mse: 3887.9514 - val_accuracy: 0.5862\n",
      "Epoch 3/1000\n",
      "541/541 [==============================] - 0s 676us/step - loss: 30.7472 - mae: 30.7472 - mse: 5661.0063 - accuracy: 0.5700 - val_loss: 25.3670 - val_mae: 25.3670 - val_mse: 3710.9844 - val_accuracy: 0.5816\n",
      "Epoch 4/1000\n",
      "541/541 [==============================] - 0s 593us/step - loss: 30.1166 - mae: 30.1166 - mse: 5368.5405 - accuracy: 0.5665 - val_loss: 23.9237 - val_mae: 23.9237 - val_mse: 3349.1174 - val_accuracy: 0.5848\n",
      "Epoch 5/1000\n",
      "541/541 [==============================] - 0s 595us/step - loss: 29.4620 - mae: 29.4620 - mse: 5244.2485 - accuracy: 0.5652 - val_loss: 23.8790 - val_mae: 23.8790 - val_mse: 3364.5754 - val_accuracy: 0.5857\n",
      "Epoch 6/1000\n",
      "541/541 [==============================] - 0s 591us/step - loss: 29.4801 - mae: 29.4801 - mse: 5167.0298 - accuracy: 0.5635 - val_loss: 23.4176 - val_mae: 23.4176 - val_mse: 3257.9194 - val_accuracy: 0.5846\n",
      "Epoch 7/1000\n",
      "541/541 [==============================] - 0s 626us/step - loss: 29.3080 - mae: 29.3080 - mse: 5220.0078 - accuracy: 0.5636 - val_loss: 23.4392 - val_mae: 23.4392 - val_mse: 3291.5063 - val_accuracy: 0.5844\n",
      "Epoch 8/1000\n",
      "541/541 [==============================] - 0s 596us/step - loss: 28.4257 - mae: 28.4257 - mse: 4999.9800 - accuracy: 0.5636 - val_loss: 22.7800 - val_mae: 22.7800 - val_mse: 3157.9863 - val_accuracy: 0.5864\n",
      "Epoch 9/1000\n",
      "541/541 [==============================] - 0s 595us/step - loss: 28.8143 - mae: 28.8143 - mse: 5075.3496 - accuracy: 0.5656 - val_loss: 22.5309 - val_mae: 22.5309 - val_mse: 3133.4287 - val_accuracy: 0.5857\n",
      "Epoch 10/1000\n",
      "541/541 [==============================] - 0s 592us/step - loss: 28.0496 - mae: 28.0496 - mse: 4850.9023 - accuracy: 0.5658 - val_loss: 22.6786 - val_mae: 22.6786 - val_mse: 3138.0605 - val_accuracy: 0.5850\n",
      "Epoch 11/1000\n",
      "541/541 [==============================] - 0s 598us/step - loss: 28.5367 - mae: 28.5367 - mse: 4968.0181 - accuracy: 0.5668 - val_loss: 22.7136 - val_mae: 22.7136 - val_mse: 3133.4636 - val_accuracy: 0.5885\n",
      "Epoch 12/1000\n",
      "541/541 [==============================] - 0s 593us/step - loss: 28.5190 - mae: 28.5190 - mse: 4918.2886 - accuracy: 0.5680 - val_loss: 22.3903 - val_mae: 22.3903 - val_mse: 3106.6865 - val_accuracy: 0.5890\n",
      "Epoch 13/1000\n",
      "541/541 [==============================] - 0s 598us/step - loss: 28.3690 - mae: 28.3690 - mse: 4976.6680 - accuracy: 0.5679 - val_loss: 22.2524 - val_mae: 22.2524 - val_mse: 3074.8496 - val_accuracy: 0.5892\n",
      "Epoch 14/1000\n",
      "541/541 [==============================] - 0s 589us/step - loss: 27.7168 - mae: 27.7168 - mse: 4707.7822 - accuracy: 0.5708 - val_loss: 22.5203 - val_mae: 22.5203 - val_mse: 3081.8950 - val_accuracy: 0.5897\n",
      "Epoch 15/1000\n",
      "541/541 [==============================] - 0s 600us/step - loss: 27.8095 - mae: 27.8095 - mse: 4777.8081 - accuracy: 0.5692 - val_loss: 22.4635 - val_mae: 22.4635 - val_mse: 3063.0232 - val_accuracy: 0.5901\n",
      "Epoch 16/1000\n",
      "541/541 [==============================] - 0s 618us/step - loss: 28.4624 - mae: 28.4624 - mse: 4933.6919 - accuracy: 0.5693 - val_loss: 22.2518 - val_mae: 22.2518 - val_mse: 3034.3521 - val_accuracy: 0.5901\n",
      "Epoch 17/1000\n",
      "541/541 [==============================] - 0s 596us/step - loss: 27.8609 - mae: 27.8609 - mse: 4760.8804 - accuracy: 0.5694 - val_loss: 22.0360 - val_mae: 22.0360 - val_mse: 2999.0139 - val_accuracy: 0.5890\n",
      "Epoch 18/1000\n",
      "541/541 [==============================] - 0s 596us/step - loss: 27.9858 - mae: 27.9858 - mse: 4860.4585 - accuracy: 0.5668 - val_loss: 22.1060 - val_mae: 22.1060 - val_mse: 2998.6399 - val_accuracy: 0.5922\n",
      "Epoch 19/1000\n",
      "541/541 [==============================] - 0s 596us/step - loss: 27.9126 - mae: 27.9126 - mse: 4811.2388 - accuracy: 0.5689 - val_loss: 21.9486 - val_mae: 21.9486 - val_mse: 2987.0063 - val_accuracy: 0.5915\n",
      "Epoch 20/1000\n",
      "541/541 [==============================] - 0s 591us/step - loss: 28.1074 - mae: 28.1074 - mse: 4868.4604 - accuracy: 0.5688 - val_loss: 21.8554 - val_mae: 21.8554 - val_mse: 2959.9314 - val_accuracy: 0.5892\n",
      "Epoch 21/1000\n",
      "541/541 [==============================] - 0s 596us/step - loss: 27.8205 - mae: 27.8205 - mse: 4768.7095 - accuracy: 0.5698 - val_loss: 22.5574 - val_mae: 22.5574 - val_mse: 3055.8655 - val_accuracy: 0.5904\n",
      "Epoch 22/1000\n",
      "541/541 [==============================] - 0s 588us/step - loss: 27.8325 - mae: 27.8325 - mse: 4815.7134 - accuracy: 0.5673 - val_loss: 22.4179 - val_mae: 22.4179 - val_mse: 3033.4075 - val_accuracy: 0.5915\n",
      "Epoch 23/1000\n",
      "541/541 [==============================] - 0s 593us/step - loss: 27.5647 - mae: 27.5647 - mse: 4727.4321 - accuracy: 0.5672 - val_loss: 21.5841 - val_mae: 21.5841 - val_mse: 2925.9636 - val_accuracy: 0.5906\n",
      "Epoch 24/1000\n",
      "541/541 [==============================] - 0s 590us/step - loss: 27.8212 - mae: 27.8212 - mse: 4787.0244 - accuracy: 0.5678 - val_loss: 23.6972 - val_mae: 23.6972 - val_mse: 3338.5190 - val_accuracy: 0.5904\n",
      "Epoch 25/1000\n",
      "541/541 [==============================] - 0s 620us/step - loss: 27.6442 - mae: 27.6442 - mse: 4887.9316 - accuracy: 0.5687 - val_loss: 21.7850 - val_mae: 21.7850 - val_mse: 2932.2327 - val_accuracy: 0.5911\n",
      "Epoch 26/1000\n",
      "541/541 [==============================] - 0s 593us/step - loss: 27.3730 - mae: 27.3730 - mse: 4658.4531 - accuracy: 0.5689 - val_loss: 21.6808 - val_mae: 21.6808 - val_mse: 2901.9778 - val_accuracy: 0.5911\n",
      "Epoch 27/1000\n",
      "541/541 [==============================] - 0s 589us/step - loss: 27.4227 - mae: 27.4227 - mse: 4627.1719 - accuracy: 0.5692 - val_loss: 21.5880 - val_mae: 21.5880 - val_mse: 2889.3130 - val_accuracy: 0.5915\n",
      "Epoch 28/1000\n",
      "541/541 [==============================] - 0s 606us/step - loss: 27.5744 - mae: 27.5744 - mse: 4751.8359 - accuracy: 0.5683 - val_loss: 22.0510 - val_mae: 22.0510 - val_mse: 2978.2710 - val_accuracy: 0.5927\n",
      "Epoch 29/1000\n",
      "541/541 [==============================] - 0s 591us/step - loss: 27.0317 - mae: 27.0317 - mse: 4658.4263 - accuracy: 0.5702 - val_loss: 21.5130 - val_mae: 21.5130 - val_mse: 2886.6782 - val_accuracy: 0.5929\n",
      "Epoch 30/1000\n",
      "541/541 [==============================] - 0s 591us/step - loss: 27.4980 - mae: 27.4980 - mse: 4682.5522 - accuracy: 0.5709 - val_loss: 21.4870 - val_mae: 21.4870 - val_mse: 2880.6145 - val_accuracy: 0.5906\n",
      "Epoch 31/1000\n",
      "541/541 [==============================] - 0s 589us/step - loss: 27.0826 - mae: 27.0826 - mse: 4635.9023 - accuracy: 0.5700 - val_loss: 21.5188 - val_mae: 21.5188 - val_mse: 2884.8467 - val_accuracy: 0.5922\n",
      "Epoch 32/1000\n",
      "541/541 [==============================] - 0s 593us/step - loss: 27.3786 - mae: 27.3786 - mse: 4699.4595 - accuracy: 0.5696 - val_loss: 22.2183 - val_mae: 22.2183 - val_mse: 2998.9937 - val_accuracy: 0.5920\n",
      "Epoch 33/1000\n",
      "541/541 [==============================] - 0s 593us/step - loss: 27.1675 - mae: 27.1675 - mse: 4607.6206 - accuracy: 0.5715 - val_loss: 21.3081 - val_mae: 21.3081 - val_mse: 2833.2864 - val_accuracy: 0.5918\n",
      "Epoch 34/1000\n",
      "541/541 [==============================] - 0s 622us/step - loss: 27.4372 - mae: 27.4372 - mse: 4663.3110 - accuracy: 0.5734 - val_loss: 21.3312 - val_mae: 21.3312 - val_mse: 2849.3301 - val_accuracy: 0.5941\n",
      "Epoch 35/1000\n",
      "541/541 [==============================] - 0s 584us/step - loss: 27.3513 - mae: 27.3513 - mse: 4647.2251 - accuracy: 0.5736 - val_loss: 21.1997 - val_mae: 21.1997 - val_mse: 2850.1597 - val_accuracy: 0.5945\n",
      "Epoch 36/1000\n",
      "541/541 [==============================] - 0s 586us/step - loss: 27.5483 - mae: 27.5483 - mse: 4906.7690 - accuracy: 0.5713 - val_loss: 21.2947 - val_mae: 21.2947 - val_mse: 2835.0867 - val_accuracy: 0.5934\n",
      "Epoch 37/1000\n",
      "541/541 [==============================] - 0s 596us/step - loss: 27.1878 - mae: 27.1878 - mse: 4538.2759 - accuracy: 0.5719 - val_loss: 21.8664 - val_mae: 21.8664 - val_mse: 2966.7327 - val_accuracy: 0.5955\n",
      "Epoch 38/1000\n",
      "541/541 [==============================] - 0s 584us/step - loss: 27.4721 - mae: 27.4721 - mse: 4738.4932 - accuracy: 0.5730 - val_loss: 21.2552 - val_mae: 21.2552 - val_mse: 2840.2163 - val_accuracy: 0.5931\n",
      "Epoch 39/1000\n",
      "541/541 [==============================] - 0s 587us/step - loss: 26.6356 - mae: 26.6356 - mse: 4490.7334 - accuracy: 0.5728 - val_loss: 21.5637 - val_mae: 21.5637 - val_mse: 2860.7405 - val_accuracy: 0.5925\n",
      "Epoch 40/1000\n",
      "541/541 [==============================] - 0s 590us/step - loss: 27.4370 - mae: 27.4370 - mse: 5046.1016 - accuracy: 0.5719 - val_loss: 21.3025 - val_mae: 21.3025 - val_mse: 2845.3477 - val_accuracy: 0.5922\n",
      "Epoch 41/1000\n",
      "541/541 [==============================] - 0s 587us/step - loss: 26.8024 - mae: 26.8024 - mse: 4461.0586 - accuracy: 0.5725 - val_loss: 21.5016 - val_mae: 21.5016 - val_mse: 2877.8730 - val_accuracy: 0.5922\n",
      "Epoch 42/1000\n",
      "541/541 [==============================] - 0s 630us/step - loss: 26.6089 - mae: 26.6089 - mse: 4421.1172 - accuracy: 0.5737 - val_loss: 21.7330 - val_mae: 21.7330 - val_mse: 2894.8906 - val_accuracy: 0.5955\n",
      "Epoch 43/1000\n",
      "541/541 [==============================] - 0s 587us/step - loss: 26.8163 - mae: 26.8163 - mse: 4538.9263 - accuracy: 0.5734 - val_loss: 21.5652 - val_mae: 21.5652 - val_mse: 2859.0454 - val_accuracy: 0.5948\n",
      "Epoch 44/1000\n",
      "541/541 [==============================] - 0s 585us/step - loss: 26.6990 - mae: 26.6990 - mse: 4522.5527 - accuracy: 0.5736 - val_loss: 21.3744 - val_mae: 21.3744 - val_mse: 2834.4795 - val_accuracy: 0.5934\n",
      "Epoch 45/1000\n",
      "541/541 [==============================] - 0s 590us/step - loss: 27.6287 - mae: 27.6287 - mse: 5038.8281 - accuracy: 0.5727 - val_loss: 21.2667 - val_mae: 21.2667 - val_mse: 2825.4741 - val_accuracy: 0.5945\n",
      "Epoch 46/1000\n",
      "541/541 [==============================] - 0s 589us/step - loss: 26.7725 - mae: 26.7725 - mse: 4471.9521 - accuracy: 0.5738 - val_loss: 20.9734 - val_mae: 20.9734 - val_mse: 2802.7964 - val_accuracy: 0.5925\n",
      "Epoch 47/1000\n",
      "541/541 [==============================] - 0s 589us/step - loss: 27.2817 - mae: 27.2817 - mse: 5132.2095 - accuracy: 0.5755 - val_loss: 22.2648 - val_mae: 22.2648 - val_mse: 2988.8145 - val_accuracy: 0.5943\n",
      "Epoch 48/1000\n",
      "541/541 [==============================] - 0s 588us/step - loss: 26.8964 - mae: 26.8964 - mse: 4560.2905 - accuracy: 0.5746 - val_loss: 21.5695 - val_mae: 21.5695 - val_mse: 2869.9795 - val_accuracy: 0.5957\n",
      "Epoch 49/1000\n",
      "541/541 [==============================] - 0s 583us/step - loss: 27.3657 - mae: 27.3657 - mse: 5086.0562 - accuracy: 0.5748 - val_loss: 20.9759 - val_mae: 20.9759 - val_mse: 2789.0769 - val_accuracy: 0.5934\n",
      "Epoch 50/1000\n",
      "541/541 [==============================] - 0s 619us/step - loss: 27.1223 - mae: 27.1223 - mse: 4650.1694 - accuracy: 0.5744 - val_loss: 21.1644 - val_mae: 21.1644 - val_mse: 2804.0481 - val_accuracy: 0.5941\n",
      "Epoch 51/1000\n",
      "541/541 [==============================] - 0s 587us/step - loss: 26.8591 - mae: 26.8591 - mse: 4573.8525 - accuracy: 0.5741 - val_loss: 21.3409 - val_mae: 21.3409 - val_mse: 2822.2979 - val_accuracy: 0.5955\n",
      "Epoch 52/1000\n",
      "541/541 [==============================] - 0s 584us/step - loss: 26.6486 - mae: 26.6486 - mse: 4414.9302 - accuracy: 0.5754 - val_loss: 21.3812 - val_mae: 21.3812 - val_mse: 2834.2397 - val_accuracy: 0.5955\n",
      "Epoch 53/1000\n",
      "541/541 [==============================] - 0s 586us/step - loss: 27.1316 - mae: 27.1316 - mse: 4899.5410 - accuracy: 0.5754 - val_loss: 20.8866 - val_mae: 20.8866 - val_mse: 2777.3552 - val_accuracy: 0.5943\n",
      "Epoch 54/1000\n",
      "541/541 [==============================] - 0s 610us/step - loss: 26.8653 - mae: 26.8653 - mse: 4534.1670 - accuracy: 0.5756 - val_loss: 21.3758 - val_mae: 21.3758 - val_mse: 2825.2002 - val_accuracy: 0.5950\n",
      "Epoch 55/1000\n",
      "541/541 [==============================] - 0s 616us/step - loss: 26.8527 - mae: 26.8527 - mse: 4595.6445 - accuracy: 0.5753 - val_loss: 21.2132 - val_mae: 21.2132 - val_mse: 2774.7544 - val_accuracy: 0.5955\n",
      "Epoch 56/1000\n",
      "541/541 [==============================] - 0s 585us/step - loss: 26.5210 - mae: 26.5210 - mse: 4739.6353 - accuracy: 0.5761 - val_loss: 21.0100 - val_mae: 21.0100 - val_mse: 2748.9187 - val_accuracy: 0.5964\n",
      "Epoch 57/1000\n",
      "541/541 [==============================] - 0s 615us/step - loss: 27.0277 - mae: 27.0277 - mse: 4648.6611 - accuracy: 0.5771 - val_loss: 21.4503 - val_mae: 21.4503 - val_mse: 2820.1226 - val_accuracy: 0.5964\n",
      "Epoch 58/1000\n",
      "541/541 [==============================] - 0s 586us/step - loss: 27.1135 - mae: 27.1135 - mse: 5138.6152 - accuracy: 0.5782 - val_loss: 21.4560 - val_mae: 21.4560 - val_mse: 2836.2412 - val_accuracy: 0.5964\n",
      "Epoch 59/1000\n",
      "541/541 [==============================] - 0s 587us/step - loss: 26.3030 - mae: 26.3030 - mse: 4350.1089 - accuracy: 0.5753 - val_loss: 20.8297 - val_mae: 20.8297 - val_mse: 2772.2659 - val_accuracy: 0.5943\n",
      "Epoch 60/1000\n",
      "541/541 [==============================] - 0s 577us/step - loss: 26.6298 - mae: 26.6298 - mse: 4471.2319 - accuracy: 0.5779 - val_loss: 21.6959 - val_mae: 21.6959 - val_mse: 2865.3928 - val_accuracy: 0.5934\n",
      "Epoch 61/1000\n",
      "541/541 [==============================] - 0s 583us/step - loss: 26.7223 - mae: 26.7223 - mse: 4796.3184 - accuracy: 0.5767 - val_loss: 20.7661 - val_mae: 20.7661 - val_mse: 2722.0322 - val_accuracy: 0.5938\n",
      "Epoch 62/1000\n",
      "541/541 [==============================] - 0s 591us/step - loss: 26.9503 - mae: 26.9503 - mse: 5340.3330 - accuracy: 0.5753 - val_loss: 20.7554 - val_mae: 20.7554 - val_mse: 2725.0745 - val_accuracy: 0.5945\n",
      "Epoch 63/1000\n",
      "541/541 [==============================] - 0s 590us/step - loss: 27.0100 - mae: 27.0100 - mse: 4678.9595 - accuracy: 0.5748 - val_loss: 20.6995 - val_mae: 20.6995 - val_mse: 2728.4871 - val_accuracy: 0.5931\n",
      "Epoch 64/1000\n",
      "541/541 [==============================] - 0s 620us/step - loss: 26.4290 - mae: 26.4290 - mse: 5138.1006 - accuracy: 0.5757 - val_loss: 21.1133 - val_mae: 21.1133 - val_mse: 2761.2314 - val_accuracy: 0.5941\n",
      "Epoch 65/1000\n",
      "541/541 [==============================] - 0s 587us/step - loss: 26.4412 - mae: 26.4412 - mse: 4372.1978 - accuracy: 0.5756 - val_loss: 20.7705 - val_mae: 20.7705 - val_mse: 2740.4221 - val_accuracy: 0.5936\n",
      "Epoch 66/1000\n",
      "541/541 [==============================] - 0s 584us/step - loss: 26.4627 - mae: 26.4627 - mse: 4482.2793 - accuracy: 0.5757 - val_loss: 21.1383 - val_mae: 21.1383 - val_mse: 2772.6465 - val_accuracy: 0.5955\n",
      "Epoch 67/1000\n",
      "541/541 [==============================] - 0s 589us/step - loss: 26.1781 - mae: 26.1781 - mse: 4389.4316 - accuracy: 0.5768 - val_loss: 20.8186 - val_mae: 20.8186 - val_mse: 2737.0059 - val_accuracy: 0.5925\n",
      "Epoch 68/1000\n",
      "541/541 [==============================] - 0s 593us/step - loss: 26.2367 - mae: 26.2367 - mse: 4378.3887 - accuracy: 0.5771 - val_loss: 20.9141 - val_mae: 20.9141 - val_mse: 2739.5188 - val_accuracy: 0.5945\n",
      "Epoch 69/1000\n",
      "541/541 [==============================] - 0s 582us/step - loss: 26.5485 - mae: 26.5485 - mse: 4565.9424 - accuracy: 0.5753 - val_loss: 21.1426 - val_mae: 21.1426 - val_mse: 2754.3745 - val_accuracy: 0.5945\n",
      "Epoch 70/1000\n",
      "541/541 [==============================] - 0s 584us/step - loss: 26.2924 - mae: 26.2924 - mse: 4377.6353 - accuracy: 0.5769 - val_loss: 21.3287 - val_mae: 21.3287 - val_mse: 2807.6218 - val_accuracy: 0.5938\n",
      "Epoch 71/1000\n",
      "541/541 [==============================] - 0s 591us/step - loss: 26.7058 - mae: 26.7058 - mse: 4576.3784 - accuracy: 0.5774 - val_loss: 20.7833 - val_mae: 20.7833 - val_mse: 2710.0842 - val_accuracy: 0.5952\n",
      "Epoch 72/1000\n",
      "541/541 [==============================] - 0s 609us/step - loss: 26.8922 - mae: 26.8922 - mse: 4656.2432 - accuracy: 0.5785 - val_loss: 21.3262 - val_mae: 21.3262 - val_mse: 2803.8516 - val_accuracy: 0.5957\n",
      "Epoch 73/1000\n",
      "541/541 [==============================] - 0s 598us/step - loss: 26.5817 - mae: 26.5817 - mse: 4441.2573 - accuracy: 0.5768 - val_loss: 21.9530 - val_mae: 21.9530 - val_mse: 2919.8586 - val_accuracy: 0.5955\n",
      "Epoch 74/1000\n",
      "541/541 [==============================] - 0s 590us/step - loss: 26.3227 - mae: 26.3227 - mse: 4379.7842 - accuracy: 0.5761 - val_loss: 21.0758 - val_mae: 21.0758 - val_mse: 2770.8760 - val_accuracy: 0.5941\n",
      "Epoch 75/1000\n",
      "541/541 [==============================] - 0s 583us/step - loss: 26.2689 - mae: 26.2689 - mse: 4450.5088 - accuracy: 0.5769 - val_loss: 20.9526 - val_mae: 20.9526 - val_mse: 2737.9653 - val_accuracy: 0.5950\n",
      "Epoch 76/1000\n",
      "541/541 [==============================] - 0s 586us/step - loss: 26.2978 - mae: 26.2978 - mse: 4385.9971 - accuracy: 0.5768 - val_loss: 20.5399 - val_mae: 20.5399 - val_mse: 2712.5283 - val_accuracy: 0.5950\n",
      "Epoch 77/1000\n",
      "541/541 [==============================] - 0s 586us/step - loss: 26.1521 - mae: 26.1521 - mse: 4349.7002 - accuracy: 0.5775 - val_loss: 21.1076 - val_mae: 21.1076 - val_mse: 2763.0457 - val_accuracy: 0.5945\n",
      "Epoch 78/1000\n",
      "541/541 [==============================] - 0s 582us/step - loss: 26.7703 - mae: 26.7703 - mse: 4578.0830 - accuracy: 0.5785 - val_loss: 21.3005 - val_mae: 21.3005 - val_mse: 2817.7900 - val_accuracy: 0.5952\n",
      "Epoch 79/1000\n",
      "541/541 [==============================] - 0s 618us/step - loss: 26.6174 - mae: 26.6174 - mse: 4590.4829 - accuracy: 0.5789 - val_loss: 21.2573 - val_mae: 21.2573 - val_mse: 2767.9614 - val_accuracy: 0.5948\n",
      "Epoch 80/1000\n",
      "541/541 [==============================] - 0s 586us/step - loss: 26.4019 - mae: 26.4019 - mse: 5108.1333 - accuracy: 0.5795 - val_loss: 21.0771 - val_mae: 21.0771 - val_mse: 2741.5623 - val_accuracy: 0.5957\n",
      "Epoch 81/1000\n",
      "541/541 [==============================] - 0s 604us/step - loss: 26.2662 - mae: 26.2662 - mse: 4440.5073 - accuracy: 0.5785 - val_loss: 21.3890 - val_mae: 21.3890 - val_mse: 2804.4587 - val_accuracy: 0.5945\n",
      "Epoch 82/1000\n",
      "541/541 [==============================] - 0s 589us/step - loss: 26.1928 - mae: 26.1928 - mse: 4304.5962 - accuracy: 0.5769 - val_loss: 20.4579 - val_mae: 20.4579 - val_mse: 2680.1992 - val_accuracy: 0.5931\n",
      "Epoch 83/1000\n",
      "541/541 [==============================] - 0s 596us/step - loss: 26.2682 - mae: 26.2682 - mse: 4439.1699 - accuracy: 0.5777 - val_loss: 20.6936 - val_mae: 20.6936 - val_mse: 2686.4661 - val_accuracy: 0.5950\n",
      "Epoch 84/1000\n",
      "541/541 [==============================] - 0s 584us/step - loss: 26.2861 - mae: 26.2861 - mse: 4319.9326 - accuracy: 0.5784 - val_loss: 20.6192 - val_mae: 20.6192 - val_mse: 2675.1631 - val_accuracy: 0.5945\n",
      "Epoch 85/1000\n",
      "541/541 [==============================] - 0s 580us/step - loss: 26.2771 - mae: 26.2771 - mse: 4439.6865 - accuracy: 0.5779 - val_loss: 21.0757 - val_mae: 21.0757 - val_mse: 2729.7649 - val_accuracy: 0.5962\n",
      "Epoch 86/1000\n",
      "541/541 [==============================] - 0s 613us/step - loss: 26.4221 - mae: 26.4221 - mse: 4488.4229 - accuracy: 0.5789 - val_loss: 21.1621 - val_mae: 21.1621 - val_mse: 2776.8489 - val_accuracy: 0.5955\n",
      "Epoch 87/1000\n",
      "541/541 [==============================] - 0s 599us/step - loss: 26.4849 - mae: 26.4849 - mse: 5010.0312 - accuracy: 0.5792 - val_loss: 20.8255 - val_mae: 20.8255 - val_mse: 2702.4431 - val_accuracy: 0.5943\n",
      "Epoch 88/1000\n",
      "541/541 [==============================] - 0s 584us/step - loss: 26.7012 - mae: 26.7012 - mse: 5616.1426 - accuracy: 0.5785 - val_loss: 20.7839 - val_mae: 20.7839 - val_mse: 2690.6968 - val_accuracy: 0.5959\n",
      "Epoch 89/1000\n",
      "541/541 [==============================] - 0s 587us/step - loss: 26.0883 - mae: 26.0883 - mse: 4366.2397 - accuracy: 0.5810 - val_loss: 20.9092 - val_mae: 20.9092 - val_mse: 2704.8740 - val_accuracy: 0.5959\n",
      "Epoch 90/1000\n",
      "541/541 [==============================] - 0s 586us/step - loss: 26.6842 - mae: 26.6842 - mse: 4919.7861 - accuracy: 0.5793 - val_loss: 20.5364 - val_mae: 20.5364 - val_mse: 2656.3835 - val_accuracy: 0.5955\n",
      "Epoch 91/1000\n",
      "541/541 [==============================] - 0s 595us/step - loss: 26.2993 - mae: 26.2993 - mse: 4327.5757 - accuracy: 0.5790 - val_loss: 20.7312 - val_mae: 20.7312 - val_mse: 2681.3145 - val_accuracy: 0.5957\n",
      "Epoch 92/1000\n",
      "541/541 [==============================] - 0s 583us/step - loss: 25.9047 - mae: 25.9047 - mse: 4247.2407 - accuracy: 0.5797 - val_loss: 21.1482 - val_mae: 21.1482 - val_mse: 2748.0205 - val_accuracy: 0.5971\n",
      "Epoch 93/1000\n",
      "541/541 [==============================] - 0s 628us/step - loss: 26.5844 - mae: 26.5844 - mse: 6295.5718 - accuracy: 0.5803 - val_loss: 20.9476 - val_mae: 20.9476 - val_mse: 2734.0510 - val_accuracy: 0.5964\n",
      "Epoch 94/1000\n",
      "541/541 [==============================] - 0s 603us/step - loss: 25.9704 - mae: 25.9704 - mse: 4325.0903 - accuracy: 0.5810 - val_loss: 20.4825 - val_mae: 20.4825 - val_mse: 2670.1013 - val_accuracy: 0.5971\n",
      "Epoch 95/1000\n",
      "541/541 [==============================] - 0s 592us/step - loss: 26.0749 - mae: 26.0749 - mse: 4352.6772 - accuracy: 0.5809 - val_loss: 21.3599 - val_mae: 21.3599 - val_mse: 2792.0664 - val_accuracy: 0.5964\n",
      "Epoch 96/1000\n",
      "541/541 [==============================] - 0s 583us/step - loss: 26.3165 - mae: 26.3165 - mse: 5148.5117 - accuracy: 0.5801 - val_loss: 21.2226 - val_mae: 21.2226 - val_mse: 2778.0791 - val_accuracy: 0.5969\n",
      "Epoch 97/1000\n",
      "541/541 [==============================] - 0s 585us/step - loss: 26.3132 - mae: 26.3132 - mse: 4322.9331 - accuracy: 0.5815 - val_loss: 20.3845 - val_mae: 20.3845 - val_mse: 2683.3909 - val_accuracy: 0.5966\n",
      "Epoch 98/1000\n",
      "541/541 [==============================] - 0s 586us/step - loss: 26.3764 - mae: 26.3764 - mse: 5151.2681 - accuracy: 0.5812 - val_loss: 20.6129 - val_mae: 20.6129 - val_mse: 2689.2576 - val_accuracy: 0.5964\n",
      "Epoch 99/1000\n",
      "541/541 [==============================] - 0s 586us/step - loss: 26.2096 - mae: 26.2096 - mse: 4481.9741 - accuracy: 0.5799 - val_loss: 20.4201 - val_mae: 20.4201 - val_mse: 2670.3840 - val_accuracy: 0.5957\n",
      "Epoch 100/1000\n",
      "541/541 [==============================] - 0s 630us/step - loss: 26.2546 - mae: 26.2546 - mse: 4517.4458 - accuracy: 0.5810 - val_loss: 20.4233 - val_mae: 20.4233 - val_mse: 2672.5933 - val_accuracy: 0.5962\n",
      "Epoch 101/1000\n",
      "541/541 [==============================] - 0s 589us/step - loss: 25.8867 - mae: 25.8867 - mse: 4597.0322 - accuracy: 0.5816 - val_loss: 21.1972 - val_mae: 21.1972 - val_mse: 2766.4062 - val_accuracy: 0.5973\n",
      "Epoch 102/1000\n",
      "541/541 [==============================] - 0s 584us/step - loss: 26.2198 - mae: 26.2198 - mse: 4441.5786 - accuracy: 0.5813 - val_loss: 20.9265 - val_mae: 20.9265 - val_mse: 2740.2852 - val_accuracy: 0.5966\n",
      "Epoch 103/1000\n",
      "541/541 [==============================] - 0s 591us/step - loss: 26.0465 - mae: 26.0465 - mse: 4377.2734 - accuracy: 0.5814 - val_loss: 21.6056 - val_mae: 21.6056 - val_mse: 2854.6990 - val_accuracy: 0.5955\n",
      "Epoch 104/1000\n",
      "541/541 [==============================] - 0s 590us/step - loss: 26.2704 - mae: 26.2704 - mse: 4455.4858 - accuracy: 0.5822 - val_loss: 20.7255 - val_mae: 20.7255 - val_mse: 2707.6650 - val_accuracy: 0.5964\n",
      "Epoch 105/1000\n",
      "541/541 [==============================] - 0s 579us/step - loss: 25.9836 - mae: 25.9836 - mse: 4728.0688 - accuracy: 0.5799 - val_loss: 20.4923 - val_mae: 20.4923 - val_mse: 2667.9216 - val_accuracy: 0.5966\n",
      "Epoch 106/1000\n",
      "541/541 [==============================] - 0s 603us/step - loss: 26.1550 - mae: 26.1550 - mse: 4446.1377 - accuracy: 0.5810 - val_loss: 20.4588 - val_mae: 20.4588 - val_mse: 2649.5227 - val_accuracy: 0.5955\n",
      "Epoch 107/1000\n",
      "541/541 [==============================] - 0s 620us/step - loss: 26.5757 - mae: 26.5757 - mse: 7417.3486 - accuracy: 0.5809 - val_loss: 20.3889 - val_mae: 20.3889 - val_mse: 2646.5657 - val_accuracy: 0.5959\n",
      "Epoch 108/1000\n",
      "541/541 [==============================] - 0s 606us/step - loss: 26.0769 - mae: 26.0769 - mse: 4358.6362 - accuracy: 0.5811 - val_loss: 20.4969 - val_mae: 20.4969 - val_mse: 2638.0496 - val_accuracy: 0.5955\n",
      "Epoch 109/1000\n",
      "541/541 [==============================] - 0s 671us/step - loss: 26.2345 - mae: 26.2345 - mse: 4496.3896 - accuracy: 0.5808 - val_loss: 20.5520 - val_mae: 20.5520 - val_mse: 2658.4177 - val_accuracy: 0.5952\n",
      "Epoch 110/1000\n",
      "541/541 [==============================] - 0s 606us/step - loss: 25.9868 - mae: 25.9868 - mse: 4526.6245 - accuracy: 0.5818 - val_loss: 21.0520 - val_mae: 21.0520 - val_mse: 2756.1082 - val_accuracy: 0.5955\n",
      "Epoch 111/1000\n",
      "541/541 [==============================] - 0s 590us/step - loss: 26.0812 - mae: 26.0812 - mse: 4440.6025 - accuracy: 0.5834 - val_loss: 20.3729 - val_mae: 20.3729 - val_mse: 2651.4241 - val_accuracy: 0.5952\n",
      "Epoch 112/1000\n",
      "541/541 [==============================] - 0s 606us/step - loss: 26.0666 - mae: 26.0666 - mse: 4397.5347 - accuracy: 0.5824 - val_loss: 21.3054 - val_mae: 21.3054 - val_mse: 2820.3579 - val_accuracy: 0.5962\n",
      "Epoch 113/1000\n",
      "541/541 [==============================] - 0s 629us/step - loss: 25.6219 - mae: 25.6219 - mse: 4174.1494 - accuracy: 0.5825 - val_loss: 20.3841 - val_mae: 20.3841 - val_mse: 2643.5696 - val_accuracy: 0.5955\n",
      "Epoch 114/1000\n",
      "541/541 [==============================] - 0s 590us/step - loss: 25.9974 - mae: 25.9974 - mse: 4409.3003 - accuracy: 0.5812 - val_loss: 20.8152 - val_mae: 20.8152 - val_mse: 2721.1448 - val_accuracy: 0.5957\n",
      "Epoch 115/1000\n",
      "541/541 [==============================] - 0s 592us/step - loss: 26.1063 - mae: 26.1063 - mse: 4508.4082 - accuracy: 0.5812 - val_loss: 20.3403 - val_mae: 20.3403 - val_mse: 2642.3101 - val_accuracy: 0.5959\n",
      "Epoch 116/1000\n",
      "541/541 [==============================] - 0s 677us/step - loss: 26.1523 - mae: 26.1523 - mse: 4461.6440 - accuracy: 0.5818 - val_loss: 20.3702 - val_mae: 20.3702 - val_mse: 2652.0610 - val_accuracy: 0.5955\n",
      "Epoch 117/1000\n",
      "541/541 [==============================] - 0s 610us/step - loss: 25.6939 - mae: 25.6939 - mse: 4391.1758 - accuracy: 0.5820 - val_loss: 20.9886 - val_mae: 20.9886 - val_mse: 2730.6233 - val_accuracy: 0.5962\n",
      "Epoch 118/1000\n",
      "541/541 [==============================] - 0s 589us/step - loss: 25.9993 - mae: 25.9993 - mse: 4398.1177 - accuracy: 0.5816 - val_loss: 20.3509 - val_mae: 20.3509 - val_mse: 2641.3582 - val_accuracy: 0.5952\n",
      "Epoch 119/1000\n",
      "541/541 [==============================] - 0s 604us/step - loss: 25.9912 - mae: 25.9912 - mse: 4443.3145 - accuracy: 0.5820 - val_loss: 20.4604 - val_mae: 20.4604 - val_mse: 2655.9978 - val_accuracy: 0.5957\n",
      "Epoch 120/1000\n",
      "541/541 [==============================] - 0s 590us/step - loss: 25.8763 - mae: 25.8763 - mse: 4350.5181 - accuracy: 0.5818 - val_loss: 20.5072 - val_mae: 20.5072 - val_mse: 2649.3208 - val_accuracy: 0.5964\n",
      "Epoch 121/1000\n",
      "541/541 [==============================] - 0s 587us/step - loss: 25.7918 - mae: 25.7918 - mse: 4337.3613 - accuracy: 0.5821 - val_loss: 20.5282 - val_mae: 20.5282 - val_mse: 2649.1736 - val_accuracy: 0.5959\n",
      "Epoch 122/1000\n",
      "541/541 [==============================] - 0s 584us/step - loss: 26.1803 - mae: 26.1803 - mse: 4409.3379 - accuracy: 0.5821 - val_loss: 20.9969 - val_mae: 20.9969 - val_mse: 2732.8059 - val_accuracy: 0.5950\n",
      "Epoch 123/1000\n",
      "541/541 [==============================] - 0s 600us/step - loss: 26.0409 - mae: 26.0409 - mse: 4354.9609 - accuracy: 0.5822 - val_loss: 20.4597 - val_mae: 20.4597 - val_mse: 2629.8459 - val_accuracy: 0.5969\n",
      "Epoch 124/1000\n",
      "541/541 [==============================] - 0s 586us/step - loss: 26.2503 - mae: 26.2503 - mse: 4439.7241 - accuracy: 0.5827 - val_loss: 20.9186 - val_mae: 20.9186 - val_mse: 2717.6350 - val_accuracy: 0.5964\n",
      "Epoch 125/1000\n",
      "541/541 [==============================] - 0s 587us/step - loss: 25.9307 - mae: 25.9307 - mse: 4670.1631 - accuracy: 0.5827 - val_loss: 20.7074 - val_mae: 20.7074 - val_mse: 2675.9519 - val_accuracy: 0.5959\n",
      "Epoch 126/1000\n",
      "541/541 [==============================] - 0s 625us/step - loss: 26.2751 - mae: 26.2751 - mse: 4434.3579 - accuracy: 0.5834 - val_loss: 20.9940 - val_mae: 20.9940 - val_mse: 2760.0454 - val_accuracy: 0.5964\n",
      "Epoch 127/1000\n",
      "541/541 [==============================] - 0s 580us/step - loss: 26.0257 - mae: 26.0257 - mse: 4392.6812 - accuracy: 0.5831 - val_loss: 20.9621 - val_mae: 20.9621 - val_mse: 2740.5178 - val_accuracy: 0.5959\n",
      "Epoch 128/1000\n",
      "541/541 [==============================] - 0s 596us/step - loss: 25.6657 - mae: 25.6657 - mse: 4296.4580 - accuracy: 0.5821 - val_loss: 20.7285 - val_mae: 20.7285 - val_mse: 2720.6614 - val_accuracy: 0.5952\n",
      "Epoch 129/1000\n",
      "541/541 [==============================] - 0s 587us/step - loss: 25.9718 - mae: 25.9718 - mse: 4350.3984 - accuracy: 0.5836 - val_loss: 20.4839 - val_mae: 20.4839 - val_mse: 2655.9014 - val_accuracy: 0.5957\n",
      "Epoch 130/1000\n",
      "541/541 [==============================] - 0s 579us/step - loss: 25.6820 - mae: 25.6820 - mse: 4266.8271 - accuracy: 0.5822 - val_loss: 20.4791 - val_mae: 20.4791 - val_mse: 2674.1921 - val_accuracy: 0.5959\n",
      "Epoch 131/1000\n",
      "541/541 [==============================] - 0s 611us/step - loss: 25.8576 - mae: 25.8576 - mse: 4402.2856 - accuracy: 0.5827 - val_loss: 21.0677 - val_mae: 21.0677 - val_mse: 2746.3713 - val_accuracy: 0.5955\n",
      "Epoch 132/1000\n",
      "541/541 [==============================] - 0s 718us/step - loss: 25.8282 - mae: 25.8282 - mse: 4354.9272 - accuracy: 0.5827 - val_loss: 20.5737 - val_mae: 20.5737 - val_mse: 2643.2463 - val_accuracy: 0.5955\n",
      "Epoch 133/1000\n",
      "541/541 [==============================] - 0s 611us/step - loss: 26.0378 - mae: 26.0378 - mse: 4430.5249 - accuracy: 0.5830 - val_loss: 20.8665 - val_mae: 20.8665 - val_mse: 2715.9963 - val_accuracy: 0.5955\n",
      "Epoch 134/1000\n",
      "541/541 [==============================] - 0s 588us/step - loss: 26.1052 - mae: 26.1052 - mse: 6338.6577 - accuracy: 0.5834 - val_loss: 20.2572 - val_mae: 20.2572 - val_mse: 2657.9551 - val_accuracy: 0.5959\n",
      "Epoch 135/1000\n",
      "541/541 [==============================] - 0s 600us/step - loss: 26.1943 - mae: 26.1943 - mse: 4501.4209 - accuracy: 0.5819 - val_loss: 20.5542 - val_mae: 20.5542 - val_mse: 2646.8669 - val_accuracy: 0.5952\n",
      "Epoch 136/1000\n",
      "541/541 [==============================] - 0s 588us/step - loss: 26.0031 - mae: 26.0031 - mse: 4347.4707 - accuracy: 0.5837 - val_loss: 20.4980 - val_mae: 20.4980 - val_mse: 2645.0479 - val_accuracy: 0.5955\n",
      "Epoch 137/1000\n",
      "541/541 [==============================] - 0s 607us/step - loss: 25.7648 - mae: 25.7648 - mse: 4258.9697 - accuracy: 0.5840 - val_loss: 20.9086 - val_mae: 20.9086 - val_mse: 2691.5417 - val_accuracy: 0.5950\n",
      "Epoch 138/1000\n",
      "541/541 [==============================] - 0s 624us/step - loss: 25.6980 - mae: 25.6980 - mse: 4196.0620 - accuracy: 0.5840 - val_loss: 20.5457 - val_mae: 20.5457 - val_mse: 2663.3386 - val_accuracy: 0.5962\n",
      "Epoch 139/1000\n",
      "541/541 [==============================] - 0s 589us/step - loss: 26.1719 - mae: 26.1719 - mse: 4370.5620 - accuracy: 0.5816 - val_loss: 20.8336 - val_mae: 20.8336 - val_mse: 2700.5618 - val_accuracy: 0.5959\n",
      "Epoch 140/1000\n",
      "541/541 [==============================] - 0s 591us/step - loss: 25.4658 - mae: 25.4658 - mse: 4146.3071 - accuracy: 0.5842 - val_loss: 20.7767 - val_mae: 20.7767 - val_mse: 2691.6367 - val_accuracy: 0.5957\n",
      "Epoch 141/1000\n",
      "541/541 [==============================] - 0s 585us/step - loss: 25.7408 - mae: 25.7408 - mse: 4297.5991 - accuracy: 0.5842 - val_loss: 20.4384 - val_mae: 20.4384 - val_mse: 2634.5923 - val_accuracy: 0.5966\n",
      "Epoch 142/1000\n",
      "541/541 [==============================] - 0s 601us/step - loss: 26.0379 - mae: 26.0379 - mse: 4427.9058 - accuracy: 0.5831 - val_loss: 20.6772 - val_mae: 20.6772 - val_mse: 2672.1658 - val_accuracy: 0.5962\n",
      "Epoch 143/1000\n",
      "541/541 [==============================] - 0s 598us/step - loss: 25.4671 - mae: 25.4671 - mse: 4144.9922 - accuracy: 0.5831 - val_loss: 20.4002 - val_mae: 20.4002 - val_mse: 2634.9482 - val_accuracy: 0.5955\n",
      "Epoch 144/1000\n",
      "541/541 [==============================] - 0s 619us/step - loss: 26.0461 - mae: 26.0461 - mse: 4381.6045 - accuracy: 0.5842 - val_loss: 20.1498 - val_mae: 20.1498 - val_mse: 2626.1782 - val_accuracy: 0.5964\n",
      "Epoch 145/1000\n",
      "541/541 [==============================] - 0s 587us/step - loss: 25.8125 - mae: 25.8125 - mse: 4385.2983 - accuracy: 0.5825 - val_loss: 20.4446 - val_mae: 20.4446 - val_mse: 2640.4939 - val_accuracy: 0.5955\n",
      "Epoch 146/1000\n",
      "541/541 [==============================] - 0s 599us/step - loss: 25.6815 - mae: 25.6815 - mse: 4257.3887 - accuracy: 0.5840 - val_loss: 21.1242 - val_mae: 21.1242 - val_mse: 2735.2688 - val_accuracy: 0.5973\n",
      "Epoch 147/1000\n",
      "541/541 [==============================] - 0s 590us/step - loss: 26.3357 - mae: 26.3357 - mse: 6524.8672 - accuracy: 0.5853 - val_loss: 20.1873 - val_mae: 20.1873 - val_mse: 2619.9338 - val_accuracy: 0.5969\n",
      "Epoch 148/1000\n",
      "541/541 [==============================] - 0s 593us/step - loss: 25.6034 - mae: 25.6034 - mse: 4282.9253 - accuracy: 0.5841 - val_loss: 20.1770 - val_mae: 20.1770 - val_mse: 2615.0010 - val_accuracy: 0.5950\n",
      "Epoch 149/1000\n",
      "541/541 [==============================] - 0s 589us/step - loss: 25.8935 - mae: 25.8935 - mse: 4335.5034 - accuracy: 0.5846 - val_loss: 20.3596 - val_mae: 20.3596 - val_mse: 2634.8247 - val_accuracy: 0.5969\n",
      "Epoch 150/1000\n",
      "541/541 [==============================] - 0s 615us/step - loss: 25.7497 - mae: 25.7497 - mse: 4317.3550 - accuracy: 0.5837 - val_loss: 20.5793 - val_mae: 20.5793 - val_mse: 2664.9812 - val_accuracy: 0.5980\n",
      "Epoch 151/1000\n",
      "541/541 [==============================] - 0s 611us/step - loss: 26.0139 - mae: 26.0139 - mse: 4422.9502 - accuracy: 0.5848 - val_loss: 20.5155 - val_mae: 20.5155 - val_mse: 2656.0867 - val_accuracy: 0.5975\n",
      "Epoch 152/1000\n",
      "541/541 [==============================] - 0s 592us/step - loss: 26.1359 - mae: 26.1359 - mse: 6762.4834 - accuracy: 0.5855 - val_loss: 20.6641 - val_mae: 20.6641 - val_mse: 2659.9341 - val_accuracy: 0.5964\n",
      "Epoch 153/1000\n",
      "541/541 [==============================] - 0s 589us/step - loss: 25.8146 - mae: 25.8146 - mse: 4446.5039 - accuracy: 0.5842 - val_loss: 20.7865 - val_mae: 20.7865 - val_mse: 2669.6133 - val_accuracy: 0.5964\n",
      "Epoch 154/1000\n",
      "541/541 [==============================] - 0s 585us/step - loss: 25.8929 - mae: 25.8929 - mse: 4317.9697 - accuracy: 0.5834 - val_loss: 20.4269 - val_mae: 20.4269 - val_mse: 2621.1062 - val_accuracy: 0.5952\n",
      "Epoch 155/1000\n",
      "541/541 [==============================] - 0s 632us/step - loss: 25.7242 - mae: 25.7242 - mse: 4270.4346 - accuracy: 0.5842 - val_loss: 20.5007 - val_mae: 20.5007 - val_mse: 2655.5623 - val_accuracy: 0.5964\n",
      "Epoch 156/1000\n",
      "541/541 [==============================] - 0s 591us/step - loss: 25.7948 - mae: 25.7948 - mse: 4881.7251 - accuracy: 0.5834 - val_loss: 20.9049 - val_mae: 20.9049 - val_mse: 2701.4873 - val_accuracy: 0.5959\n",
      "Epoch 157/1000\n",
      "541/541 [==============================] - 0s 589us/step - loss: 26.0880 - mae: 26.0880 - mse: 5528.4233 - accuracy: 0.5841 - val_loss: 21.2408 - val_mae: 21.2408 - val_mse: 2739.2200 - val_accuracy: 0.5957\n",
      "Epoch 158/1000\n",
      "541/541 [==============================] - 0s 594us/step - loss: 25.9180 - mae: 25.9180 - mse: 6245.6362 - accuracy: 0.5837 - val_loss: 20.8543 - val_mae: 20.8543 - val_mse: 2682.2437 - val_accuracy: 0.5962\n",
      "Epoch 159/1000\n",
      "541/541 [==============================] - 0s 598us/step - loss: 25.5771 - mae: 25.5771 - mse: 4239.3364 - accuracy: 0.5848 - val_loss: 20.5522 - val_mae: 20.5522 - val_mse: 2635.7917 - val_accuracy: 0.5957\n",
      "Epoch 160/1000\n",
      "541/541 [==============================] - 0s 583us/step - loss: 26.4009 - mae: 26.4009 - mse: 6735.8267 - accuracy: 0.5845 - val_loss: 20.4812 - val_mae: 20.4812 - val_mse: 2629.7942 - val_accuracy: 0.5962\n",
      "Epoch 161/1000\n",
      "541/541 [==============================] - 0s 621us/step - loss: 25.8922 - mae: 25.8922 - mse: 4435.0283 - accuracy: 0.5836 - val_loss: 20.4985 - val_mae: 20.4985 - val_mse: 2643.8826 - val_accuracy: 0.5957\n",
      "Epoch 162/1000\n",
      "541/541 [==============================] - 0s 588us/step - loss: 25.5864 - mae: 25.5864 - mse: 4228.4150 - accuracy: 0.5836 - val_loss: 21.0915 - val_mae: 21.0915 - val_mse: 2728.9607 - val_accuracy: 0.5955\n",
      "Epoch 163/1000\n",
      "541/541 [==============================] - 0s 588us/step - loss: 25.8216 - mae: 25.8216 - mse: 4453.1416 - accuracy: 0.5830 - val_loss: 20.1808 - val_mae: 20.1808 - val_mse: 2622.4800 - val_accuracy: 0.5969\n",
      "Epoch 164/1000\n",
      "541/541 [==============================] - 0s 599us/step - loss: 25.6831 - mae: 25.6831 - mse: 4230.8813 - accuracy: 0.5832 - val_loss: 21.2488 - val_mae: 21.2488 - val_mse: 2747.2590 - val_accuracy: 0.5952\n",
      "Epoch 165/1000\n",
      "541/541 [==============================] - 0s 588us/step - loss: 25.3499 - mae: 25.3499 - mse: 4155.1504 - accuracy: 0.5831 - val_loss: 20.2072 - val_mae: 20.2072 - val_mse: 2627.0015 - val_accuracy: 0.5955\n",
      "Epoch 166/1000\n",
      "541/541 [==============================] - 0s 591us/step - loss: 25.6904 - mae: 25.6904 - mse: 4400.9185 - accuracy: 0.5832 - val_loss: 20.2322 - val_mae: 20.2322 - val_mse: 2646.2922 - val_accuracy: 0.5959\n",
      "Epoch 167/1000\n",
      "541/541 [==============================] - 0s 616us/step - loss: 25.7111 - mae: 25.7111 - mse: 4284.1655 - accuracy: 0.5844 - val_loss: 20.2583 - val_mae: 20.2583 - val_mse: 2616.2834 - val_accuracy: 0.5952\n",
      "Epoch 168/1000\n",
      "541/541 [==============================] - 0s 604us/step - loss: 26.1960 - mae: 26.1960 - mse: 6891.5317 - accuracy: 0.5843 - val_loss: 21.3708 - val_mae: 21.3708 - val_mse: 2805.3135 - val_accuracy: 0.5952\n",
      "Epoch 169/1000\n",
      "541/541 [==============================] - 0s 588us/step - loss: 25.4758 - mae: 25.4758 - mse: 4220.2612 - accuracy: 0.5834 - val_loss: 20.3722 - val_mae: 20.3722 - val_mse: 2617.3943 - val_accuracy: 0.5966\n",
      "Epoch 170/1000\n",
      "541/541 [==============================] - 0s 581us/step - loss: 25.9511 - mae: 25.9511 - mse: 4426.2456 - accuracy: 0.5841 - val_loss: 20.2299 - val_mae: 20.2299 - val_mse: 2642.8364 - val_accuracy: 0.5952\n",
      "Epoch 171/1000\n",
      "541/541 [==============================] - 0s 588us/step - loss: 25.2698 - mae: 25.2698 - mse: 4191.0620 - accuracy: 0.5841 - val_loss: 20.4059 - val_mae: 20.4059 - val_mse: 2639.5488 - val_accuracy: 0.5955\n",
      "Epoch 172/1000\n",
      "541/541 [==============================] - 0s 617us/step - loss: 25.7594 - mae: 25.7594 - mse: 4302.8315 - accuracy: 0.5829 - val_loss: 21.9881 - val_mae: 21.9881 - val_mse: 2940.1074 - val_accuracy: 0.5962\n",
      "Epoch 173/1000\n",
      "541/541 [==============================] - 0s 599us/step - loss: 25.4136 - mae: 25.4136 - mse: 4212.0376 - accuracy: 0.5847 - val_loss: 20.4610 - val_mae: 20.4610 - val_mse: 2624.6897 - val_accuracy: 0.5959\n",
      "Epoch 174/1000\n",
      "541/541 [==============================] - 0s 593us/step - loss: 25.6943 - mae: 25.6943 - mse: 4354.8926 - accuracy: 0.5842 - val_loss: 20.4921 - val_mae: 20.4921 - val_mse: 2627.9958 - val_accuracy: 0.5964\n",
      "Epoch 175/1000\n",
      "541/541 [==============================] - 0s 584us/step - loss: 25.7393 - mae: 25.7393 - mse: 4265.0469 - accuracy: 0.5846 - val_loss: 20.7725 - val_mae: 20.7725 - val_mse: 2671.8972 - val_accuracy: 0.5952\n",
      "Epoch 176/1000\n",
      "541/541 [==============================] - 0s 588us/step - loss: 25.6542 - mae: 25.6542 - mse: 4326.2319 - accuracy: 0.5844 - val_loss: 21.1440 - val_mae: 21.1440 - val_mse: 2745.2175 - val_accuracy: 0.5964\n",
      "Epoch 177/1000\n",
      "541/541 [==============================] - 0s 589us/step - loss: 25.0930 - mae: 25.0930 - mse: 4106.3882 - accuracy: 0.5848 - val_loss: 20.9048 - val_mae: 20.9048 - val_mse: 2712.5422 - val_accuracy: 0.5964\n",
      "Epoch 178/1000\n",
      "541/541 [==============================] - 0s 623us/step - loss: 25.9981 - mae: 25.9981 - mse: 4420.4004 - accuracy: 0.5850 - val_loss: 21.3244 - val_mae: 21.3244 - val_mse: 2800.5508 - val_accuracy: 0.5962\n",
      "Epoch 179/1000\n",
      "541/541 [==============================] - 0s 592us/step - loss: 25.2078 - mae: 25.2078 - mse: 4149.2109 - accuracy: 0.5842 - val_loss: 20.2876 - val_mae: 20.2876 - val_mse: 2634.2959 - val_accuracy: 0.5955\n",
      "Epoch 180/1000\n",
      "541/541 [==============================] - 0s 582us/step - loss: 25.7558 - mae: 25.7558 - mse: 4326.5908 - accuracy: 0.5852 - val_loss: 20.3214 - val_mae: 20.3214 - val_mse: 2619.2761 - val_accuracy: 0.5950\n",
      "Epoch 181/1000\n",
      "541/541 [==============================] - 0s 586us/step - loss: 25.4593 - mae: 25.4593 - mse: 4180.1768 - accuracy: 0.5834 - val_loss: 20.9648 - val_mae: 20.9648 - val_mse: 2724.3931 - val_accuracy: 0.5955\n",
      "Epoch 182/1000\n",
      "541/541 [==============================] - 0s 587us/step - loss: 25.6464 - mae: 25.6464 - mse: 4273.9219 - accuracy: 0.5830 - val_loss: 20.8826 - val_mae: 20.8826 - val_mse: 2710.9321 - val_accuracy: 0.5950\n",
      "Epoch 183/1000\n",
      "541/541 [==============================] - 0s 641us/step - loss: 25.8457 - mae: 25.8457 - mse: 4401.0117 - accuracy: 0.5858 - val_loss: 20.5834 - val_mae: 20.5834 - val_mse: 2631.0430 - val_accuracy: 0.5957\n",
      "Epoch 184/1000\n",
      "541/541 [==============================] - 0s 584us/step - loss: 25.3029 - mae: 25.3029 - mse: 4086.1228 - accuracy: 0.5838 - val_loss: 20.4247 - val_mae: 20.4247 - val_mse: 2615.0576 - val_accuracy: 0.5945\n",
      "Epoch 185/1000\n",
      "541/541 [==============================] - 0s 589us/step - loss: 25.7604 - mae: 25.7604 - mse: 6052.0151 - accuracy: 0.5846 - val_loss: 20.3028 - val_mae: 20.3028 - val_mse: 2603.7876 - val_accuracy: 0.5950\n",
      "Epoch 186/1000\n",
      "541/541 [==============================] - 0s 588us/step - loss: 25.8318 - mae: 25.8318 - mse: 4325.7417 - accuracy: 0.5835 - val_loss: 20.3862 - val_mae: 20.3862 - val_mse: 2624.6201 - val_accuracy: 0.5952\n",
      "Epoch 187/1000\n",
      "541/541 [==============================] - 0s 586us/step - loss: 25.5182 - mae: 25.5182 - mse: 4210.8115 - accuracy: 0.5852 - val_loss: 20.3110 - val_mae: 20.3110 - val_mse: 2628.8098 - val_accuracy: 0.5957\n",
      "Epoch 188/1000\n",
      "541/541 [==============================] - 0s 601us/step - loss: 25.6514 - mae: 25.6514 - mse: 4537.7368 - accuracy: 0.5842 - val_loss: 20.5413 - val_mae: 20.5413 - val_mse: 2633.0955 - val_accuracy: 0.5957\n",
      "Epoch 189/1000\n",
      "541/541 [==============================] - 0s 618us/step - loss: 25.2553 - mae: 25.2553 - mse: 4214.3579 - accuracy: 0.5845 - val_loss: 20.4210 - val_mae: 20.4210 - val_mse: 2634.9204 - val_accuracy: 0.5952\n",
      "Epoch 190/1000\n",
      "541/541 [==============================] - 0s 588us/step - loss: 25.6253 - mae: 25.6253 - mse: 4745.0176 - accuracy: 0.5847 - val_loss: 20.8854 - val_mae: 20.8854 - val_mse: 2699.8442 - val_accuracy: 0.5957\n",
      "Epoch 191/1000\n",
      "541/541 [==============================] - 0s 592us/step - loss: 25.7575 - mae: 25.7575 - mse: 4459.6621 - accuracy: 0.5840 - val_loss: 20.3440 - val_mae: 20.3440 - val_mse: 2606.6587 - val_accuracy: 0.5957\n",
      "Epoch 192/1000\n",
      "541/541 [==============================] - 0s 589us/step - loss: 26.0337 - mae: 26.0337 - mse: 5835.9741 - accuracy: 0.5844 - val_loss: 20.8639 - val_mae: 20.8639 - val_mse: 2684.6084 - val_accuracy: 0.5959\n",
      "Epoch 193/1000\n",
      "541/541 [==============================] - 0s 594us/step - loss: 25.5372 - mae: 25.5372 - mse: 4243.1333 - accuracy: 0.5844 - val_loss: 20.5096 - val_mae: 20.5096 - val_mse: 2646.5493 - val_accuracy: 0.5969\n",
      "Epoch 194/1000\n",
      "541/541 [==============================] - 0s 622us/step - loss: 25.5219 - mae: 25.5219 - mse: 4203.0176 - accuracy: 0.5847 - val_loss: 20.4222 - val_mae: 20.4222 - val_mse: 2630.0134 - val_accuracy: 0.5969\n",
      "Epoch 195/1000\n",
      "541/541 [==============================] - 0s 584us/step - loss: 25.7047 - mae: 25.7047 - mse: 4340.2246 - accuracy: 0.5842 - val_loss: 20.4468 - val_mae: 20.4468 - val_mse: 2630.2913 - val_accuracy: 0.5962\n",
      "Epoch 196/1000\n",
      "541/541 [==============================] - 0s 589us/step - loss: 25.8568 - mae: 25.8568 - mse: 5784.3623 - accuracy: 0.5855 - val_loss: 20.3904 - val_mae: 20.3904 - val_mse: 2625.3813 - val_accuracy: 0.5959\n",
      "Epoch 197/1000\n",
      "541/541 [==============================] - 0s 587us/step - loss: 25.5858 - mae: 25.5858 - mse: 4252.2695 - accuracy: 0.5831 - val_loss: 20.0979 - val_mae: 20.0979 - val_mse: 2587.7195 - val_accuracy: 0.5955\n",
      "Epoch 198/1000\n",
      "541/541 [==============================] - 0s 597us/step - loss: 25.0061 - mae: 25.0061 - mse: 3980.4097 - accuracy: 0.5847 - val_loss: 20.4487 - val_mae: 20.4487 - val_mse: 2612.4580 - val_accuracy: 0.5957\n",
      "Epoch 199/1000\n",
      "541/541 [==============================] - 0s 617us/step - loss: 25.8894 - mae: 25.8894 - mse: 4350.8330 - accuracy: 0.5836 - val_loss: 21.2247 - val_mae: 21.2247 - val_mse: 2739.0815 - val_accuracy: 0.5943\n",
      "Epoch 200/1000\n",
      "541/541 [==============================] - 0s 587us/step - loss: 25.5836 - mae: 25.5836 - mse: 4238.0557 - accuracy: 0.5838 - val_loss: 20.3983 - val_mae: 20.3983 - val_mse: 2612.8413 - val_accuracy: 0.5957\n",
      "Epoch 201/1000\n",
      "541/541 [==============================] - 0s 588us/step - loss: 25.0943 - mae: 25.0943 - mse: 4109.7339 - accuracy: 0.5851 - val_loss: 20.4151 - val_mae: 20.4151 - val_mse: 2610.5835 - val_accuracy: 0.5950\n",
      "Epoch 202/1000\n",
      "541/541 [==============================] - 0s 598us/step - loss: 25.2604 - mae: 25.2604 - mse: 4130.0908 - accuracy: 0.5840 - val_loss: 20.3222 - val_mae: 20.3222 - val_mse: 2606.6133 - val_accuracy: 0.5952\n",
      "Epoch 203/1000\n",
      "541/541 [==============================] - 0s 583us/step - loss: 25.5226 - mae: 25.5226 - mse: 4190.9849 - accuracy: 0.5842 - val_loss: 20.7242 - val_mae: 20.7242 - val_mse: 2669.7002 - val_accuracy: 0.5952\n",
      "Epoch 204/1000\n",
      "541/541 [==============================] - 0s 613us/step - loss: 25.4228 - mae: 25.4228 - mse: 4725.8979 - accuracy: 0.5842 - val_loss: 20.1643 - val_mae: 20.1643 - val_mse: 2598.1753 - val_accuracy: 0.5945\n",
      "Epoch 205/1000\n",
      "541/541 [==============================] - 0s 588us/step - loss: 25.0867 - mae: 25.0867 - mse: 4121.5239 - accuracy: 0.5838 - val_loss: 20.4072 - val_mae: 20.4072 - val_mse: 2617.6519 - val_accuracy: 0.5934\n",
      "Epoch 206/1000\n",
      "541/541 [==============================] - 0s 583us/step - loss: 25.0581 - mae: 25.0581 - mse: 4111.5771 - accuracy: 0.5835 - val_loss: 20.8586 - val_mae: 20.8586 - val_mse: 2747.4788 - val_accuracy: 0.5969\n",
      "Epoch 207/1000\n",
      "541/541 [==============================] - 0s 595us/step - loss: 25.7998 - mae: 25.7998 - mse: 4583.0913 - accuracy: 0.5840 - val_loss: 20.2593 - val_mae: 20.2593 - val_mse: 2594.0940 - val_accuracy: 0.5955\n",
      "Epoch 208/1000\n",
      "541/541 [==============================] - 0s 592us/step - loss: 25.6238 - mae: 25.6238 - mse: 4198.6719 - accuracy: 0.5830 - val_loss: 20.5647 - val_mae: 20.5647 - val_mse: 2627.7598 - val_accuracy: 0.5952\n",
      "Epoch 209/1000\n",
      "541/541 [==============================] - 0s 613us/step - loss: 25.4233 - mae: 25.4233 - mse: 4132.1646 - accuracy: 0.5840 - val_loss: 20.0947 - val_mae: 20.0947 - val_mse: 2627.3369 - val_accuracy: 0.5962\n",
      "Epoch 210/1000\n",
      "541/541 [==============================] - 0s 586us/step - loss: 25.8201 - mae: 25.8201 - mse: 4382.9951 - accuracy: 0.5842 - val_loss: 20.7434 - val_mae: 20.7434 - val_mse: 2650.4702 - val_accuracy: 0.5943\n",
      "Epoch 211/1000\n",
      "541/541 [==============================] - 0s 587us/step - loss: 25.3103 - mae: 25.3103 - mse: 4162.0630 - accuracy: 0.5838 - val_loss: 20.2870 - val_mae: 20.2870 - val_mse: 2582.2993 - val_accuracy: 0.5957\n",
      "Epoch 212/1000\n",
      "541/541 [==============================] - 0s 606us/step - loss: 26.0015 - mae: 26.0015 - mse: 13067.7783 - accuracy: 0.5841 - val_loss: 20.5466 - val_mae: 20.5466 - val_mse: 2633.7544 - val_accuracy: 0.5945\n",
      "Epoch 213/1000\n",
      "541/541 [==============================] - 0s 586us/step - loss: 25.7454 - mae: 25.7454 - mse: 4280.5591 - accuracy: 0.5835 - val_loss: 20.3642 - val_mae: 20.3642 - val_mse: 2636.1584 - val_accuracy: 0.5948\n",
      "Epoch 214/1000\n",
      "541/541 [==============================] - 0s 617us/step - loss: 25.5730 - mae: 25.5730 - mse: 4323.6152 - accuracy: 0.5841 - val_loss: 20.4828 - val_mae: 20.4828 - val_mse: 2636.6758 - val_accuracy: 0.5952\n",
      "Epoch 215/1000\n",
      "541/541 [==============================] - 0s 590us/step - loss: 25.4956 - mae: 25.4956 - mse: 4233.0742 - accuracy: 0.5851 - val_loss: 20.3514 - val_mae: 20.3514 - val_mse: 2628.7998 - val_accuracy: 0.5943\n",
      "Epoch 216/1000\n",
      "541/541 [==============================] - 0s 584us/step - loss: 25.8154 - mae: 25.8154 - mse: 4875.0981 - accuracy: 0.5838 - val_loss: 20.2331 - val_mae: 20.2331 - val_mse: 2617.6604 - val_accuracy: 0.5945\n",
      "Epoch 217/1000\n",
      "541/541 [==============================] - 0s 589us/step - loss: 25.5595 - mae: 25.5595 - mse: 4435.1235 - accuracy: 0.5837 - val_loss: 20.9709 - val_mae: 20.9709 - val_mse: 2720.3984 - val_accuracy: 0.5950\n",
      "Epoch 218/1000\n",
      "541/541 [==============================] - 0s 604us/step - loss: 24.9369 - mae: 24.9369 - mse: 4046.2896 - accuracy: 0.5844 - val_loss: 21.5048 - val_mae: 21.5048 - val_mse: 2827.8313 - val_accuracy: 0.5943\n",
      "Epoch 219/1000\n",
      "541/541 [==============================] - 0s 614us/step - loss: 25.6542 - mae: 25.6542 - mse: 4395.7085 - accuracy: 0.5818 - val_loss: 20.0834 - val_mae: 20.0834 - val_mse: 2604.6846 - val_accuracy: 0.5929\n",
      "Epoch 220/1000\n",
      "541/541 [==============================] - 0s 584us/step - loss: 25.1502 - mae: 25.1502 - mse: 4109.4800 - accuracy: 0.5807 - val_loss: 20.4355 - val_mae: 20.4355 - val_mse: 2626.4299 - val_accuracy: 0.5938\n",
      "Epoch 221/1000\n",
      "541/541 [==============================] - 0s 586us/step - loss: 25.2532 - mae: 25.2532 - mse: 4193.9102 - accuracy: 0.5803 - val_loss: 20.1762 - val_mae: 20.1762 - val_mse: 2573.3335 - val_accuracy: 0.5927\n",
      "Epoch 222/1000\n",
      "541/541 [==============================] - 0s 595us/step - loss: 25.2742 - mae: 25.2742 - mse: 4149.0996 - accuracy: 0.5795 - val_loss: 20.1166 - val_mae: 20.1166 - val_mse: 2637.5969 - val_accuracy: 0.5927\n",
      "Epoch 223/1000\n",
      "541/541 [==============================] - 0s 631us/step - loss: 25.5733 - mae: 25.5733 - mse: 5434.1133 - accuracy: 0.5800 - val_loss: 20.4752 - val_mae: 20.4752 - val_mse: 2639.1331 - val_accuracy: 0.5934\n",
      "Epoch 224/1000\n",
      "541/541 [==============================] - 0s 587us/step - loss: 24.8946 - mae: 24.8946 - mse: 3987.3516 - accuracy: 0.5801 - val_loss: 20.4808 - val_mae: 20.4808 - val_mse: 2620.5115 - val_accuracy: 0.5920\n",
      "Epoch 225/1000\n",
      "541/541 [==============================] - 0s 591us/step - loss: 24.8660 - mae: 24.8660 - mse: 3955.4436 - accuracy: 0.5803 - val_loss: 20.5189 - val_mae: 20.5189 - val_mse: 2620.4138 - val_accuracy: 0.5920\n",
      "Epoch 226/1000\n",
      "541/541 [==============================] - 0s 595us/step - loss: 24.9467 - mae: 24.9467 - mse: 3973.4365 - accuracy: 0.5794 - val_loss: 20.1070 - val_mae: 20.1070 - val_mse: 2622.4761 - val_accuracy: 0.5927\n",
      "Epoch 227/1000\n",
      "541/541 [==============================] - 0s 604us/step - loss: 25.5972 - mae: 25.5972 - mse: 4240.3354 - accuracy: 0.5803 - val_loss: 20.3370 - val_mae: 20.3370 - val_mse: 2606.2495 - val_accuracy: 0.5929\n",
      "Epoch 228/1000\n",
      "541/541 [==============================] - 0s 627us/step - loss: 25.7576 - mae: 25.7576 - mse: 5924.6064 - accuracy: 0.5803 - val_loss: 20.3186 - val_mae: 20.3186 - val_mse: 2602.7961 - val_accuracy: 0.5934\n",
      "Epoch 229/1000\n",
      "541/541 [==============================] - 0s 587us/step - loss: 24.9949 - mae: 24.9949 - mse: 4049.6799 - accuracy: 0.5804 - val_loss: 20.5172 - val_mae: 20.5172 - val_mse: 2638.0200 - val_accuracy: 0.5929\n",
      "Epoch 230/1000\n",
      "541/541 [==============================] - 0s 589us/step - loss: 25.2399 - mae: 25.2399 - mse: 4166.3169 - accuracy: 0.5796 - val_loss: 20.6402 - val_mae: 20.6402 - val_mse: 2636.4045 - val_accuracy: 0.5918\n",
      "Epoch 231/1000\n",
      "541/541 [==============================] - 0s 598us/step - loss: 25.4223 - mae: 25.4223 - mse: 4249.1436 - accuracy: 0.5796 - val_loss: 20.1183 - val_mae: 20.1183 - val_mse: 2638.5042 - val_accuracy: 0.5931\n",
      "Epoch 232/1000\n",
      "541/541 [==============================] - 0s 602us/step - loss: 25.3361 - mae: 25.3361 - mse: 4247.7300 - accuracy: 0.5811 - val_loss: 21.5785 - val_mae: 21.5785 - val_mse: 2786.0610 - val_accuracy: 0.5929\n",
      "Epoch 233/1000\n",
      "541/541 [==============================] - 0s 621us/step - loss: 25.0323 - mae: 25.0323 - mse: 4029.0508 - accuracy: 0.5796 - val_loss: 20.7187 - val_mae: 20.7187 - val_mse: 2654.9810 - val_accuracy: 0.5931\n",
      "Epoch 234/1000\n",
      "541/541 [==============================] - 0s 586us/step - loss: 25.1160 - mae: 25.1160 - mse: 3994.3496 - accuracy: 0.5803 - val_loss: 20.3020 - val_mae: 20.3020 - val_mse: 2593.6272 - val_accuracy: 0.5925\n",
      "Epoch 235/1000\n",
      "541/541 [==============================] - 0s 593us/step - loss: 25.0644 - mae: 25.0644 - mse: 4036.9106 - accuracy: 0.5782 - val_loss: 20.1049 - val_mae: 20.1049 - val_mse: 2613.7239 - val_accuracy: 0.5925\n",
      "Epoch 236/1000\n",
      "541/541 [==============================] - 0s 590us/step - loss: 25.2667 - mae: 25.2667 - mse: 4117.5347 - accuracy: 0.5780 - val_loss: 20.7070 - val_mae: 20.7070 - val_mse: 2682.7861 - val_accuracy: 0.5929\n",
      "Epoch 237/1000\n",
      "541/541 [==============================] - 0s 585us/step - loss: 25.1079 - mae: 25.1079 - mse: 4111.0444 - accuracy: 0.5801 - val_loss: 20.3774 - val_mae: 20.3774 - val_mse: 2620.8535 - val_accuracy: 0.5929\n",
      "Epoch 238/1000\n",
      "541/541 [==============================] - 0s 629us/step - loss: 25.3834 - mae: 25.3834 - mse: 4278.3574 - accuracy: 0.5805 - val_loss: 20.9436 - val_mae: 20.9436 - val_mse: 2713.1755 - val_accuracy: 0.5938\n",
      "Epoch 239/1000\n",
      "541/541 [==============================] - 0s 590us/step - loss: 25.0786 - mae: 25.0786 - mse: 4057.4299 - accuracy: 0.5803 - val_loss: 20.5561 - val_mae: 20.5561 - val_mse: 2625.2197 - val_accuracy: 0.5927\n",
      "Epoch 240/1000\n",
      "541/541 [==============================] - 0s 590us/step - loss: 25.1550 - mae: 25.1550 - mse: 4152.0166 - accuracy: 0.5797 - val_loss: 21.1392 - val_mae: 21.1392 - val_mse: 2735.2061 - val_accuracy: 0.5943\n",
      "Epoch 241/1000\n",
      "541/541 [==============================] - 0s 590us/step - loss: 25.3741 - mae: 25.3741 - mse: 4183.5498 - accuracy: 0.5810 - val_loss: 20.3116 - val_mae: 20.3116 - val_mse: 2617.2444 - val_accuracy: 0.5934\n",
      "Epoch 242/1000\n",
      "541/541 [==============================] - 0s 616us/step - loss: 25.2153 - mae: 25.2153 - mse: 4116.9443 - accuracy: 0.5799 - val_loss: 21.1189 - val_mae: 21.1189 - val_mse: 2751.2805 - val_accuracy: 0.5936\n",
      "Epoch 243/1000\n",
      "541/541 [==============================] - 0s 600us/step - loss: 24.9131 - mae: 24.9131 - mse: 4079.9148 - accuracy: 0.5800 - val_loss: 20.5418 - val_mae: 20.5418 - val_mse: 2639.2842 - val_accuracy: 0.5936\n",
      "Epoch 244/1000\n",
      "541/541 [==============================] - 0s 583us/step - loss: 25.3145 - mae: 25.3145 - mse: 4237.0381 - accuracy: 0.5809 - val_loss: 20.6458 - val_mae: 20.6458 - val_mse: 2650.2068 - val_accuracy: 0.5936\n",
      "Epoch 245/1000\n",
      "541/541 [==============================] - 0s 588us/step - loss: 24.9775 - mae: 24.9775 - mse: 4709.8130 - accuracy: 0.5813 - val_loss: 20.1301 - val_mae: 20.1301 - val_mse: 2590.5049 - val_accuracy: 0.5920\n",
      "Epoch 246/1000\n",
      "541/541 [==============================] - 0s 591us/step - loss: 25.2428 - mae: 25.2428 - mse: 4213.7002 - accuracy: 0.5792 - val_loss: 20.1980 - val_mae: 20.1980 - val_mse: 2607.0171 - val_accuracy: 0.5925\n",
      "Epoch 247/1000\n",
      "541/541 [==============================] - 0s 618us/step - loss: 25.4344 - mae: 25.4344 - mse: 4225.9639 - accuracy: 0.5791 - val_loss: 20.3787 - val_mae: 20.3787 - val_mse: 2618.3660 - val_accuracy: 0.5915\n",
      "Epoch 248/1000\n",
      "541/541 [==============================] - 0s 601us/step - loss: 24.8323 - mae: 24.8323 - mse: 4014.8135 - accuracy: 0.5800 - val_loss: 20.3800 - val_mae: 20.3800 - val_mse: 2629.1184 - val_accuracy: 0.5931\n",
      "Epoch 249/1000\n",
      "541/541 [==============================] - 0s 594us/step - loss: 25.5756 - mae: 25.5756 - mse: 4266.0864 - accuracy: 0.5815 - val_loss: 20.5913 - val_mae: 20.5913 - val_mse: 2624.9822 - val_accuracy: 0.5927\n",
      "Epoch 250/1000\n",
      "541/541 [==============================] - 0s 587us/step - loss: 25.0448 - mae: 25.0448 - mse: 4074.8440 - accuracy: 0.5801 - val_loss: 20.4879 - val_mae: 20.4879 - val_mse: 2622.4036 - val_accuracy: 0.5936\n",
      "Epoch 251/1000\n",
      "541/541 [==============================] - 0s 615us/step - loss: 25.0621 - mae: 25.0621 - mse: 4050.7644 - accuracy: 0.5805 - val_loss: 20.2481 - val_mae: 20.2481 - val_mse: 2589.2676 - val_accuracy: 0.5934\n",
      "Epoch 252/1000\n",
      "541/541 [==============================] - 0s 627us/step - loss: 25.4507 - mae: 25.4507 - mse: 4266.1924 - accuracy: 0.5796 - val_loss: 20.9300 - val_mae: 20.9300 - val_mse: 2713.9438 - val_accuracy: 0.5938\n",
      "Epoch 253/1000\n",
      "541/541 [==============================] - 0s 599us/step - loss: 25.3945 - mae: 25.3945 - mse: 4176.1289 - accuracy: 0.5803 - val_loss: 20.3039 - val_mae: 20.3039 - val_mse: 2589.3796 - val_accuracy: 0.5931\n",
      "Epoch 254/1000\n",
      "541/541 [==============================] - 0s 594us/step - loss: 25.5818 - mae: 25.5818 - mse: 5937.0488 - accuracy: 0.5811 - val_loss: 20.3374 - val_mae: 20.3374 - val_mse: 2605.9993 - val_accuracy: 0.5925\n",
      "Epoch 255/1000\n",
      "541/541 [==============================] - 0s 587us/step - loss: 25.3243 - mae: 25.3243 - mse: 4214.7764 - accuracy: 0.5801 - val_loss: 20.2060 - val_mae: 20.2060 - val_mse: 2581.9062 - val_accuracy: 0.5920\n",
      "Epoch 256/1000\n",
      "541/541 [==============================] - 0s 622us/step - loss: 24.6291 - mae: 24.6291 - mse: 3935.2747 - accuracy: 0.5804 - val_loss: 20.3015 - val_mae: 20.3015 - val_mse: 2595.9092 - val_accuracy: 0.5927\n",
      "Epoch 257/1000\n",
      "541/541 [==============================] - 0s 602us/step - loss: 25.0943 - mae: 25.0943 - mse: 4170.2554 - accuracy: 0.5810 - val_loss: 20.6995 - val_mae: 20.6995 - val_mse: 2669.5789 - val_accuracy: 0.5934\n",
      "Epoch 258/1000\n",
      "541/541 [==============================] - 0s 584us/step - loss: 24.8511 - mae: 24.8511 - mse: 4018.5234 - accuracy: 0.5813 - val_loss: 20.0928 - val_mae: 20.0928 - val_mse: 2657.6707 - val_accuracy: 0.5938\n",
      "Epoch 259/1000\n",
      "541/541 [==============================] - 0s 591us/step - loss: 24.6566 - mae: 24.6566 - mse: 4072.5366 - accuracy: 0.5808 - val_loss: 20.7991 - val_mae: 20.7991 - val_mse: 2686.6277 - val_accuracy: 0.5931\n",
      "Epoch 260/1000\n",
      "541/541 [==============================] - 0s 613us/step - loss: 24.6764 - mae: 24.6764 - mse: 3999.9519 - accuracy: 0.5814 - val_loss: 20.0988 - val_mae: 20.0988 - val_mse: 2591.1484 - val_accuracy: 0.5925\n",
      "Epoch 261/1000\n",
      "541/541 [==============================] - 0s 588us/step - loss: 24.8676 - mae: 24.8676 - mse: 4146.2759 - accuracy: 0.5807 - val_loss: 20.7986 - val_mae: 20.7986 - val_mse: 2673.4377 - val_accuracy: 0.5931\n",
      "Epoch 262/1000\n",
      "541/541 [==============================] - 0s 603us/step - loss: 25.2845 - mae: 25.2845 - mse: 4116.0312 - accuracy: 0.5802 - val_loss: 20.9549 - val_mae: 20.9549 - val_mse: 2698.8865 - val_accuracy: 0.5929\n",
      "Epoch 263/1000\n",
      "541/541 [==============================] - 0s 598us/step - loss: 25.0850 - mae: 25.0850 - mse: 4119.3677 - accuracy: 0.5793 - val_loss: 20.0657 - val_mae: 20.0657 - val_mse: 2601.4348 - val_accuracy: 0.5927\n",
      "Epoch 264/1000\n",
      "541/541 [==============================] - 0s 593us/step - loss: 25.2866 - mae: 25.2866 - mse: 4225.4434 - accuracy: 0.5810 - val_loss: 20.2047 - val_mae: 20.2047 - val_mse: 2584.1506 - val_accuracy: 0.5934\n",
      "Epoch 265/1000\n",
      "541/541 [==============================] - 0s 615us/step - loss: 25.2109 - mae: 25.2109 - mse: 4123.5005 - accuracy: 0.5816 - val_loss: 20.4618 - val_mae: 20.4618 - val_mse: 2599.7615 - val_accuracy: 0.5929\n",
      "Epoch 266/1000\n",
      "541/541 [==============================] - 0s 595us/step - loss: 25.0944 - mae: 25.0944 - mse: 4143.0454 - accuracy: 0.5812 - val_loss: 21.2404 - val_mae: 21.2404 - val_mse: 2758.2100 - val_accuracy: 0.5934\n",
      "Epoch 267/1000\n",
      "541/541 [==============================] - 0s 607us/step - loss: 25.5741 - mae: 25.5741 - mse: 4238.7290 - accuracy: 0.5814 - val_loss: 20.1451 - val_mae: 20.1451 - val_mse: 2666.9807 - val_accuracy: 0.5925\n",
      "Epoch 268/1000\n",
      "541/541 [==============================] - 0s 589us/step - loss: 25.3571 - mae: 25.3571 - mse: 4198.0034 - accuracy: 0.5814 - val_loss: 20.0107 - val_mae: 20.0107 - val_mse: 2600.0461 - val_accuracy: 0.5925\n",
      "Epoch 269/1000\n",
      "541/541 [==============================] - 0s 598us/step - loss: 25.0990 - mae: 25.0990 - mse: 4186.3066 - accuracy: 0.5808 - val_loss: 20.3100 - val_mae: 20.3100 - val_mse: 2590.2329 - val_accuracy: 0.5934\n",
      "Epoch 270/1000\n",
      "541/541 [==============================] - 0s 615us/step - loss: 25.2587 - mae: 25.2587 - mse: 4160.5244 - accuracy: 0.5804 - val_loss: 20.0100 - val_mae: 20.0100 - val_mse: 2583.7051 - val_accuracy: 0.5927\n",
      "Epoch 271/1000\n",
      "541/541 [==============================] - 0s 606us/step - loss: 25.0836 - mae: 25.0836 - mse: 4170.9614 - accuracy: 0.5803 - val_loss: 20.2709 - val_mae: 20.2709 - val_mse: 2617.7180 - val_accuracy: 0.5922\n",
      "Epoch 272/1000\n",
      "541/541 [==============================] - 0s 592us/step - loss: 26.0238 - mae: 26.0238 - mse: 11575.1309 - accuracy: 0.5808 - val_loss: 20.4750 - val_mae: 20.4750 - val_mse: 2635.6362 - val_accuracy: 0.5922\n",
      "Epoch 273/1000\n",
      "541/541 [==============================] - 0s 587us/step - loss: 25.2554 - mae: 25.2554 - mse: 4313.3999 - accuracy: 0.5812 - val_loss: 20.4979 - val_mae: 20.4979 - val_mse: 2635.7622 - val_accuracy: 0.5931\n",
      "Epoch 274/1000\n",
      "541/541 [==============================] - 0s 618us/step - loss: 25.4096 - mae: 25.4096 - mse: 4363.2700 - accuracy: 0.5813 - val_loss: 20.1949 - val_mae: 20.1949 - val_mse: 2602.9395 - val_accuracy: 0.5931\n",
      "Epoch 275/1000\n",
      "541/541 [==============================] - 0s 590us/step - loss: 25.2691 - mae: 25.2691 - mse: 4182.8916 - accuracy: 0.5823 - val_loss: 20.1310 - val_mae: 20.1310 - val_mse: 2601.0112 - val_accuracy: 0.5938\n",
      "Epoch 276/1000\n",
      "541/541 [==============================] - 0s 608us/step - loss: 25.1460 - mae: 25.1460 - mse: 4310.1182 - accuracy: 0.5809 - val_loss: 20.2884 - val_mae: 20.2884 - val_mse: 2608.8655 - val_accuracy: 0.5934\n",
      "Epoch 277/1000\n",
      "541/541 [==============================] - 0s 604us/step - loss: 24.8801 - mae: 24.8801 - mse: 4051.1492 - accuracy: 0.5811 - val_loss: 20.3436 - val_mae: 20.3436 - val_mse: 2595.3953 - val_accuracy: 0.5918\n",
      "Epoch 278/1000\n",
      "541/541 [==============================] - 0s 603us/step - loss: 25.4284 - mae: 25.4284 - mse: 5335.9316 - accuracy: 0.5797 - val_loss: 20.4313 - val_mae: 20.4313 - val_mse: 2608.2307 - val_accuracy: 0.5918\n",
      "Epoch 279/1000\n",
      "541/541 [==============================] - 0s 624us/step - loss: 25.4448 - mae: 25.4448 - mse: 4154.2500 - accuracy: 0.5809 - val_loss: 20.6554 - val_mae: 20.6554 - val_mse: 2656.2024 - val_accuracy: 0.5920\n",
      "Epoch 280/1000\n",
      "541/541 [==============================] - 0s 606us/step - loss: 26.0761 - mae: 26.0761 - mse: 9871.9580 - accuracy: 0.5816 - val_loss: 20.2968 - val_mae: 20.2968 - val_mse: 2600.5825 - val_accuracy: 0.5920\n",
      "Epoch 281/1000\n",
      "541/541 [==============================] - 0s 583us/step - loss: 24.8553 - mae: 24.8553 - mse: 3995.4421 - accuracy: 0.5811 - val_loss: 20.2625 - val_mae: 20.2625 - val_mse: 2607.7271 - val_accuracy: 0.5922\n",
      "Epoch 282/1000\n",
      "541/541 [==============================] - 0s 588us/step - loss: 24.6778 - mae: 24.6778 - mse: 3949.9475 - accuracy: 0.5805 - val_loss: 20.1751 - val_mae: 20.1751 - val_mse: 2582.3149 - val_accuracy: 0.5920\n",
      "Epoch 283/1000\n",
      "541/541 [==============================] - 0s 623us/step - loss: 24.9059 - mae: 24.9059 - mse: 4168.1201 - accuracy: 0.5805 - val_loss: 20.2115 - val_mae: 20.2115 - val_mse: 2595.9753 - val_accuracy: 0.5922\n",
      "Epoch 284/1000\n",
      "541/541 [==============================] - 0s 590us/step - loss: 24.7719 - mae: 24.7719 - mse: 4020.0820 - accuracy: 0.5808 - val_loss: 19.9923 - val_mae: 19.9923 - val_mse: 2576.3450 - val_accuracy: 0.5922\n",
      "Epoch 285/1000\n",
      "541/541 [==============================] - 0s 609us/step - loss: 25.4057 - mae: 25.4057 - mse: 4207.6362 - accuracy: 0.5799 - val_loss: 20.2639 - val_mae: 20.2639 - val_mse: 2590.3071 - val_accuracy: 0.5920\n",
      "Epoch 286/1000\n",
      "541/541 [==============================] - 0s 601us/step - loss: 25.2071 - mae: 25.2071 - mse: 4186.9790 - accuracy: 0.5805 - val_loss: 20.3030 - val_mae: 20.3030 - val_mse: 2586.8823 - val_accuracy: 0.5918\n",
      "Epoch 287/1000\n",
      "541/541 [==============================] - 0s 589us/step - loss: 25.3020 - mae: 25.3020 - mse: 4097.2974 - accuracy: 0.5811 - val_loss: 20.3457 - val_mae: 20.3457 - val_mse: 2604.8862 - val_accuracy: 0.5929\n",
      "Epoch 288/1000\n",
      "541/541 [==============================] - 0s 623us/step - loss: 25.0965 - mae: 25.0965 - mse: 4121.2881 - accuracy: 0.5801 - val_loss: 20.3260 - val_mae: 20.3260 - val_mse: 2605.6877 - val_accuracy: 0.5931\n",
      "Epoch 289/1000\n",
      "541/541 [==============================] - 0s 599us/step - loss: 25.0210 - mae: 25.0210 - mse: 4102.8267 - accuracy: 0.5805 - val_loss: 19.8855 - val_mae: 19.8855 - val_mse: 2552.4534 - val_accuracy: 0.5929\n",
      "Epoch 290/1000\n",
      "541/541 [==============================] - 0s 596us/step - loss: 25.2827 - mae: 25.2827 - mse: 4154.6001 - accuracy: 0.5804 - val_loss: 20.1699 - val_mae: 20.1699 - val_mse: 2571.3447 - val_accuracy: 0.5925\n",
      "Epoch 291/1000\n",
      "541/541 [==============================] - 0s 596us/step - loss: 24.6309 - mae: 24.6309 - mse: 3987.2039 - accuracy: 0.5811 - val_loss: 20.9341 - val_mae: 20.9341 - val_mse: 2715.1489 - val_accuracy: 0.5934\n",
      "Epoch 292/1000\n",
      "541/541 [==============================] - 0s 623us/step - loss: 25.3193 - mae: 25.3193 - mse: 4220.5054 - accuracy: 0.5800 - val_loss: 20.5447 - val_mae: 20.5447 - val_mse: 2616.0732 - val_accuracy: 0.5929\n",
      "Epoch 293/1000\n",
      "541/541 [==============================] - 0s 598us/step - loss: 25.0690 - mae: 25.0690 - mse: 4091.9949 - accuracy: 0.5801 - val_loss: 20.1786 - val_mae: 20.1786 - val_mse: 2588.0215 - val_accuracy: 0.5920\n",
      "Epoch 294/1000\n",
      "541/541 [==============================] - 0s 594us/step - loss: 24.8167 - mae: 24.8167 - mse: 3998.5344 - accuracy: 0.5811 - val_loss: 20.0227 - val_mae: 20.0227 - val_mse: 2609.5486 - val_accuracy: 0.5931\n",
      "Epoch 295/1000\n",
      "541/541 [==============================] - 0s 589us/step - loss: 25.0082 - mae: 25.0082 - mse: 4159.6343 - accuracy: 0.5797 - val_loss: 20.4397 - val_mae: 20.4397 - val_mse: 2599.2988 - val_accuracy: 0.5938\n",
      "Epoch 296/1000\n",
      "541/541 [==============================] - 0s 628us/step - loss: 25.2008 - mae: 25.2008 - mse: 4098.6865 - accuracy: 0.5809 - val_loss: 19.9770 - val_mae: 19.9770 - val_mse: 2605.7764 - val_accuracy: 0.5906\n",
      "Epoch 297/1000\n",
      "541/541 [==============================] - 0s 603us/step - loss: 24.9298 - mae: 24.9298 - mse: 4002.0156 - accuracy: 0.5799 - val_loss: 20.3048 - val_mae: 20.3048 - val_mse: 2594.4712 - val_accuracy: 0.5913\n",
      "Epoch 298/1000\n",
      "541/541 [==============================] - 0s 595us/step - loss: 25.0012 - mae: 25.0012 - mse: 4045.2175 - accuracy: 0.5791 - val_loss: 19.9513 - val_mae: 19.9513 - val_mse: 2600.5083 - val_accuracy: 0.5913\n",
      "Epoch 299/1000\n",
      "541/541 [==============================] - 0s 591us/step - loss: 25.1720 - mae: 25.1720 - mse: 4128.2993 - accuracy: 0.5801 - val_loss: 20.3001 - val_mae: 20.3001 - val_mse: 2584.4954 - val_accuracy: 0.5934\n",
      "Epoch 300/1000\n",
      "541/541 [==============================] - 0s 615us/step - loss: 25.2650 - mae: 25.2650 - mse: 4157.2690 - accuracy: 0.5812 - val_loss: 20.1828 - val_mae: 20.1828 - val_mse: 2589.4421 - val_accuracy: 0.5927\n",
      "Epoch 301/1000\n",
      "541/541 [==============================] - 0s 603us/step - loss: 25.1442 - mae: 25.1442 - mse: 4075.7969 - accuracy: 0.5809 - val_loss: 20.3832 - val_mae: 20.3832 - val_mse: 2582.6272 - val_accuracy: 0.5934\n",
      "Epoch 302/1000\n",
      "541/541 [==============================] - 0s 589us/step - loss: 25.1004 - mae: 25.1004 - mse: 4095.2561 - accuracy: 0.5812 - val_loss: 20.2873 - val_mae: 20.2873 - val_mse: 2585.9590 - val_accuracy: 0.5929\n",
      "Epoch 303/1000\n",
      "541/541 [==============================] - 0s 590us/step - loss: 25.3595 - mae: 25.3595 - mse: 5255.2832 - accuracy: 0.5802 - val_loss: 20.7663 - val_mae: 20.7663 - val_mse: 2658.6484 - val_accuracy: 0.5943\n",
      "Epoch 304/1000\n",
      "541/541 [==============================] - 0s 617us/step - loss: 25.0236 - mae: 25.0236 - mse: 4031.6477 - accuracy: 0.5821 - val_loss: 20.8116 - val_mae: 20.8116 - val_mse: 2693.7275 - val_accuracy: 0.5934\n",
      "Epoch 305/1000\n",
      "541/541 [==============================] - 0s 600us/step - loss: 25.4569 - mae: 25.4569 - mse: 4186.1250 - accuracy: 0.5801 - val_loss: 20.2717 - val_mae: 20.2717 - val_mse: 2569.7451 - val_accuracy: 0.5931\n",
      "Epoch 306/1000\n",
      "541/541 [==============================] - 0s 588us/step - loss: 25.1167 - mae: 25.1167 - mse: 4113.9175 - accuracy: 0.5806 - val_loss: 20.3202 - val_mae: 20.3202 - val_mse: 2595.9736 - val_accuracy: 0.5927\n",
      "Epoch 307/1000\n",
      "541/541 [==============================] - 0s 589us/step - loss: 25.2344 - mae: 25.2344 - mse: 4134.9868 - accuracy: 0.5823 - val_loss: 20.1877 - val_mae: 20.1877 - val_mse: 2569.8625 - val_accuracy: 0.5936\n",
      "Epoch 308/1000\n",
      "541/541 [==============================] - 0s 618us/step - loss: 25.4734 - mae: 25.4734 - mse: 4264.6040 - accuracy: 0.5821 - val_loss: 20.5072 - val_mae: 20.5072 - val_mse: 2619.7485 - val_accuracy: 0.5915\n",
      "Epoch 309/1000\n",
      "541/541 [==============================] - 0s 609us/step - loss: 24.9146 - mae: 24.9146 - mse: 4049.1458 - accuracy: 0.5811 - val_loss: 20.0728 - val_mae: 20.0728 - val_mse: 2570.9783 - val_accuracy: 0.5915\n",
      "Epoch 310/1000\n",
      "541/541 [==============================] - 0s 594us/step - loss: 24.5842 - mae: 24.5842 - mse: 3911.7205 - accuracy: 0.5802 - val_loss: 20.1215 - val_mae: 20.1215 - val_mse: 2663.7361 - val_accuracy: 0.5920\n",
      "Epoch 311/1000\n",
      "541/541 [==============================] - 0s 585us/step - loss: 25.4809 - mae: 25.4809 - mse: 4745.2305 - accuracy: 0.5807 - val_loss: 20.2337 - val_mae: 20.2337 - val_mse: 2596.6472 - val_accuracy: 0.5920\n",
      "Epoch 312/1000\n",
      "541/541 [==============================] - 0s 624us/step - loss: 25.1079 - mae: 25.1079 - mse: 4132.1973 - accuracy: 0.5807 - val_loss: 20.8702 - val_mae: 20.8702 - val_mse: 2688.7393 - val_accuracy: 0.5931\n",
      "Epoch 313/1000\n",
      "541/541 [==============================] - 0s 606us/step - loss: 24.9811 - mae: 24.9811 - mse: 4139.2764 - accuracy: 0.5819 - val_loss: 20.0407 - val_mae: 20.0407 - val_mse: 2606.0610 - val_accuracy: 0.5929\n",
      "Epoch 314/1000\n",
      "541/541 [==============================] - 0s 592us/step - loss: 25.2858 - mae: 25.2858 - mse: 4259.4893 - accuracy: 0.5808 - val_loss: 20.0323 - val_mae: 20.0323 - val_mse: 2627.8435 - val_accuracy: 0.5922\n",
      "Epoch 315/1000\n",
      "541/541 [==============================] - 0s 584us/step - loss: 25.2911 - mae: 25.2911 - mse: 4351.4434 - accuracy: 0.5814 - val_loss: 20.2992 - val_mae: 20.2992 - val_mse: 2588.2290 - val_accuracy: 0.5920\n",
      "Epoch 316/1000\n",
      "541/541 [==============================] - 0s 626us/step - loss: 24.9929 - mae: 24.9929 - mse: 4065.2161 - accuracy: 0.5788 - val_loss: 20.8754 - val_mae: 20.8754 - val_mse: 2690.8245 - val_accuracy: 0.5922\n",
      "Epoch 317/1000\n",
      "541/541 [==============================] - 0s 607us/step - loss: 25.0338 - mae: 25.0338 - mse: 4140.7930 - accuracy: 0.5797 - val_loss: 20.1542 - val_mae: 20.1542 - val_mse: 2591.6655 - val_accuracy: 0.5920\n",
      "Epoch 318/1000\n",
      "541/541 [==============================] - 0s 587us/step - loss: 25.0668 - mae: 25.0668 - mse: 4089.9238 - accuracy: 0.5816 - val_loss: 20.3819 - val_mae: 20.3819 - val_mse: 2598.1575 - val_accuracy: 0.5911\n",
      "Epoch 319/1000\n",
      "541/541 [==============================] - 0s 593us/step - loss: 25.1016 - mae: 25.1016 - mse: 4091.6204 - accuracy: 0.5803 - val_loss: 20.3224 - val_mae: 20.3224 - val_mse: 2586.4424 - val_accuracy: 0.5911\n",
      "Epoch 320/1000\n",
      "541/541 [==============================] - 0s 615us/step - loss: 24.9692 - mae: 24.9692 - mse: 4087.0593 - accuracy: 0.5793 - val_loss: 20.0712 - val_mae: 20.0712 - val_mse: 2586.3958 - val_accuracy: 0.5920\n",
      "Epoch 321/1000\n",
      "541/541 [==============================] - 0s 601us/step - loss: 24.9081 - mae: 24.9081 - mse: 4043.0413 - accuracy: 0.5807 - val_loss: 20.1576 - val_mae: 20.1576 - val_mse: 2607.6667 - val_accuracy: 0.5922\n",
      "Epoch 322/1000\n",
      "541/541 [==============================] - 0s 591us/step - loss: 25.5570 - mae: 25.5570 - mse: 4337.1504 - accuracy: 0.5796 - val_loss: 20.1898 - val_mae: 20.1898 - val_mse: 2574.9922 - val_accuracy: 0.5920\n",
      "Epoch 323/1000\n",
      "541/541 [==============================] - 0s 592us/step - loss: 24.9395 - mae: 24.9395 - mse: 4077.2451 - accuracy: 0.5803 - val_loss: 20.1892 - val_mae: 20.1892 - val_mse: 2591.7581 - val_accuracy: 0.5920\n",
      "Epoch 324/1000\n",
      "541/541 [==============================] - 0s 619us/step - loss: 25.2571 - mae: 25.2571 - mse: 4392.2837 - accuracy: 0.5803 - val_loss: 20.4019 - val_mae: 20.4019 - val_mse: 2592.2898 - val_accuracy: 0.5929\n",
      "Epoch 325/1000\n",
      "541/541 [==============================] - 0s 603us/step - loss: 24.8968 - mae: 24.8968 - mse: 3998.4336 - accuracy: 0.5807 - val_loss: 20.9999 - val_mae: 20.9999 - val_mse: 2717.3582 - val_accuracy: 0.5920\n",
      "Epoch 326/1000\n",
      "541/541 [==============================] - 0s 590us/step - loss: 25.0438 - mae: 25.0438 - mse: 4120.2368 - accuracy: 0.5814 - val_loss: 20.7315 - val_mae: 20.7315 - val_mse: 2647.1738 - val_accuracy: 0.5922\n",
      "Epoch 327/1000\n",
      "541/541 [==============================] - 0s 593us/step - loss: 25.1566 - mae: 25.1566 - mse: 4163.3799 - accuracy: 0.5812 - val_loss: 19.9454 - val_mae: 19.9454 - val_mse: 2588.2910 - val_accuracy: 0.5920\n",
      "Epoch 328/1000\n",
      "541/541 [==============================] - 0s 619us/step - loss: 24.9526 - mae: 24.9526 - mse: 4101.0405 - accuracy: 0.5811 - val_loss: 21.3783 - val_mae: 21.3783 - val_mse: 2792.5281 - val_accuracy: 0.5915\n",
      "Epoch 329/1000\n",
      "541/541 [==============================] - 0s 603us/step - loss: 25.7610 - mae: 25.7610 - mse: 12618.0977 - accuracy: 0.5812 - val_loss: 20.2245 - val_mae: 20.2245 - val_mse: 2596.4856 - val_accuracy: 0.5918\n",
      "Epoch 330/1000\n",
      "541/541 [==============================] - 0s 594us/step - loss: 24.9285 - mae: 24.9285 - mse: 4071.6497 - accuracy: 0.5795 - val_loss: 20.2268 - val_mae: 20.2268 - val_mse: 2588.5562 - val_accuracy: 0.5922\n",
      "Epoch 331/1000\n",
      "541/541 [==============================] - 0s 621us/step - loss: 24.8959 - mae: 24.8959 - mse: 4056.9402 - accuracy: 0.5793 - val_loss: 20.4653 - val_mae: 20.4653 - val_mse: 2606.5891 - val_accuracy: 0.5915\n",
      "Epoch 332/1000\n",
      "541/541 [==============================] - 0s 592us/step - loss: 24.8276 - mae: 24.8276 - mse: 4092.8240 - accuracy: 0.5803 - val_loss: 19.9884 - val_mae: 19.9884 - val_mse: 2591.1338 - val_accuracy: 0.5913\n",
      "Epoch 333/1000\n",
      "541/541 [==============================] - 0s 606us/step - loss: 25.0290 - mae: 25.0290 - mse: 4149.2104 - accuracy: 0.5795 - val_loss: 20.2195 - val_mae: 20.2195 - val_mse: 2573.1660 - val_accuracy: 0.5915\n",
      "Epoch 334/1000\n",
      "541/541 [==============================] - 0s 595us/step - loss: 25.0579 - mae: 25.0579 - mse: 5146.3926 - accuracy: 0.5789 - val_loss: 19.9812 - val_mae: 19.9812 - val_mse: 2585.9766 - val_accuracy: 0.5920\n",
      "Epoch 335/1000\n",
      "541/541 [==============================] - 0s 624us/step - loss: 24.5437 - mae: 24.5437 - mse: 3887.3640 - accuracy: 0.5807 - val_loss: 20.0103 - val_mae: 20.0103 - val_mse: 2587.8972 - val_accuracy: 0.5915\n",
      "Epoch 336/1000\n",
      "541/541 [==============================] - 0s 589us/step - loss: 25.1482 - mae: 25.1482 - mse: 4097.6094 - accuracy: 0.5810 - val_loss: 20.0542 - val_mae: 20.0542 - val_mse: 2578.9548 - val_accuracy: 0.5913\n",
      "Epoch 337/1000\n",
      "541/541 [==============================] - 0s 603us/step - loss: 24.7275 - mae: 24.7275 - mse: 3983.0820 - accuracy: 0.5800 - val_loss: 20.1420 - val_mae: 20.1420 - val_mse: 2577.7705 - val_accuracy: 0.5911\n",
      "Epoch 338/1000\n",
      "541/541 [==============================] - 0s 623us/step - loss: 24.8265 - mae: 24.8265 - mse: 4057.3591 - accuracy: 0.5797 - val_loss: 20.4229 - val_mae: 20.4229 - val_mse: 2618.3181 - val_accuracy: 0.5915\n",
      "Epoch 339/1000\n",
      "541/541 [==============================] - 0s 624us/step - loss: 24.9279 - mae: 24.9279 - mse: 4094.1821 - accuracy: 0.5783 - val_loss: 20.1167 - val_mae: 20.1167 - val_mse: 2582.0081 - val_accuracy: 0.5920\n",
      "Epoch 340/1000\n",
      "541/541 [==============================] - 0s 607us/step - loss: 24.8518 - mae: 24.8518 - mse: 4033.2517 - accuracy: 0.5801 - val_loss: 20.1122 - val_mae: 20.1122 - val_mse: 2564.9712 - val_accuracy: 0.5913\n",
      "Epoch 341/1000\n",
      "541/541 [==============================] - 0s 593us/step - loss: 24.9215 - mae: 24.9215 - mse: 4021.1777 - accuracy: 0.5808 - val_loss: 20.8594 - val_mae: 20.8594 - val_mse: 2684.8110 - val_accuracy: 0.5915\n",
      "Epoch 342/1000\n",
      "541/541 [==============================] - 0s 618us/step - loss: 25.0432 - mae: 25.0432 - mse: 4115.0493 - accuracy: 0.5791 - val_loss: 21.4698 - val_mae: 21.4698 - val_mse: 2788.5906 - val_accuracy: 0.5913\n",
      "Epoch 343/1000\n",
      "541/541 [==============================] - 0s 588us/step - loss: 25.3428 - mae: 25.3428 - mse: 4183.1138 - accuracy: 0.5803 - val_loss: 20.3820 - val_mae: 20.3820 - val_mse: 2589.7844 - val_accuracy: 0.5920\n",
      "Epoch 344/1000\n",
      "541/541 [==============================] - 0s 605us/step - loss: 25.1399 - mae: 25.1399 - mse: 4120.8413 - accuracy: 0.5790 - val_loss: 20.4840 - val_mae: 20.4840 - val_mse: 2620.8743 - val_accuracy: 0.5906\n",
      "Epoch 345/1000\n",
      "541/541 [==============================] - 0s 591us/step - loss: 25.0092 - mae: 25.0092 - mse: 4054.3145 - accuracy: 0.5796 - val_loss: 20.5322 - val_mae: 20.5322 - val_mse: 2618.2737 - val_accuracy: 0.5925\n",
      "Epoch 346/1000\n",
      "541/541 [==============================] - 0s 625us/step - loss: 24.8556 - mae: 24.8556 - mse: 4047.2117 - accuracy: 0.5811 - val_loss: 20.4857 - val_mae: 20.4857 - val_mse: 2629.0862 - val_accuracy: 0.5922\n",
      "Epoch 347/1000\n",
      "541/541 [==============================] - 0s 591us/step - loss: 24.4852 - mae: 24.4852 - mse: 3952.3499 - accuracy: 0.5799 - val_loss: 20.4912 - val_mae: 20.4912 - val_mse: 2628.5930 - val_accuracy: 0.5929\n",
      "Epoch 348/1000\n",
      "541/541 [==============================] - 0s 606us/step - loss: 24.9424 - mae: 24.9424 - mse: 4088.5374 - accuracy: 0.5805 - val_loss: 20.0774 - val_mae: 20.0774 - val_mse: 2592.7239 - val_accuracy: 0.5922\n",
      "Epoch 349/1000\n",
      "541/541 [==============================] - 0s 589us/step - loss: 24.8705 - mae: 24.8705 - mse: 3982.9729 - accuracy: 0.5789 - val_loss: 20.7239 - val_mae: 20.7239 - val_mse: 2640.2808 - val_accuracy: 0.5920\n",
      "Epoch 350/1000\n",
      "541/541 [==============================] - 0s 625us/step - loss: 24.5149 - mae: 24.5149 - mse: 3919.4885 - accuracy: 0.5806 - val_loss: 20.8258 - val_mae: 20.8258 - val_mse: 2670.4539 - val_accuracy: 0.5920\n",
      "Epoch 351/1000\n",
      "541/541 [==============================] - 0s 605us/step - loss: 25.0476 - mae: 25.0476 - mse: 4107.5444 - accuracy: 0.5814 - val_loss: 20.3576 - val_mae: 20.3576 - val_mse: 2585.8787 - val_accuracy: 0.5915\n",
      "Epoch 352/1000\n",
      "541/541 [==============================] - 0s 589us/step - loss: 24.9900 - mae: 24.9900 - mse: 4170.5166 - accuracy: 0.5800 - val_loss: 20.0103 - val_mae: 20.0103 - val_mse: 2609.3933 - val_accuracy: 0.5918\n",
      "Epoch 353/1000\n",
      "541/541 [==============================] - 0s 592us/step - loss: 24.7315 - mae: 24.7315 - mse: 4054.8928 - accuracy: 0.5796 - val_loss: 20.1021 - val_mae: 20.1021 - val_mse: 2589.8057 - val_accuracy: 0.5911\n",
      "Epoch 354/1000\n",
      "541/541 [==============================] - 0s 621us/step - loss: 24.5635 - mae: 24.5635 - mse: 3996.2444 - accuracy: 0.5801 - val_loss: 20.1946 - val_mae: 20.1946 - val_mse: 2560.5139 - val_accuracy: 0.5915\n",
      "Epoch 355/1000\n",
      "541/541 [==============================] - 0s 606us/step - loss: 25.5214 - mae: 25.5214 - mse: 4236.5210 - accuracy: 0.5802 - val_loss: 20.1358 - val_mae: 20.1358 - val_mse: 2569.4355 - val_accuracy: 0.5915\n",
      "Epoch 356/1000\n",
      "541/541 [==============================] - 0s 590us/step - loss: 24.5317 - mae: 24.5317 - mse: 3898.6487 - accuracy: 0.5800 - val_loss: 20.2266 - val_mae: 20.2266 - val_mse: 2566.8694 - val_accuracy: 0.5920\n",
      "Epoch 357/1000\n",
      "541/541 [==============================] - 0s 592us/step - loss: 25.1401 - mae: 25.1401 - mse: 4351.0757 - accuracy: 0.5815 - val_loss: 19.9100 - val_mae: 19.9100 - val_mse: 2583.2170 - val_accuracy: 0.5920\n",
      "Epoch 358/1000\n",
      "541/541 [==============================] - 0s 632us/step - loss: 24.9124 - mae: 24.9124 - mse: 4086.0188 - accuracy: 0.5803 - val_loss: 21.1073 - val_mae: 21.1073 - val_mse: 2720.2437 - val_accuracy: 0.5922\n",
      "Epoch 359/1000\n",
      "541/541 [==============================] - 0s 600us/step - loss: 24.7919 - mae: 24.7919 - mse: 4020.1208 - accuracy: 0.5790 - val_loss: 19.9528 - val_mae: 19.9528 - val_mse: 2567.7063 - val_accuracy: 0.5906\n",
      "Epoch 360/1000\n",
      "541/541 [==============================] - 0s 588us/step - loss: 24.9429 - mae: 24.9429 - mse: 4053.1179 - accuracy: 0.5801 - val_loss: 20.2728 - val_mae: 20.2728 - val_mse: 2576.8398 - val_accuracy: 0.5906\n",
      "Epoch 361/1000\n",
      "541/541 [==============================] - 0s 620us/step - loss: 25.1203 - mae: 25.1203 - mse: 4188.6816 - accuracy: 0.5805 - val_loss: 20.5199 - val_mae: 20.5199 - val_mse: 2621.3491 - val_accuracy: 0.5918\n",
      "Epoch 362/1000\n",
      "541/541 [==============================] - 0s 603us/step - loss: 24.6071 - mae: 24.6071 - mse: 3968.2258 - accuracy: 0.5802 - val_loss: 19.8644 - val_mae: 19.8644 - val_mse: 2541.0615 - val_accuracy: 0.5915\n",
      "Epoch 363/1000\n",
      "541/541 [==============================] - 0s 592us/step - loss: 25.1645 - mae: 25.1645 - mse: 4156.5381 - accuracy: 0.5800 - val_loss: 20.1287 - val_mae: 20.1287 - val_mse: 2580.7400 - val_accuracy: 0.5936\n",
      "Epoch 364/1000\n",
      "541/541 [==============================] - 0s 585us/step - loss: 24.9557 - mae: 24.9557 - mse: 4065.5664 - accuracy: 0.5803 - val_loss: 20.2689 - val_mae: 20.2689 - val_mse: 2589.3210 - val_accuracy: 0.5931\n",
      "Epoch 365/1000\n",
      "541/541 [==============================] - 0s 631us/step - loss: 25.5180 - mae: 25.5180 - mse: 4597.3574 - accuracy: 0.5809 - val_loss: 19.9893 - val_mae: 19.9893 - val_mse: 2592.4819 - val_accuracy: 0.5931\n",
      "Epoch 366/1000\n",
      "541/541 [==============================] - 0s 584us/step - loss: 25.0595 - mae: 25.0595 - mse: 4121.6367 - accuracy: 0.5812 - val_loss: 20.9215 - val_mae: 20.9215 - val_mse: 2701.9658 - val_accuracy: 0.5929\n",
      "Epoch 367/1000\n",
      "541/541 [==============================] - 0s 593us/step - loss: 24.7381 - mae: 24.7381 - mse: 3985.3022 - accuracy: 0.5803 - val_loss: 20.5801 - val_mae: 20.5801 - val_mse: 2624.4102 - val_accuracy: 0.5911\n",
      "Epoch 368/1000\n",
      "541/541 [==============================] - 0s 626us/step - loss: 25.5227 - mae: 25.5227 - mse: 4220.6411 - accuracy: 0.5800 - val_loss: 20.1189 - val_mae: 20.1189 - val_mse: 2577.0032 - val_accuracy: 0.5922\n",
      "Epoch 369/1000\n",
      "541/541 [==============================] - 0s 606us/step - loss: 24.9168 - mae: 24.9168 - mse: 4047.9163 - accuracy: 0.5807 - val_loss: 20.2038 - val_mae: 20.2038 - val_mse: 2610.7053 - val_accuracy: 0.5929\n",
      "Epoch 370/1000\n",
      "541/541 [==============================] - 0s 596us/step - loss: 24.7554 - mae: 24.7554 - mse: 3999.8589 - accuracy: 0.5802 - val_loss: 20.0259 - val_mae: 20.0259 - val_mse: 2617.8721 - val_accuracy: 0.5922\n",
      "Epoch 371/1000\n",
      "541/541 [==============================] - 0s 592us/step - loss: 25.1417 - mae: 25.1417 - mse: 4089.7271 - accuracy: 0.5806 - val_loss: 20.0892 - val_mae: 20.0892 - val_mse: 2606.8945 - val_accuracy: 0.5922\n",
      "Epoch 372/1000\n",
      "541/541 [==============================] - 0s 634us/step - loss: 24.9226 - mae: 24.9226 - mse: 4148.7783 - accuracy: 0.5805 - val_loss: 20.2454 - val_mae: 20.2454 - val_mse: 2681.9424 - val_accuracy: 0.5918\n",
      "Epoch 373/1000\n",
      "541/541 [==============================] - 0s 594us/step - loss: 25.2292 - mae: 25.2292 - mse: 4232.4297 - accuracy: 0.5797 - val_loss: 20.0550 - val_mae: 20.0550 - val_mse: 2562.3677 - val_accuracy: 0.5918\n",
      "Epoch 374/1000\n",
      "541/541 [==============================] - 0s 588us/step - loss: 24.8781 - mae: 24.8781 - mse: 4056.0486 - accuracy: 0.5808 - val_loss: 20.6666 - val_mae: 20.6666 - val_mse: 2640.0476 - val_accuracy: 0.5913\n",
      "Epoch 375/1000\n",
      "541/541 [==============================] - 0s 588us/step - loss: 25.3363 - mae: 25.3363 - mse: 4115.0762 - accuracy: 0.5797 - val_loss: 20.5389 - val_mae: 20.5389 - val_mse: 2621.6929 - val_accuracy: 0.5922\n",
      "Epoch 376/1000\n",
      "541/541 [==============================] - 0s 635us/step - loss: 25.0106 - mae: 25.0106 - mse: 4147.7812 - accuracy: 0.5802 - val_loss: 20.5323 - val_mae: 20.5323 - val_mse: 2614.5073 - val_accuracy: 0.5922\n",
      "Epoch 377/1000\n",
      "541/541 [==============================] - 0s 586us/step - loss: 24.9888 - mae: 24.9888 - mse: 4081.2175 - accuracy: 0.5801 - val_loss: 21.3908 - val_mae: 21.3908 - val_mse: 2797.0776 - val_accuracy: 0.5920\n",
      "Epoch 378/1000\n",
      "541/541 [==============================] - 0s 589us/step - loss: 25.1643 - mae: 25.1643 - mse: 4225.5830 - accuracy: 0.5808 - val_loss: 20.6639 - val_mae: 20.6639 - val_mse: 2622.9663 - val_accuracy: 0.5911\n",
      "Epoch 379/1000\n",
      "541/541 [==============================] - 0s 606us/step - loss: 24.7928 - mae: 24.7928 - mse: 4048.9517 - accuracy: 0.5797 - val_loss: 20.0194 - val_mae: 20.0194 - val_mse: 2605.7739 - val_accuracy: 0.5922\n",
      "Epoch 380/1000\n",
      "541/541 [==============================] - 0s 624us/step - loss: 25.0662 - mae: 25.0662 - mse: 4156.5557 - accuracy: 0.5800 - val_loss: 20.1749 - val_mae: 20.1749 - val_mse: 2568.1802 - val_accuracy: 0.5915\n",
      "Epoch 381/1000\n",
      "541/541 [==============================] - 0s 599us/step - loss: 25.0695 - mae: 25.0695 - mse: 4131.5967 - accuracy: 0.5804 - val_loss: 20.5219 - val_mae: 20.5219 - val_mse: 2616.9644 - val_accuracy: 0.5927\n",
      "Epoch 382/1000\n",
      "541/541 [==============================] - 0s 607us/step - loss: 25.0421 - mae: 25.0421 - mse: 4067.2695 - accuracy: 0.5790 - val_loss: 20.0724 - val_mae: 20.0724 - val_mse: 2593.3699 - val_accuracy: 0.5913\n",
      "Epoch 383/1000\n",
      "541/541 [==============================] - 0s 620us/step - loss: 25.0974 - mae: 25.0974 - mse: 4167.6924 - accuracy: 0.5806 - val_loss: 20.9150 - val_mae: 20.9150 - val_mse: 2690.3176 - val_accuracy: 0.5908\n",
      "Epoch 384/1000\n",
      "541/541 [==============================] - 0s 596us/step - loss: 24.6575 - mae: 24.6575 - mse: 3967.9712 - accuracy: 0.5800 - val_loss: 21.0171 - val_mae: 21.0171 - val_mse: 2688.6443 - val_accuracy: 0.5906\n",
      "Epoch 385/1000\n",
      "541/541 [==============================] - 0s 594us/step - loss: 24.8605 - mae: 24.8605 - mse: 4093.0869 - accuracy: 0.5788 - val_loss: 20.0294 - val_mae: 20.0294 - val_mse: 2557.2671 - val_accuracy: 0.5908\n",
      "Epoch 386/1000\n",
      "541/541 [==============================] - 0s 603us/step - loss: 24.6547 - mae: 24.6547 - mse: 3936.7727 - accuracy: 0.5816 - val_loss: 21.5860 - val_mae: 21.5860 - val_mse: 2837.1558 - val_accuracy: 0.5927\n",
      "Epoch 387/1000\n",
      "541/541 [==============================] - 0s 612us/step - loss: 25.0115 - mae: 25.0115 - mse: 4058.0571 - accuracy: 0.5800 - val_loss: 20.5128 - val_mae: 20.5128 - val_mse: 2626.9485 - val_accuracy: 0.5915\n",
      "Epoch 388/1000\n",
      "541/541 [==============================] - 0s 589us/step - loss: 24.8472 - mae: 24.8472 - mse: 4148.3115 - accuracy: 0.5797 - val_loss: 20.2690 - val_mae: 20.2690 - val_mse: 2574.9773 - val_accuracy: 0.5911\n",
      "Epoch 389/1000\n",
      "541/541 [==============================] - 0s 605us/step - loss: 25.3912 - mae: 25.3912 - mse: 4227.5439 - accuracy: 0.5798 - val_loss: 20.8420 - val_mae: 20.8420 - val_mse: 2688.9165 - val_accuracy: 0.5906\n",
      "Epoch 390/1000\n",
      "541/541 [==============================] - 0s 593us/step - loss: 25.1417 - mae: 25.1417 - mse: 4152.1382 - accuracy: 0.5785 - val_loss: 19.9631 - val_mae: 19.9631 - val_mse: 2556.4399 - val_accuracy: 0.5918\n",
      "Epoch 391/1000\n",
      "541/541 [==============================] - 0s 620us/step - loss: 24.7752 - mae: 24.7752 - mse: 4034.8894 - accuracy: 0.5803 - val_loss: 20.2209 - val_mae: 20.2209 - val_mse: 2589.1689 - val_accuracy: 0.5915\n",
      "Epoch 392/1000\n",
      "541/541 [==============================] - 0s 602us/step - loss: 24.7339 - mae: 24.7339 - mse: 3990.7415 - accuracy: 0.5792 - val_loss: 19.9349 - val_mae: 19.9349 - val_mse: 2574.3328 - val_accuracy: 0.5915\n",
      "Epoch 393/1000\n",
      "541/541 [==============================] - 0s 592us/step - loss: 24.9738 - mae: 24.9738 - mse: 4092.3352 - accuracy: 0.5796 - val_loss: 20.5590 - val_mae: 20.5590 - val_mse: 2648.4153 - val_accuracy: 0.5915\n",
      "Epoch 394/1000\n",
      "541/541 [==============================] - 0s 590us/step - loss: 25.0100 - mae: 25.0100 - mse: 4041.3286 - accuracy: 0.5787 - val_loss: 20.0194 - val_mae: 20.0194 - val_mse: 2548.0249 - val_accuracy: 0.5918\n",
      "Epoch 395/1000\n",
      "541/541 [==============================] - 0s 630us/step - loss: 24.9510 - mae: 24.9510 - mse: 4067.8755 - accuracy: 0.5796 - val_loss: 20.6564 - val_mae: 20.6564 - val_mse: 2643.0918 - val_accuracy: 0.5915\n",
      "Epoch 396/1000\n",
      "541/541 [==============================] - 0s 588us/step - loss: 24.9910 - mae: 24.9910 - mse: 4133.6084 - accuracy: 0.5801 - val_loss: 20.1273 - val_mae: 20.1273 - val_mse: 2583.1125 - val_accuracy: 0.5915\n",
      "Epoch 397/1000\n",
      "541/541 [==============================] - 0s 593us/step - loss: 25.2609 - mae: 25.2609 - mse: 4352.8506 - accuracy: 0.5796 - val_loss: 20.7429 - val_mae: 20.7429 - val_mse: 2686.6343 - val_accuracy: 0.5920\n",
      "Epoch 398/1000\n",
      "541/541 [==============================] - 0s 606us/step - loss: 25.0513 - mae: 25.0513 - mse: 4122.0366 - accuracy: 0.5792 - val_loss: 19.9443 - val_mae: 19.9443 - val_mse: 2612.9355 - val_accuracy: 0.5920\n",
      "Epoch 399/1000\n",
      "541/541 [==============================] - 0s 617us/step - loss: 24.8247 - mae: 24.8247 - mse: 4020.5208 - accuracy: 0.5787 - val_loss: 20.1023 - val_mae: 20.1023 - val_mse: 2574.7141 - val_accuracy: 0.5906\n",
      "Epoch 400/1000\n",
      "541/541 [==============================] - 0s 594us/step - loss: 25.1181 - mae: 25.1181 - mse: 4611.8032 - accuracy: 0.5779 - val_loss: 20.0075 - val_mae: 20.0075 - val_mse: 2586.1221 - val_accuracy: 0.5908\n",
      "Epoch 401/1000\n",
      "541/541 [==============================] - 0s 609us/step - loss: 24.8130 - mae: 24.8130 - mse: 4012.7681 - accuracy: 0.5770 - val_loss: 21.8939 - val_mae: 21.8939 - val_mse: 2902.5383 - val_accuracy: 0.5913\n",
      "Epoch 402/1000\n",
      "541/541 [==============================] - 0s 626us/step - loss: 24.9073 - mae: 24.9073 - mse: 4352.6675 - accuracy: 0.5772 - val_loss: 20.4518 - val_mae: 20.4518 - val_mse: 2601.8333 - val_accuracy: 0.5906\n",
      "Epoch 403/1000\n",
      "541/541 [==============================] - 0s 591us/step - loss: 24.8260 - mae: 24.8260 - mse: 4082.3748 - accuracy: 0.5782 - val_loss: 20.9713 - val_mae: 20.9713 - val_mse: 2676.7683 - val_accuracy: 0.5904\n",
      "Epoch 404/1000\n",
      "541/541 [==============================] - 0s 613us/step - loss: 25.0433 - mae: 25.0433 - mse: 4158.4111 - accuracy: 0.5789 - val_loss: 20.1062 - val_mae: 20.1062 - val_mse: 2571.4453 - val_accuracy: 0.5906\n",
      "Epoch 405/1000\n",
      "541/541 [==============================] - 0s 587us/step - loss: 24.6680 - mae: 24.6680 - mse: 3956.0393 - accuracy: 0.5788 - val_loss: 20.0916 - val_mae: 20.0916 - val_mse: 2609.0869 - val_accuracy: 0.5915\n",
      "Epoch 406/1000\n",
      "541/541 [==============================] - 0s 619us/step - loss: 25.0149 - mae: 25.0149 - mse: 4054.0793 - accuracy: 0.5783 - val_loss: 19.9224 - val_mae: 19.9224 - val_mse: 2587.5413 - val_accuracy: 0.5915\n",
      "Epoch 407/1000\n",
      "541/541 [==============================] - 0s 603us/step - loss: 24.7510 - mae: 24.7510 - mse: 4030.1335 - accuracy: 0.5789 - val_loss: 20.2900 - val_mae: 20.2900 - val_mse: 2604.2542 - val_accuracy: 0.5922\n",
      "Epoch 408/1000\n",
      "541/541 [==============================] - 0s 588us/step - loss: 24.8725 - mae: 24.8725 - mse: 4011.0945 - accuracy: 0.5793 - val_loss: 19.9305 - val_mae: 19.9305 - val_mse: 2583.4246 - val_accuracy: 0.5908\n",
      "Epoch 409/1000\n",
      "541/541 [==============================] - 0s 590us/step - loss: 24.7328 - mae: 24.7328 - mse: 4010.6433 - accuracy: 0.5793 - val_loss: 21.9343 - val_mae: 21.9343 - val_mse: 2923.3638 - val_accuracy: 0.5915\n",
      "Epoch 410/1000\n",
      "541/541 [==============================] - 0s 644us/step - loss: 24.8090 - mae: 24.8090 - mse: 4005.8364 - accuracy: 0.5789 - val_loss: 20.2578 - val_mae: 20.2578 - val_mse: 2574.7288 - val_accuracy: 0.5904\n",
      "Epoch 411/1000\n",
      "541/541 [==============================] - 0s 592us/step - loss: 24.6668 - mae: 24.6668 - mse: 3960.5725 - accuracy: 0.5778 - val_loss: 19.9359 - val_mae: 19.9359 - val_mse: 2581.1956 - val_accuracy: 0.5908\n",
      "Epoch 412/1000\n",
      "541/541 [==============================] - 0s 592us/step - loss: 24.4518 - mae: 24.4518 - mse: 3866.8018 - accuracy: 0.5784 - val_loss: 20.2943 - val_mae: 20.2943 - val_mse: 2583.0259 - val_accuracy: 0.5913\n",
      "Epoch 413/1000\n",
      "541/541 [==============================] - 0s 636us/step - loss: 24.9556 - mae: 24.9556 - mse: 4057.3892 - accuracy: 0.5786 - val_loss: 20.0923 - val_mae: 20.0923 - val_mse: 2565.9192 - val_accuracy: 0.5915\n",
      "Epoch 414/1000\n",
      "541/541 [==============================] - 0s 589us/step - loss: 24.8131 - mae: 24.8131 - mse: 4019.2561 - accuracy: 0.5797 - val_loss: 20.3505 - val_mae: 20.3505 - val_mse: 2591.3757 - val_accuracy: 0.5918\n",
      "Epoch 415/1000\n",
      "541/541 [==============================] - 0s 588us/step - loss: 24.5383 - mae: 24.5383 - mse: 3888.1663 - accuracy: 0.5786 - val_loss: 20.2505 - val_mae: 20.2505 - val_mse: 2573.7478 - val_accuracy: 0.5913\n",
      "Epoch 416/1000\n",
      "541/541 [==============================] - 0s 632us/step - loss: 24.7836 - mae: 24.7836 - mse: 4035.5352 - accuracy: 0.5792 - val_loss: 20.3645 - val_mae: 20.3645 - val_mse: 2610.9673 - val_accuracy: 0.5913\n",
      "Epoch 417/1000\n",
      "541/541 [==============================] - 0s 596us/step - loss: 25.0829 - mae: 25.0829 - mse: 4153.3110 - accuracy: 0.5797 - val_loss: 20.8453 - val_mae: 20.8453 - val_mse: 2699.9084 - val_accuracy: 0.5913\n",
      "Epoch 418/1000\n",
      "541/541 [==============================] - 0s 592us/step - loss: 24.9811 - mae: 24.9811 - mse: 4113.3052 - accuracy: 0.5792 - val_loss: 20.5276 - val_mae: 20.5276 - val_mse: 2617.1182 - val_accuracy: 0.5920\n",
      "Epoch 419/1000\n",
      "541/541 [==============================] - 0s 609us/step - loss: 24.8622 - mae: 24.8622 - mse: 4060.2217 - accuracy: 0.5802 - val_loss: 21.6971 - val_mae: 21.6971 - val_mse: 2845.5793 - val_accuracy: 0.5915\n",
      "Epoch 420/1000\n",
      "541/541 [==============================] - 0s 621us/step - loss: 24.8903 - mae: 24.8903 - mse: 4124.4404 - accuracy: 0.5797 - val_loss: 20.2258 - val_mae: 20.2258 - val_mse: 2570.7600 - val_accuracy: 0.5915\n",
      "Epoch 421/1000\n",
      "541/541 [==============================] - 0s 594us/step - loss: 24.9548 - mae: 24.9548 - mse: 4111.3994 - accuracy: 0.5800 - val_loss: 20.5246 - val_mae: 20.5246 - val_mse: 2625.2717 - val_accuracy: 0.5918\n",
      "Epoch 422/1000\n",
      "541/541 [==============================] - 0s 606us/step - loss: 25.0201 - mae: 25.0201 - mse: 4128.6841 - accuracy: 0.5790 - val_loss: 19.8745 - val_mae: 19.8745 - val_mse: 2551.2542 - val_accuracy: 0.5927\n",
      "Epoch 423/1000\n",
      "541/541 [==============================] - 0s 616us/step - loss: 25.0379 - mae: 25.0379 - mse: 4046.5410 - accuracy: 0.5813 - val_loss: 19.9905 - val_mae: 19.9905 - val_mse: 2579.9548 - val_accuracy: 0.5918\n",
      "Epoch 424/1000\n",
      "541/541 [==============================] - 0s 598us/step - loss: 25.0914 - mae: 25.0914 - mse: 4080.8508 - accuracy: 0.5789 - val_loss: 19.9553 - val_mae: 19.9553 - val_mse: 2541.7622 - val_accuracy: 0.5918\n",
      "Epoch 425/1000\n",
      "541/541 [==============================] - 0s 605us/step - loss: 24.7826 - mae: 24.7826 - mse: 4071.3459 - accuracy: 0.5800 - val_loss: 20.1784 - val_mae: 20.1784 - val_mse: 2584.3774 - val_accuracy: 0.5922\n",
      "Epoch 426/1000\n",
      "541/541 [==============================] - 0s 630us/step - loss: 25.0687 - mae: 25.0687 - mse: 4066.7510 - accuracy: 0.5805 - val_loss: 20.1567 - val_mae: 20.1567 - val_mse: 2573.7083 - val_accuracy: 0.5927\n",
      "Epoch 427/1000\n",
      "541/541 [==============================] - 0s 593us/step - loss: 24.5593 - mae: 24.5593 - mse: 3965.3022 - accuracy: 0.5801 - val_loss: 19.8774 - val_mae: 19.8774 - val_mse: 2583.8416 - val_accuracy: 0.5920\n",
      "Epoch 428/1000\n",
      "541/541 [==============================] - 0s 613us/step - loss: 24.6681 - mae: 24.6681 - mse: 4069.4722 - accuracy: 0.5794 - val_loss: 19.9467 - val_mae: 19.9467 - val_mse: 2568.6489 - val_accuracy: 0.5918\n",
      "Epoch 429/1000\n",
      "541/541 [==============================] - 0s 597us/step - loss: 24.8759 - mae: 24.8759 - mse: 4033.1299 - accuracy: 0.5804 - val_loss: 20.1576 - val_mae: 20.1576 - val_mse: 2578.9299 - val_accuracy: 0.5913\n",
      "Epoch 430/1000\n",
      "541/541 [==============================] - 0s 622us/step - loss: 24.6832 - mae: 24.6832 - mse: 3993.7466 - accuracy: 0.5808 - val_loss: 20.1306 - val_mae: 20.1306 - val_mse: 2568.1636 - val_accuracy: 0.5920\n",
      "Epoch 431/1000\n",
      "541/541 [==============================] - 0s 606us/step - loss: 24.7920 - mae: 24.7920 - mse: 4055.6538 - accuracy: 0.5802 - val_loss: 20.0405 - val_mae: 20.0405 - val_mse: 2592.0933 - val_accuracy: 0.5920\n",
      "Epoch 432/1000\n",
      "541/541 [==============================] - 0s 595us/step - loss: 24.4123 - mae: 24.4123 - mse: 3896.6323 - accuracy: 0.5792 - val_loss: 20.0102 - val_mae: 20.0102 - val_mse: 2570.2173 - val_accuracy: 0.5922\n",
      "Epoch 433/1000\n",
      "541/541 [==============================] - 0s 590us/step - loss: 24.8299 - mae: 24.8299 - mse: 4036.7109 - accuracy: 0.5803 - val_loss: 20.1015 - val_mae: 20.1015 - val_mse: 2574.3511 - val_accuracy: 0.5922\n",
      "Epoch 434/1000\n",
      "541/541 [==============================] - 0s 643us/step - loss: 24.5797 - mae: 24.5797 - mse: 3935.7788 - accuracy: 0.5797 - val_loss: 20.2518 - val_mae: 20.2518 - val_mse: 2600.3892 - val_accuracy: 0.5915\n",
      "Epoch 435/1000\n",
      "541/541 [==============================] - 0s 601us/step - loss: 24.7303 - mae: 24.7303 - mse: 3953.2175 - accuracy: 0.5798 - val_loss: 20.3501 - val_mae: 20.3501 - val_mse: 2582.0173 - val_accuracy: 0.5908\n",
      "Epoch 436/1000\n",
      "541/541 [==============================] - 0s 596us/step - loss: 24.7792 - mae: 24.7792 - mse: 4046.1270 - accuracy: 0.5798 - val_loss: 20.1291 - val_mae: 20.1291 - val_mse: 2568.2190 - val_accuracy: 0.5897\n",
      "Epoch 437/1000\n",
      "541/541 [==============================] - 0s 642us/step - loss: 24.4820 - mae: 24.4820 - mse: 3938.1934 - accuracy: 0.5781 - val_loss: 20.6885 - val_mae: 20.6885 - val_mse: 2632.2461 - val_accuracy: 0.5894\n",
      "Epoch 438/1000\n",
      "541/541 [==============================] - 0s 595us/step - loss: 25.1382 - mae: 25.1382 - mse: 4101.6479 - accuracy: 0.5792 - val_loss: 19.9587 - val_mae: 19.9587 - val_mse: 2573.5361 - val_accuracy: 0.5913\n",
      "Epoch 439/1000\n",
      "541/541 [==============================] - 0s 609us/step - loss: 25.0937 - mae: 25.0937 - mse: 4112.8677 - accuracy: 0.5789 - val_loss: 20.8843 - val_mae: 20.8843 - val_mse: 2686.3933 - val_accuracy: 0.5925\n",
      "Epoch 440/1000\n",
      "541/541 [==============================] - 0s 618us/step - loss: 24.7486 - mae: 24.7486 - mse: 3984.9360 - accuracy: 0.5815 - val_loss: 20.0700 - val_mae: 20.0700 - val_mse: 2613.2239 - val_accuracy: 0.5922\n",
      "Epoch 441/1000\n",
      "541/541 [==============================] - 0s 599us/step - loss: 24.8249 - mae: 24.8249 - mse: 4006.0405 - accuracy: 0.5804 - val_loss: 20.0898 - val_mae: 20.0898 - val_mse: 2558.3210 - val_accuracy: 0.5927\n",
      "Epoch 442/1000\n",
      "541/541 [==============================] - 0s 610us/step - loss: 24.5359 - mae: 24.5359 - mse: 3899.3992 - accuracy: 0.5802 - val_loss: 20.0930 - val_mae: 20.0930 - val_mse: 2572.7910 - val_accuracy: 0.5931\n",
      "Epoch 443/1000\n",
      "541/541 [==============================] - 0s 627us/step - loss: 24.2640 - mae: 24.2640 - mse: 3812.4590 - accuracy: 0.5802 - val_loss: 20.0517 - val_mae: 20.0517 - val_mse: 2557.2874 - val_accuracy: 0.5922\n",
      "Epoch 444/1000\n",
      "541/541 [==============================] - 0s 590us/step - loss: 25.0224 - mae: 25.0224 - mse: 4131.2485 - accuracy: 0.5808 - val_loss: 20.0530 - val_mae: 20.0530 - val_mse: 2530.3760 - val_accuracy: 0.5934\n",
      "Epoch 445/1000\n",
      "541/541 [==============================] - 0s 608us/step - loss: 24.4822 - mae: 24.4822 - mse: 3915.9514 - accuracy: 0.5806 - val_loss: 20.1853 - val_mae: 20.1853 - val_mse: 2556.5217 - val_accuracy: 0.5922\n",
      "Epoch 446/1000\n",
      "541/541 [==============================] - 0s 592us/step - loss: 24.6034 - mae: 24.6034 - mse: 3978.8821 - accuracy: 0.5812 - val_loss: 19.9447 - val_mae: 19.9447 - val_mse: 2528.3848 - val_accuracy: 0.5922\n",
      "Epoch 447/1000\n",
      "541/541 [==============================] - 0s 624us/step - loss: 24.7521 - mae: 24.7521 - mse: 4034.2678 - accuracy: 0.5802 - val_loss: 20.3864 - val_mae: 20.3864 - val_mse: 2618.5137 - val_accuracy: 0.5906\n",
      "Epoch 448/1000\n",
      "541/541 [==============================] - 0s 610us/step - loss: 24.6205 - mae: 24.6205 - mse: 3976.1726 - accuracy: 0.5790 - val_loss: 19.9792 - val_mae: 19.9792 - val_mse: 2560.6650 - val_accuracy: 0.5915\n",
      "Epoch 449/1000\n",
      "541/541 [==============================] - 0s 594us/step - loss: 25.2952 - mae: 25.2952 - mse: 4208.3096 - accuracy: 0.5798 - val_loss: 20.4032 - val_mae: 20.4032 - val_mse: 2583.2161 - val_accuracy: 0.5918\n",
      "Epoch 450/1000\n",
      "541/541 [==============================] - 0s 625us/step - loss: 24.4846 - mae: 24.4846 - mse: 3905.3901 - accuracy: 0.5803 - val_loss: 20.1418 - val_mae: 20.1418 - val_mse: 2589.1721 - val_accuracy: 0.5906\n",
      "Epoch 451/1000\n",
      "541/541 [==============================] - 0s 608us/step - loss: 24.9188 - mae: 24.9188 - mse: 3982.9414 - accuracy: 0.5787 - val_loss: 20.2455 - val_mae: 20.2455 - val_mse: 2577.5950 - val_accuracy: 0.5911\n",
      "Epoch 452/1000\n",
      "541/541 [==============================] - 0s 598us/step - loss: 24.7680 - mae: 24.7680 - mse: 4031.5227 - accuracy: 0.5793 - val_loss: 20.5643 - val_mae: 20.5643 - val_mse: 2617.9248 - val_accuracy: 0.5918\n",
      "Epoch 453/1000\n",
      "541/541 [==============================] - 0s 611us/step - loss: 24.8944 - mae: 24.8944 - mse: 4069.2146 - accuracy: 0.5801 - val_loss: 20.2631 - val_mae: 20.2631 - val_mse: 2568.7253 - val_accuracy: 0.5920\n",
      "Epoch 454/1000\n",
      "541/541 [==============================] - 0s 623us/step - loss: 24.8355 - mae: 24.8355 - mse: 4061.1365 - accuracy: 0.5792 - val_loss: 20.1042 - val_mae: 20.1042 - val_mse: 2571.9700 - val_accuracy: 0.5906\n",
      "Epoch 455/1000\n",
      "541/541 [==============================] - 0s 596us/step - loss: 25.0772 - mae: 25.0772 - mse: 4110.2412 - accuracy: 0.5803 - val_loss: 20.9168 - val_mae: 20.9168 - val_mse: 2678.1240 - val_accuracy: 0.5913\n",
      "Epoch 456/1000\n",
      "541/541 [==============================] - 0s 613us/step - loss: 24.2882 - mae: 24.2882 - mse: 3852.3906 - accuracy: 0.5796 - val_loss: 19.9554 - val_mae: 19.9554 - val_mse: 2546.9590 - val_accuracy: 0.5925\n",
      "Epoch 457/1000\n",
      "541/541 [==============================] - 0s 624us/step - loss: 24.6023 - mae: 24.6023 - mse: 3966.7463 - accuracy: 0.5810 - val_loss: 20.2987 - val_mae: 20.2987 - val_mse: 2580.4368 - val_accuracy: 0.5922\n",
      "Epoch 458/1000\n",
      "541/541 [==============================] - 0s 599us/step - loss: 24.6632 - mae: 24.6632 - mse: 4013.3655 - accuracy: 0.5794 - val_loss: 20.7917 - val_mae: 20.7917 - val_mse: 2667.1980 - val_accuracy: 0.5931\n",
      "Epoch 459/1000\n",
      "541/541 [==============================] - 0s 612us/step - loss: 24.9949 - mae: 24.9949 - mse: 4031.0913 - accuracy: 0.5804 - val_loss: 19.9706 - val_mae: 19.9706 - val_mse: 2593.0381 - val_accuracy: 0.5927\n",
      "Epoch 460/1000\n",
      "541/541 [==============================] - 0s 706us/step - loss: 24.9847 - mae: 24.9847 - mse: 4018.1868 - accuracy: 0.5796 - val_loss: 20.3282 - val_mae: 20.3282 - val_mse: 2607.4341 - val_accuracy: 0.5934\n",
      "Epoch 461/1000\n",
      "541/541 [==============================] - 0s 612us/step - loss: 24.7871 - mae: 24.7871 - mse: 4023.4028 - accuracy: 0.5794 - val_loss: 20.2306 - val_mae: 20.2306 - val_mse: 2571.0601 - val_accuracy: 0.5925\n",
      "Epoch 462/1000\n",
      "541/541 [==============================] - 0s 600us/step - loss: 24.7669 - mae: 24.7669 - mse: 4013.8809 - accuracy: 0.5814 - val_loss: 20.2745 - val_mae: 20.2745 - val_mse: 2590.7188 - val_accuracy: 0.5931\n"
     ]
    }
   ],
   "source": [
    "model_c = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.InputLayer(input_shape=54),\n",
    "    #ak.MultiCategoryEncoding(encoding=['int','int','int','int','none','none','none','none','none',\n",
    "    #                                   'none','none','none','none','none','int','int','int','int',\n",
    "    #                                   'int','none','int','none','none','int','int','none','none',\n",
    "    #                                   'int','int','int','int','none','none','int','none','none',\n",
    "    #                                   'none','int','int','int','int','int','int','none','none',\n",
    "    #                                   'int','int','int','int','int','int','int','int']),\n",
    "    normalizer_C, \n",
    "    tf.keras.layers.Dense(32, activation='linear'),\n",
    "    tf.keras.layers.ReLU(),\n",
    "    tf.keras.layers.Dropout(0.25),\n",
    "    tf.keras.layers.Dense(32, activation='linear'),\n",
    "    tf.keras.layers.ReLU(),\n",
    "    tf.keras.layers.Dropout(0.25),\n",
    "    tf.keras.layers.Dropout(0.25),\n",
    "    tf.keras.layers.Dense(1)\n",
    "])\n",
    "\n",
    "model_c.compile(optimizer=tf.keras.optimizers.RMSprop(learning_rate=0.001), \n",
    "                loss=\"mae\", \n",
    "                metrics=[\"mae\", \"mse\", 'accuracy'])\n",
    "\n",
    "history_c = model_c.fit(x=x_train_c, y=y_train_c, epochs=1000, callbacks=[early_stop], validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "139/139 [==============================] - 0s 462us/step - loss: 20.9895 - mae: 20.9895 - mse: 2860.6399 - accuracy: 0.5944\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[20.989486694335938, 20.989486694335938, 2860.639892578125, 0.594350278377533]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_c.evaluate(x_val_c, y_val_c)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Seems like `C` and `B` can utilize same model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "1155/1155 [==============================] - 2s 2ms/step - loss: 8577.5303 - mae: 38.2884 - mse: 8577.5303 - accuracy: 0.4473 - val_loss: 4700.8291 - val_mae: 29.5693 - val_mse: 4700.8291 - val_accuracy: 0.4485\n",
      "Epoch 2/1000\n",
      "1155/1155 [==============================] - 2s 1ms/step - loss: 6793.8525 - mae: 34.3520 - mse: 6793.8525 - accuracy: 0.4038 - val_loss: 4807.6777 - val_mae: 28.6058 - val_mse: 4807.6777 - val_accuracy: 0.3445\n",
      "Epoch 3/1000\n",
      "1155/1155 [==============================] - 2s 2ms/step - loss: 6504.5742 - mae: 33.4531 - mse: 6504.5742 - accuracy: 0.2085 - val_loss: 4983.7480 - val_mae: 28.5085 - val_mse: 4983.7480 - val_accuracy: 0.1510\n",
      "Epoch 4/1000\n",
      "1155/1155 [==============================] - 2s 1ms/step - loss: 6475.0308 - mae: 33.2066 - mse: 6475.0308 - accuracy: 0.1663 - val_loss: 5101.8428 - val_mae: 28.1440 - val_mse: 5101.8428 - val_accuracy: 0.1326\n",
      "Epoch 5/1000\n",
      "1155/1155 [==============================] - 2s 1ms/step - loss: 6592.3984 - mae: 33.4765 - mse: 6592.3984 - accuracy: 0.1789 - val_loss: 5412.1162 - val_mae: 27.6647 - val_mse: 5412.1162 - val_accuracy: 0.0776\n",
      "Epoch 6/1000\n",
      "1155/1155 [==============================] - 2s 1ms/step - loss: 6560.7539 - mae: 33.4509 - mse: 6560.7539 - accuracy: 0.1750 - val_loss: 5757.7583 - val_mae: 27.6416 - val_mse: 5757.7583 - val_accuracy: 0.1021\n",
      "Epoch 7/1000\n",
      "1155/1155 [==============================] - 2s 1ms/step - loss: 6552.1489 - mae: 33.4166 - mse: 6552.1489 - accuracy: 0.1563 - val_loss: 6004.4795 - val_mae: 27.3655 - val_mse: 6004.4795 - val_accuracy: 0.0470\n",
      "Epoch 8/1000\n",
      "1155/1155 [==============================] - 2s 2ms/step - loss: 6488.2505 - mae: 33.3816 - mse: 6488.2505 - accuracy: 0.1521 - val_loss: 6276.2471 - val_mae: 28.0523 - val_mse: 6276.2471 - val_accuracy: 0.0395\n",
      "Epoch 9/1000\n",
      "1155/1155 [==============================] - 2s 1ms/step - loss: 6396.2173 - mae: 33.0514 - mse: 6396.2173 - accuracy: 0.1700 - val_loss: 6378.6709 - val_mae: 27.9461 - val_mse: 6378.6709 - val_accuracy: 0.0663\n",
      "Epoch 10/1000\n",
      "1155/1155 [==============================] - 2s 1ms/step - loss: 6340.6704 - mae: 33.0965 - mse: 6340.6704 - accuracy: 0.1768 - val_loss: 7007.0361 - val_mae: 28.0180 - val_mse: 7007.0361 - val_accuracy: 0.1376\n",
      "Epoch 11/1000\n",
      "1155/1155 [==============================] - 2s 2ms/step - loss: 6435.2222 - mae: 33.2061 - mse: 6435.2222 - accuracy: 0.1903 - val_loss: 6932.2012 - val_mae: 28.7310 - val_mse: 6932.2012 - val_accuracy: 0.0462\n",
      "Epoch 12/1000\n",
      "1155/1155 [==============================] - 2s 1ms/step - loss: 6447.0742 - mae: 33.1221 - mse: 6447.0742 - accuracy: 0.1887 - val_loss: 7285.6782 - val_mae: 28.4530 - val_mse: 7285.6782 - val_accuracy: 0.1043\n",
      "Epoch 13/1000\n",
      "1155/1155 [==============================] - 2s 1ms/step - loss: 6276.5239 - mae: 32.6079 - mse: 6276.5239 - accuracy: 0.1948 - val_loss: 7029.6235 - val_mae: 28.0966 - val_mse: 7029.6235 - val_accuracy: 0.0742\n",
      "Epoch 14/1000\n",
      "1155/1155 [==============================] - 2s 1ms/step - loss: 6317.8599 - mae: 32.9209 - mse: 6317.8599 - accuracy: 0.1915 - val_loss: 7557.8228 - val_mae: 27.0152 - val_mse: 7557.8228 - val_accuracy: 0.1274\n",
      "Epoch 15/1000\n",
      "1155/1155 [==============================] - 2s 1ms/step - loss: 6266.4146 - mae: 32.7991 - mse: 6266.4146 - accuracy: 0.1938 - val_loss: 8018.0630 - val_mae: 28.8744 - val_mse: 8018.0630 - val_accuracy: 0.0707\n",
      "Epoch 16/1000\n",
      "1155/1155 [==============================] - 2s 2ms/step - loss: 6233.8530 - mae: 32.8489 - mse: 6233.8530 - accuracy: 0.1914 - val_loss: 7952.8525 - val_mae: 28.4268 - val_mse: 7952.8525 - val_accuracy: 0.0732\n",
      "Epoch 17/1000\n",
      "1155/1155 [==============================] - 2s 1ms/step - loss: 6138.1255 - mae: 32.5688 - mse: 6138.1255 - accuracy: 0.1917 - val_loss: 7782.1216 - val_mae: 27.4416 - val_mse: 7782.1216 - val_accuracy: 0.0461\n",
      "Epoch 18/1000\n",
      "1155/1155 [==============================] - 2s 1ms/step - loss: 6234.1235 - mae: 32.7773 - mse: 6234.1235 - accuracy: 0.1929 - val_loss: 8008.7563 - val_mae: 26.6117 - val_mse: 8008.7563 - val_accuracy: 0.0606\n",
      "Epoch 19/1000\n",
      "1155/1155 [==============================] - 2s 1ms/step - loss: 6109.9121 - mae: 32.7189 - mse: 6109.9121 - accuracy: 0.1928 - val_loss: 8108.0020 - val_mae: 26.7283 - val_mse: 8108.0020 - val_accuracy: 0.0505\n",
      "Epoch 20/1000\n",
      "1155/1155 [==============================] - 2s 1ms/step - loss: 6180.7925 - mae: 32.7254 - mse: 6180.7925 - accuracy: 0.1906 - val_loss: 8478.4180 - val_mae: 27.8206 - val_mse: 8478.4180 - val_accuracy: 0.0470\n",
      "Epoch 21/1000\n",
      "1155/1155 [==============================] - 2s 2ms/step - loss: 6236.6875 - mae: 32.9179 - mse: 6236.6875 - accuracy: 0.1886 - val_loss: 8171.2300 - val_mae: 27.9473 - val_mse: 8171.2300 - val_accuracy: 0.0859\n",
      "Epoch 22/1000\n",
      "1155/1155 [==============================] - 2s 1ms/step - loss: 6057.4419 - mae: 32.6334 - mse: 6057.4419 - accuracy: 0.1895 - val_loss: 7940.8325 - val_mae: 27.5633 - val_mse: 7940.8325 - val_accuracy: 0.0661\n",
      "Epoch 23/1000\n",
      "1155/1155 [==============================] - 2s 1ms/step - loss: 6102.2988 - mae: 32.7555 - mse: 6102.2988 - accuracy: 0.1913 - val_loss: 8249.0947 - val_mae: 27.5829 - val_mse: 8249.0947 - val_accuracy: 0.0918\n",
      "Epoch 24/1000\n",
      "1155/1155 [==============================] - 2s 2ms/step - loss: 6141.1260 - mae: 32.9790 - mse: 6141.1260 - accuracy: 0.1926 - val_loss: 8500.7275 - val_mae: 27.2261 - val_mse: 8500.7275 - val_accuracy: 0.0656\n",
      "Epoch 25/1000\n",
      "1155/1155 [==============================] - 2s 1ms/step - loss: 5961.4351 - mae: 32.7309 - mse: 5961.4351 - accuracy: 0.1920 - val_loss: 8756.4775 - val_mae: 26.4418 - val_mse: 8756.4775 - val_accuracy: 0.0965\n",
      "Epoch 26/1000\n",
      "1155/1155 [==============================] - 2s 1ms/step - loss: 5937.7207 - mae: 32.5943 - mse: 5937.7207 - accuracy: 0.1940 - val_loss: 8902.5225 - val_mae: 27.2385 - val_mse: 8902.5225 - val_accuracy: 0.1074\n",
      "Epoch 27/1000\n",
      "1155/1155 [==============================] - 2s 1ms/step - loss: 5979.1890 - mae: 32.6184 - mse: 5979.1890 - accuracy: 0.1926 - val_loss: 9429.0352 - val_mae: 27.1683 - val_mse: 9429.0352 - val_accuracy: 0.0673\n",
      "Epoch 28/1000\n",
      "1155/1155 [==============================] - 2s 2ms/step - loss: 5954.4531 - mae: 32.5614 - mse: 5954.4531 - accuracy: 0.1925 - val_loss: 9046.4307 - val_mae: 27.0487 - val_mse: 9046.4307 - val_accuracy: 0.0334\n",
      "Epoch 29/1000\n",
      "1155/1155 [==============================] - 2s 1ms/step - loss: 5972.9751 - mae: 32.7908 - mse: 5972.9751 - accuracy: 0.1953 - val_loss: 9286.5752 - val_mae: 26.9755 - val_mse: 9286.5752 - val_accuracy: 0.1777\n",
      "Epoch 30/1000\n",
      "1155/1155 [==============================] - 2s 1ms/step - loss: 6070.9956 - mae: 32.9844 - mse: 6070.9956 - accuracy: 0.1937 - val_loss: 9660.7949 - val_mae: 27.4372 - val_mse: 9660.7949 - val_accuracy: 0.0199\n",
      "Epoch 31/1000\n",
      "1155/1155 [==============================] - 2s 1ms/step - loss: 6017.8906 - mae: 32.8581 - mse: 6017.8906 - accuracy: 0.1940 - val_loss: 9917.6240 - val_mae: 27.0881 - val_mse: 9917.6240 - val_accuracy: 0.0943\n",
      "Epoch 32/1000\n",
      "1155/1155 [==============================] - 2s 2ms/step - loss: 5803.2998 - mae: 32.5654 - mse: 5803.2998 - accuracy: 0.1968 - val_loss: 9845.6631 - val_mae: 26.7678 - val_mse: 9845.6631 - val_accuracy: 0.0729\n",
      "Epoch 33/1000\n",
      "1155/1155 [==============================] - 2s 1ms/step - loss: 6082.6841 - mae: 33.1371 - mse: 6082.6841 - accuracy: 0.1941 - val_loss: 9432.1982 - val_mae: 27.0644 - val_mse: 9432.1982 - val_accuracy: 0.0070\n",
      "Epoch 34/1000\n",
      "1155/1155 [==============================] - 2s 1ms/step - loss: 5870.8535 - mae: 32.6367 - mse: 5870.8535 - accuracy: 0.1934 - val_loss: 9698.0449 - val_mae: 26.4673 - val_mse: 9698.0449 - val_accuracy: 0.0886\n",
      "Epoch 35/1000\n",
      "1155/1155 [==============================] - 2s 1ms/step - loss: 6039.9707 - mae: 33.1367 - mse: 6039.9707 - accuracy: 0.1962 - val_loss: 9202.2627 - val_mae: 26.7483 - val_mse: 9202.2627 - val_accuracy: 0.0090\n",
      "Epoch 36/1000\n",
      "1155/1155 [==============================] - 2s 1ms/step - loss: 5832.3062 - mae: 32.7054 - mse: 5832.3062 - accuracy: 0.1956 - val_loss: 10356.3184 - val_mae: 28.9775 - val_mse: 10356.3184 - val_accuracy: 0.0112\n",
      "Epoch 37/1000\n",
      "1155/1155 [==============================] - 2s 1ms/step - loss: 5894.9253 - mae: 32.7978 - mse: 5894.9253 - accuracy: 0.1949 - val_loss: 10587.9375 - val_mae: 26.7560 - val_mse: 10587.9375 - val_accuracy: 0.0195\n",
      "Epoch 38/1000\n",
      "1155/1155 [==============================] - 2s 1ms/step - loss: 5855.3384 - mae: 32.9145 - mse: 5855.3384 - accuracy: 0.1945 - val_loss: 9635.2139 - val_mae: 26.1008 - val_mse: 9635.2139 - val_accuracy: 0.1124\n",
      "Epoch 39/1000\n",
      "1155/1155 [==============================] - 2s 2ms/step - loss: 5908.6470 - mae: 32.9294 - mse: 5908.6470 - accuracy: 0.1928 - val_loss: 9443.5430 - val_mae: 27.6442 - val_mse: 9443.5430 - val_accuracy: 0.0105\n",
      "Epoch 40/1000\n",
      "1155/1155 [==============================] - 2s 1ms/step - loss: 5821.4160 - mae: 32.9155 - mse: 5821.4160 - accuracy: 0.1968 - val_loss: 9139.0830 - val_mae: 27.4380 - val_mse: 9139.0830 - val_accuracy: 0.0293\n",
      "Epoch 41/1000\n",
      "1155/1155 [==============================] - 2s 1ms/step - loss: 5914.0483 - mae: 33.0114 - mse: 5914.0483 - accuracy: 0.1937 - val_loss: 8553.1055 - val_mae: 26.9511 - val_mse: 8553.1055 - val_accuracy: 0.1284\n",
      "Epoch 42/1000\n",
      "1155/1155 [==============================] - 2s 1ms/step - loss: 5823.7163 - mae: 32.8062 - mse: 5823.7163 - accuracy: 0.1965 - val_loss: 8993.3340 - val_mae: 27.5100 - val_mse: 8993.3340 - val_accuracy: 0.0238\n",
      "Epoch 43/1000\n",
      "1155/1155 [==============================] - 2s 1ms/step - loss: 5827.0850 - mae: 32.9962 - mse: 5827.0850 - accuracy: 0.1943 - val_loss: 8826.7988 - val_mae: 28.6185 - val_mse: 8826.7988 - val_accuracy: 0.0479\n",
      "Epoch 44/1000\n",
      "1155/1155 [==============================] - 2s 1ms/step - loss: 5889.9199 - mae: 33.0707 - mse: 5889.9199 - accuracy: 0.1945 - val_loss: 8992.5889 - val_mae: 26.7498 - val_mse: 8992.5889 - val_accuracy: 0.0368\n",
      "Epoch 45/1000\n",
      "1155/1155 [==============================] - 2s 1ms/step - loss: 5655.1826 - mae: 32.6180 - mse: 5655.1826 - accuracy: 0.1963 - val_loss: 8966.4150 - val_mae: 27.0379 - val_mse: 8966.4150 - val_accuracy: 0.0047\n",
      "Epoch 46/1000\n",
      "1155/1155 [==============================] - 2s 1ms/step - loss: 5686.9741 - mae: 32.9982 - mse: 5686.9741 - accuracy: 0.1970 - val_loss: 9191.5615 - val_mae: 26.8167 - val_mse: 9191.5615 - val_accuracy: 0.0047\n",
      "Epoch 47/1000\n",
      "1155/1155 [==============================] - 2s 1ms/step - loss: 5699.8872 - mae: 32.8499 - mse: 5699.8872 - accuracy: 0.1937 - val_loss: 8098.1650 - val_mae: 26.1948 - val_mse: 8098.1650 - val_accuracy: 0.0858\n",
      "Epoch 48/1000\n",
      "1155/1155 [==============================] - 2s 1ms/step - loss: 5691.1133 - mae: 32.9036 - mse: 5691.1133 - accuracy: 0.1962 - val_loss: 8307.0859 - val_mae: 27.6357 - val_mse: 8307.0859 - val_accuracy: 0.0216\n",
      "Epoch 49/1000\n",
      "1155/1155 [==============================] - 2s 1ms/step - loss: 5566.9165 - mae: 32.7177 - mse: 5566.9165 - accuracy: 0.1978 - val_loss: 9150.1465 - val_mae: 27.0989 - val_mse: 9150.1465 - val_accuracy: 0.0194\n",
      "Epoch 50/1000\n",
      "1155/1155 [==============================] - 2s 2ms/step - loss: 5697.4067 - mae: 33.1098 - mse: 5697.4067 - accuracy: 0.1944 - val_loss: 8344.3389 - val_mae: 26.9687 - val_mse: 8344.3389 - val_accuracy: 0.0153\n",
      "Epoch 51/1000\n",
      "1155/1155 [==============================] - 2s 2ms/step - loss: 5656.1401 - mae: 33.0762 - mse: 5656.1401 - accuracy: 0.1957 - val_loss: 9217.0879 - val_mae: 30.9918 - val_mse: 9217.0879 - val_accuracy: 7.5807e-04\n",
      "Epoch 52/1000\n",
      "1155/1155 [==============================] - 2s 1ms/step - loss: 5657.7729 - mae: 32.9726 - mse: 5657.7729 - accuracy: 0.1949 - val_loss: 9066.7090 - val_mae: 27.6680 - val_mse: 9066.7090 - val_accuracy: 0.0011\n",
      "Epoch 53/1000\n",
      "1155/1155 [==============================] - 2s 2ms/step - loss: 5575.1162 - mae: 32.9077 - mse: 5575.1162 - accuracy: 0.1954 - val_loss: 8730.6270 - val_mae: 26.3940 - val_mse: 8730.6270 - val_accuracy: 0.0547\n",
      "Epoch 54/1000\n",
      "1155/1155 [==============================] - 2s 1ms/step - loss: 5756.6567 - mae: 33.1568 - mse: 5756.6567 - accuracy: 0.1927 - val_loss: 8495.5010 - val_mae: 28.1873 - val_mse: 8495.5010 - val_accuracy: 0.0122\n",
      "Epoch 55/1000\n",
      "1155/1155 [==============================] - 2s 1ms/step - loss: 5747.5347 - mae: 33.2765 - mse: 5747.5347 - accuracy: 0.1962 - val_loss: 8185.0239 - val_mae: 28.5610 - val_mse: 8185.0239 - val_accuracy: 0.0126\n",
      "Epoch 56/1000\n",
      "1155/1155 [==============================] - 2s 1ms/step - loss: 5800.3545 - mae: 33.5109 - mse: 5800.3545 - accuracy: 0.1958 - val_loss: 7620.7285 - val_mae: 25.7885 - val_mse: 7620.7285 - val_accuracy: 0.0820\n",
      "Epoch 57/1000\n",
      "1155/1155 [==============================] - 2s 2ms/step - loss: 5763.5630 - mae: 33.3602 - mse: 5763.5630 - accuracy: 0.1963 - val_loss: 7896.8491 - val_mae: 27.5796 - val_mse: 7896.8491 - val_accuracy: 0.0107\n",
      "Epoch 58/1000\n",
      "1155/1155 [==============================] - 2s 1ms/step - loss: 5680.7080 - mae: 33.3405 - mse: 5680.7080 - accuracy: 0.1937 - val_loss: 6871.0386 - val_mae: 26.1641 - val_mse: 6871.0386 - val_accuracy: 0.0572\n",
      "Epoch 59/1000\n",
      "1155/1155 [==============================] - 2s 2ms/step - loss: 5681.8892 - mae: 33.4717 - mse: 5681.8892 - accuracy: 0.1989 - val_loss: 7019.7539 - val_mae: 27.5961 - val_mse: 7019.7539 - val_accuracy: 0.0134\n",
      "Epoch 60/1000\n",
      "1155/1155 [==============================] - 2s 2ms/step - loss: 5641.0332 - mae: 33.3767 - mse: 5641.0332 - accuracy: 0.1971 - val_loss: 7341.7710 - val_mae: 26.4907 - val_mse: 7341.7710 - val_accuracy: 0.0197\n",
      "Epoch 61/1000\n",
      "1155/1155 [==============================] - 2s 1ms/step - loss: 5721.0713 - mae: 33.6459 - mse: 5721.0713 - accuracy: 0.1979 - val_loss: 7656.4204 - val_mae: 28.4409 - val_mse: 7656.4204 - val_accuracy: 0.0018\n",
      "Epoch 62/1000\n",
      "1155/1155 [==============================] - 2s 2ms/step - loss: 5587.8066 - mae: 33.5311 - mse: 5587.8066 - accuracy: 0.1956 - val_loss: 7058.3765 - val_mae: 27.3448 - val_mse: 7058.3765 - val_accuracy: 0.0144\n",
      "Epoch 63/1000\n",
      "1155/1155 [==============================] - 2s 2ms/step - loss: 5703.9287 - mae: 33.7636 - mse: 5703.9287 - accuracy: 0.1980 - val_loss: 7128.3398 - val_mae: 26.0868 - val_mse: 7128.3398 - val_accuracy: 0.0436\n",
      "Epoch 64/1000\n",
      "1155/1155 [==============================] - 2s 1ms/step - loss: 5619.9170 - mae: 33.4890 - mse: 5619.9170 - accuracy: 0.1948 - val_loss: 7285.9155 - val_mae: 25.9877 - val_mse: 7285.9155 - val_accuracy: 0.0675\n",
      "Epoch 65/1000\n",
      "1155/1155 [==============================] - 2s 2ms/step - loss: 5580.8301 - mae: 33.5994 - mse: 5580.8301 - accuracy: 0.1948 - val_loss: 6974.4399 - val_mae: 27.2022 - val_mse: 6974.4399 - val_accuracy: 0.0029\n",
      "Epoch 66/1000\n",
      "1155/1155 [==============================] - 2s 1ms/step - loss: 5610.2866 - mae: 33.6815 - mse: 5610.2866 - accuracy: 0.1945 - val_loss: 7369.2119 - val_mae: 30.3054 - val_mse: 7369.2119 - val_accuracy: 0.0094\n",
      "Epoch 67/1000\n",
      "1155/1155 [==============================] - 2s 1ms/step - loss: 5714.4028 - mae: 33.7314 - mse: 5714.4028 - accuracy: 0.1988 - val_loss: 7102.8730 - val_mae: 27.5194 - val_mse: 7102.8730 - val_accuracy: 0.0019\n",
      "Epoch 68/1000\n",
      "1155/1155 [==============================] - 2s 1ms/step - loss: 5607.5503 - mae: 33.6138 - mse: 5607.5503 - accuracy: 0.1999 - val_loss: 6872.6450 - val_mae: 26.6176 - val_mse: 6872.6450 - val_accuracy: 0.0262\n",
      "Epoch 69/1000\n",
      "1155/1155 [==============================] - 2s 1ms/step - loss: 5651.4961 - mae: 33.8279 - mse: 5651.4961 - accuracy: 0.1959 - val_loss: 6917.7041 - val_mae: 26.7354 - val_mse: 6917.7041 - val_accuracy: 0.0099\n",
      "Epoch 70/1000\n",
      "1155/1155 [==============================] - 2s 1ms/step - loss: 5571.5757 - mae: 33.5098 - mse: 5571.5757 - accuracy: 0.1953 - val_loss: 7046.2520 - val_mae: 29.4606 - val_mse: 7046.2520 - val_accuracy: 0.0014\n",
      "Epoch 71/1000\n",
      "1155/1155 [==============================] - 2s 1ms/step - loss: 5627.6343 - mae: 33.6507 - mse: 5627.6343 - accuracy: 0.1973 - val_loss: 7243.3560 - val_mae: 27.6645 - val_mse: 7243.3560 - val_accuracy: 0.0145\n",
      "Epoch 72/1000\n",
      "1155/1155 [==============================] - 2s 1ms/step - loss: 5471.3882 - mae: 33.4628 - mse: 5471.3882 - accuracy: 0.1958 - val_loss: 6982.3276 - val_mae: 27.9768 - val_mse: 6982.3276 - val_accuracy: 0.0070\n",
      "Epoch 73/1000\n",
      "1155/1155 [==============================] - 2s 1ms/step - loss: 5485.1133 - mae: 33.5111 - mse: 5485.1133 - accuracy: 0.1967 - val_loss: 6327.2207 - val_mae: 26.1010 - val_mse: 6327.2207 - val_accuracy: 0.0199\n",
      "Epoch 74/1000\n",
      "1155/1155 [==============================] - 2s 1ms/step - loss: 5502.3345 - mae: 33.5895 - mse: 5502.3345 - accuracy: 0.1962 - val_loss: 6472.0747 - val_mae: 26.0480 - val_mse: 6472.0747 - val_accuracy: 0.0226\n",
      "Epoch 75/1000\n",
      "1155/1155 [==============================] - 2s 1ms/step - loss: 5479.3555 - mae: 33.6982 - mse: 5479.3555 - accuracy: 0.1970 - val_loss: 6462.4727 - val_mae: 27.3230 - val_mse: 6462.4727 - val_accuracy: 0.0092\n",
      "Epoch 76/1000\n",
      "1155/1155 [==============================] - 2s 1ms/step - loss: 5352.8618 - mae: 33.3521 - mse: 5352.8618 - accuracy: 0.1980 - val_loss: 6351.9097 - val_mae: 26.0927 - val_mse: 6351.9097 - val_accuracy: 0.0332\n",
      "Epoch 77/1000\n",
      "1155/1155 [==============================] - 2s 1ms/step - loss: 5428.3276 - mae: 33.6005 - mse: 5428.3276 - accuracy: 0.1964 - val_loss: 6209.9097 - val_mae: 28.1097 - val_mse: 6209.9097 - val_accuracy: 0.0015\n",
      "Epoch 78/1000\n",
      "1155/1155 [==============================] - 2s 1ms/step - loss: 5559.6714 - mae: 33.7551 - mse: 5559.6714 - accuracy: 0.1969 - val_loss: 5912.0640 - val_mae: 26.8129 - val_mse: 5912.0640 - val_accuracy: 0.0533\n",
      "Epoch 79/1000\n",
      "1155/1155 [==============================] - 2s 1ms/step - loss: 5348.9575 - mae: 33.4812 - mse: 5348.9575 - accuracy: 0.1965 - val_loss: 6114.6475 - val_mae: 28.2976 - val_mse: 6114.6475 - val_accuracy: 0.0172\n",
      "Epoch 80/1000\n",
      "1155/1155 [==============================] - 2s 1ms/step - loss: 5465.2104 - mae: 33.7456 - mse: 5465.2104 - accuracy: 0.1968 - val_loss: 5740.9644 - val_mae: 26.3566 - val_mse: 5740.9644 - val_accuracy: 0.0145\n",
      "Epoch 81/1000\n",
      "1155/1155 [==============================] - 2s 1ms/step - loss: 5486.5127 - mae: 33.9260 - mse: 5486.5127 - accuracy: 0.1984 - val_loss: 6105.1812 - val_mae: 29.9070 - val_mse: 6105.1812 - val_accuracy: 1.0830e-04\n",
      "Epoch 82/1000\n",
      "1155/1155 [==============================] - 2s 1ms/step - loss: 5494.4658 - mae: 33.7361 - mse: 5494.4658 - accuracy: 0.1977 - val_loss: 5789.7725 - val_mae: 26.5034 - val_mse: 5789.7725 - val_accuracy: 0.0114\n",
      "Epoch 83/1000\n",
      "1155/1155 [==============================] - 2s 1ms/step - loss: 5681.7021 - mae: 33.9307 - mse: 5681.7021 - accuracy: 0.2020 - val_loss: 5278.9600 - val_mae: 26.8320 - val_mse: 5278.9600 - val_accuracy: 0.0241\n",
      "Epoch 84/1000\n",
      "1155/1155 [==============================] - 2s 1ms/step - loss: 5545.4053 - mae: 33.7203 - mse: 5545.4053 - accuracy: 0.2004 - val_loss: 5688.6890 - val_mae: 26.1114 - val_mse: 5688.6890 - val_accuracy: 0.0096\n",
      "Epoch 85/1000\n",
      "1155/1155 [==============================] - 2s 1ms/step - loss: 5515.2871 - mae: 33.7135 - mse: 5515.2871 - accuracy: 0.1995 - val_loss: 5702.7388 - val_mae: 27.5270 - val_mse: 5702.7388 - val_accuracy: 5.4148e-04\n",
      "Epoch 86/1000\n",
      "1155/1155 [==============================] - 2s 1ms/step - loss: 5375.4487 - mae: 33.3656 - mse: 5375.4487 - accuracy: 0.1997 - val_loss: 5862.9146 - val_mae: 28.6864 - val_mse: 5862.9146 - val_accuracy: 0.0067\n",
      "Epoch 87/1000\n",
      "1155/1155 [==============================] - 2s 1ms/step - loss: 5524.1597 - mae: 33.7661 - mse: 5524.1597 - accuracy: 0.2030 - val_loss: 5373.6265 - val_mae: 27.8899 - val_mse: 5373.6265 - val_accuracy: 0.0040\n",
      "Epoch 88/1000\n",
      "1155/1155 [==============================] - 2s 1ms/step - loss: 5476.5244 - mae: 33.8074 - mse: 5476.5244 - accuracy: 0.1996 - val_loss: 5129.9199 - val_mae: 26.9313 - val_mse: 5129.9199 - val_accuracy: 0.0055\n",
      "Epoch 89/1000\n",
      "1155/1155 [==============================] - 2s 1ms/step - loss: 5438.5391 - mae: 33.7806 - mse: 5438.5391 - accuracy: 0.2009 - val_loss: 5610.3042 - val_mae: 27.9257 - val_mse: 5610.3042 - val_accuracy: 0.0029\n",
      "Epoch 90/1000\n",
      "1155/1155 [==============================] - 2s 1ms/step - loss: 5570.8486 - mae: 33.9698 - mse: 5570.8486 - accuracy: 0.2016 - val_loss: 5249.5142 - val_mae: 26.4850 - val_mse: 5249.5142 - val_accuracy: 0.0043\n",
      "Epoch 91/1000\n",
      "1155/1155 [==============================] - 2s 1ms/step - loss: 5506.5674 - mae: 33.9739 - mse: 5506.5674 - accuracy: 0.2009 - val_loss: 5324.5972 - val_mae: 27.2272 - val_mse: 5324.5972 - val_accuracy: 0.0026\n",
      "Epoch 92/1000\n",
      "1155/1155 [==============================] - 2s 1ms/step - loss: 5469.0479 - mae: 33.8218 - mse: 5469.0479 - accuracy: 0.2003 - val_loss: 5130.8291 - val_mae: 26.4522 - val_mse: 5130.8291 - val_accuracy: 0.0125\n",
      "Epoch 93/1000\n",
      "1155/1155 [==============================] - 2s 1ms/step - loss: 5358.4639 - mae: 33.7376 - mse: 5358.4639 - accuracy: 0.2024 - val_loss: 4825.1611 - val_mae: 26.3129 - val_mse: 4825.1611 - val_accuracy: 0.0023\n",
      "Epoch 94/1000\n",
      "1155/1155 [==============================] - 2s 1ms/step - loss: 5349.4258 - mae: 33.7885 - mse: 5349.4258 - accuracy: 0.2001 - val_loss: 4777.3657 - val_mae: 26.5436 - val_mse: 4777.3657 - val_accuracy: 0.0247\n",
      "Epoch 95/1000\n",
      "1155/1155 [==============================] - 2s 1ms/step - loss: 5365.1255 - mae: 33.6525 - mse: 5365.1255 - accuracy: 0.2013 - val_loss: 5136.5830 - val_mae: 28.0036 - val_mse: 5136.5830 - val_accuracy: 0.0066\n",
      "Epoch 96/1000\n",
      "1155/1155 [==============================] - 2s 1ms/step - loss: 5401.4126 - mae: 33.7718 - mse: 5401.4126 - accuracy: 0.1987 - val_loss: 4830.6401 - val_mae: 26.2845 - val_mse: 4830.6401 - val_accuracy: 0.0038\n",
      "Epoch 97/1000\n",
      "1155/1155 [==============================] - 2s 1ms/step - loss: 5403.9453 - mae: 33.9157 - mse: 5403.9453 - accuracy: 0.2004 - val_loss: 4711.5161 - val_mae: 26.5142 - val_mse: 4711.5161 - val_accuracy: 0.0218\n",
      "Epoch 98/1000\n",
      "1155/1155 [==============================] - 2s 1ms/step - loss: 5563.0317 - mae: 34.0886 - mse: 5563.0317 - accuracy: 0.2017 - val_loss: 5104.8252 - val_mae: 28.8518 - val_mse: 5104.8252 - val_accuracy: 0.0024\n",
      "Epoch 99/1000\n",
      "1155/1155 [==============================] - 2s 2ms/step - loss: 5414.8647 - mae: 33.7441 - mse: 5414.8647 - accuracy: 0.2014 - val_loss: 5248.0288 - val_mae: 28.4877 - val_mse: 5248.0288 - val_accuracy: 0.0863\n",
      "Epoch 100/1000\n",
      "1155/1155 [==============================] - 2s 1ms/step - loss: 5493.6084 - mae: 34.0541 - mse: 5493.6084 - accuracy: 0.2016 - val_loss: 4666.7197 - val_mae: 27.1873 - val_mse: 4666.7197 - val_accuracy: 0.0012\n",
      "Epoch 101/1000\n",
      "1155/1155 [==============================] - 2s 1ms/step - loss: 5418.3032 - mae: 33.9283 - mse: 5418.3032 - accuracy: 0.2026 - val_loss: 4663.4526 - val_mae: 26.9204 - val_mse: 4663.4526 - val_accuracy: 0.0087\n",
      "Epoch 102/1000\n",
      "1155/1155 [==============================] - 2s 1ms/step - loss: 5330.5796 - mae: 33.9273 - mse: 5330.5796 - accuracy: 0.2023 - val_loss: 4481.5332 - val_mae: 26.1014 - val_mse: 4481.5332 - val_accuracy: 0.0112\n",
      "Epoch 103/1000\n",
      "1155/1155 [==============================] - 2s 1ms/step - loss: 5257.6846 - mae: 33.8770 - mse: 5257.6846 - accuracy: 0.2017 - val_loss: 4497.5781 - val_mae: 27.4993 - val_mse: 4497.5781 - val_accuracy: 0.0013\n",
      "Epoch 104/1000\n",
      "1155/1155 [==============================] - 2s 1ms/step - loss: 5409.5195 - mae: 34.0607 - mse: 5409.5195 - accuracy: 0.2024 - val_loss: 4445.9028 - val_mae: 25.2785 - val_mse: 4445.9028 - val_accuracy: 0.0473\n",
      "Epoch 105/1000\n",
      "1155/1155 [==============================] - 2s 1ms/step - loss: 5304.6582 - mae: 33.8780 - mse: 5304.6582 - accuracy: 0.2025 - val_loss: 4799.0166 - val_mae: 28.5846 - val_mse: 4799.0166 - val_accuracy: 0.0025\n",
      "Epoch 106/1000\n",
      "1155/1155 [==============================] - 2s 1ms/step - loss: 5271.2300 - mae: 33.8451 - mse: 5271.2300 - accuracy: 0.2021 - val_loss: 4561.8760 - val_mae: 26.5699 - val_mse: 4561.8760 - val_accuracy: 0.0592\n",
      "Epoch 107/1000\n",
      "1155/1155 [==============================] - 2s 1ms/step - loss: 5295.1953 - mae: 33.9048 - mse: 5295.1953 - accuracy: 0.2006 - val_loss: 4322.3066 - val_mae: 27.9017 - val_mse: 4322.3066 - val_accuracy: 0.0070\n",
      "Epoch 108/1000\n",
      "1155/1155 [==============================] - 2s 1ms/step - loss: 5405.7729 - mae: 34.2020 - mse: 5405.7729 - accuracy: 0.2021 - val_loss: 4169.1816 - val_mae: 26.0429 - val_mse: 4169.1816 - val_accuracy: 0.0116\n",
      "Epoch 109/1000\n",
      "1155/1155 [==============================] - 2s 2ms/step - loss: 5289.5542 - mae: 34.1030 - mse: 5289.5542 - accuracy: 0.2016 - val_loss: 4238.1450 - val_mae: 26.4612 - val_mse: 4238.1450 - val_accuracy: 0.0071\n",
      "Epoch 110/1000\n",
      "1155/1155 [==============================] - 2s 1ms/step - loss: 5438.4810 - mae: 34.4274 - mse: 5438.4810 - accuracy: 0.2003 - val_loss: 4603.8945 - val_mae: 28.1245 - val_mse: 4603.8945 - val_accuracy: 0.0082\n",
      "Epoch 111/1000\n",
      "1155/1155 [==============================] - 2s 1ms/step - loss: 5396.8467 - mae: 34.0899 - mse: 5396.8467 - accuracy: 0.2018 - val_loss: 4857.3574 - val_mae: 28.9068 - val_mse: 4857.3574 - val_accuracy: 0.0048\n",
      "Epoch 112/1000\n",
      "1155/1155 [==============================] - 2s 1ms/step - loss: 5304.9810 - mae: 34.0772 - mse: 5304.9810 - accuracy: 0.1999 - val_loss: 4117.1558 - val_mae: 26.4419 - val_mse: 4117.1558 - val_accuracy: 0.0107\n",
      "Epoch 113/1000\n",
      "1155/1155 [==============================] - 2s 1ms/step - loss: 5321.7466 - mae: 34.2545 - mse: 5321.7466 - accuracy: 0.1984 - val_loss: 4424.0713 - val_mae: 27.1039 - val_mse: 4424.0713 - val_accuracy: 0.0298\n",
      "Epoch 114/1000\n",
      "1155/1155 [==============================] - 2s 1ms/step - loss: 5344.5654 - mae: 34.2424 - mse: 5344.5654 - accuracy: 0.2016 - val_loss: 4412.9004 - val_mae: 26.3989 - val_mse: 4412.9004 - val_accuracy: 0.0468\n",
      "Epoch 115/1000\n",
      "1155/1155 [==============================] - 2s 1ms/step - loss: 5306.7627 - mae: 34.1784 - mse: 5306.7627 - accuracy: 0.2021 - val_loss: 4219.6909 - val_mae: 27.7235 - val_mse: 4219.6909 - val_accuracy: 0.0051\n",
      "Epoch 116/1000\n",
      "1155/1155 [==============================] - 2s 1ms/step - loss: 5416.4570 - mae: 34.4411 - mse: 5416.4570 - accuracy: 0.2029 - val_loss: 4447.8989 - val_mae: 26.9126 - val_mse: 4447.8989 - val_accuracy: 0.0068\n",
      "Epoch 117/1000\n",
      "1155/1155 [==============================] - 2s 1ms/step - loss: 5162.5884 - mae: 33.9593 - mse: 5162.5884 - accuracy: 0.2009 - val_loss: 4199.8672 - val_mae: 25.5448 - val_mse: 4199.8672 - val_accuracy: 0.0446\n",
      "Epoch 118/1000\n",
      "1155/1155 [==============================] - 2s 1ms/step - loss: 5190.8462 - mae: 33.8715 - mse: 5190.8462 - accuracy: 0.2015 - val_loss: 4248.6963 - val_mae: 26.9401 - val_mse: 4248.6963 - val_accuracy: 0.0056\n",
      "Epoch 119/1000\n",
      "1155/1155 [==============================] - 2s 1ms/step - loss: 5217.8604 - mae: 33.9315 - mse: 5217.8604 - accuracy: 0.2025 - val_loss: 4176.3677 - val_mae: 27.2358 - val_mse: 4176.3677 - val_accuracy: 0.0087\n",
      "Epoch 120/1000\n",
      "1155/1155 [==============================] - 2s 1ms/step - loss: 5272.9048 - mae: 34.2483 - mse: 5272.9048 - accuracy: 0.2029 - val_loss: 4005.9453 - val_mae: 25.9212 - val_mse: 4005.9453 - val_accuracy: 0.0174\n",
      "Epoch 121/1000\n",
      "1155/1155 [==============================] - 2s 1ms/step - loss: 5142.3848 - mae: 33.9922 - mse: 5142.3848 - accuracy: 0.2039 - val_loss: 4030.7173 - val_mae: 27.1324 - val_mse: 4030.7173 - val_accuracy: 6.4977e-04\n",
      "Epoch 122/1000\n",
      "1155/1155 [==============================] - 2s 1ms/step - loss: 5115.9570 - mae: 33.8342 - mse: 5115.9570 - accuracy: 0.2007 - val_loss: 3980.8533 - val_mae: 25.6415 - val_mse: 3980.8533 - val_accuracy: 0.0448\n",
      "Epoch 123/1000\n",
      "1155/1155 [==============================] - 2s 1ms/step - loss: 5082.5825 - mae: 34.0385 - mse: 5082.5825 - accuracy: 0.2019 - val_loss: 4021.3091 - val_mae: 26.0571 - val_mse: 4021.3091 - val_accuracy: 0.0074\n",
      "Epoch 124/1000\n",
      "1155/1155 [==============================] - 2s 1ms/step - loss: 5361.2554 - mae: 34.5502 - mse: 5361.2554 - accuracy: 0.1999 - val_loss: 4440.4380 - val_mae: 27.9299 - val_mse: 4440.4380 - val_accuracy: 0.0028\n",
      "Epoch 125/1000\n",
      "1155/1155 [==============================] - 2s 1ms/step - loss: 5275.7939 - mae: 34.4205 - mse: 5275.7939 - accuracy: 0.2029 - val_loss: 4220.2466 - val_mae: 27.8069 - val_mse: 4220.2466 - val_accuracy: 0.0045\n",
      "Epoch 126/1000\n",
      "1155/1155 [==============================] - 2s 1ms/step - loss: 5184.8125 - mae: 34.2253 - mse: 5184.8125 - accuracy: 0.2020 - val_loss: 4048.3445 - val_mae: 25.7193 - val_mse: 4048.3445 - val_accuracy: 0.0194\n",
      "Epoch 127/1000\n",
      "1155/1155 [==============================] - 2s 1ms/step - loss: 5278.1348 - mae: 34.4267 - mse: 5278.1348 - accuracy: 0.2030 - val_loss: 4082.9929 - val_mae: 26.3952 - val_mse: 4082.9929 - val_accuracy: 0.0041\n",
      "Epoch 128/1000\n",
      "1155/1155 [==============================] - 2s 1ms/step - loss: 5213.5762 - mae: 34.3405 - mse: 5213.5762 - accuracy: 0.2003 - val_loss: 4182.3291 - val_mae: 26.9701 - val_mse: 4182.3291 - val_accuracy: 0.0043\n",
      "Epoch 129/1000\n",
      "1155/1155 [==============================] - 2s 1ms/step - loss: 5094.8159 - mae: 33.9033 - mse: 5094.8159 - accuracy: 0.2012 - val_loss: 4092.6746 - val_mae: 25.9055 - val_mse: 4092.6746 - val_accuracy: 0.0146\n",
      "Epoch 130/1000\n",
      "1155/1155 [==============================] - 2s 1ms/step - loss: 5265.7710 - mae: 34.4042 - mse: 5265.7710 - accuracy: 0.2007 - val_loss: 4091.3684 - val_mae: 27.1482 - val_mse: 4091.3684 - val_accuracy: 0.0125\n",
      "Epoch 131/1000\n",
      "1155/1155 [==============================] - 2s 1ms/step - loss: 5281.5762 - mae: 34.3732 - mse: 5281.5762 - accuracy: 0.1985 - val_loss: 4242.7036 - val_mae: 27.7140 - val_mse: 4242.7036 - val_accuracy: 0.0011\n",
      "Epoch 132/1000\n",
      "1155/1155 [==============================] - 2s 1ms/step - loss: 5131.7334 - mae: 34.1784 - mse: 5131.7334 - accuracy: 0.2037 - val_loss: 4209.5625 - val_mae: 28.1998 - val_mse: 4209.5625 - val_accuracy: 5.4148e-04\n",
      "Epoch 133/1000\n",
      "1155/1155 [==============================] - 2s 1ms/step - loss: 5166.7305 - mae: 34.3611 - mse: 5166.7305 - accuracy: 0.2026 - val_loss: 4231.6572 - val_mae: 26.9004 - val_mse: 4231.6572 - val_accuracy: 0.0275\n",
      "Epoch 134/1000\n",
      "1155/1155 [==============================] - 2s 1ms/step - loss: 4974.7129 - mae: 33.9421 - mse: 4974.7129 - accuracy: 0.2020 - val_loss: 4076.0549 - val_mae: 27.9594 - val_mse: 4076.0549 - val_accuracy: 0.0021\n",
      "Epoch 135/1000\n",
      "1155/1155 [==============================] - 2s 2ms/step - loss: 5237.1230 - mae: 34.3619 - mse: 5237.1230 - accuracy: 0.2053 - val_loss: 4288.2207 - val_mae: 27.2513 - val_mse: 4288.2207 - val_accuracy: 0.0035\n",
      "Epoch 136/1000\n",
      "1155/1155 [==============================] - 2s 1ms/step - loss: 5188.2451 - mae: 34.3064 - mse: 5188.2451 - accuracy: 0.2028 - val_loss: 4225.5020 - val_mae: 26.8279 - val_mse: 4225.5020 - val_accuracy: 0.0024\n",
      "Epoch 137/1000\n",
      "1155/1155 [==============================] - 2s 1ms/step - loss: 5046.1772 - mae: 34.1608 - mse: 5046.1772 - accuracy: 0.2022 - val_loss: 4001.1853 - val_mae: 27.1219 - val_mse: 4001.1853 - val_accuracy: 0.0011\n",
      "Epoch 138/1000\n",
      "1155/1155 [==============================] - 2s 1ms/step - loss: 5114.9131 - mae: 34.2268 - mse: 5114.9131 - accuracy: 0.2031 - val_loss: 4011.2939 - val_mae: 26.4429 - val_mse: 4011.2939 - val_accuracy: 0.0074\n",
      "Epoch 139/1000\n",
      "1155/1155 [==============================] - 2s 1ms/step - loss: 5332.7310 - mae: 34.7087 - mse: 5332.7310 - accuracy: 0.2024 - val_loss: 4262.7910 - val_mae: 28.3266 - val_mse: 4262.7910 - val_accuracy: 0.0023\n",
      "Epoch 140/1000\n",
      "1155/1155 [==============================] - 2s 1ms/step - loss: 5156.3535 - mae: 34.4349 - mse: 5156.3535 - accuracy: 0.2021 - val_loss: 4000.0940 - val_mae: 25.2032 - val_mse: 4000.0940 - val_accuracy: 0.0423\n",
      "Epoch 141/1000\n",
      "1155/1155 [==============================] - 2s 1ms/step - loss: 5151.7129 - mae: 34.3716 - mse: 5151.7129 - accuracy: 0.2032 - val_loss: 4089.2878 - val_mae: 27.8378 - val_mse: 4089.2878 - val_accuracy: 0.0029\n",
      "Epoch 142/1000\n",
      "1155/1155 [==============================] - 2s 1ms/step - loss: 5249.2002 - mae: 34.6975 - mse: 5249.2002 - accuracy: 0.2021 - val_loss: 4066.6099 - val_mae: 27.0789 - val_mse: 4066.6099 - val_accuracy: 0.0027\n",
      "Epoch 143/1000\n",
      "1155/1155 [==============================] - 2s 1ms/step - loss: 5106.7334 - mae: 34.3633 - mse: 5106.7334 - accuracy: 0.2033 - val_loss: 3984.0527 - val_mae: 27.3898 - val_mse: 3984.0527 - val_accuracy: 0.0026\n",
      "Epoch 144/1000\n",
      "1155/1155 [==============================] - 2s 1ms/step - loss: 5065.3892 - mae: 34.4029 - mse: 5065.3892 - accuracy: 0.2030 - val_loss: 3762.8145 - val_mae: 26.5986 - val_mse: 3762.8145 - val_accuracy: 0.0070\n",
      "Epoch 145/1000\n",
      "1155/1155 [==============================] - 2s 1ms/step - loss: 5093.4937 - mae: 34.4658 - mse: 5093.4937 - accuracy: 0.2026 - val_loss: 3828.8225 - val_mae: 27.1201 - val_mse: 3828.8225 - val_accuracy: 0.0094\n",
      "Epoch 146/1000\n",
      "1155/1155 [==============================] - 2s 1ms/step - loss: 5229.3369 - mae: 34.5642 - mse: 5229.3369 - accuracy: 0.2049 - val_loss: 3943.0344 - val_mae: 28.0008 - val_mse: 3943.0344 - val_accuracy: 0.0030\n",
      "Epoch 147/1000\n",
      "1155/1155 [==============================] - 2s 1ms/step - loss: 5009.3159 - mae: 34.1657 - mse: 5009.3159 - accuracy: 0.2035 - val_loss: 3903.8147 - val_mae: 27.1712 - val_mse: 3903.8147 - val_accuracy: 0.0061\n",
      "Epoch 148/1000\n",
      "1155/1155 [==============================] - 2s 1ms/step - loss: 5241.4668 - mae: 34.6250 - mse: 5241.4668 - accuracy: 0.2033 - val_loss: 3780.1199 - val_mae: 25.8691 - val_mse: 3780.1199 - val_accuracy: 0.0191\n",
      "Epoch 149/1000\n",
      "1155/1155 [==============================] - 2s 1ms/step - loss: 5062.2256 - mae: 34.5091 - mse: 5062.2256 - accuracy: 0.2007 - val_loss: 3941.8379 - val_mae: 26.8297 - val_mse: 3941.8379 - val_accuracy: 0.0056\n",
      "Epoch 150/1000\n",
      "1155/1155 [==============================] - 2s 1ms/step - loss: 5138.8735 - mae: 34.6403 - mse: 5138.8735 - accuracy: 0.2013 - val_loss: 3742.6074 - val_mae: 26.4347 - val_mse: 3742.6074 - val_accuracy: 0.0099\n",
      "Epoch 151/1000\n",
      "1155/1155 [==============================] - 2s 1ms/step - loss: 5103.7769 - mae: 34.4963 - mse: 5103.7769 - accuracy: 0.2012 - val_loss: 3839.2385 - val_mae: 26.6652 - val_mse: 3839.2385 - val_accuracy: 0.0135\n",
      "Epoch 152/1000\n",
      "1155/1155 [==============================] - 2s 1ms/step - loss: 4960.9136 - mae: 34.2443 - mse: 4960.9136 - accuracy: 0.2035 - val_loss: 4155.8789 - val_mae: 30.1169 - val_mse: 4155.8789 - val_accuracy: 8.6636e-04\n",
      "Epoch 153/1000\n",
      "1155/1155 [==============================] - 2s 1ms/step - loss: 5059.9165 - mae: 34.4049 - mse: 5059.9165 - accuracy: 0.2029 - val_loss: 3523.7227 - val_mae: 25.9638 - val_mse: 3523.7227 - val_accuracy: 0.0162\n",
      "Epoch 154/1000\n",
      "1155/1155 [==============================] - 2s 1ms/step - loss: 5021.5195 - mae: 34.5701 - mse: 5021.5195 - accuracy: 0.2014 - val_loss: 3668.0125 - val_mae: 27.4014 - val_mse: 3668.0125 - val_accuracy: 0.0042\n",
      "Epoch 155/1000\n",
      "1155/1155 [==============================] - 2s 1ms/step - loss: 5033.9805 - mae: 34.4005 - mse: 5033.9805 - accuracy: 0.2007 - val_loss: 3736.3418 - val_mae: 26.6129 - val_mse: 3736.3418 - val_accuracy: 0.0173\n",
      "Epoch 156/1000\n",
      "1155/1155 [==============================] - 2s 1ms/step - loss: 5275.8740 - mae: 35.0522 - mse: 5275.8740 - accuracy: 0.2015 - val_loss: 3657.8384 - val_mae: 27.3890 - val_mse: 3657.8384 - val_accuracy: 6.4977e-04\n",
      "Epoch 157/1000\n",
      "1155/1155 [==============================] - 2s 1ms/step - loss: 5119.0542 - mae: 34.7038 - mse: 5119.0542 - accuracy: 0.2021 - val_loss: 3727.1428 - val_mae: 27.2612 - val_mse: 3727.1428 - val_accuracy: 0.0043\n",
      "Epoch 158/1000\n",
      "1155/1155 [==============================] - 2s 1ms/step - loss: 5072.7954 - mae: 34.6317 - mse: 5072.7954 - accuracy: 0.2030 - val_loss: 4019.6074 - val_mae: 28.4108 - val_mse: 4019.6074 - val_accuracy: 0.0039\n",
      "Epoch 159/1000\n",
      "1155/1155 [==============================] - 2s 1ms/step - loss: 5188.1914 - mae: 34.8394 - mse: 5188.1914 - accuracy: 0.2028 - val_loss: 3773.9302 - val_mae: 27.2615 - val_mse: 3773.9302 - val_accuracy: 0.0194\n",
      "Epoch 160/1000\n",
      "1155/1155 [==============================] - 2s 2ms/step - loss: 5178.0249 - mae: 34.8962 - mse: 5178.0249 - accuracy: 0.2015 - val_loss: 3544.7043 - val_mae: 26.8295 - val_mse: 3544.7043 - val_accuracy: 0.0087\n",
      "Epoch 161/1000\n",
      "1155/1155 [==============================] - 2s 2ms/step - loss: 5151.3809 - mae: 34.8523 - mse: 5151.3809 - accuracy: 0.2020 - val_loss: 3624.2390 - val_mae: 28.0367 - val_mse: 3624.2390 - val_accuracy: 0.0012\n",
      "Epoch 162/1000\n",
      "1155/1155 [==============================] - 2s 2ms/step - loss: 5050.2378 - mae: 34.6362 - mse: 5050.2378 - accuracy: 0.2031 - val_loss: 3390.5325 - val_mae: 26.8817 - val_mse: 3390.5325 - val_accuracy: 0.0038\n",
      "Epoch 163/1000\n",
      "1155/1155 [==============================] - 2s 2ms/step - loss: 5031.4961 - mae: 34.5826 - mse: 5031.4961 - accuracy: 0.2037 - val_loss: 3530.4299 - val_mae: 28.2124 - val_mse: 3530.4299 - val_accuracy: 8.6636e-04\n",
      "Epoch 164/1000\n",
      "1155/1155 [==============================] - 2s 2ms/step - loss: 4983.0425 - mae: 34.4633 - mse: 4983.0425 - accuracy: 0.2026 - val_loss: 3503.3960 - val_mae: 27.2832 - val_mse: 3503.3960 - val_accuracy: 0.0028\n",
      "Epoch 165/1000\n",
      "1155/1155 [==============================] - 2s 2ms/step - loss: 5098.2314 - mae: 34.7356 - mse: 5098.2314 - accuracy: 0.2022 - val_loss: 3412.0625 - val_mae: 26.4279 - val_mse: 3412.0625 - val_accuracy: 0.0045\n",
      "Epoch 166/1000\n",
      "1155/1155 [==============================] - 2s 2ms/step - loss: 5226.5957 - mae: 34.8686 - mse: 5226.5957 - accuracy: 0.2020 - val_loss: 3332.7939 - val_mae: 26.8541 - val_mse: 3332.7939 - val_accuracy: 0.0027\n",
      "Epoch 167/1000\n",
      "1155/1155 [==============================] - 2s 2ms/step - loss: 5096.4443 - mae: 34.7280 - mse: 5096.4443 - accuracy: 0.2038 - val_loss: 3419.6028 - val_mae: 26.6699 - val_mse: 3419.6028 - val_accuracy: 0.0300\n",
      "Epoch 168/1000\n",
      "1155/1155 [==============================] - 2s 2ms/step - loss: 4942.1821 - mae: 34.3201 - mse: 4942.1821 - accuracy: 0.2081 - val_loss: 3321.5759 - val_mae: 26.4366 - val_mse: 3321.5759 - val_accuracy: 0.0031\n",
      "Epoch 169/1000\n",
      "1155/1155 [==============================] - 2s 1ms/step - loss: 4982.3770 - mae: 34.3661 - mse: 4982.3770 - accuracy: 0.2066 - val_loss: 3522.5872 - val_mae: 27.4572 - val_mse: 3522.5872 - val_accuracy: 0.0021\n",
      "Epoch 170/1000\n",
      "1155/1155 [==============================] - 2s 1ms/step - loss: 5016.6064 - mae: 34.4992 - mse: 5016.6064 - accuracy: 0.2041 - val_loss: 3494.2751 - val_mae: 27.6522 - val_mse: 3494.2751 - val_accuracy: 0.0018\n",
      "Epoch 171/1000\n",
      "1155/1155 [==============================] - 2s 2ms/step - loss: 5199.8169 - mae: 34.7901 - mse: 5199.8169 - accuracy: 0.2101 - val_loss: 3500.5349 - val_mae: 27.3614 - val_mse: 3500.5349 - val_accuracy: 0.0117\n",
      "Epoch 172/1000\n",
      "1155/1155 [==============================] - 2s 2ms/step - loss: 5006.9692 - mae: 34.4402 - mse: 5006.9692 - accuracy: 0.2050 - val_loss: 3381.9365 - val_mae: 28.1087 - val_mse: 3381.9365 - val_accuracy: 5.4148e-04\n",
      "Epoch 173/1000\n",
      "1155/1155 [==============================] - 2s 2ms/step - loss: 5053.1255 - mae: 34.5751 - mse: 5053.1255 - accuracy: 0.2061 - val_loss: 3412.0508 - val_mae: 26.2800 - val_mse: 3412.0508 - val_accuracy: 0.0217\n",
      "Epoch 174/1000\n",
      "1155/1155 [==============================] - 2s 2ms/step - loss: 4933.6504 - mae: 34.4371 - mse: 4933.6504 - accuracy: 0.2054 - val_loss: 3326.1304 - val_mae: 27.0587 - val_mse: 3326.1304 - val_accuracy: 0.0013\n",
      "Epoch 175/1000\n",
      "1155/1155 [==============================] - 2s 2ms/step - loss: 5119.4390 - mae: 34.5693 - mse: 5119.4390 - accuracy: 0.2060 - val_loss: 3361.1023 - val_mae: 26.7841 - val_mse: 3361.1023 - val_accuracy: 0.0039\n",
      "Epoch 176/1000\n",
      "1155/1155 [==============================] - 2s 2ms/step - loss: 4923.3716 - mae: 34.2051 - mse: 4923.3716 - accuracy: 0.2078 - val_loss: 3350.2502 - val_mae: 27.2367 - val_mse: 3350.2502 - val_accuracy: 0.0017\n",
      "Epoch 177/1000\n",
      "1155/1155 [==============================] - 2s 2ms/step - loss: 5077.5645 - mae: 34.7186 - mse: 5077.5645 - accuracy: 0.2057 - val_loss: 3521.0488 - val_mae: 26.8302 - val_mse: 3521.0488 - val_accuracy: 0.0473\n",
      "Epoch 178/1000\n",
      "1155/1155 [==============================] - 2s 2ms/step - loss: 4982.5918 - mae: 34.6451 - mse: 4982.5918 - accuracy: 0.2062 - val_loss: 3658.9014 - val_mae: 27.2319 - val_mse: 3658.9014 - val_accuracy: 0.0172\n",
      "Epoch 179/1000\n",
      "1155/1155 [==============================] - 2s 1ms/step - loss: 5136.7310 - mae: 34.8481 - mse: 5136.7310 - accuracy: 0.2076 - val_loss: 3281.3181 - val_mae: 27.6477 - val_mse: 3281.3181 - val_accuracy: 6.4977e-04\n",
      "Epoch 180/1000\n",
      "1155/1155 [==============================] - 2s 1ms/step - loss: 4946.4570 - mae: 34.4529 - mse: 4946.4570 - accuracy: 0.2075 - val_loss: 3628.6770 - val_mae: 26.6101 - val_mse: 3628.6770 - val_accuracy: 0.0941\n",
      "Epoch 181/1000\n",
      "1155/1155 [==============================] - 2s 2ms/step - loss: 4945.9199 - mae: 34.7872 - mse: 4945.9199 - accuracy: 0.2094 - val_loss: 3412.0356 - val_mae: 26.5064 - val_mse: 3412.0356 - val_accuracy: 0.0140\n",
      "Epoch 182/1000\n",
      "1155/1155 [==============================] - 2s 1ms/step - loss: 5037.2163 - mae: 34.5556 - mse: 5037.2163 - accuracy: 0.2078 - val_loss: 3276.0413 - val_mae: 26.8653 - val_mse: 3276.0413 - val_accuracy: 0.0052\n",
      "Epoch 183/1000\n",
      "1155/1155 [==============================] - 2s 1ms/step - loss: 4930.3892 - mae: 34.5475 - mse: 4930.3892 - accuracy: 0.2078 - val_loss: 3416.0813 - val_mae: 27.2134 - val_mse: 3416.0813 - val_accuracy: 0.0060\n",
      "Epoch 184/1000\n",
      "1155/1155 [==============================] - 2s 1ms/step - loss: 4851.2246 - mae: 34.3372 - mse: 4851.2246 - accuracy: 0.2063 - val_loss: 3140.0010 - val_mae: 26.5175 - val_mse: 3140.0010 - val_accuracy: 0.0018\n",
      "Epoch 185/1000\n",
      "1155/1155 [==============================] - 2s 1ms/step - loss: 4855.1162 - mae: 34.3799 - mse: 4855.1162 - accuracy: 0.2063 - val_loss: 3364.8713 - val_mae: 28.0454 - val_mse: 3364.8713 - val_accuracy: 2.1659e-04\n",
      "Epoch 186/1000\n",
      "1155/1155 [==============================] - 2s 1ms/step - loss: 4979.7017 - mae: 34.7401 - mse: 4979.7017 - accuracy: 0.2055 - val_loss: 3229.2695 - val_mae: 24.6308 - val_mse: 3229.2695 - val_accuracy: 0.1593\n",
      "Epoch 187/1000\n",
      "1155/1155 [==============================] - 2s 1ms/step - loss: 4885.8213 - mae: 34.4823 - mse: 4885.8213 - accuracy: 0.2075 - val_loss: 3221.4854 - val_mae: 25.4247 - val_mse: 3221.4854 - val_accuracy: 0.0483\n",
      "Epoch 188/1000\n",
      "1155/1155 [==============================] - 2s 1ms/step - loss: 5136.7402 - mae: 34.8826 - mse: 5136.7402 - accuracy: 0.2085 - val_loss: 3329.7451 - val_mae: 26.5747 - val_mse: 3329.7451 - val_accuracy: 0.0038\n",
      "Epoch 189/1000\n",
      "1155/1155 [==============================] - 2s 1ms/step - loss: 4984.2197 - mae: 34.8610 - mse: 4984.2197 - accuracy: 0.2089 - val_loss: 3276.3691 - val_mae: 25.6884 - val_mse: 3276.3691 - val_accuracy: 0.0214\n",
      "Epoch 190/1000\n",
      "1155/1155 [==============================] - 2s 1ms/step - loss: 4950.3218 - mae: 34.6733 - mse: 4950.3218 - accuracy: 0.2065 - val_loss: 3155.2864 - val_mae: 26.5044 - val_mse: 3155.2864 - val_accuracy: 0.0027\n",
      "Epoch 191/1000\n",
      "1155/1155 [==============================] - 2s 1ms/step - loss: 4929.9561 - mae: 34.5009 - mse: 4929.9561 - accuracy: 0.2088 - val_loss: 3126.1399 - val_mae: 26.6212 - val_mse: 3126.1399 - val_accuracy: 0.0022\n",
      "Epoch 192/1000\n",
      "1155/1155 [==============================] - 2s 2ms/step - loss: 4810.9707 - mae: 34.3595 - mse: 4810.9707 - accuracy: 0.2075 - val_loss: 3049.3008 - val_mae: 25.7317 - val_mse: 3049.3008 - val_accuracy: 0.0057\n",
      "Epoch 193/1000\n",
      "1155/1155 [==============================] - 2s 2ms/step - loss: 4933.2812 - mae: 34.5980 - mse: 4933.2812 - accuracy: 0.2073 - val_loss: 3270.0571 - val_mae: 25.8185 - val_mse: 3270.0571 - val_accuracy: 0.0404\n",
      "Epoch 194/1000\n",
      "1155/1155 [==============================] - 2s 2ms/step - loss: 4995.3545 - mae: 34.8303 - mse: 4995.3545 - accuracy: 0.2084 - val_loss: 3269.6147 - val_mae: 27.2849 - val_mse: 3269.6147 - val_accuracy: 0.0023\n",
      "Epoch 195/1000\n",
      "1155/1155 [==============================] - 2s 2ms/step - loss: 4910.3379 - mae: 34.6784 - mse: 4910.3379 - accuracy: 0.2064 - val_loss: 3299.5818 - val_mae: 26.9251 - val_mse: 3299.5818 - val_accuracy: 0.0113\n",
      "Epoch 196/1000\n",
      "1155/1155 [==============================] - 2s 2ms/step - loss: 4831.2559 - mae: 34.3538 - mse: 4831.2559 - accuracy: 0.2076 - val_loss: 3610.3962 - val_mae: 28.1364 - val_mse: 3610.3962 - val_accuracy: 0.0043\n",
      "Epoch 197/1000\n",
      "1155/1155 [==============================] - 2s 1ms/step - loss: 5009.7266 - mae: 34.8035 - mse: 5009.7266 - accuracy: 0.2100 - val_loss: 3345.0032 - val_mae: 27.8922 - val_mse: 3345.0032 - val_accuracy: 0.0012\n",
      "Epoch 198/1000\n",
      "1155/1155 [==============================] - 2s 2ms/step - loss: 4866.8271 - mae: 34.4663 - mse: 4866.8271 - accuracy: 0.2059 - val_loss: 3278.4924 - val_mae: 26.6390 - val_mse: 3278.4924 - val_accuracy: 0.0100\n",
      "Epoch 199/1000\n",
      "1155/1155 [==============================] - 2s 1ms/step - loss: 4995.0728 - mae: 34.7877 - mse: 4995.0728 - accuracy: 0.2082 - val_loss: 3463.5745 - val_mae: 27.5409 - val_mse: 3463.5745 - val_accuracy: 0.0080\n",
      "Epoch 200/1000\n",
      "1155/1155 [==============================] - 2s 1ms/step - loss: 4908.4082 - mae: 34.7077 - mse: 4908.4082 - accuracy: 0.2091 - val_loss: 3195.0598 - val_mae: 26.1469 - val_mse: 3195.0598 - val_accuracy: 0.0134\n",
      "Epoch 201/1000\n",
      "1155/1155 [==============================] - 2s 1ms/step - loss: 4869.0303 - mae: 34.4373 - mse: 4869.0303 - accuracy: 0.2076 - val_loss: 3391.4258 - val_mae: 27.0868 - val_mse: 3391.4258 - val_accuracy: 0.0117\n",
      "Epoch 202/1000\n",
      "1155/1155 [==============================] - 2s 1ms/step - loss: 5094.6245 - mae: 35.1376 - mse: 5094.6245 - accuracy: 0.2069 - val_loss: 3208.7366 - val_mae: 26.8755 - val_mse: 3208.7366 - val_accuracy: 0.0038\n",
      "Epoch 203/1000\n",
      "1155/1155 [==============================] - 2s 2ms/step - loss: 5089.7666 - mae: 34.9837 - mse: 5089.7666 - accuracy: 0.2082 - val_loss: 3214.5410 - val_mae: 26.1247 - val_mse: 3214.5410 - val_accuracy: 0.0420\n",
      "Epoch 204/1000\n",
      "1155/1155 [==============================] - 2s 1ms/step - loss: 4898.2031 - mae: 34.8902 - mse: 4898.2031 - accuracy: 0.2095 - val_loss: 3644.7346 - val_mae: 29.3076 - val_mse: 3644.7346 - val_accuracy: 0.0014\n",
      "Epoch 205/1000\n",
      "1155/1155 [==============================] - 2s 1ms/step - loss: 5076.7974 - mae: 35.1753 - mse: 5076.7974 - accuracy: 0.2067 - val_loss: 3185.6709 - val_mae: 27.0365 - val_mse: 3185.6709 - val_accuracy: 0.0037\n",
      "Epoch 206/1000\n",
      "1155/1155 [==============================] - 2s 2ms/step - loss: 4775.5913 - mae: 34.3651 - mse: 4775.5913 - accuracy: 0.2073 - val_loss: 3228.1218 - val_mae: 26.2483 - val_mse: 3228.1218 - val_accuracy: 0.0277\n",
      "Epoch 207/1000\n",
      "1155/1155 [==============================] - 2s 1ms/step - loss: 4864.5278 - mae: 34.6645 - mse: 4864.5278 - accuracy: 0.2089 - val_loss: 3333.8340 - val_mae: 28.0936 - val_mse: 3333.8340 - val_accuracy: 0.0023\n",
      "Epoch 208/1000\n",
      "1155/1155 [==============================] - 2s 1ms/step - loss: 4811.2271 - mae: 34.5167 - mse: 4811.2271 - accuracy: 0.2065 - val_loss: 3152.9285 - val_mae: 26.1252 - val_mse: 3152.9285 - val_accuracy: 0.0071\n",
      "Epoch 209/1000\n",
      "1155/1155 [==============================] - 2s 1ms/step - loss: 4691.5566 - mae: 34.1804 - mse: 4691.5566 - accuracy: 0.2088 - val_loss: 3169.9526 - val_mae: 26.0153 - val_mse: 3169.9526 - val_accuracy: 0.0237\n",
      "Epoch 210/1000\n",
      "1155/1155 [==============================] - 2s 1ms/step - loss: 4788.9873 - mae: 34.5449 - mse: 4788.9873 - accuracy: 0.2100 - val_loss: 3050.0916 - val_mae: 24.8543 - val_mse: 3050.0916 - val_accuracy: 0.0280\n",
      "Epoch 211/1000\n",
      "1155/1155 [==============================] - 2s 1ms/step - loss: 4885.5068 - mae: 34.7389 - mse: 4885.5068 - accuracy: 0.2085 - val_loss: 3047.8992 - val_mae: 25.0436 - val_mse: 3047.8992 - val_accuracy: 0.0200\n",
      "Epoch 212/1000\n",
      "1155/1155 [==============================] - 2s 1ms/step - loss: 4905.1689 - mae: 34.7680 - mse: 4905.1689 - accuracy: 0.2059 - val_loss: 3470.2146 - val_mae: 27.0164 - val_mse: 3470.2146 - val_accuracy: 0.0156\n",
      "Epoch 213/1000\n",
      "1155/1155 [==============================] - 2s 1ms/step - loss: 4927.6743 - mae: 34.8871 - mse: 4927.6743 - accuracy: 0.2092 - val_loss: 3310.4312 - val_mae: 26.1849 - val_mse: 3310.4312 - val_accuracy: 0.0494\n",
      "Epoch 214/1000\n",
      "1155/1155 [==============================] - 2s 1ms/step - loss: 5098.0161 - mae: 35.1962 - mse: 5098.0161 - accuracy: 0.2085 - val_loss: 3104.9929 - val_mae: 27.0260 - val_mse: 3104.9929 - val_accuracy: 7.5807e-04\n",
      "Epoch 215/1000\n",
      "1155/1155 [==============================] - 2s 1ms/step - loss: 4801.1191 - mae: 34.6757 - mse: 4801.1191 - accuracy: 0.2098 - val_loss: 3027.3887 - val_mae: 26.1722 - val_mse: 3027.3887 - val_accuracy: 0.0064\n",
      "Epoch 216/1000\n",
      "1155/1155 [==============================] - 2s 1ms/step - loss: 4897.5894 - mae: 34.6408 - mse: 4897.5894 - accuracy: 0.2082 - val_loss: 3107.5137 - val_mae: 25.3743 - val_mse: 3107.5137 - val_accuracy: 0.0246\n",
      "Epoch 217/1000\n",
      "1155/1155 [==============================] - 2s 2ms/step - loss: 4895.5503 - mae: 34.9246 - mse: 4895.5503 - accuracy: 0.2094 - val_loss: 3207.5708 - val_mae: 26.4260 - val_mse: 3207.5708 - val_accuracy: 0.0115\n",
      "Epoch 218/1000\n",
      "1155/1155 [==============================] - 2s 2ms/step - loss: 4737.1475 - mae: 34.5433 - mse: 4737.1475 - accuracy: 0.2082 - val_loss: 3085.9180 - val_mae: 26.3212 - val_mse: 3085.9180 - val_accuracy: 0.0018\n",
      "Epoch 219/1000\n",
      "1155/1155 [==============================] - 2s 1ms/step - loss: 4870.4033 - mae: 34.7942 - mse: 4870.4033 - accuracy: 0.2101 - val_loss: 3354.7788 - val_mae: 28.0139 - val_mse: 3354.7788 - val_accuracy: 0.0021\n",
      "Epoch 220/1000\n",
      "1155/1155 [==============================] - 2s 1ms/step - loss: 5030.1621 - mae: 35.1480 - mse: 5030.1621 - accuracy: 0.2089 - val_loss: 3197.1199 - val_mae: 26.0678 - val_mse: 3197.1199 - val_accuracy: 0.0108\n",
      "Epoch 221/1000\n",
      "1155/1155 [==============================] - 2s 1ms/step - loss: 4931.7979 - mae: 35.0642 - mse: 4931.7979 - accuracy: 0.2063 - val_loss: 3087.4163 - val_mae: 25.9896 - val_mse: 3087.4163 - val_accuracy: 0.0148\n",
      "Epoch 222/1000\n",
      "1155/1155 [==============================] - 2s 1ms/step - loss: 5037.5825 - mae: 35.1216 - mse: 5037.5825 - accuracy: 0.2088 - val_loss: 3004.8491 - val_mae: 25.2865 - val_mse: 3004.8491 - val_accuracy: 0.0095\n",
      "Epoch 223/1000\n",
      "1155/1155 [==============================] - 2s 1ms/step - loss: 4816.2524 - mae: 34.8598 - mse: 4816.2524 - accuracy: 0.2076 - val_loss: 3167.4031 - val_mae: 25.9161 - val_mse: 3167.4031 - val_accuracy: 0.0317\n",
      "Epoch 224/1000\n",
      "1155/1155 [==============================] - 2s 1ms/step - loss: 4734.6152 - mae: 34.6306 - mse: 4734.6152 - accuracy: 0.2073 - val_loss: 3125.0930 - val_mae: 25.6942 - val_mse: 3125.0930 - val_accuracy: 0.0134\n",
      "Epoch 225/1000\n",
      "1155/1155 [==============================] - 2s 1ms/step - loss: 4894.6987 - mae: 34.9356 - mse: 4894.6987 - accuracy: 0.2075 - val_loss: 3242.1587 - val_mae: 26.0083 - val_mse: 3242.1587 - val_accuracy: 0.0267\n",
      "Epoch 226/1000\n",
      "1155/1155 [==============================] - 2s 1ms/step - loss: 4941.8896 - mae: 34.9692 - mse: 4941.8896 - accuracy: 0.2092 - val_loss: 3345.1172 - val_mae: 27.5123 - val_mse: 3345.1172 - val_accuracy: 0.0050\n",
      "Epoch 227/1000\n",
      "1155/1155 [==============================] - 2s 1ms/step - loss: 4871.3574 - mae: 34.8565 - mse: 4871.3574 - accuracy: 0.2081 - val_loss: 3204.1367 - val_mae: 25.1645 - val_mse: 3204.1367 - val_accuracy: 0.1720\n",
      "Epoch 228/1000\n",
      "1155/1155 [==============================] - 2s 1ms/step - loss: 4848.6504 - mae: 34.7759 - mse: 4848.6504 - accuracy: 0.2082 - val_loss: 3015.5466 - val_mae: 25.4815 - val_mse: 3015.5466 - val_accuracy: 0.0196\n",
      "Epoch 229/1000\n",
      "1155/1155 [==============================] - 2s 1ms/step - loss: 5002.9521 - mae: 35.1400 - mse: 5002.9521 - accuracy: 0.2089 - val_loss: 3210.3274 - val_mae: 26.6177 - val_mse: 3210.3274 - val_accuracy: 0.0061\n",
      "Epoch 230/1000\n",
      "1155/1155 [==============================] - 2s 1ms/step - loss: 4981.8003 - mae: 35.1686 - mse: 4981.8003 - accuracy: 0.2101 - val_loss: 3446.0002 - val_mae: 27.5238 - val_mse: 3446.0002 - val_accuracy: 0.0518\n",
      "Epoch 231/1000\n",
      "1155/1155 [==============================] - 2s 1ms/step - loss: 4770.6416 - mae: 34.6679 - mse: 4770.6416 - accuracy: 0.2090 - val_loss: 3081.5479 - val_mae: 26.4634 - val_mse: 3081.5479 - val_accuracy: 0.0067\n",
      "Epoch 232/1000\n",
      "1155/1155 [==============================] - 2s 1ms/step - loss: 4855.1416 - mae: 35.0271 - mse: 4855.1416 - accuracy: 0.2068 - val_loss: 3532.0833 - val_mae: 29.1333 - val_mse: 3532.0833 - val_accuracy: 3.2489e-04\n",
      "Epoch 233/1000\n",
      "1155/1155 [==============================] - 2s 2ms/step - loss: 4749.2959 - mae: 34.5901 - mse: 4749.2959 - accuracy: 0.2091 - val_loss: 3142.5452 - val_mae: 27.0432 - val_mse: 3142.5452 - val_accuracy: 8.6636e-04\n",
      "Epoch 234/1000\n",
      "1155/1155 [==============================] - 2s 1ms/step - loss: 4769.7646 - mae: 34.8944 - mse: 4769.7646 - accuracy: 0.2094 - val_loss: 3017.3433 - val_mae: 27.2340 - val_mse: 3017.3433 - val_accuracy: 8.6636e-04\n",
      "Epoch 235/1000\n",
      "1155/1155 [==============================] - 2s 1ms/step - loss: 4924.1899 - mae: 35.0661 - mse: 4924.1899 - accuracy: 0.2070 - val_loss: 3391.3557 - val_mae: 26.5284 - val_mse: 3391.3557 - val_accuracy: 0.0269\n",
      "Epoch 236/1000\n",
      "1155/1155 [==============================] - 2s 1ms/step - loss: 4850.6064 - mae: 34.8990 - mse: 4850.6064 - accuracy: 0.2105 - val_loss: 3051.1138 - val_mae: 26.7362 - val_mse: 3051.1138 - val_accuracy: 0.0024\n",
      "Epoch 237/1000\n",
      "1155/1155 [==============================] - 2s 1ms/step - loss: 4859.9043 - mae: 35.1263 - mse: 4859.9043 - accuracy: 0.2066 - val_loss: 3011.7490 - val_mae: 26.0593 - val_mse: 3011.7490 - val_accuracy: 0.0050\n",
      "Epoch 238/1000\n",
      "1155/1155 [==============================] - 2s 1ms/step - loss: 4949.3398 - mae: 35.2174 - mse: 4949.3398 - accuracy: 0.2090 - val_loss: 3207.1594 - val_mae: 27.0028 - val_mse: 3207.1594 - val_accuracy: 0.0095\n",
      "Epoch 239/1000\n",
      "1155/1155 [==============================] - 2s 1ms/step - loss: 4761.4731 - mae: 34.6436 - mse: 4761.4731 - accuracy: 0.2095 - val_loss: 3008.5249 - val_mae: 27.0371 - val_mse: 3008.5249 - val_accuracy: 0.0014\n",
      "Epoch 240/1000\n",
      "1155/1155 [==============================] - 2s 1ms/step - loss: 4953.3818 - mae: 35.2627 - mse: 4953.3818 - accuracy: 0.2087 - val_loss: 3052.8516 - val_mae: 26.3036 - val_mse: 3052.8516 - val_accuracy: 0.0028\n",
      "Epoch 241/1000\n",
      "1155/1155 [==============================] - 2s 1ms/step - loss: 4753.1724 - mae: 34.9141 - mse: 4753.1724 - accuracy: 0.2076 - val_loss: 3054.9182 - val_mae: 26.8308 - val_mse: 3054.9182 - val_accuracy: 5.4148e-04\n",
      "Epoch 242/1000\n",
      "1155/1155 [==============================] - 2s 1ms/step - loss: 4664.2119 - mae: 34.6823 - mse: 4664.2119 - accuracy: 0.2085 - val_loss: 3000.0139 - val_mae: 26.3535 - val_mse: 3000.0139 - val_accuracy: 0.0054\n",
      "Epoch 243/1000\n",
      "1155/1155 [==============================] - 2s 1ms/step - loss: 4725.7163 - mae: 34.5889 - mse: 4725.7163 - accuracy: 0.2102 - val_loss: 3575.8789 - val_mae: 28.4683 - val_mse: 3575.8789 - val_accuracy: 0.0022\n",
      "Epoch 244/1000\n",
      "1155/1155 [==============================] - 2s 1ms/step - loss: 4822.3301 - mae: 34.8308 - mse: 4822.3301 - accuracy: 0.2111 - val_loss: 3079.4966 - val_mae: 26.2803 - val_mse: 3079.4966 - val_accuracy: 0.0125\n",
      "Epoch 245/1000\n",
      "1155/1155 [==============================] - 2s 1ms/step - loss: 4737.8188 - mae: 34.7767 - mse: 4737.8188 - accuracy: 0.2106 - val_loss: 3176.4155 - val_mae: 26.6434 - val_mse: 3176.4155 - val_accuracy: 0.0139\n",
      "Epoch 246/1000\n",
      "1155/1155 [==============================] - 2s 1ms/step - loss: 4724.4912 - mae: 34.8961 - mse: 4724.4912 - accuracy: 0.2100 - val_loss: 3104.9568 - val_mae: 27.5844 - val_mse: 3104.9568 - val_accuracy: 8.6636e-04\n",
      "Epoch 247/1000\n",
      "1155/1155 [==============================] - 2s 1ms/step - loss: 4738.2017 - mae: 34.8244 - mse: 4738.2017 - accuracy: 0.2072 - val_loss: 2982.0354 - val_mae: 26.1157 - val_mse: 2982.0354 - val_accuracy: 0.0036\n",
      "Epoch 248/1000\n",
      "1155/1155 [==============================] - 2s 1ms/step - loss: 4884.1802 - mae: 35.0078 - mse: 4884.1802 - accuracy: 0.2101 - val_loss: 3034.1050 - val_mae: 27.0709 - val_mse: 3034.1050 - val_accuracy: 9.7466e-04\n",
      "Epoch 249/1000\n",
      "1155/1155 [==============================] - 2s 1ms/step - loss: 4858.7393 - mae: 35.1703 - mse: 4858.7393 - accuracy: 0.2107 - val_loss: 3097.9658 - val_mae: 27.5910 - val_mse: 3097.9658 - val_accuracy: 2.1659e-04\n",
      "Epoch 250/1000\n",
      "1155/1155 [==============================] - 2s 1ms/step - loss: 4702.1914 - mae: 34.7806 - mse: 4702.1914 - accuracy: 0.2095 - val_loss: 2979.8564 - val_mae: 26.5526 - val_mse: 2979.8564 - val_accuracy: 8.6636e-04\n",
      "Epoch 251/1000\n",
      "1155/1155 [==============================] - 2s 1ms/step - loss: 4667.4229 - mae: 34.6358 - mse: 4667.4229 - accuracy: 0.2074 - val_loss: 3263.7932 - val_mae: 27.9544 - val_mse: 3263.7932 - val_accuracy: 0.0011\n",
      "Epoch 252/1000\n",
      "1155/1155 [==============================] - 2s 1ms/step - loss: 4793.8862 - mae: 34.9953 - mse: 4793.8862 - accuracy: 0.2085 - val_loss: 3131.2991 - val_mae: 27.6482 - val_mse: 3131.2991 - val_accuracy: 3.2489e-04\n",
      "Epoch 253/1000\n",
      "1155/1155 [==============================] - 2s 1ms/step - loss: 4727.0049 - mae: 34.8050 - mse: 4727.0049 - accuracy: 0.2101 - val_loss: 2977.5168 - val_mae: 25.9376 - val_mse: 2977.5168 - val_accuracy: 0.0042\n",
      "Epoch 254/1000\n",
      "1155/1155 [==============================] - 2s 1ms/step - loss: 4803.1929 - mae: 35.0826 - mse: 4803.1929 - accuracy: 0.2092 - val_loss: 3019.1819 - val_mae: 25.8407 - val_mse: 3019.1819 - val_accuracy: 0.0074\n",
      "Epoch 255/1000\n",
      "1155/1155 [==============================] - 2s 1ms/step - loss: 4830.5947 - mae: 35.0395 - mse: 4830.5947 - accuracy: 0.2074 - val_loss: 3287.0078 - val_mae: 29.1284 - val_mse: 3287.0078 - val_accuracy: 2.1659e-04\n",
      "Epoch 256/1000\n",
      "1155/1155 [==============================] - 2s 1ms/step - loss: 4803.1421 - mae: 35.0160 - mse: 4803.1421 - accuracy: 0.2077 - val_loss: 3041.5110 - val_mae: 24.5710 - val_mse: 3041.5110 - val_accuracy: 0.0944\n",
      "Epoch 257/1000\n",
      "1155/1155 [==============================] - 2s 1ms/step - loss: 4844.7583 - mae: 35.1032 - mse: 4844.7583 - accuracy: 0.2074 - val_loss: 3252.8755 - val_mae: 26.9419 - val_mse: 3252.8755 - val_accuracy: 0.0048\n",
      "Epoch 258/1000\n",
      "1155/1155 [==============================] - 2s 1ms/step - loss: 4780.9360 - mae: 35.1280 - mse: 4780.9360 - accuracy: 0.2092 - val_loss: 2983.4917 - val_mae: 25.3743 - val_mse: 2983.4917 - val_accuracy: 0.0269\n",
      "Epoch 259/1000\n",
      "1155/1155 [==============================] - 2s 1ms/step - loss: 4806.0776 - mae: 35.0806 - mse: 4806.0776 - accuracy: 0.2076 - val_loss: 3189.8809 - val_mae: 27.5809 - val_mse: 3189.8809 - val_accuracy: 0.0016\n",
      "Epoch 260/1000\n",
      "1155/1155 [==============================] - 2s 1ms/step - loss: 4885.0435 - mae: 35.3810 - mse: 4885.0435 - accuracy: 0.2075 - val_loss: 2959.3931 - val_mae: 25.8653 - val_mse: 2959.3931 - val_accuracy: 0.0074\n",
      "Epoch 261/1000\n",
      "1155/1155 [==============================] - 2s 1ms/step - loss: 4724.8979 - mae: 34.8426 - mse: 4724.8979 - accuracy: 0.2094 - val_loss: 3036.2639 - val_mae: 27.8465 - val_mse: 3036.2639 - val_accuracy: 2.1659e-04\n",
      "Epoch 262/1000\n",
      "1155/1155 [==============================] - 2s 1ms/step - loss: 4726.2139 - mae: 35.0282 - mse: 4726.2139 - accuracy: 0.2111 - val_loss: 3415.7354 - val_mae: 28.4791 - val_mse: 3415.7354 - val_accuracy: 0.0058\n",
      "Epoch 263/1000\n",
      "1155/1155 [==============================] - 2s 1ms/step - loss: 4718.3462 - mae: 34.9874 - mse: 4718.3462 - accuracy: 0.2102 - val_loss: 2972.0566 - val_mae: 27.5182 - val_mse: 2972.0566 - val_accuracy: 6.4977e-04\n",
      "Epoch 264/1000\n",
      "1155/1155 [==============================] - 2s 1ms/step - loss: 4822.7710 - mae: 35.2682 - mse: 4822.7710 - accuracy: 0.2074 - val_loss: 3087.4023 - val_mae: 25.5193 - val_mse: 3087.4023 - val_accuracy: 0.0374\n",
      "Epoch 265/1000\n",
      "1155/1155 [==============================] - 2s 1ms/step - loss: 4658.1826 - mae: 34.7904 - mse: 4658.1826 - accuracy: 0.2086 - val_loss: 3069.4551 - val_mae: 27.1081 - val_mse: 3069.4551 - val_accuracy: 0.0018\n",
      "Epoch 266/1000\n",
      "1155/1155 [==============================] - 2s 1ms/step - loss: 4722.2095 - mae: 35.0708 - mse: 4722.2095 - accuracy: 0.2086 - val_loss: 3052.5496 - val_mae: 25.9609 - val_mse: 3052.5496 - val_accuracy: 0.0112\n",
      "Epoch 267/1000\n",
      "1155/1155 [==============================] - 2s 1ms/step - loss: 4942.8931 - mae: 35.4463 - mse: 4942.8931 - accuracy: 0.2086 - val_loss: 3122.2603 - val_mae: 26.4480 - val_mse: 3122.2603 - val_accuracy: 0.0073\n",
      "Epoch 268/1000\n",
      "1155/1155 [==============================] - 2s 1ms/step - loss: 4591.8208 - mae: 34.6522 - mse: 4591.8208 - accuracy: 0.2115 - val_loss: 3020.3694 - val_mae: 27.4465 - val_mse: 3020.3694 - val_accuracy: 9.7466e-04\n",
      "Epoch 269/1000\n",
      "1155/1155 [==============================] - 2s 1ms/step - loss: 4734.7441 - mae: 35.0801 - mse: 4734.7441 - accuracy: 0.2089 - val_loss: 2945.6836 - val_mae: 24.5021 - val_mse: 2945.6836 - val_accuracy: 0.0569\n",
      "Epoch 270/1000\n",
      "1155/1155 [==============================] - 2s 1ms/step - loss: 4696.3735 - mae: 34.9129 - mse: 4696.3735 - accuracy: 0.2089 - val_loss: 3071.6558 - val_mae: 27.6082 - val_mse: 3071.6558 - val_accuracy: 0.0013\n",
      "Epoch 271/1000\n",
      "1155/1155 [==============================] - 2s 1ms/step - loss: 4731.5571 - mae: 34.9228 - mse: 4731.5571 - accuracy: 0.2073 - val_loss: 3221.3647 - val_mae: 27.0868 - val_mse: 3221.3647 - val_accuracy: 0.0053\n",
      "Epoch 272/1000\n",
      "1155/1155 [==============================] - 2s 1ms/step - loss: 4679.9478 - mae: 34.8823 - mse: 4679.9478 - accuracy: 0.2119 - val_loss: 3123.0540 - val_mae: 26.7045 - val_mse: 3123.0540 - val_accuracy: 0.0054\n",
      "Epoch 273/1000\n",
      "1155/1155 [==============================] - 2s 1ms/step - loss: 4703.0312 - mae: 35.0788 - mse: 4703.0312 - accuracy: 0.2068 - val_loss: 3222.1406 - val_mae: 27.9480 - val_mse: 3222.1406 - val_accuracy: 7.5807e-04\n",
      "Epoch 274/1000\n",
      "1155/1155 [==============================] - 2s 1ms/step - loss: 4824.5381 - mae: 35.2532 - mse: 4824.5381 - accuracy: 0.2078 - val_loss: 3048.9358 - val_mae: 26.0589 - val_mse: 3048.9358 - val_accuracy: 0.0060\n",
      "Epoch 275/1000\n",
      "1155/1155 [==============================] - 2s 1ms/step - loss: 4729.9702 - mae: 35.0635 - mse: 4729.9702 - accuracy: 0.2087 - val_loss: 3006.8748 - val_mae: 26.2228 - val_mse: 3006.8748 - val_accuracy: 0.0016\n",
      "Epoch 276/1000\n",
      "1155/1155 [==============================] - 2s 1ms/step - loss: 4756.3218 - mae: 34.9990 - mse: 4756.3218 - accuracy: 0.2079 - val_loss: 3150.4890 - val_mae: 25.7188 - val_mse: 3150.4890 - val_accuracy: 0.0229\n",
      "Epoch 277/1000\n",
      "1155/1155 [==============================] - 2s 1ms/step - loss: 4618.7944 - mae: 34.9065 - mse: 4618.7944 - accuracy: 0.2076 - val_loss: 2954.3184 - val_mae: 25.4829 - val_mse: 2954.3184 - val_accuracy: 0.0252\n",
      "Epoch 278/1000\n",
      "1155/1155 [==============================] - 2s 1ms/step - loss: 4709.3608 - mae: 35.0439 - mse: 4709.3608 - accuracy: 0.2081 - val_loss: 2989.9985 - val_mae: 26.7568 - val_mse: 2989.9985 - val_accuracy: 0.0018\n",
      "Epoch 279/1000\n",
      "1155/1155 [==============================] - 2s 1ms/step - loss: 4718.0205 - mae: 35.1963 - mse: 4718.0205 - accuracy: 0.2100 - val_loss: 2967.3057 - val_mae: 24.7587 - val_mse: 2967.3057 - val_accuracy: 0.0260\n",
      "Epoch 280/1000\n",
      "1155/1155 [==============================] - 2s 1ms/step - loss: 4765.0703 - mae: 35.0809 - mse: 4765.0703 - accuracy: 0.2109 - val_loss: 3198.9673 - val_mae: 27.0729 - val_mse: 3198.9673 - val_accuracy: 0.0055\n",
      "Epoch 281/1000\n",
      "1155/1155 [==============================] - 2s 1ms/step - loss: 4797.5479 - mae: 35.3240 - mse: 4797.5479 - accuracy: 0.2079 - val_loss: 3070.7314 - val_mae: 27.5721 - val_mse: 3070.7314 - val_accuracy: 0.0012\n",
      "Epoch 282/1000\n",
      "1155/1155 [==============================] - 2s 1ms/step - loss: 4684.0718 - mae: 35.1741 - mse: 4684.0718 - accuracy: 0.2103 - val_loss: 2911.4670 - val_mae: 25.8120 - val_mse: 2911.4670 - val_accuracy: 0.0069\n",
      "Epoch 283/1000\n",
      "1155/1155 [==============================] - 2s 1ms/step - loss: 4597.6377 - mae: 34.7424 - mse: 4597.6377 - accuracy: 0.2091 - val_loss: 3156.9004 - val_mae: 27.1356 - val_mse: 3156.9004 - val_accuracy: 0.0015\n",
      "Epoch 284/1000\n",
      "1155/1155 [==============================] - 2s 1ms/step - loss: 4603.0825 - mae: 34.9247 - mse: 4603.0825 - accuracy: 0.2113 - val_loss: 2942.7322 - val_mae: 25.0624 - val_mse: 2942.7322 - val_accuracy: 0.0245\n",
      "Epoch 285/1000\n",
      "1155/1155 [==============================] - 2s 1ms/step - loss: 4756.6118 - mae: 34.9989 - mse: 4756.6118 - accuracy: 0.2090 - val_loss: 2943.2456 - val_mae: 25.0664 - val_mse: 2943.2456 - val_accuracy: 0.0153\n",
      "Epoch 286/1000\n",
      "1155/1155 [==============================] - 2s 1ms/step - loss: 4627.6514 - mae: 34.8945 - mse: 4627.6514 - accuracy: 0.2102 - val_loss: 2951.9932 - val_mae: 25.8540 - val_mse: 2951.9932 - val_accuracy: 0.0032\n",
      "Epoch 287/1000\n",
      "1155/1155 [==============================] - 2s 1ms/step - loss: 4627.3257 - mae: 34.8396 - mse: 4627.3257 - accuracy: 0.2084 - val_loss: 3725.5383 - val_mae: 28.1470 - val_mse: 3725.5383 - val_accuracy: 0.0108\n",
      "Epoch 288/1000\n",
      "1155/1155 [==============================] - 2s 1ms/step - loss: 4569.4302 - mae: 34.8062 - mse: 4569.4302 - accuracy: 0.2124 - val_loss: 2970.5996 - val_mae: 24.6947 - val_mse: 2970.5996 - val_accuracy: 0.0983\n",
      "Epoch 289/1000\n",
      "1155/1155 [==============================] - 2s 1ms/step - loss: 4678.3018 - mae: 34.8608 - mse: 4678.3018 - accuracy: 0.2114 - val_loss: 2967.5000 - val_mae: 25.4113 - val_mse: 2967.5000 - val_accuracy: 0.0264\n",
      "Epoch 290/1000\n",
      "1155/1155 [==============================] - 2s 1ms/step - loss: 4596.1792 - mae: 34.7940 - mse: 4596.1792 - accuracy: 0.2097 - val_loss: 2962.8906 - val_mae: 26.1830 - val_mse: 2962.8906 - val_accuracy: 0.0050\n",
      "Epoch 291/1000\n",
      "1155/1155 [==============================] - 2s 1ms/step - loss: 4686.0659 - mae: 34.9633 - mse: 4686.0659 - accuracy: 0.2074 - val_loss: 3239.8811 - val_mae: 27.3100 - val_mse: 3239.8811 - val_accuracy: 0.0021\n",
      "Epoch 292/1000\n",
      "1155/1155 [==============================] - 2s 1ms/step - loss: 4818.9526 - mae: 35.4171 - mse: 4818.9526 - accuracy: 0.2081 - val_loss: 3557.0955 - val_mae: 28.6693 - val_mse: 3557.0955 - val_accuracy: 0.0026\n",
      "Epoch 293/1000\n",
      "1155/1155 [==============================] - 2s 1ms/step - loss: 4757.8394 - mae: 35.0485 - mse: 4757.8394 - accuracy: 0.2090 - val_loss: 2993.3672 - val_mae: 25.6865 - val_mse: 2993.3672 - val_accuracy: 0.0049\n",
      "Epoch 294/1000\n",
      "1155/1155 [==============================] - 2s 1ms/step - loss: 4720.6401 - mae: 34.9067 - mse: 4720.6401 - accuracy: 0.2105 - val_loss: 2992.5381 - val_mae: 26.8997 - val_mse: 2992.5381 - val_accuracy: 8.6636e-04\n",
      "Epoch 295/1000\n",
      "1155/1155 [==============================] - 2s 1ms/step - loss: 4646.4590 - mae: 35.1044 - mse: 4646.4590 - accuracy: 0.2114 - val_loss: 2959.1489 - val_mae: 25.7177 - val_mse: 2959.1489 - val_accuracy: 0.0040\n",
      "Epoch 296/1000\n",
      "1155/1155 [==============================] - 2s 1ms/step - loss: 4608.5151 - mae: 34.7799 - mse: 4608.5151 - accuracy: 0.2120 - val_loss: 3253.5178 - val_mae: 27.2223 - val_mse: 3253.5178 - val_accuracy: 0.0102\n",
      "Epoch 297/1000\n",
      "1155/1155 [==============================] - 2s 1ms/step - loss: 4779.0522 - mae: 35.3297 - mse: 4779.0522 - accuracy: 0.2077 - val_loss: 3169.7217 - val_mae: 28.7285 - val_mse: 3169.7217 - val_accuracy: 4.3318e-04\n",
      "Epoch 298/1000\n",
      "1155/1155 [==============================] - 2s 1ms/step - loss: 4582.4619 - mae: 34.7924 - mse: 4582.4619 - accuracy: 0.2121 - val_loss: 2941.4358 - val_mae: 24.7641 - val_mse: 2941.4358 - val_accuracy: 0.0615\n",
      "Epoch 299/1000\n",
      "1155/1155 [==============================] - 2s 1ms/step - loss: 4588.8911 - mae: 34.8402 - mse: 4588.8911 - accuracy: 0.2102 - val_loss: 3176.2998 - val_mae: 27.8665 - val_mse: 3176.2998 - val_accuracy: 0.0011\n",
      "Epoch 300/1000\n",
      "1155/1155 [==============================] - 2s 1ms/step - loss: 4685.6626 - mae: 35.1177 - mse: 4685.6626 - accuracy: 0.2106 - val_loss: 3080.3369 - val_mae: 25.0910 - val_mse: 3080.3369 - val_accuracy: 0.0681\n",
      "Epoch 301/1000\n",
      "1155/1155 [==============================] - 2s 1ms/step - loss: 4637.4712 - mae: 34.9368 - mse: 4637.4712 - accuracy: 0.2073 - val_loss: 3026.2432 - val_mae: 28.1137 - val_mse: 3026.2432 - val_accuracy: 2.1659e-04\n",
      "Epoch 302/1000\n",
      "1155/1155 [==============================] - 2s 1ms/step - loss: 4566.5908 - mae: 34.9318 - mse: 4566.5908 - accuracy: 0.2102 - val_loss: 3105.1350 - val_mae: 25.3547 - val_mse: 3105.1350 - val_accuracy: 0.0610\n",
      "Epoch 303/1000\n",
      "1155/1155 [==============================] - 2s 1ms/step - loss: 4706.3691 - mae: 35.0825 - mse: 4706.3691 - accuracy: 0.2133 - val_loss: 2933.3064 - val_mae: 25.4321 - val_mse: 2933.3064 - val_accuracy: 0.0054\n",
      "Epoch 304/1000\n",
      "1155/1155 [==============================] - 2s 1ms/step - loss: 4586.5938 - mae: 34.7727 - mse: 4586.5938 - accuracy: 0.2072 - val_loss: 3020.1228 - val_mae: 27.0709 - val_mse: 3020.1228 - val_accuracy: 0.0038\n",
      "Epoch 305/1000\n",
      "1155/1155 [==============================] - 2s 1ms/step - loss: 4791.2432 - mae: 35.3279 - mse: 4791.2432 - accuracy: 0.2086 - val_loss: 3391.3914 - val_mae: 28.2035 - val_mse: 3391.3914 - val_accuracy: 0.0018\n",
      "Epoch 306/1000\n",
      "1155/1155 [==============================] - 2s 1ms/step - loss: 4628.6021 - mae: 34.9315 - mse: 4628.6021 - accuracy: 0.2113 - val_loss: 3166.3738 - val_mae: 26.0229 - val_mse: 3166.3738 - val_accuracy: 0.0263\n",
      "Epoch 307/1000\n",
      "1155/1155 [==============================] - 2s 1ms/step - loss: 4582.6602 - mae: 34.9079 - mse: 4582.6602 - accuracy: 0.2103 - val_loss: 2965.7358 - val_mae: 25.8333 - val_mse: 2965.7358 - val_accuracy: 0.0051\n",
      "Epoch 308/1000\n",
      "1155/1155 [==============================] - 2s 1ms/step - loss: 4589.2900 - mae: 34.9204 - mse: 4589.2900 - accuracy: 0.2107 - val_loss: 3024.9944 - val_mae: 26.0974 - val_mse: 3024.9944 - val_accuracy: 0.0056\n",
      "Epoch 309/1000\n",
      "1155/1155 [==============================] - 2s 1ms/step - loss: 4581.5181 - mae: 34.8283 - mse: 4581.5181 - accuracy: 0.2120 - val_loss: 3137.9036 - val_mae: 28.0019 - val_mse: 3137.9036 - val_accuracy: 7.5807e-04\n",
      "Epoch 310/1000\n",
      "1155/1155 [==============================] - 2s 1ms/step - loss: 4767.9370 - mae: 35.2392 - mse: 4767.9370 - accuracy: 0.2094 - val_loss: 3006.9683 - val_mae: 25.4454 - val_mse: 3006.9683 - val_accuracy: 0.0071\n",
      "Epoch 311/1000\n",
      "1155/1155 [==============================] - 2s 1ms/step - loss: 4660.3315 - mae: 35.0240 - mse: 4660.3315 - accuracy: 0.2090 - val_loss: 2957.8772 - val_mae: 24.5730 - val_mse: 2957.8772 - val_accuracy: 0.0355\n",
      "Epoch 312/1000\n",
      "1155/1155 [==============================] - 2s 2ms/step - loss: 4530.2686 - mae: 34.9379 - mse: 4530.2686 - accuracy: 0.2093 - val_loss: 2914.5747 - val_mae: 26.2925 - val_mse: 2914.5747 - val_accuracy: 9.7466e-04\n",
      "Epoch 313/1000\n",
      "1155/1155 [==============================] - 2s 2ms/step - loss: 4648.5493 - mae: 35.0438 - mse: 4648.5493 - accuracy: 0.2079 - val_loss: 2998.9658 - val_mae: 27.4303 - val_mse: 2998.9658 - val_accuracy: 3.2489e-04\n",
      "Epoch 314/1000\n",
      "1155/1155 [==============================] - 2s 1ms/step - loss: 4563.7246 - mae: 34.8643 - mse: 4563.7246 - accuracy: 0.2109 - val_loss: 3104.9299 - val_mae: 27.2205 - val_mse: 3104.9299 - val_accuracy: 0.0031\n",
      "Epoch 315/1000\n",
      "1155/1155 [==============================] - 2s 1ms/step - loss: 4598.0645 - mae: 35.0216 - mse: 4598.0645 - accuracy: 0.2104 - val_loss: 2976.6321 - val_mae: 25.9315 - val_mse: 2976.6321 - val_accuracy: 0.0045\n",
      "Epoch 316/1000\n",
      "1155/1155 [==============================] - 2s 1ms/step - loss: 4707.6074 - mae: 35.2357 - mse: 4707.6074 - accuracy: 0.2117 - val_loss: 3105.5442 - val_mae: 27.5490 - val_mse: 3105.5442 - val_accuracy: 7.5807e-04\n",
      "Epoch 317/1000\n",
      "1155/1155 [==============================] - 2s 1ms/step - loss: 4656.4932 - mae: 35.0698 - mse: 4656.4932 - accuracy: 0.2093 - val_loss: 3049.2175 - val_mae: 25.8875 - val_mse: 3049.2175 - val_accuracy: 0.0073\n",
      "Epoch 318/1000\n",
      "1155/1155 [==============================] - 2s 1ms/step - loss: 4523.0781 - mae: 34.8660 - mse: 4523.0781 - accuracy: 0.2107 - val_loss: 3025.4248 - val_mae: 27.5138 - val_mse: 3025.4248 - val_accuracy: 9.7466e-04\n",
      "Epoch 319/1000\n",
      "1155/1155 [==============================] - 2s 1ms/step - loss: 4612.1890 - mae: 34.9735 - mse: 4612.1890 - accuracy: 0.2085 - val_loss: 3213.6052 - val_mae: 26.7706 - val_mse: 3213.6052 - val_accuracy: 0.0113\n",
      "Epoch 320/1000\n",
      "1155/1155 [==============================] - 2s 1ms/step - loss: 4703.7876 - mae: 35.1785 - mse: 4703.7876 - accuracy: 0.2084 - val_loss: 2988.3262 - val_mae: 26.4193 - val_mse: 2988.3262 - val_accuracy: 0.0015\n",
      "Epoch 321/1000\n",
      "1155/1155 [==============================] - 2s 1ms/step - loss: 4679.0029 - mae: 35.1313 - mse: 4679.0029 - accuracy: 0.2115 - val_loss: 2902.0330 - val_mae: 25.7363 - val_mse: 2902.0330 - val_accuracy: 0.0013\n",
      "Epoch 322/1000\n",
      "1155/1155 [==============================] - 2s 1ms/step - loss: 4640.7271 - mae: 35.0259 - mse: 4640.7271 - accuracy: 0.2105 - val_loss: 3200.7939 - val_mae: 26.1859 - val_mse: 3200.7939 - val_accuracy: 0.0175\n",
      "Epoch 323/1000\n",
      "1155/1155 [==============================] - 2s 1ms/step - loss: 4562.1167 - mae: 34.9661 - mse: 4562.1167 - accuracy: 0.2088 - val_loss: 2998.9590 - val_mae: 28.1144 - val_mse: 2998.9590 - val_accuracy: 1.0830e-04\n",
      "Epoch 324/1000\n",
      "1155/1155 [==============================] - 2s 1ms/step - loss: 4540.1860 - mae: 34.8991 - mse: 4540.1860 - accuracy: 0.2102 - val_loss: 3087.6057 - val_mae: 26.4622 - val_mse: 3087.6057 - val_accuracy: 0.0115\n",
      "Epoch 325/1000\n",
      "1155/1155 [==============================] - 2s 1ms/step - loss: 4534.7266 - mae: 34.8427 - mse: 4534.7266 - accuracy: 0.2120 - val_loss: 2912.4666 - val_mae: 25.2262 - val_mse: 2912.4666 - val_accuracy: 0.0245\n",
      "Epoch 326/1000\n",
      "1155/1155 [==============================] - 2s 1ms/step - loss: 4580.1694 - mae: 34.8271 - mse: 4580.1694 - accuracy: 0.2110 - val_loss: 3131.3848 - val_mae: 27.5375 - val_mse: 3131.3848 - val_accuracy: 0.0013\n",
      "Epoch 327/1000\n",
      "1155/1155 [==============================] - 2s 1ms/step - loss: 4655.2778 - mae: 35.2055 - mse: 4655.2778 - accuracy: 0.2108 - val_loss: 2994.1172 - val_mae: 26.3610 - val_mse: 2994.1172 - val_accuracy: 0.0030\n",
      "Epoch 328/1000\n",
      "1155/1155 [==============================] - 2s 1ms/step - loss: 4677.6069 - mae: 35.2361 - mse: 4677.6069 - accuracy: 0.2106 - val_loss: 2938.0623 - val_mae: 25.6675 - val_mse: 2938.0623 - val_accuracy: 0.0030\n",
      "Epoch 329/1000\n",
      "1155/1155 [==============================] - 2s 1ms/step - loss: 4599.0513 - mae: 35.0294 - mse: 4599.0513 - accuracy: 0.2103 - val_loss: 2899.0420 - val_mae: 23.7929 - val_mse: 2899.0420 - val_accuracy: 0.0995\n",
      "Epoch 330/1000\n",
      "1155/1155 [==============================] - 2s 1ms/step - loss: 4551.7676 - mae: 34.9972 - mse: 4551.7676 - accuracy: 0.2112 - val_loss: 2895.8301 - val_mae: 25.4929 - val_mse: 2895.8301 - val_accuracy: 0.0012\n",
      "Epoch 331/1000\n",
      "1155/1155 [==============================] - 2s 1ms/step - loss: 4564.5195 - mae: 34.9156 - mse: 4564.5195 - accuracy: 0.2097 - val_loss: 2934.4817 - val_mae: 26.5841 - val_mse: 2934.4817 - val_accuracy: 9.7466e-04\n",
      "Epoch 332/1000\n",
      "1155/1155 [==============================] - 2s 1ms/step - loss: 4505.9604 - mae: 34.7370 - mse: 4505.9604 - accuracy: 0.2081 - val_loss: 3051.7917 - val_mae: 25.9718 - val_mse: 3051.7917 - val_accuracy: 0.0055\n",
      "Epoch 333/1000\n",
      "1155/1155 [==============================] - 2s 1ms/step - loss: 4532.2080 - mae: 35.0065 - mse: 4532.2080 - accuracy: 0.2107 - val_loss: 3008.4482 - val_mae: 27.0323 - val_mse: 3008.4482 - val_accuracy: 8.6636e-04\n",
      "Epoch 334/1000\n",
      "1155/1155 [==============================] - 2s 1ms/step - loss: 4663.3652 - mae: 35.2802 - mse: 4663.3652 - accuracy: 0.2121 - val_loss: 3050.6724 - val_mae: 26.1701 - val_mse: 3050.6724 - val_accuracy: 0.0104\n",
      "Epoch 335/1000\n",
      "1155/1155 [==============================] - 2s 1ms/step - loss: 4511.6289 - mae: 34.9002 - mse: 4511.6289 - accuracy: 0.2092 - val_loss: 2971.4563 - val_mae: 25.9250 - val_mse: 2971.4563 - val_accuracy: 0.0045\n",
      "Epoch 336/1000\n",
      "1155/1155 [==============================] - 2s 1ms/step - loss: 4612.9224 - mae: 35.0872 - mse: 4612.9224 - accuracy: 0.2091 - val_loss: 2959.0085 - val_mae: 27.6182 - val_mse: 2959.0085 - val_accuracy: 0.0011\n",
      "Epoch 337/1000\n",
      "1155/1155 [==============================] - 2s 1ms/step - loss: 4663.4263 - mae: 35.2334 - mse: 4663.4263 - accuracy: 0.2097 - val_loss: 3229.1121 - val_mae: 26.6211 - val_mse: 3229.1121 - val_accuracy: 0.0105\n",
      "Epoch 338/1000\n",
      "1155/1155 [==============================] - 2s 1ms/step - loss: 4538.5850 - mae: 34.8393 - mse: 4538.5850 - accuracy: 0.2134 - val_loss: 3026.5469 - val_mae: 27.2580 - val_mse: 3026.5469 - val_accuracy: 2.1659e-04\n",
      "Epoch 339/1000\n",
      "1155/1155 [==============================] - 2s 1ms/step - loss: 4614.7900 - mae: 35.1164 - mse: 4614.7900 - accuracy: 0.2121 - val_loss: 3108.9836 - val_mae: 27.8330 - val_mse: 3108.9836 - val_accuracy: 4.3318e-04\n",
      "Epoch 340/1000\n",
      "1155/1155 [==============================] - 2s 1ms/step - loss: 4494.5625 - mae: 34.8906 - mse: 4494.5625 - accuracy: 0.2090 - val_loss: 2941.1533 - val_mae: 26.2102 - val_mse: 2941.1533 - val_accuracy: 0.0012\n",
      "Epoch 341/1000\n",
      "1155/1155 [==============================] - 2s 1ms/step - loss: 4663.4175 - mae: 35.1439 - mse: 4663.4175 - accuracy: 0.2109 - val_loss: 2912.2620 - val_mae: 26.1957 - val_mse: 2912.2620 - val_accuracy: 0.0015\n",
      "Epoch 342/1000\n",
      "1155/1155 [==============================] - 2s 1ms/step - loss: 4595.0493 - mae: 35.0183 - mse: 4595.0493 - accuracy: 0.2107 - val_loss: 2998.4263 - val_mae: 27.4866 - val_mse: 2998.4263 - val_accuracy: 0.0000e+00\n",
      "Epoch 343/1000\n",
      "1155/1155 [==============================] - 2s 1ms/step - loss: 4550.1353 - mae: 34.9647 - mse: 4550.1353 - accuracy: 0.2093 - val_loss: 2953.5752 - val_mae: 26.8839 - val_mse: 2953.5752 - val_accuracy: 2.1659e-04\n",
      "Epoch 344/1000\n",
      "1155/1155 [==============================] - 2s 1ms/step - loss: 4613.7451 - mae: 35.1579 - mse: 4613.7451 - accuracy: 0.2116 - val_loss: 2942.4932 - val_mae: 26.0391 - val_mse: 2942.4932 - val_accuracy: 0.0025\n",
      "Epoch 345/1000\n",
      "1155/1155 [==============================] - 2s 1ms/step - loss: 4648.9575 - mae: 35.1787 - mse: 4648.9575 - accuracy: 0.2111 - val_loss: 2925.7092 - val_mae: 26.1664 - val_mse: 2925.7092 - val_accuracy: 0.0024\n",
      "Epoch 346/1000\n",
      "1155/1155 [==============================] - 2s 1ms/step - loss: 4668.9229 - mae: 35.2887 - mse: 4668.9229 - accuracy: 0.2114 - val_loss: 3157.1133 - val_mae: 27.2726 - val_mse: 3157.1133 - val_accuracy: 0.0026\n",
      "Epoch 347/1000\n",
      "1155/1155 [==============================] - 2s 1ms/step - loss: 4477.5205 - mae: 34.8838 - mse: 4477.5205 - accuracy: 0.2101 - val_loss: 3468.3035 - val_mae: 28.8808 - val_mse: 3468.3035 - val_accuracy: 0.0021\n",
      "Epoch 348/1000\n",
      "1155/1155 [==============================] - 2s 1ms/step - loss: 4475.3433 - mae: 34.8665 - mse: 4475.3433 - accuracy: 0.2138 - val_loss: 2952.7080 - val_mae: 26.6233 - val_mse: 2952.7080 - val_accuracy: 0.0016\n",
      "Epoch 349/1000\n",
      "1155/1155 [==============================] - 2s 1ms/step - loss: 4710.6133 - mae: 35.4136 - mse: 4710.6133 - accuracy: 0.2114 - val_loss: 2994.9143 - val_mae: 26.5558 - val_mse: 2994.9143 - val_accuracy: 0.0050\n",
      "Epoch 350/1000\n",
      "1155/1155 [==============================] - 2s 1ms/step - loss: 4660.6567 - mae: 35.1674 - mse: 4660.6567 - accuracy: 0.2111 - val_loss: 3339.8306 - val_mae: 27.9716 - val_mse: 3339.8306 - val_accuracy: 0.0036\n",
      "Epoch 351/1000\n",
      "1155/1155 [==============================] - 2s 1ms/step - loss: 4659.1479 - mae: 35.1723 - mse: 4659.1479 - accuracy: 0.2108 - val_loss: 3178.3494 - val_mae: 27.9660 - val_mse: 3178.3494 - val_accuracy: 4.3318e-04\n",
      "Epoch 352/1000\n",
      "1155/1155 [==============================] - 2s 1ms/step - loss: 4656.1826 - mae: 35.2198 - mse: 4656.1826 - accuracy: 0.2125 - val_loss: 2913.4294 - val_mae: 25.2253 - val_mse: 2913.4294 - val_accuracy: 0.0062\n",
      "Epoch 353/1000\n",
      "1155/1155 [==============================] - 2s 1ms/step - loss: 4541.3223 - mae: 34.9850 - mse: 4541.3223 - accuracy: 0.2092 - val_loss: 3197.9004 - val_mae: 27.5583 - val_mse: 3197.9004 - val_accuracy: 0.0054\n",
      "Epoch 354/1000\n",
      "1155/1155 [==============================] - 2s 1ms/step - loss: 4500.8105 - mae: 35.0917 - mse: 4500.8105 - accuracy: 0.2111 - val_loss: 3114.2720 - val_mae: 25.2637 - val_mse: 3114.2720 - val_accuracy: 0.0506\n",
      "Epoch 355/1000\n",
      "1155/1155 [==============================] - 2s 1ms/step - loss: 4494.2139 - mae: 34.9178 - mse: 4494.2139 - accuracy: 0.2117 - val_loss: 3059.8022 - val_mae: 28.7069 - val_mse: 3059.8022 - val_accuracy: 0.0000e+00\n",
      "Epoch 356/1000\n",
      "1155/1155 [==============================] - 2s 1ms/step - loss: 4521.3613 - mae: 34.9473 - mse: 4521.3613 - accuracy: 0.2090 - val_loss: 3146.7688 - val_mae: 27.8253 - val_mse: 3146.7688 - val_accuracy: 6.4977e-04\n",
      "Epoch 357/1000\n",
      "1155/1155 [==============================] - 2s 1ms/step - loss: 4429.5356 - mae: 34.7789 - mse: 4429.5356 - accuracy: 0.2105 - val_loss: 2940.1929 - val_mae: 25.2652 - val_mse: 2940.1929 - val_accuracy: 0.0088\n",
      "Epoch 358/1000\n",
      "1155/1155 [==============================] - 2s 1ms/step - loss: 4588.2695 - mae: 34.9581 - mse: 4588.2695 - accuracy: 0.2120 - val_loss: 3061.1528 - val_mae: 26.5734 - val_mse: 3061.1528 - val_accuracy: 0.0036\n",
      "Epoch 359/1000\n",
      "1155/1155 [==============================] - 2s 1ms/step - loss: 4522.7163 - mae: 34.9522 - mse: 4522.7163 - accuracy: 0.2100 - val_loss: 2959.5415 - val_mae: 26.3009 - val_mse: 2959.5415 - val_accuracy: 0.0015\n",
      "Epoch 360/1000\n",
      "1155/1155 [==============================] - 2s 1ms/step - loss: 4467.2861 - mae: 34.8471 - mse: 4467.2861 - accuracy: 0.2106 - val_loss: 2911.8792 - val_mae: 26.7568 - val_mse: 2911.8792 - val_accuracy: 0.0019\n",
      "Epoch 361/1000\n",
      "1155/1155 [==============================] - 2s 1ms/step - loss: 4537.6982 - mae: 35.0845 - mse: 4537.6982 - accuracy: 0.2094 - val_loss: 3100.7837 - val_mae: 25.9513 - val_mse: 3100.7837 - val_accuracy: 0.0461\n",
      "Epoch 362/1000\n",
      "1155/1155 [==============================] - 2s 1ms/step - loss: 4622.5400 - mae: 35.0749 - mse: 4622.5400 - accuracy: 0.2112 - val_loss: 2908.7878 - val_mae: 25.3734 - val_mse: 2908.7878 - val_accuracy: 0.0028\n",
      "Epoch 363/1000\n",
      "1155/1155 [==============================] - 2s 1ms/step - loss: 4569.1079 - mae: 35.0527 - mse: 4569.1079 - accuracy: 0.2078 - val_loss: 2948.4561 - val_mae: 25.4671 - val_mse: 2948.4561 - val_accuracy: 0.0081\n",
      "Epoch 364/1000\n",
      "1155/1155 [==============================] - 2s 1ms/step - loss: 4464.6313 - mae: 34.9146 - mse: 4464.6313 - accuracy: 0.2110 - val_loss: 2944.3386 - val_mae: 24.6505 - val_mse: 2944.3386 - val_accuracy: 0.0309\n",
      "Epoch 365/1000\n",
      "1155/1155 [==============================] - 2s 1ms/step - loss: 4502.3325 - mae: 35.0660 - mse: 4502.3325 - accuracy: 0.2105 - val_loss: 2922.0010 - val_mae: 25.2770 - val_mse: 2922.0010 - val_accuracy: 0.0213\n",
      "Epoch 366/1000\n",
      "1155/1155 [==============================] - 2s 1ms/step - loss: 4487.0449 - mae: 34.8880 - mse: 4487.0449 - accuracy: 0.2092 - val_loss: 3028.5579 - val_mae: 24.9610 - val_mse: 3028.5579 - val_accuracy: 0.0559\n",
      "Epoch 367/1000\n",
      "1155/1155 [==============================] - 2s 1ms/step - loss: 4618.6577 - mae: 35.2662 - mse: 4618.6577 - accuracy: 0.2126 - val_loss: 2936.1729 - val_mae: 26.2328 - val_mse: 2936.1729 - val_accuracy: 6.4977e-04\n",
      "Epoch 368/1000\n",
      "1155/1155 [==============================] - 2s 1ms/step - loss: 4516.1011 - mae: 34.9954 - mse: 4516.1011 - accuracy: 0.2091 - val_loss: 2878.5425 - val_mae: 26.3035 - val_mse: 2878.5425 - val_accuracy: 8.6636e-04\n",
      "Epoch 369/1000\n",
      "1155/1155 [==============================] - 2s 1ms/step - loss: 4555.9561 - mae: 34.9332 - mse: 4555.9561 - accuracy: 0.2081 - val_loss: 2948.0432 - val_mae: 25.8999 - val_mse: 2948.0432 - val_accuracy: 0.0037\n",
      "Epoch 370/1000\n",
      "1155/1155 [==============================] - 2s 1ms/step - loss: 4645.6860 - mae: 35.2746 - mse: 4645.6860 - accuracy: 0.2136 - val_loss: 2867.6689 - val_mae: 24.9115 - val_mse: 2867.6689 - val_accuracy: 0.0407\n",
      "Epoch 371/1000\n",
      "1155/1155 [==============================] - 2s 1ms/step - loss: 4488.4453 - mae: 35.0141 - mse: 4488.4453 - accuracy: 0.2091 - val_loss: 3169.9070 - val_mae: 28.0192 - val_mse: 3169.9070 - val_accuracy: 3.2489e-04\n",
      "Epoch 372/1000\n",
      "1155/1155 [==============================] - 2s 1ms/step - loss: 4532.4331 - mae: 35.0820 - mse: 4532.4331 - accuracy: 0.2105 - val_loss: 2969.3425 - val_mae: 26.7150 - val_mse: 2969.3425 - val_accuracy: 0.0018\n",
      "Epoch 373/1000\n",
      "1155/1155 [==============================] - 2s 1ms/step - loss: 4498.7671 - mae: 34.8911 - mse: 4498.7671 - accuracy: 0.2124 - val_loss: 3181.5437 - val_mae: 28.4194 - val_mse: 3181.5437 - val_accuracy: 4.3318e-04\n",
      "Epoch 374/1000\n",
      "1155/1155 [==============================] - 2s 1ms/step - loss: 4539.4971 - mae: 35.0739 - mse: 4539.4971 - accuracy: 0.2117 - val_loss: 3079.9836 - val_mae: 26.7328 - val_mse: 3079.9836 - val_accuracy: 0.0041\n",
      "Epoch 375/1000\n",
      "1155/1155 [==============================] - 2s 1ms/step - loss: 4545.4033 - mae: 35.0815 - mse: 4545.4033 - accuracy: 0.2104 - val_loss: 3328.5674 - val_mae: 28.6448 - val_mse: 3328.5674 - val_accuracy: 5.4148e-04\n",
      "Epoch 376/1000\n",
      "1155/1155 [==============================] - 2s 1ms/step - loss: 4567.8599 - mae: 34.9667 - mse: 4567.8599 - accuracy: 0.2117 - val_loss: 3033.6790 - val_mae: 27.3708 - val_mse: 3033.6790 - val_accuracy: 4.3318e-04\n",
      "Epoch 377/1000\n",
      "1155/1155 [==============================] - 2s 1ms/step - loss: 4530.7222 - mae: 34.8604 - mse: 4530.7222 - accuracy: 0.2117 - val_loss: 3067.0439 - val_mae: 27.3350 - val_mse: 3067.0439 - val_accuracy: 0.0015\n",
      "Epoch 378/1000\n",
      "1155/1155 [==============================] - 2s 1ms/step - loss: 4652.6108 - mae: 35.2064 - mse: 4652.6108 - accuracy: 0.2091 - val_loss: 2998.3987 - val_mae: 28.4650 - val_mse: 2998.3987 - val_accuracy: 0.0000e+00\n",
      "Epoch 379/1000\n",
      "1155/1155 [==============================] - 2s 1ms/step - loss: 4457.1460 - mae: 34.8141 - mse: 4457.1460 - accuracy: 0.2107 - val_loss: 2938.0627 - val_mae: 26.1300 - val_mse: 2938.0627 - val_accuracy: 0.0014\n",
      "Epoch 380/1000\n",
      "1155/1155 [==============================] - 2s 1ms/step - loss: 4554.4971 - mae: 35.0656 - mse: 4554.4971 - accuracy: 0.2121 - val_loss: 3091.5435 - val_mae: 27.8670 - val_mse: 3091.5435 - val_accuracy: 0.0014\n",
      "Epoch 381/1000\n",
      "1155/1155 [==============================] - 2s 1ms/step - loss: 4474.7920 - mae: 34.7470 - mse: 4474.7920 - accuracy: 0.2103 - val_loss: 2909.2678 - val_mae: 26.8037 - val_mse: 2909.2678 - val_accuracy: 6.4977e-04\n",
      "Epoch 382/1000\n",
      "1155/1155 [==============================] - 2s 1ms/step - loss: 4554.5356 - mae: 34.9898 - mse: 4554.5356 - accuracy: 0.2109 - val_loss: 3457.5781 - val_mae: 28.2768 - val_mse: 3457.5781 - val_accuracy: 0.0037\n",
      "Epoch 383/1000\n",
      "1155/1155 [==============================] - 2s 1ms/step - loss: 4523.4658 - mae: 34.9273 - mse: 4523.4658 - accuracy: 0.2127 - val_loss: 3020.5193 - val_mae: 26.6133 - val_mse: 3020.5193 - val_accuracy: 0.0025\n",
      "Epoch 384/1000\n",
      "1155/1155 [==============================] - 2s 1ms/step - loss: 4576.2026 - mae: 34.9821 - mse: 4576.2026 - accuracy: 0.2124 - val_loss: 2922.0583 - val_mae: 26.2262 - val_mse: 2922.0583 - val_accuracy: 0.0013\n",
      "Epoch 385/1000\n",
      "1155/1155 [==============================] - 2s 1ms/step - loss: 4651.4619 - mae: 35.2958 - mse: 4651.4619 - accuracy: 0.2098 - val_loss: 2959.7695 - val_mae: 25.6276 - val_mse: 2959.7695 - val_accuracy: 0.0244\n",
      "Epoch 386/1000\n",
      "1155/1155 [==============================] - 2s 1ms/step - loss: 4483.6733 - mae: 35.0482 - mse: 4483.6733 - accuracy: 0.2122 - val_loss: 3037.5806 - val_mae: 26.4626 - val_mse: 3037.5806 - val_accuracy: 0.0023\n",
      "Epoch 387/1000\n",
      "1155/1155 [==============================] - 2s 1ms/step - loss: 4586.4478 - mae: 35.3456 - mse: 4586.4478 - accuracy: 0.2091 - val_loss: 3939.5715 - val_mae: 28.9148 - val_mse: 3939.5715 - val_accuracy: 0.0093\n",
      "Epoch 388/1000\n",
      "1155/1155 [==============================] - 2s 1ms/step - loss: 4534.0288 - mae: 34.9064 - mse: 4534.0288 - accuracy: 0.2117 - val_loss: 2961.6433 - val_mae: 25.9002 - val_mse: 2961.6433 - val_accuracy: 0.0142\n",
      "Epoch 389/1000\n",
      "1155/1155 [==============================] - 2s 1ms/step - loss: 4400.9751 - mae: 34.7296 - mse: 4400.9751 - accuracy: 0.2117 - val_loss: 3018.0330 - val_mae: 25.5922 - val_mse: 3018.0330 - val_accuracy: 0.0139\n",
      "Epoch 390/1000\n",
      "1155/1155 [==============================] - 2s 1ms/step - loss: 4480.2061 - mae: 35.0219 - mse: 4480.2061 - accuracy: 0.2098 - val_loss: 2900.9260 - val_mae: 24.8705 - val_mse: 2900.9260 - val_accuracy: 0.0341\n",
      "Epoch 391/1000\n",
      "1155/1155 [==============================] - 2s 1ms/step - loss: 4559.1528 - mae: 35.0817 - mse: 4559.1528 - accuracy: 0.2116 - val_loss: 2976.7075 - val_mae: 25.9675 - val_mse: 2976.7075 - val_accuracy: 0.0041\n",
      "Epoch 392/1000\n",
      "1155/1155 [==============================] - 2s 1ms/step - loss: 4647.5078 - mae: 35.3057 - mse: 4647.5078 - accuracy: 0.2134 - val_loss: 2926.3494 - val_mae: 25.3658 - val_mse: 2926.3494 - val_accuracy: 0.0095\n",
      "Epoch 393/1000\n",
      "1155/1155 [==============================] - 2s 1ms/step - loss: 4479.5869 - mae: 34.8179 - mse: 4479.5869 - accuracy: 0.2117 - val_loss: 2897.3035 - val_mae: 26.2906 - val_mse: 2897.3035 - val_accuracy: 0.0055\n",
      "Epoch 394/1000\n",
      "1155/1155 [==============================] - 2s 1ms/step - loss: 4491.1836 - mae: 35.1618 - mse: 4491.1836 - accuracy: 0.2083 - val_loss: 2853.6626 - val_mae: 25.7405 - val_mse: 2853.6626 - val_accuracy: 0.0030\n",
      "Epoch 395/1000\n",
      "1155/1155 [==============================] - 2s 1ms/step - loss: 4505.5527 - mae: 34.8634 - mse: 4505.5527 - accuracy: 0.2094 - val_loss: 3150.0054 - val_mae: 25.6995 - val_mse: 3150.0054 - val_accuracy: 0.0394\n",
      "Epoch 396/1000\n",
      "1155/1155 [==============================] - 2s 1ms/step - loss: 4475.4756 - mae: 34.9339 - mse: 4475.4756 - accuracy: 0.2096 - val_loss: 3013.1350 - val_mae: 26.8475 - val_mse: 3013.1350 - val_accuracy: 0.0018\n",
      "Epoch 397/1000\n",
      "1155/1155 [==============================] - 2s 1ms/step - loss: 4501.5991 - mae: 35.2359 - mse: 4501.5991 - accuracy: 0.2139 - val_loss: 3110.6467 - val_mae: 27.2816 - val_mse: 3110.6467 - val_accuracy: 0.0027\n",
      "Epoch 398/1000\n",
      "1155/1155 [==============================] - 2s 1ms/step - loss: 4522.4058 - mae: 35.2245 - mse: 4522.4058 - accuracy: 0.2102 - val_loss: 3356.8474 - val_mae: 27.7770 - val_mse: 3356.8474 - val_accuracy: 0.0048\n",
      "Epoch 399/1000\n",
      "1155/1155 [==============================] - 2s 1ms/step - loss: 4434.9062 - mae: 34.7999 - mse: 4434.9062 - accuracy: 0.2095 - val_loss: 3017.8472 - val_mae: 25.3864 - val_mse: 3017.8472 - val_accuracy: 0.0233\n",
      "Epoch 400/1000\n",
      "1155/1155 [==============================] - 2s 1ms/step - loss: 4375.3169 - mae: 34.8585 - mse: 4375.3169 - accuracy: 0.2127 - val_loss: 2870.6819 - val_mae: 24.5933 - val_mse: 2870.6819 - val_accuracy: 0.0290\n",
      "Epoch 401/1000\n",
      "1155/1155 [==============================] - 2s 1ms/step - loss: 4474.3896 - mae: 34.9253 - mse: 4474.3896 - accuracy: 0.2096 - val_loss: 2863.4827 - val_mae: 25.1088 - val_mse: 2863.4827 - val_accuracy: 0.0197\n",
      "Epoch 402/1000\n",
      "1155/1155 [==============================] - 2s 1ms/step - loss: 4453.2207 - mae: 34.8164 - mse: 4453.2207 - accuracy: 0.2144 - val_loss: 2877.8264 - val_mae: 27.5529 - val_mse: 2877.8264 - val_accuracy: 3.2489e-04\n",
      "Epoch 403/1000\n",
      "1155/1155 [==============================] - 2s 1ms/step - loss: 4559.6982 - mae: 35.2710 - mse: 4559.6982 - accuracy: 0.2101 - val_loss: 2929.9812 - val_mae: 26.8919 - val_mse: 2929.9812 - val_accuracy: 0.0015\n",
      "Epoch 404/1000\n",
      "1155/1155 [==============================] - 2s 2ms/step - loss: 4533.2251 - mae: 35.2171 - mse: 4533.2251 - accuracy: 0.2102 - val_loss: 2827.2212 - val_mae: 25.4998 - val_mse: 2827.2212 - val_accuracy: 0.0043\n",
      "Epoch 405/1000\n",
      "1155/1155 [==============================] - 2s 1ms/step - loss: 4380.0928 - mae: 34.6983 - mse: 4380.0928 - accuracy: 0.2111 - val_loss: 3063.7812 - val_mae: 27.3625 - val_mse: 3063.7812 - val_accuracy: 0.0024\n",
      "Epoch 406/1000\n",
      "1155/1155 [==============================] - 2s 1ms/step - loss: 4540.4141 - mae: 35.0260 - mse: 4540.4141 - accuracy: 0.2106 - val_loss: 2848.7371 - val_mae: 26.3702 - val_mse: 2848.7371 - val_accuracy: 0.0011\n",
      "Epoch 407/1000\n",
      "1155/1155 [==============================] - 2s 2ms/step - loss: 4474.3677 - mae: 35.2058 - mse: 4474.3677 - accuracy: 0.2109 - val_loss: 2994.4854 - val_mae: 25.7350 - val_mse: 2994.4854 - val_accuracy: 0.0095\n",
      "Epoch 408/1000\n",
      "1155/1155 [==============================] - 2s 2ms/step - loss: 4449.9189 - mae: 34.9673 - mse: 4449.9189 - accuracy: 0.2100 - val_loss: 2995.2981 - val_mae: 28.1982 - val_mse: 2995.2981 - val_accuracy: 0.0000e+00\n",
      "Epoch 409/1000\n",
      "1155/1155 [==============================] - 2s 1ms/step - loss: 4446.9272 - mae: 35.0700 - mse: 4446.9272 - accuracy: 0.2110 - val_loss: 2866.4399 - val_mae: 26.5765 - val_mse: 2866.4399 - val_accuracy: 0.0012\n",
      "Epoch 410/1000\n",
      "1155/1155 [==============================] - 2s 1ms/step - loss: 4522.1665 - mae: 35.1033 - mse: 4522.1665 - accuracy: 0.2105 - val_loss: 2941.7346 - val_mae: 25.9316 - val_mse: 2941.7346 - val_accuracy: 0.0045\n",
      "Epoch 411/1000\n",
      "1155/1155 [==============================] - 2s 2ms/step - loss: 4501.3003 - mae: 35.1325 - mse: 4501.3003 - accuracy: 0.2117 - val_loss: 2888.1973 - val_mae: 26.3212 - val_mse: 2888.1973 - val_accuracy: 0.0024\n",
      "Epoch 412/1000\n",
      "1155/1155 [==============================] - 2s 1ms/step - loss: 4416.8286 - mae: 34.9349 - mse: 4416.8286 - accuracy: 0.2109 - val_loss: 2837.0972 - val_mae: 25.4953 - val_mse: 2837.0972 - val_accuracy: 0.0036\n",
      "Epoch 413/1000\n",
      "1155/1155 [==============================] - 2s 1ms/step - loss: 4441.3667 - mae: 34.8586 - mse: 4441.3667 - accuracy: 0.2112 - val_loss: 2828.5991 - val_mae: 24.8748 - val_mse: 2828.5991 - val_accuracy: 0.0118\n",
      "Epoch 414/1000\n",
      "1155/1155 [==============================] - 2s 1ms/step - loss: 4391.4600 - mae: 34.7841 - mse: 4391.4600 - accuracy: 0.2135 - val_loss: 3281.3716 - val_mae: 28.4465 - val_mse: 3281.3716 - val_accuracy: 0.0012\n",
      "Epoch 415/1000\n",
      "1155/1155 [==============================] - 2s 1ms/step - loss: 4455.2681 - mae: 34.9393 - mse: 4455.2681 - accuracy: 0.2107 - val_loss: 2957.2434 - val_mae: 27.7743 - val_mse: 2957.2434 - val_accuracy: 3.2489e-04\n",
      "Epoch 416/1000\n",
      "1155/1155 [==============================] - 2s 2ms/step - loss: 4301.3467 - mae: 34.6346 - mse: 4301.3467 - accuracy: 0.2126 - val_loss: 2839.4651 - val_mae: 25.2093 - val_mse: 2839.4651 - val_accuracy: 0.0051\n",
      "Epoch 417/1000\n",
      "1155/1155 [==============================] - 2s 2ms/step - loss: 4454.0181 - mae: 35.0515 - mse: 4454.0181 - accuracy: 0.2125 - val_loss: 3442.6199 - val_mae: 29.1644 - val_mse: 3442.6199 - val_accuracy: 1.0830e-04\n",
      "Epoch 418/1000\n",
      "1155/1155 [==============================] - 2s 1ms/step - loss: 4478.2979 - mae: 35.0272 - mse: 4478.2979 - accuracy: 0.2106 - val_loss: 2829.7976 - val_mae: 25.5989 - val_mse: 2829.7976 - val_accuracy: 0.0017\n",
      "Epoch 419/1000\n",
      "1155/1155 [==============================] - 2s 1ms/step - loss: 4411.6431 - mae: 34.9724 - mse: 4411.6431 - accuracy: 0.2092 - val_loss: 2859.5691 - val_mae: 24.9635 - val_mse: 2859.5691 - val_accuracy: 0.0099\n",
      "Epoch 420/1000\n",
      "1155/1155 [==============================] - 2s 1ms/step - loss: 4564.3843 - mae: 35.2295 - mse: 4564.3843 - accuracy: 0.2131 - val_loss: 2836.5156 - val_mae: 26.6911 - val_mse: 2836.5156 - val_accuracy: 0.0011\n",
      "Epoch 421/1000\n",
      "1155/1155 [==============================] - 2s 1ms/step - loss: 4612.6719 - mae: 35.4923 - mse: 4612.6719 - accuracy: 0.2092 - val_loss: 3006.5708 - val_mae: 26.1629 - val_mse: 3006.5708 - val_accuracy: 0.0071\n",
      "Epoch 422/1000\n",
      "1155/1155 [==============================] - 2s 1ms/step - loss: 4505.0459 - mae: 35.0529 - mse: 4505.0459 - accuracy: 0.2112 - val_loss: 2848.8723 - val_mae: 24.3149 - val_mse: 2848.8723 - val_accuracy: 0.0546\n",
      "Epoch 423/1000\n",
      "1155/1155 [==============================] - 2s 1ms/step - loss: 4496.0732 - mae: 34.8303 - mse: 4496.0732 - accuracy: 0.2126 - val_loss: 3071.0398 - val_mae: 26.6114 - val_mse: 3071.0398 - val_accuracy: 0.0065\n",
      "Epoch 424/1000\n",
      "1155/1155 [==============================] - 2s 2ms/step - loss: 4608.5054 - mae: 35.3534 - mse: 4608.5054 - accuracy: 0.2115 - val_loss: 3448.8425 - val_mae: 28.3486 - val_mse: 3448.8425 - val_accuracy: 0.0031\n",
      "Epoch 425/1000\n",
      "1155/1155 [==============================] - 2s 2ms/step - loss: 4286.6514 - mae: 34.7840 - mse: 4286.6514 - accuracy: 0.2107 - val_loss: 2881.2644 - val_mae: 25.1408 - val_mse: 2881.2644 - val_accuracy: 0.0065\n",
      "Epoch 426/1000\n",
      "1155/1155 [==============================] - 2s 1ms/step - loss: 4538.2959 - mae: 35.0130 - mse: 4538.2959 - accuracy: 0.2143 - val_loss: 2872.6536 - val_mae: 26.6867 - val_mse: 2872.6536 - val_accuracy: 7.5807e-04\n",
      "Epoch 427/1000\n",
      "1155/1155 [==============================] - 2s 1ms/step - loss: 4409.6484 - mae: 34.8128 - mse: 4409.6484 - accuracy: 0.2121 - val_loss: 2828.5181 - val_mae: 25.6135 - val_mse: 2828.5181 - val_accuracy: 0.0038\n",
      "Epoch 428/1000\n",
      "1155/1155 [==============================] - 2s 2ms/step - loss: 4513.1055 - mae: 35.1949 - mse: 4513.1055 - accuracy: 0.2108 - val_loss: 3112.1997 - val_mae: 27.2998 - val_mse: 3112.1997 - val_accuracy: 0.0011\n",
      "Epoch 429/1000\n",
      "1155/1155 [==============================] - 2s 2ms/step - loss: 4326.7671 - mae: 34.6788 - mse: 4326.7671 - accuracy: 0.2101 - val_loss: 3024.8296 - val_mae: 26.9440 - val_mse: 3024.8296 - val_accuracy: 0.0025\n",
      "Epoch 430/1000\n",
      "1155/1155 [==============================] - 2s 2ms/step - loss: 4512.3682 - mae: 35.2402 - mse: 4512.3682 - accuracy: 0.2121 - val_loss: 2842.9426 - val_mae: 24.4410 - val_mse: 2842.9426 - val_accuracy: 0.0094\n",
      "Epoch 431/1000\n",
      "1155/1155 [==============================] - 2s 2ms/step - loss: 4449.5093 - mae: 34.8831 - mse: 4449.5093 - accuracy: 0.2085 - val_loss: 2868.7039 - val_mae: 25.3592 - val_mse: 2868.7039 - val_accuracy: 0.0244\n",
      "Epoch 432/1000\n",
      "1155/1155 [==============================] - 2s 2ms/step - loss: 4509.8145 - mae: 35.1474 - mse: 4509.8145 - accuracy: 0.2130 - val_loss: 2840.6482 - val_mae: 25.3408 - val_mse: 2840.6482 - val_accuracy: 0.0076\n",
      "Epoch 433/1000\n",
      "1155/1155 [==============================] - 2s 1ms/step - loss: 4411.9526 - mae: 34.9642 - mse: 4411.9526 - accuracy: 0.2115 - val_loss: 2944.1509 - val_mae: 26.0630 - val_mse: 2944.1509 - val_accuracy: 0.0044\n",
      "Epoch 434/1000\n",
      "1155/1155 [==============================] - 2s 2ms/step - loss: 4532.6733 - mae: 35.2343 - mse: 4532.6733 - accuracy: 0.2117 - val_loss: 2979.8403 - val_mae: 27.4681 - val_mse: 2979.8403 - val_accuracy: 0.0016\n",
      "Epoch 435/1000\n",
      "1155/1155 [==============================] - 2s 2ms/step - loss: 4464.1016 - mae: 35.0646 - mse: 4464.1016 - accuracy: 0.2131 - val_loss: 3028.6870 - val_mae: 28.3557 - val_mse: 3028.6870 - val_accuracy: 0.0000e+00\n",
      "Epoch 436/1000\n",
      "1155/1155 [==============================] - 2s 2ms/step - loss: 4437.1206 - mae: 35.0098 - mse: 4437.1206 - accuracy: 0.2106 - val_loss: 3075.1111 - val_mae: 26.1307 - val_mse: 3075.1111 - val_accuracy: 0.0096\n",
      "Epoch 437/1000\n",
      "1155/1155 [==============================] - 2s 2ms/step - loss: 4477.0376 - mae: 35.1563 - mse: 4477.0376 - accuracy: 0.2103 - val_loss: 3024.2822 - val_mae: 25.4528 - val_mse: 3024.2822 - val_accuracy: 0.0114\n",
      "Epoch 438/1000\n",
      "1155/1155 [==============================] - 2s 2ms/step - loss: 4418.0591 - mae: 34.7541 - mse: 4418.0591 - accuracy: 0.2135 - val_loss: 2988.0054 - val_mae: 26.8268 - val_mse: 2988.0054 - val_accuracy: 0.0023\n",
      "Epoch 439/1000\n",
      "1155/1155 [==============================] - 2s 2ms/step - loss: 4345.9595 - mae: 34.8415 - mse: 4345.9595 - accuracy: 0.2108 - val_loss: 3047.6267 - val_mae: 28.1129 - val_mse: 3047.6267 - val_accuracy: 2.1659e-04\n",
      "Epoch 440/1000\n",
      "1155/1155 [==============================] - 2s 2ms/step - loss: 4442.2319 - mae: 35.0880 - mse: 4442.2319 - accuracy: 0.2112 - val_loss: 2891.2241 - val_mae: 25.8308 - val_mse: 2891.2241 - val_accuracy: 0.0076\n",
      "Epoch 441/1000\n",
      "1155/1155 [==============================] - 2s 2ms/step - loss: 4507.4385 - mae: 34.9655 - mse: 4507.4385 - accuracy: 0.2149 - val_loss: 3140.5269 - val_mae: 28.0891 - val_mse: 3140.5269 - val_accuracy: 7.5807e-04\n",
      "Epoch 442/1000\n",
      "1155/1155 [==============================] - 2s 2ms/step - loss: 4491.0537 - mae: 35.2286 - mse: 4491.0537 - accuracy: 0.2117 - val_loss: 3089.5251 - val_mae: 26.1416 - val_mse: 3089.5251 - val_accuracy: 0.0230\n",
      "Epoch 443/1000\n",
      "1155/1155 [==============================] - 2s 2ms/step - loss: 4394.5483 - mae: 34.7729 - mse: 4394.5483 - accuracy: 0.2111 - val_loss: 3016.1001 - val_mae: 27.6161 - val_mse: 3016.1001 - val_accuracy: 0.0011\n",
      "Epoch 444/1000\n",
      "1155/1155 [==============================] - 2s 2ms/step - loss: 4450.8047 - mae: 35.0501 - mse: 4450.8047 - accuracy: 0.2129 - val_loss: 2844.5884 - val_mae: 24.8582 - val_mse: 2844.5884 - val_accuracy: 0.0164\n",
      "Epoch 445/1000\n",
      "1155/1155 [==============================] - 2s 2ms/step - loss: 4388.9648 - mae: 34.9303 - mse: 4388.9648 - accuracy: 0.2135 - val_loss: 2964.9546 - val_mae: 25.3986 - val_mse: 2964.9546 - val_accuracy: 0.0155\n",
      "Epoch 446/1000\n",
      "1155/1155 [==============================] - 2s 2ms/step - loss: 4581.9370 - mae: 35.2464 - mse: 4581.9370 - accuracy: 0.2113 - val_loss: 3100.2351 - val_mae: 25.9899 - val_mse: 3100.2351 - val_accuracy: 0.0396\n",
      "Epoch 447/1000\n",
      "1155/1155 [==============================] - 2s 1ms/step - loss: 4390.0332 - mae: 34.9991 - mse: 4390.0332 - accuracy: 0.2113 - val_loss: 2818.9531 - val_mae: 24.8555 - val_mse: 2818.9531 - val_accuracy: 0.0061\n",
      "Epoch 448/1000\n",
      "1155/1155 [==============================] - 2s 2ms/step - loss: 4458.8716 - mae: 35.0121 - mse: 4458.8716 - accuracy: 0.2115 - val_loss: 2888.8105 - val_mae: 25.5184 - val_mse: 2888.8105 - val_accuracy: 0.0063\n",
      "Epoch 449/1000\n",
      "1155/1155 [==============================] - 2s 1ms/step - loss: 4329.0737 - mae: 34.6343 - mse: 4329.0737 - accuracy: 0.2135 - val_loss: 2829.5039 - val_mae: 24.2019 - val_mse: 2829.5039 - val_accuracy: 0.0361\n",
      "Epoch 450/1000\n",
      "1155/1155 [==============================] - 2s 1ms/step - loss: 4426.6982 - mae: 34.9482 - mse: 4426.6982 - accuracy: 0.2098 - val_loss: 2835.2129 - val_mae: 26.6556 - val_mse: 2835.2129 - val_accuracy: 0.0058\n",
      "Epoch 451/1000\n",
      "1155/1155 [==============================] - 2s 2ms/step - loss: 4418.5708 - mae: 35.1157 - mse: 4418.5708 - accuracy: 0.2121 - val_loss: 2948.0571 - val_mae: 27.6749 - val_mse: 2948.0571 - val_accuracy: 5.4148e-04\n",
      "Epoch 452/1000\n",
      "1155/1155 [==============================] - 2s 2ms/step - loss: 4409.5303 - mae: 34.7529 - mse: 4409.5303 - accuracy: 0.2116 - val_loss: 2883.9170 - val_mae: 25.7124 - val_mse: 2883.9170 - val_accuracy: 0.0036\n",
      "Epoch 453/1000\n",
      "1155/1155 [==============================] - 2s 2ms/step - loss: 4396.4209 - mae: 34.8080 - mse: 4396.4209 - accuracy: 0.2112 - val_loss: 3046.4976 - val_mae: 26.8446 - val_mse: 3046.4976 - val_accuracy: 0.0035\n",
      "Epoch 454/1000\n",
      "1155/1155 [==============================] - 2s 2ms/step - loss: 4631.6812 - mae: 35.2761 - mse: 4631.6812 - accuracy: 0.2107 - val_loss: 2948.7498 - val_mae: 27.2642 - val_mse: 2948.7498 - val_accuracy: 0.0023\n",
      "Epoch 455/1000\n",
      "1155/1155 [==============================] - 2s 1ms/step - loss: 4458.6890 - mae: 35.1923 - mse: 4458.6890 - accuracy: 0.2086 - val_loss: 2868.7561 - val_mae: 24.7465 - val_mse: 2868.7561 - val_accuracy: 0.0105\n",
      "Epoch 456/1000\n",
      "1155/1155 [==============================] - 2s 1ms/step - loss: 4503.2104 - mae: 35.1343 - mse: 4503.2104 - accuracy: 0.2133 - val_loss: 2918.0571 - val_mae: 24.9642 - val_mse: 2918.0571 - val_accuracy: 0.0240\n",
      "Epoch 457/1000\n",
      "1155/1155 [==============================] - 2s 1ms/step - loss: 4298.7954 - mae: 34.6585 - mse: 4298.7954 - accuracy: 0.2120 - val_loss: 2925.3877 - val_mae: 28.0329 - val_mse: 2925.3877 - val_accuracy: 0.0000e+00\n",
      "Epoch 458/1000\n",
      "1155/1155 [==============================] - 2s 2ms/step - loss: 4332.4150 - mae: 34.7478 - mse: 4332.4150 - accuracy: 0.2136 - val_loss: 2822.2871 - val_mae: 25.9902 - val_mse: 2822.2871 - val_accuracy: 0.0019\n",
      "Epoch 459/1000\n",
      "1155/1155 [==============================] - 2s 1ms/step - loss: 4352.9785 - mae: 34.7114 - mse: 4352.9785 - accuracy: 0.2116 - val_loss: 2842.2168 - val_mae: 25.5445 - val_mse: 2842.2168 - val_accuracy: 0.0026\n",
      "Epoch 460/1000\n",
      "1155/1155 [==============================] - 2s 1ms/step - loss: 4265.1001 - mae: 34.5901 - mse: 4265.1001 - accuracy: 0.2125 - val_loss: 2845.3333 - val_mae: 25.5305 - val_mse: 2845.3333 - val_accuracy: 0.0028\n",
      "Epoch 461/1000\n",
      "1155/1155 [==============================] - 2s 2ms/step - loss: 4500.3340 - mae: 35.2346 - mse: 4500.3340 - accuracy: 0.2108 - val_loss: 2887.7712 - val_mae: 26.4746 - val_mse: 2887.7712 - val_accuracy: 7.5807e-04\n",
      "Epoch 462/1000\n",
      "1155/1155 [==============================] - 2s 2ms/step - loss: 4453.2715 - mae: 35.0608 - mse: 4453.2715 - accuracy: 0.2130 - val_loss: 2924.4250 - val_mae: 25.7533 - val_mse: 2924.4250 - val_accuracy: 0.0054\n",
      "Epoch 463/1000\n",
      "1155/1155 [==============================] - 2s 2ms/step - loss: 4407.1562 - mae: 34.8945 - mse: 4407.1562 - accuracy: 0.2116 - val_loss: 3248.8152 - val_mae: 26.4917 - val_mse: 3248.8152 - val_accuracy: 0.0296\n",
      "Epoch 464/1000\n",
      "1155/1155 [==============================] - 2s 2ms/step - loss: 4412.1411 - mae: 34.8254 - mse: 4412.1411 - accuracy: 0.2137 - val_loss: 2809.7058 - val_mae: 25.0830 - val_mse: 2809.7058 - val_accuracy: 0.0052\n",
      "Epoch 465/1000\n",
      "1155/1155 [==============================] - 2s 2ms/step - loss: 4439.4868 - mae: 34.8746 - mse: 4439.4868 - accuracy: 0.2123 - val_loss: 2909.6094 - val_mae: 26.4883 - val_mse: 2909.6094 - val_accuracy: 0.0021\n",
      "Epoch 466/1000\n",
      "1155/1155 [==============================] - 2s 1ms/step - loss: 4274.3813 - mae: 34.7292 - mse: 4274.3813 - accuracy: 0.2118 - val_loss: 3150.0598 - val_mae: 26.8793 - val_mse: 3150.0598 - val_accuracy: 0.0039\n",
      "Epoch 467/1000\n",
      "1155/1155 [==============================] - 2s 1ms/step - loss: 4414.7808 - mae: 34.9726 - mse: 4414.7808 - accuracy: 0.2135 - val_loss: 3029.4404 - val_mae: 26.5073 - val_mse: 3029.4404 - val_accuracy: 0.0071\n",
      "Epoch 468/1000\n",
      "1155/1155 [==============================] - 2s 2ms/step - loss: 4362.2202 - mae: 34.9113 - mse: 4362.2202 - accuracy: 0.2120 - val_loss: 2875.5728 - val_mae: 25.0202 - val_mse: 2875.5728 - val_accuracy: 0.0065\n",
      "Epoch 469/1000\n",
      "1155/1155 [==============================] - 2s 2ms/step - loss: 4418.3018 - mae: 34.7995 - mse: 4418.3018 - accuracy: 0.2120 - val_loss: 2918.6958 - val_mae: 25.1917 - val_mse: 2918.6958 - val_accuracy: 0.0148\n",
      "Epoch 470/1000\n",
      "1155/1155 [==============================] - 2s 2ms/step - loss: 4430.1396 - mae: 34.9831 - mse: 4430.1396 - accuracy: 0.2123 - val_loss: 2917.4180 - val_mae: 26.0499 - val_mse: 2917.4180 - val_accuracy: 0.0118\n",
      "Epoch 471/1000\n",
      "1155/1155 [==============================] - 2s 2ms/step - loss: 4284.3564 - mae: 34.5541 - mse: 4284.3564 - accuracy: 0.2143 - val_loss: 2841.5303 - val_mae: 26.2861 - val_mse: 2841.5303 - val_accuracy: 0.0054\n",
      "Epoch 472/1000\n",
      "1155/1155 [==============================] - 2s 2ms/step - loss: 4605.6831 - mae: 35.3670 - mse: 4605.6831 - accuracy: 0.2115 - val_loss: 2942.4888 - val_mae: 25.7573 - val_mse: 2942.4888 - val_accuracy: 0.0047\n",
      "Epoch 473/1000\n",
      "1155/1155 [==============================] - 2s 2ms/step - loss: 4459.3735 - mae: 34.9183 - mse: 4459.3735 - accuracy: 0.2123 - val_loss: 2859.1545 - val_mae: 25.5901 - val_mse: 2859.1545 - val_accuracy: 0.0054\n",
      "Epoch 474/1000\n",
      "1155/1155 [==============================] - 2s 1ms/step - loss: 4396.8154 - mae: 34.8039 - mse: 4396.8154 - accuracy: 0.2123 - val_loss: 2929.0039 - val_mae: 25.6105 - val_mse: 2929.0039 - val_accuracy: 0.0105\n",
      "Epoch 475/1000\n",
      "1155/1155 [==============================] - 2s 2ms/step - loss: 4378.2344 - mae: 34.7210 - mse: 4378.2344 - accuracy: 0.2108 - val_loss: 2883.2207 - val_mae: 25.1042 - val_mse: 2883.2207 - val_accuracy: 0.0990\n",
      "Epoch 476/1000\n",
      "1155/1155 [==============================] - 2s 1ms/step - loss: 4274.2959 - mae: 34.5204 - mse: 4274.2959 - accuracy: 0.2115 - val_loss: 3024.7524 - val_mae: 27.4761 - val_mse: 3024.7524 - val_accuracy: 2.1659e-04\n",
      "Epoch 477/1000\n",
      "1155/1155 [==============================] - 2s 1ms/step - loss: 4416.9639 - mae: 34.9154 - mse: 4416.9639 - accuracy: 0.2120 - val_loss: 3050.2932 - val_mae: 27.5936 - val_mse: 3050.2932 - val_accuracy: 2.1659e-04\n",
      "Epoch 478/1000\n",
      "1155/1155 [==============================] - 2s 1ms/step - loss: 4362.0337 - mae: 34.7305 - mse: 4362.0337 - accuracy: 0.2097 - val_loss: 3096.8887 - val_mae: 26.5841 - val_mse: 3096.8887 - val_accuracy: 0.0034\n",
      "Epoch 479/1000\n",
      "1155/1155 [==============================] - 2s 2ms/step - loss: 4436.5898 - mae: 35.0493 - mse: 4436.5898 - accuracy: 0.2143 - val_loss: 2945.2239 - val_mae: 25.2590 - val_mse: 2945.2239 - val_accuracy: 0.0272\n",
      "Epoch 480/1000\n",
      "1155/1155 [==============================] - 2s 2ms/step - loss: 4394.4741 - mae: 34.6715 - mse: 4394.4741 - accuracy: 0.2138 - val_loss: 3148.0310 - val_mae: 27.3719 - val_mse: 3148.0310 - val_accuracy: 0.0014\n",
      "Epoch 481/1000\n",
      "1155/1155 [==============================] - 2s 1ms/step - loss: 4404.0508 - mae: 34.8932 - mse: 4404.0508 - accuracy: 0.2127 - val_loss: 2909.5679 - val_mae: 26.8704 - val_mse: 2909.5679 - val_accuracy: 0.0018\n",
      "Epoch 482/1000\n",
      "1155/1155 [==============================] - 2s 2ms/step - loss: 4403.9995 - mae: 34.8138 - mse: 4403.9995 - accuracy: 0.2145 - val_loss: 3046.9922 - val_mae: 28.6735 - val_mse: 3046.9922 - val_accuracy: 0.0000e+00\n",
      "Epoch 483/1000\n",
      "1155/1155 [==============================] - 2s 2ms/step - loss: 4447.4185 - mae: 34.8852 - mse: 4447.4185 - accuracy: 0.2125 - val_loss: 2947.5896 - val_mae: 27.0314 - val_mse: 2947.5896 - val_accuracy: 6.4977e-04\n",
      "Epoch 484/1000\n",
      "1155/1155 [==============================] - 2s 2ms/step - loss: 4329.3906 - mae: 34.9001 - mse: 4329.3906 - accuracy: 0.2118 - val_loss: 2814.9858 - val_mae: 25.2951 - val_mse: 2814.9858 - val_accuracy: 0.0036\n",
      "Epoch 485/1000\n",
      "1155/1155 [==============================] - 2s 2ms/step - loss: 4380.3706 - mae: 34.9353 - mse: 4380.3706 - accuracy: 0.2098 - val_loss: 3140.9619 - val_mae: 26.6085 - val_mse: 3140.9619 - val_accuracy: 0.0055\n",
      "Epoch 486/1000\n",
      "1155/1155 [==============================] - 2s 2ms/step - loss: 4565.7866 - mae: 35.3353 - mse: 4565.7866 - accuracy: 0.2103 - val_loss: 2853.7087 - val_mae: 25.7531 - val_mse: 2853.7087 - val_accuracy: 0.0050\n",
      "Epoch 487/1000\n",
      "1155/1155 [==============================] - 2s 2ms/step - loss: 4201.1743 - mae: 34.4628 - mse: 4201.1743 - accuracy: 0.2096 - val_loss: 3070.5686 - val_mae: 27.0602 - val_mse: 3070.5686 - val_accuracy: 0.0015\n",
      "Epoch 488/1000\n",
      "1155/1155 [==============================] - 2s 2ms/step - loss: 4475.8984 - mae: 35.0286 - mse: 4475.8984 - accuracy: 0.2122 - val_loss: 3116.4888 - val_mae: 27.7062 - val_mse: 3116.4888 - val_accuracy: 0.0071\n",
      "Epoch 489/1000\n",
      "1155/1155 [==============================] - 2s 2ms/step - loss: 4369.8169 - mae: 34.8866 - mse: 4369.8169 - accuracy: 0.2104 - val_loss: 2933.3616 - val_mae: 27.8633 - val_mse: 2933.3616 - val_accuracy: 4.3318e-04\n",
      "Epoch 490/1000\n",
      "1155/1155 [==============================] - 2s 2ms/step - loss: 4293.8452 - mae: 34.7357 - mse: 4293.8452 - accuracy: 0.2109 - val_loss: 2828.1592 - val_mae: 26.2508 - val_mse: 2828.1592 - val_accuracy: 9.7466e-04\n",
      "Epoch 491/1000\n",
      "1155/1155 [==============================] - 2s 2ms/step - loss: 4413.2026 - mae: 34.9388 - mse: 4413.2026 - accuracy: 0.2096 - val_loss: 3262.3694 - val_mae: 26.2404 - val_mse: 3262.3694 - val_accuracy: 0.0379\n",
      "Epoch 492/1000\n",
      "1155/1155 [==============================] - 2s 2ms/step - loss: 4359.6226 - mae: 34.6936 - mse: 4359.6226 - accuracy: 0.2148 - val_loss: 3229.6667 - val_mae: 27.7576 - val_mse: 3229.6667 - val_accuracy: 0.0012\n",
      "Epoch 493/1000\n",
      "1155/1155 [==============================] - 2s 2ms/step - loss: 4437.3271 - mae: 34.8780 - mse: 4437.3271 - accuracy: 0.2111 - val_loss: 3016.9954 - val_mae: 27.7866 - val_mse: 3016.9954 - val_accuracy: 2.1659e-04\n",
      "Epoch 494/1000\n",
      "1155/1155 [==============================] - 2s 2ms/step - loss: 4421.7544 - mae: 34.9504 - mse: 4421.7544 - accuracy: 0.2118 - val_loss: 2982.2593 - val_mae: 28.3860 - val_mse: 2982.2593 - val_accuracy: 0.0000e+00\n",
      "Epoch 495/1000\n",
      "1155/1155 [==============================] - 2s 2ms/step - loss: 4298.5571 - mae: 34.5028 - mse: 4298.5571 - accuracy: 0.2127 - val_loss: 2881.6958 - val_mae: 25.4874 - val_mse: 2881.6958 - val_accuracy: 0.0081\n",
      "Epoch 496/1000\n",
      "1155/1155 [==============================] - 2s 2ms/step - loss: 4380.3730 - mae: 34.8235 - mse: 4380.3730 - accuracy: 0.2111 - val_loss: 2893.5630 - val_mae: 25.5508 - val_mse: 2893.5630 - val_accuracy: 0.0095\n",
      "Epoch 497/1000\n",
      "1155/1155 [==============================] - 2s 2ms/step - loss: 4376.4102 - mae: 34.8515 - mse: 4376.4102 - accuracy: 0.2110 - val_loss: 2864.1477 - val_mae: 25.6109 - val_mse: 2864.1477 - val_accuracy: 0.0035\n",
      "Epoch 498/1000\n",
      "1155/1155 [==============================] - 2s 1ms/step - loss: 4317.9907 - mae: 34.7451 - mse: 4317.9907 - accuracy: 0.2124 - val_loss: 2927.8308 - val_mae: 26.6724 - val_mse: 2927.8308 - val_accuracy: 0.0037\n",
      "Epoch 499/1000\n",
      "1155/1155 [==============================] - 2s 1ms/step - loss: 4361.3555 - mae: 34.8300 - mse: 4361.3555 - accuracy: 0.2115 - val_loss: 3013.1675 - val_mae: 26.7447 - val_mse: 3013.1675 - val_accuracy: 9.7466e-04\n",
      "Epoch 500/1000\n",
      "1155/1155 [==============================] - 2s 2ms/step - loss: 4300.1172 - mae: 34.7624 - mse: 4300.1172 - accuracy: 0.2123 - val_loss: 2791.3567 - val_mae: 25.0877 - val_mse: 2791.3567 - val_accuracy: 0.0070\n",
      "Epoch 501/1000\n",
      "1155/1155 [==============================] - 2s 2ms/step - loss: 4317.0625 - mae: 34.6182 - mse: 4317.0625 - accuracy: 0.2113 - val_loss: 2927.7686 - val_mae: 25.2326 - val_mse: 2927.7686 - val_accuracy: 0.0066\n",
      "Epoch 502/1000\n",
      "1155/1155 [==============================] - 2s 2ms/step - loss: 4410.6660 - mae: 34.9028 - mse: 4410.6660 - accuracy: 0.2141 - val_loss: 2991.8521 - val_mae: 28.4382 - val_mse: 2991.8521 - val_accuracy: 2.1659e-04\n",
      "Epoch 503/1000\n",
      "1155/1155 [==============================] - 2s 2ms/step - loss: 4351.9907 - mae: 34.8475 - mse: 4351.9907 - accuracy: 0.2095 - val_loss: 3052.3459 - val_mae: 27.3208 - val_mse: 3052.3459 - val_accuracy: 0.0063\n",
      "Epoch 504/1000\n",
      "1155/1155 [==============================] - 2s 2ms/step - loss: 4343.6787 - mae: 34.7701 - mse: 4343.6787 - accuracy: 0.2128 - val_loss: 2880.2148 - val_mae: 27.0136 - val_mse: 2880.2148 - val_accuracy: 4.3318e-04\n",
      "Epoch 505/1000\n",
      "1155/1155 [==============================] - 2s 2ms/step - loss: 4412.1787 - mae: 35.0676 - mse: 4412.1787 - accuracy: 0.2085 - val_loss: 2816.1887 - val_mae: 27.2361 - val_mse: 2816.1887 - val_accuracy: 1.0830e-04\n",
      "Epoch 506/1000\n",
      "1155/1155 [==============================] - 2s 1ms/step - loss: 4327.6729 - mae: 34.7812 - mse: 4327.6729 - accuracy: 0.2115 - val_loss: 2805.4138 - val_mae: 24.4163 - val_mse: 2805.4138 - val_accuracy: 0.0126\n",
      "Epoch 507/1000\n",
      "1155/1155 [==============================] - 2s 2ms/step - loss: 4290.4800 - mae: 34.7610 - mse: 4290.4800 - accuracy: 0.2135 - val_loss: 2951.6726 - val_mae: 26.7275 - val_mse: 2951.6726 - val_accuracy: 0.0029\n",
      "Epoch 508/1000\n",
      "1155/1155 [==============================] - 2s 2ms/step - loss: 4323.7588 - mae: 34.6846 - mse: 4323.7588 - accuracy: 0.2125 - val_loss: 2794.6733 - val_mae: 25.0182 - val_mse: 2794.6733 - val_accuracy: 0.0039\n",
      "Epoch 509/1000\n",
      "1155/1155 [==============================] - 2s 2ms/step - loss: 4284.8696 - mae: 34.6409 - mse: 4284.8696 - accuracy: 0.2123 - val_loss: 3284.9185 - val_mae: 26.8823 - val_mse: 3284.9185 - val_accuracy: 0.0037\n",
      "Epoch 510/1000\n",
      "1155/1155 [==============================] - 2s 2ms/step - loss: 4430.9443 - mae: 34.9101 - mse: 4430.9443 - accuracy: 0.2122 - val_loss: 2905.3901 - val_mae: 27.2178 - val_mse: 2905.3901 - val_accuracy: 2.1659e-04\n",
      "Epoch 511/1000\n",
      "1155/1155 [==============================] - 2s 2ms/step - loss: 4385.0005 - mae: 34.8976 - mse: 4385.0005 - accuracy: 0.2119 - val_loss: 3140.7429 - val_mae: 28.6234 - val_mse: 3140.7429 - val_accuracy: 2.1659e-04\n",
      "Epoch 512/1000\n",
      "1155/1155 [==============================] - 2s 2ms/step - loss: 4286.2700 - mae: 34.7066 - mse: 4286.2700 - accuracy: 0.2132 - val_loss: 3119.9861 - val_mae: 27.3886 - val_mse: 3119.9861 - val_accuracy: 5.4148e-04\n",
      "Epoch 513/1000\n",
      "1155/1155 [==============================] - 2s 2ms/step - loss: 4339.5132 - mae: 34.8671 - mse: 4339.5132 - accuracy: 0.2122 - val_loss: 2965.7334 - val_mae: 27.8438 - val_mse: 2965.7334 - val_accuracy: 2.1659e-04\n",
      "Epoch 514/1000\n",
      "1155/1155 [==============================] - 2s 1ms/step - loss: 4205.0698 - mae: 34.4008 - mse: 4205.0698 - accuracy: 0.2132 - val_loss: 2895.4797 - val_mae: 27.2802 - val_mse: 2895.4797 - val_accuracy: 3.2489e-04\n",
      "Epoch 515/1000\n",
      "1155/1155 [==============================] - 2s 2ms/step - loss: 4329.8228 - mae: 34.7334 - mse: 4329.8228 - accuracy: 0.2115 - val_loss: 3007.4001 - val_mae: 25.4861 - val_mse: 3007.4001 - val_accuracy: 0.0168\n",
      "Epoch 516/1000\n",
      "1155/1155 [==============================] - 2s 2ms/step - loss: 4170.3008 - mae: 34.2915 - mse: 4170.3008 - accuracy: 0.2122 - val_loss: 3132.0547 - val_mae: 29.0380 - val_mse: 3132.0547 - val_accuracy: 7.5807e-04\n",
      "Epoch 517/1000\n",
      "1155/1155 [==============================] - 2s 2ms/step - loss: 4298.2998 - mae: 34.6543 - mse: 4298.2998 - accuracy: 0.2139 - val_loss: 3290.3638 - val_mae: 27.8729 - val_mse: 3290.3638 - val_accuracy: 0.0024\n",
      "Epoch 518/1000\n",
      "1155/1155 [==============================] - 2s 2ms/step - loss: 4300.1475 - mae: 34.7137 - mse: 4300.1475 - accuracy: 0.2110 - val_loss: 2866.9077 - val_mae: 26.3761 - val_mse: 2866.9077 - val_accuracy: 8.6636e-04\n",
      "Epoch 519/1000\n",
      "1155/1155 [==============================] - 2s 1ms/step - loss: 4409.2578 - mae: 35.1092 - mse: 4409.2578 - accuracy: 0.2096 - val_loss: 2859.5901 - val_mae: 26.5495 - val_mse: 2859.5901 - val_accuracy: 0.0049\n",
      "Epoch 520/1000\n",
      "1155/1155 [==============================] - 2s 1ms/step - loss: 4240.5054 - mae: 34.5037 - mse: 4240.5054 - accuracy: 0.2128 - val_loss: 2775.5122 - val_mae: 25.5261 - val_mse: 2775.5122 - val_accuracy: 0.0015\n",
      "Epoch 521/1000\n",
      "1155/1155 [==============================] - 2s 1ms/step - loss: 4441.5474 - mae: 34.9038 - mse: 4441.5474 - accuracy: 0.2127 - val_loss: 2895.0989 - val_mae: 26.7224 - val_mse: 2895.0989 - val_accuracy: 0.0014\n",
      "Epoch 522/1000\n",
      "1155/1155 [==============================] - 2s 1ms/step - loss: 4359.1621 - mae: 34.9695 - mse: 4359.1621 - accuracy: 0.2098 - val_loss: 2955.1951 - val_mae: 25.4076 - val_mse: 2955.1951 - val_accuracy: 0.0113\n",
      "Epoch 523/1000\n",
      "1155/1155 [==============================] - 2s 2ms/step - loss: 4328.9570 - mae: 34.8399 - mse: 4328.9570 - accuracy: 0.2128 - val_loss: 2933.0742 - val_mae: 26.3201 - val_mse: 2933.0742 - val_accuracy: 0.0016\n",
      "Epoch 524/1000\n",
      "1155/1155 [==============================] - 2s 2ms/step - loss: 4303.2788 - mae: 34.6824 - mse: 4303.2788 - accuracy: 0.2110 - val_loss: 3067.7964 - val_mae: 26.3699 - val_mse: 3067.7964 - val_accuracy: 0.0273\n",
      "Epoch 525/1000\n",
      "1155/1155 [==============================] - 2s 2ms/step - loss: 4258.9087 - mae: 34.3852 - mse: 4258.9087 - accuracy: 0.2156 - val_loss: 2995.4421 - val_mae: 28.3287 - val_mse: 2995.4421 - val_accuracy: 0.0000e+00\n",
      "Epoch 526/1000\n",
      "1155/1155 [==============================] - 2s 1ms/step - loss: 4313.5000 - mae: 34.6006 - mse: 4313.5000 - accuracy: 0.2110 - val_loss: 3025.9834 - val_mae: 27.5181 - val_mse: 3025.9834 - val_accuracy: 8.6636e-04\n",
      "Epoch 527/1000\n",
      "1155/1155 [==============================] - 2s 2ms/step - loss: 4382.3232 - mae: 34.8349 - mse: 4382.3232 - accuracy: 0.2119 - val_loss: 2985.7168 - val_mae: 27.5291 - val_mse: 2985.7168 - val_accuracy: 0.0021\n",
      "Epoch 528/1000\n",
      "1155/1155 [==============================] - 2s 2ms/step - loss: 4285.9155 - mae: 34.7607 - mse: 4285.9155 - accuracy: 0.2132 - val_loss: 2911.4299 - val_mae: 26.3224 - val_mse: 2911.4299 - val_accuracy: 0.0027\n",
      "Epoch 529/1000\n",
      "1155/1155 [==============================] - 2s 1ms/step - loss: 4291.8628 - mae: 34.5558 - mse: 4291.8628 - accuracy: 0.2108 - val_loss: 2901.0979 - val_mae: 25.1160 - val_mse: 2901.0979 - val_accuracy: 0.0057\n",
      "Epoch 530/1000\n",
      "1155/1155 [==============================] - 2s 1ms/step - loss: 4325.3125 - mae: 34.7178 - mse: 4325.3125 - accuracy: 0.2120 - val_loss: 2965.3945 - val_mae: 25.6394 - val_mse: 2965.3945 - val_accuracy: 0.0129\n",
      "Epoch 531/1000\n",
      "1155/1155 [==============================] - 2s 1ms/step - loss: 4234.6680 - mae: 34.5716 - mse: 4234.6680 - accuracy: 0.2138 - val_loss: 2848.0781 - val_mae: 25.2686 - val_mse: 2848.0781 - val_accuracy: 0.0038\n",
      "Epoch 532/1000\n",
      "1155/1155 [==============================] - 2s 2ms/step - loss: 4150.8354 - mae: 34.5511 - mse: 4150.8354 - accuracy: 0.2122 - val_loss: 2811.8125 - val_mae: 25.4887 - val_mse: 2811.8125 - val_accuracy: 0.0037\n",
      "Epoch 533/1000\n",
      "1155/1155 [==============================] - 2s 1ms/step - loss: 4402.4604 - mae: 34.9443 - mse: 4402.4604 - accuracy: 0.2130 - val_loss: 2952.6819 - val_mae: 27.0336 - val_mse: 2952.6819 - val_accuracy: 0.0014\n",
      "Epoch 534/1000\n",
      "1155/1155 [==============================] - 2s 2ms/step - loss: 4202.4961 - mae: 34.4109 - mse: 4202.4961 - accuracy: 0.2124 - val_loss: 3325.6938 - val_mae: 28.0154 - val_mse: 3325.6938 - val_accuracy: 0.0018\n",
      "Epoch 535/1000\n",
      "1155/1155 [==============================] - 2s 2ms/step - loss: 4276.1826 - mae: 34.5038 - mse: 4276.1826 - accuracy: 0.2122 - val_loss: 2866.2725 - val_mae: 26.0203 - val_mse: 2866.2725 - val_accuracy: 0.0021\n",
      "Epoch 536/1000\n",
      "1155/1155 [==============================] - 2s 1ms/step - loss: 4263.8706 - mae: 34.7630 - mse: 4263.8706 - accuracy: 0.2112 - val_loss: 2783.7942 - val_mae: 25.0072 - val_mse: 2783.7942 - val_accuracy: 0.0058\n",
      "Epoch 537/1000\n",
      "1155/1155 [==============================] - 2s 2ms/step - loss: 4440.4551 - mae: 34.9956 - mse: 4440.4551 - accuracy: 0.2099 - val_loss: 3180.9563 - val_mae: 28.2795 - val_mse: 3180.9563 - val_accuracy: 2.1659e-04\n",
      "Epoch 538/1000\n",
      "1155/1155 [==============================] - 2s 1ms/step - loss: 4221.1782 - mae: 34.5586 - mse: 4221.1782 - accuracy: 0.2115 - val_loss: 2740.8997 - val_mae: 24.6525 - val_mse: 2740.8997 - val_accuracy: 0.0078\n",
      "Epoch 539/1000\n",
      "1155/1155 [==============================] - 2s 2ms/step - loss: 4401.2686 - mae: 34.8119 - mse: 4401.2686 - accuracy: 0.2135 - val_loss: 2820.4978 - val_mae: 24.2655 - val_mse: 2820.4978 - val_accuracy: 0.0597\n",
      "Epoch 540/1000\n",
      "1155/1155 [==============================] - 2s 1ms/step - loss: 4196.5552 - mae: 34.4546 - mse: 4196.5552 - accuracy: 0.2131 - val_loss: 3247.8018 - val_mae: 27.1934 - val_mse: 3247.8018 - val_accuracy: 0.0027\n",
      "Epoch 541/1000\n",
      "1155/1155 [==============================] - 2s 2ms/step - loss: 4277.4106 - mae: 34.4860 - mse: 4277.4106 - accuracy: 0.2156 - val_loss: 2832.1941 - val_mae: 25.7246 - val_mse: 2832.1941 - val_accuracy: 0.0013\n",
      "Epoch 542/1000\n",
      "1155/1155 [==============================] - 2s 2ms/step - loss: 4321.5039 - mae: 34.7922 - mse: 4321.5039 - accuracy: 0.2110 - val_loss: 2763.8560 - val_mae: 24.4713 - val_mse: 2763.8560 - val_accuracy: 0.0433\n",
      "Epoch 543/1000\n",
      "1155/1155 [==============================] - 2s 2ms/step - loss: 4395.0591 - mae: 34.7710 - mse: 4395.0591 - accuracy: 0.2134 - val_loss: 2775.9023 - val_mae: 24.2815 - val_mse: 2775.9023 - val_accuracy: 0.0153\n",
      "Epoch 544/1000\n",
      "1155/1155 [==============================] - 2s 2ms/step - loss: 4267.1289 - mae: 34.7226 - mse: 4267.1289 - accuracy: 0.2120 - val_loss: 2976.3350 - val_mae: 25.4113 - val_mse: 2976.3350 - val_accuracy: 0.0256\n",
      "Epoch 545/1000\n",
      "1155/1155 [==============================] - 2s 2ms/step - loss: 4352.7524 - mae: 34.9034 - mse: 4352.7524 - accuracy: 0.2107 - val_loss: 2995.9502 - val_mae: 26.1711 - val_mse: 2995.9502 - val_accuracy: 0.0058\n",
      "Epoch 546/1000\n",
      "1155/1155 [==============================] - 2s 1ms/step - loss: 4218.7866 - mae: 34.4491 - mse: 4218.7866 - accuracy: 0.2107 - val_loss: 2973.1875 - val_mae: 27.1482 - val_mse: 2973.1875 - val_accuracy: 0.0013\n",
      "Epoch 547/1000\n",
      "1155/1155 [==============================] - 2s 1ms/step - loss: 4211.4009 - mae: 34.4385 - mse: 4211.4009 - accuracy: 0.2124 - val_loss: 2825.8145 - val_mae: 24.7934 - val_mse: 2825.8145 - val_accuracy: 0.0191\n",
      "Epoch 548/1000\n",
      "1155/1155 [==============================] - 2s 2ms/step - loss: 4286.7261 - mae: 34.8586 - mse: 4286.7261 - accuracy: 0.2159 - val_loss: 2780.8689 - val_mae: 25.6004 - val_mse: 2780.8689 - val_accuracy: 0.0119\n",
      "Epoch 549/1000\n",
      "1155/1155 [==============================] - 2s 2ms/step - loss: 4166.3091 - mae: 34.4034 - mse: 4166.3091 - accuracy: 0.2140 - val_loss: 3006.6421 - val_mae: 27.4464 - val_mse: 3006.6421 - val_accuracy: 4.3318e-04\n",
      "Epoch 550/1000\n",
      "1155/1155 [==============================] - 2s 1ms/step - loss: 4400.7207 - mae: 34.8559 - mse: 4400.7207 - accuracy: 0.2126 - val_loss: 2806.9033 - val_mae: 26.3286 - val_mse: 2806.9033 - val_accuracy: 5.4148e-04\n",
      "Epoch 551/1000\n",
      "1155/1155 [==============================] - 2s 2ms/step - loss: 4237.7900 - mae: 34.5184 - mse: 4237.7900 - accuracy: 0.2138 - val_loss: 3193.0354 - val_mae: 29.4352 - val_mse: 3193.0354 - val_accuracy: 1.0830e-04\n",
      "Epoch 552/1000\n",
      "1155/1155 [==============================] - 2s 1ms/step - loss: 4394.9023 - mae: 34.8176 - mse: 4394.9023 - accuracy: 0.2134 - val_loss: 2984.8250 - val_mae: 26.4759 - val_mse: 2984.8250 - val_accuracy: 0.0019\n",
      "Epoch 553/1000\n",
      "1155/1155 [==============================] - 2s 2ms/step - loss: 4294.3364 - mae: 34.5116 - mse: 4294.3364 - accuracy: 0.2120 - val_loss: 2787.2761 - val_mae: 26.4135 - val_mse: 2787.2761 - val_accuracy: 2.1659e-04\n",
      "Epoch 554/1000\n",
      "1155/1155 [==============================] - 2s 1ms/step - loss: 4247.4927 - mae: 34.6241 - mse: 4247.4927 - accuracy: 0.2122 - val_loss: 2793.1226 - val_mae: 26.5900 - val_mse: 2793.1226 - val_accuracy: 1.0830e-04\n",
      "Epoch 555/1000\n",
      "1155/1155 [==============================] - 2s 2ms/step - loss: 4309.1797 - mae: 34.7820 - mse: 4309.1797 - accuracy: 0.2126 - val_loss: 2994.4595 - val_mae: 27.4821 - val_mse: 2994.4595 - val_accuracy: 2.1659e-04\n",
      "Epoch 556/1000\n",
      "1155/1155 [==============================] - 2s 1ms/step - loss: 4474.9175 - mae: 35.1866 - mse: 4474.9175 - accuracy: 0.2134 - val_loss: 2874.4585 - val_mae: 25.3925 - val_mse: 2874.4585 - val_accuracy: 0.0035\n",
      "Epoch 557/1000\n",
      "1155/1155 [==============================] - 2s 2ms/step - loss: 4348.2227 - mae: 34.8431 - mse: 4348.2227 - accuracy: 0.2093 - val_loss: 2788.7241 - val_mae: 26.3935 - val_mse: 2788.7241 - val_accuracy: 4.3318e-04\n",
      "Epoch 558/1000\n",
      "1155/1155 [==============================] - 2s 2ms/step - loss: 4163.4536 - mae: 34.2416 - mse: 4163.4536 - accuracy: 0.2108 - val_loss: 2847.9795 - val_mae: 25.7079 - val_mse: 2847.9795 - val_accuracy: 0.0041\n",
      "Epoch 559/1000\n",
      "1155/1155 [==============================] - 2s 1ms/step - loss: 4322.9683 - mae: 34.6843 - mse: 4322.9683 - accuracy: 0.2113 - val_loss: 2803.3806 - val_mae: 26.7725 - val_mse: 2803.3806 - val_accuracy: 4.3318e-04\n",
      "Epoch 560/1000\n",
      "1155/1155 [==============================] - 2s 1ms/step - loss: 4280.2559 - mae: 34.5360 - mse: 4280.2559 - accuracy: 0.2109 - val_loss: 2751.4910 - val_mae: 26.6955 - val_mse: 2751.4910 - val_accuracy: 2.1659e-04\n",
      "Epoch 561/1000\n",
      "1155/1155 [==============================] - 2s 1ms/step - loss: 4209.9438 - mae: 34.5941 - mse: 4209.9438 - accuracy: 0.2134 - val_loss: 2843.3928 - val_mae: 26.5234 - val_mse: 2843.3928 - val_accuracy: 0.0021\n",
      "Epoch 562/1000\n",
      "1155/1155 [==============================] - 2s 1ms/step - loss: 4267.5928 - mae: 34.7085 - mse: 4267.5928 - accuracy: 0.2122 - val_loss: 2901.5684 - val_mae: 26.3090 - val_mse: 2901.5684 - val_accuracy: 0.0015\n",
      "Epoch 563/1000\n",
      "1155/1155 [==============================] - 2s 1ms/step - loss: 4271.0166 - mae: 34.6711 - mse: 4271.0166 - accuracy: 0.2136 - val_loss: 3262.4780 - val_mae: 25.6996 - val_mse: 3262.4780 - val_accuracy: 0.0379\n",
      "Epoch 564/1000\n",
      "1155/1155 [==============================] - 2s 1ms/step - loss: 4084.3262 - mae: 34.1615 - mse: 4084.3262 - accuracy: 0.2140 - val_loss: 2798.3823 - val_mae: 25.8638 - val_mse: 2798.3823 - val_accuracy: 0.0024\n",
      "Epoch 565/1000\n",
      "1155/1155 [==============================] - 2s 2ms/step - loss: 4272.6538 - mae: 34.5349 - mse: 4272.6538 - accuracy: 0.2162 - val_loss: 3072.6270 - val_mae: 28.1206 - val_mse: 3072.6270 - val_accuracy: 5.4148e-04\n",
      "Epoch 566/1000\n",
      "1155/1155 [==============================] - 2s 1ms/step - loss: 4206.1841 - mae: 34.4660 - mse: 4206.1841 - accuracy: 0.2103 - val_loss: 2750.5408 - val_mae: 23.6934 - val_mse: 2750.5408 - val_accuracy: 0.0383\n",
      "Epoch 567/1000\n",
      "1155/1155 [==============================] - 2s 1ms/step - loss: 4320.6030 - mae: 34.6666 - mse: 4320.6030 - accuracy: 0.2118 - val_loss: 2897.2908 - val_mae: 25.7362 - val_mse: 2897.2908 - val_accuracy: 0.0053\n",
      "Epoch 568/1000\n",
      "1155/1155 [==============================] - 2s 1ms/step - loss: 4302.0459 - mae: 34.6654 - mse: 4302.0459 - accuracy: 0.2126 - val_loss: 3031.7683 - val_mae: 26.8737 - val_mse: 3031.7683 - val_accuracy: 7.5807e-04\n",
      "Epoch 569/1000\n",
      "1155/1155 [==============================] - 2s 2ms/step - loss: 4351.1973 - mae: 34.8354 - mse: 4351.1973 - accuracy: 0.2145 - val_loss: 2816.9805 - val_mae: 25.6549 - val_mse: 2816.9805 - val_accuracy: 0.0015\n",
      "Epoch 570/1000\n",
      "1155/1155 [==============================] - 2s 1ms/step - loss: 4264.2212 - mae: 34.4317 - mse: 4264.2212 - accuracy: 0.2128 - val_loss: 2748.2390 - val_mae: 25.3090 - val_mse: 2748.2390 - val_accuracy: 9.7466e-04\n",
      "Epoch 571/1000\n",
      "1155/1155 [==============================] - 2s 2ms/step - loss: 4241.9907 - mae: 34.7482 - mse: 4241.9907 - accuracy: 0.2134 - val_loss: 2762.4702 - val_mae: 24.8576 - val_mse: 2762.4702 - val_accuracy: 0.0040\n",
      "Epoch 572/1000\n",
      "1155/1155 [==============================] - 2s 2ms/step - loss: 4192.5337 - mae: 34.2867 - mse: 4192.5337 - accuracy: 0.2127 - val_loss: 2905.4985 - val_mae: 26.5471 - val_mse: 2905.4985 - val_accuracy: 0.0011\n",
      "Epoch 573/1000\n",
      "1155/1155 [==============================] - 2s 2ms/step - loss: 4190.8115 - mae: 34.3708 - mse: 4190.8115 - accuracy: 0.2124 - val_loss: 3013.2219 - val_mae: 26.8613 - val_mse: 3013.2219 - val_accuracy: 0.0012\n",
      "Epoch 574/1000\n",
      "1155/1155 [==============================] - 2s 1ms/step - loss: 4201.1143 - mae: 34.4683 - mse: 4201.1143 - accuracy: 0.2120 - val_loss: 2946.7646 - val_mae: 26.5225 - val_mse: 2946.7646 - val_accuracy: 5.4148e-04\n",
      "Epoch 575/1000\n",
      "1155/1155 [==============================] - 2s 2ms/step - loss: 4263.4482 - mae: 34.5500 - mse: 4263.4482 - accuracy: 0.2134 - val_loss: 2957.7236 - val_mae: 27.0365 - val_mse: 2957.7236 - val_accuracy: 0.0014\n",
      "Epoch 576/1000\n",
      "1155/1155 [==============================] - 2s 2ms/step - loss: 4602.0464 - mae: 35.4887 - mse: 4602.0464 - accuracy: 0.2133 - val_loss: 3167.1785 - val_mae: 26.8682 - val_mse: 3167.1785 - val_accuracy: 0.0081\n",
      "Epoch 577/1000\n",
      "1155/1155 [==============================] - 2s 2ms/step - loss: 4257.2686 - mae: 34.6891 - mse: 4257.2686 - accuracy: 0.2122 - val_loss: 2892.8386 - val_mae: 26.1467 - val_mse: 2892.8386 - val_accuracy: 0.0027\n",
      "Epoch 578/1000\n",
      "1155/1155 [==============================] - 2s 2ms/step - loss: 4262.6504 - mae: 34.7446 - mse: 4262.6504 - accuracy: 0.2137 - val_loss: 2866.3901 - val_mae: 25.0696 - val_mse: 2866.3901 - val_accuracy: 0.0154\n",
      "Epoch 579/1000\n",
      "1155/1155 [==============================] - 2s 1ms/step - loss: 4077.9409 - mae: 34.2338 - mse: 4077.9409 - accuracy: 0.2144 - val_loss: 2922.6711 - val_mae: 27.1287 - val_mse: 2922.6711 - val_accuracy: 3.2489e-04\n",
      "Epoch 580/1000\n",
      "1155/1155 [==============================] - 2s 2ms/step - loss: 4342.2373 - mae: 34.6132 - mse: 4342.2373 - accuracy: 0.2108 - val_loss: 2795.5911 - val_mae: 25.3159 - val_mse: 2795.5911 - val_accuracy: 0.0018\n",
      "Epoch 581/1000\n",
      "1155/1155 [==============================] - 2s 2ms/step - loss: 4346.8833 - mae: 34.8748 - mse: 4346.8833 - accuracy: 0.2126 - val_loss: 3138.6782 - val_mae: 27.2467 - val_mse: 3138.6782 - val_accuracy: 0.0077\n",
      "Epoch 582/1000\n",
      "1155/1155 [==============================] - 2s 2ms/step - loss: 4344.6357 - mae: 34.7759 - mse: 4344.6357 - accuracy: 0.2126 - val_loss: 2962.6028 - val_mae: 25.3823 - val_mse: 2962.6028 - val_accuracy: 0.0099\n",
      "Epoch 583/1000\n",
      "1155/1155 [==============================] - 2s 1ms/step - loss: 4165.8716 - mae: 34.5639 - mse: 4165.8716 - accuracy: 0.2119 - val_loss: 2897.2246 - val_mae: 25.9258 - val_mse: 2897.2246 - val_accuracy: 0.0030\n",
      "Epoch 584/1000\n",
      "1155/1155 [==============================] - 2s 2ms/step - loss: 4373.9409 - mae: 34.8823 - mse: 4373.9409 - accuracy: 0.2141 - val_loss: 2991.2239 - val_mae: 28.1094 - val_mse: 2991.2239 - val_accuracy: 3.2489e-04\n",
      "Epoch 585/1000\n",
      "1155/1155 [==============================] - 2s 1ms/step - loss: 4169.9409 - mae: 34.4923 - mse: 4169.9409 - accuracy: 0.2128 - val_loss: 2843.6704 - val_mae: 24.9607 - val_mse: 2843.6704 - val_accuracy: 0.0279\n",
      "Epoch 586/1000\n",
      "1155/1155 [==============================] - 2s 2ms/step - loss: 4309.2109 - mae: 34.6610 - mse: 4309.2109 - accuracy: 0.2144 - val_loss: 2944.7949 - val_mae: 26.7515 - val_mse: 2944.7949 - val_accuracy: 0.0014\n",
      "Epoch 587/1000\n",
      "1155/1155 [==============================] - 2s 2ms/step - loss: 4255.8057 - mae: 34.5626 - mse: 4255.8057 - accuracy: 0.2105 - val_loss: 2838.2463 - val_mae: 24.9149 - val_mse: 2838.2463 - val_accuracy: 0.0252\n",
      "Epoch 588/1000\n",
      "1155/1155 [==============================] - 2s 2ms/step - loss: 4288.9990 - mae: 34.7111 - mse: 4288.9990 - accuracy: 0.2108 - val_loss: 2845.7878 - val_mae: 24.7221 - val_mse: 2845.7878 - val_accuracy: 0.0093\n",
      "Epoch 589/1000\n",
      "1155/1155 [==============================] - 2s 1ms/step - loss: 4299.0337 - mae: 34.8364 - mse: 4299.0337 - accuracy: 0.2133 - val_loss: 3146.2620 - val_mae: 26.0330 - val_mse: 3146.2620 - val_accuracy: 0.0161\n",
      "Epoch 590/1000\n",
      "1155/1155 [==============================] - 2s 2ms/step - loss: 4292.4072 - mae: 34.5553 - mse: 4292.4072 - accuracy: 0.2114 - val_loss: 2889.4763 - val_mae: 26.0719 - val_mse: 2889.4763 - val_accuracy: 0.0024\n",
      "Epoch 591/1000\n",
      "1155/1155 [==============================] - 2s 1ms/step - loss: 4162.4409 - mae: 34.3385 - mse: 4162.4409 - accuracy: 0.2135 - val_loss: 2839.9780 - val_mae: 27.5990 - val_mse: 2839.9780 - val_accuracy: 0.0012\n",
      "Epoch 592/1000\n",
      "1155/1155 [==============================] - 2s 2ms/step - loss: 4323.9341 - mae: 34.9090 - mse: 4323.9341 - accuracy: 0.2118 - val_loss: 3012.8167 - val_mae: 27.1177 - val_mse: 3012.8167 - val_accuracy: 0.0016\n",
      "Epoch 593/1000\n",
      "1155/1155 [==============================] - 2s 2ms/step - loss: 4181.7026 - mae: 34.3411 - mse: 4181.7026 - accuracy: 0.2123 - val_loss: 2819.8293 - val_mae: 25.0931 - val_mse: 2819.8293 - val_accuracy: 0.0266\n",
      "Epoch 594/1000\n",
      "1155/1155 [==============================] - 2s 1ms/step - loss: 4222.9702 - mae: 34.5245 - mse: 4222.9702 - accuracy: 0.2118 - val_loss: 3029.6206 - val_mae: 26.0899 - val_mse: 3029.6206 - val_accuracy: 0.0164\n",
      "Epoch 595/1000\n",
      "1155/1155 [==============================] - 2s 2ms/step - loss: 4224.5645 - mae: 34.5090 - mse: 4224.5645 - accuracy: 0.2110 - val_loss: 3136.1450 - val_mae: 26.5841 - val_mse: 3136.1450 - val_accuracy: 0.0040\n",
      "Epoch 596/1000\n",
      "1155/1155 [==============================] - 2s 1ms/step - loss: 4224.1353 - mae: 34.4914 - mse: 4224.1353 - accuracy: 0.2134 - val_loss: 2929.1877 - val_mae: 26.1828 - val_mse: 2929.1877 - val_accuracy: 0.0022\n",
      "Epoch 597/1000\n",
      "1155/1155 [==============================] - 2s 2ms/step - loss: 4391.0391 - mae: 34.9208 - mse: 4391.0391 - accuracy: 0.2133 - val_loss: 2864.6228 - val_mae: 25.9594 - val_mse: 2864.6228 - val_accuracy: 0.0024\n",
      "Epoch 598/1000\n",
      "1155/1155 [==============================] - 2s 2ms/step - loss: 4340.8262 - mae: 34.6459 - mse: 4340.8262 - accuracy: 0.2136 - val_loss: 2884.8557 - val_mae: 26.0560 - val_mse: 2884.8557 - val_accuracy: 0.0029\n",
      "Epoch 599/1000\n",
      "1155/1155 [==============================] - 2s 1ms/step - loss: 4189.7163 - mae: 34.6516 - mse: 4189.7163 - accuracy: 0.2124 - val_loss: 2741.7651 - val_mae: 24.5742 - val_mse: 2741.7651 - val_accuracy: 0.0115\n",
      "Epoch 600/1000\n",
      "1155/1155 [==============================] - 2s 2ms/step - loss: 4195.8066 - mae: 34.4082 - mse: 4195.8066 - accuracy: 0.2133 - val_loss: 2829.2891 - val_mae: 27.7384 - val_mse: 2829.2891 - val_accuracy: 0.0000e+00\n",
      "Epoch 601/1000\n",
      "1155/1155 [==============================] - 2s 2ms/step - loss: 4220.4014 - mae: 34.6003 - mse: 4220.4014 - accuracy: 0.2107 - val_loss: 3072.2925 - val_mae: 28.4680 - val_mse: 3072.2925 - val_accuracy: 4.3318e-04\n",
      "Epoch 602/1000\n",
      "1155/1155 [==============================] - 2s 2ms/step - loss: 4315.6738 - mae: 34.7681 - mse: 4315.6738 - accuracy: 0.2112 - val_loss: 2797.4404 - val_mae: 25.0428 - val_mse: 2797.4404 - val_accuracy: 0.0090\n",
      "Epoch 603/1000\n",
      "1155/1155 [==============================] - 2s 2ms/step - loss: 4239.5688 - mae: 34.5165 - mse: 4239.5688 - accuracy: 0.2140 - val_loss: 3059.6958 - val_mae: 28.6716 - val_mse: 3059.6958 - val_accuracy: 2.1659e-04\n",
      "Epoch 604/1000\n",
      "1155/1155 [==============================] - 2s 2ms/step - loss: 4231.8345 - mae: 34.6220 - mse: 4231.8345 - accuracy: 0.2107 - val_loss: 2952.7163 - val_mae: 26.9435 - val_mse: 2952.7163 - val_accuracy: 0.0030\n",
      "Epoch 605/1000\n",
      "1155/1155 [==============================] - 2s 2ms/step - loss: 4267.1533 - mae: 34.4635 - mse: 4267.1533 - accuracy: 0.2145 - val_loss: 2787.2263 - val_mae: 24.0062 - val_mse: 2787.2263 - val_accuracy: 0.0520\n",
      "Epoch 606/1000\n",
      "1155/1155 [==============================] - 2s 1ms/step - loss: 4252.9097 - mae: 34.7576 - mse: 4252.9097 - accuracy: 0.2133 - val_loss: 2815.6960 - val_mae: 24.9992 - val_mse: 2815.6960 - val_accuracy: 0.0354\n",
      "Epoch 607/1000\n",
      "1155/1155 [==============================] - 2s 2ms/step - loss: 4315.6689 - mae: 34.8311 - mse: 4315.6689 - accuracy: 0.2115 - val_loss: 3079.4136 - val_mae: 27.7223 - val_mse: 3079.4136 - val_accuracy: 0.0017\n",
      "Epoch 608/1000\n",
      "1155/1155 [==============================] - 2s 2ms/step - loss: 4268.6216 - mae: 34.5065 - mse: 4268.6216 - accuracy: 0.2113 - val_loss: 2931.5273 - val_mae: 26.1437 - val_mse: 2931.5273 - val_accuracy: 0.0025\n",
      "Epoch 609/1000\n",
      "1155/1155 [==============================] - 2s 1ms/step - loss: 4245.9585 - mae: 34.6908 - mse: 4245.9585 - accuracy: 0.2130 - val_loss: 2755.6423 - val_mae: 24.5799 - val_mse: 2755.6423 - val_accuracy: 0.0126\n",
      "Epoch 610/1000\n",
      "1155/1155 [==============================] - 2s 2ms/step - loss: 4244.2568 - mae: 34.6615 - mse: 4244.2568 - accuracy: 0.2128 - val_loss: 2801.8616 - val_mae: 24.1477 - val_mse: 2801.8616 - val_accuracy: 0.0081\n",
      "Epoch 611/1000\n",
      "1155/1155 [==============================] - 2s 2ms/step - loss: 4266.5732 - mae: 34.6784 - mse: 4266.5732 - accuracy: 0.2130 - val_loss: 2832.3354 - val_mae: 24.3309 - val_mse: 2832.3354 - val_accuracy: 0.0575\n",
      "Epoch 612/1000\n",
      "1155/1155 [==============================] - 2s 1ms/step - loss: 4147.9219 - mae: 34.3817 - mse: 4147.9219 - accuracy: 0.2138 - val_loss: 2996.8040 - val_mae: 26.9342 - val_mse: 2996.8040 - val_accuracy: 6.4977e-04\n",
      "Epoch 613/1000\n",
      "1155/1155 [==============================] - 2s 2ms/step - loss: 4203.5776 - mae: 34.3451 - mse: 4203.5776 - accuracy: 0.2115 - val_loss: 2837.0391 - val_mae: 26.8367 - val_mse: 2837.0391 - val_accuracy: 0.0011\n",
      "Epoch 614/1000\n",
      "1155/1155 [==============================] - 2s 1ms/step - loss: 4155.0449 - mae: 34.3395 - mse: 4155.0449 - accuracy: 0.2128 - val_loss: 3056.3660 - val_mae: 27.8672 - val_mse: 3056.3660 - val_accuracy: 0.0017\n",
      "Epoch 615/1000\n",
      "1155/1155 [==============================] - 2s 2ms/step - loss: 4251.3115 - mae: 34.5729 - mse: 4251.3115 - accuracy: 0.2135 - val_loss: 3025.6069 - val_mae: 27.8669 - val_mse: 3025.6069 - val_accuracy: 5.4148e-04\n",
      "Epoch 616/1000\n",
      "1155/1155 [==============================] - 2s 2ms/step - loss: 4145.5137 - mae: 34.4884 - mse: 4145.5137 - accuracy: 0.2125 - val_loss: 3113.5059 - val_mae: 26.6183 - val_mse: 3113.5059 - val_accuracy: 0.0019\n",
      "Epoch 617/1000\n",
      "1155/1155 [==============================] - 2s 2ms/step - loss: 4309.4819 - mae: 34.8508 - mse: 4309.4819 - accuracy: 0.2108 - val_loss: 2977.2175 - val_mae: 26.6717 - val_mse: 2977.2175 - val_accuracy: 7.5807e-04\n",
      "Epoch 618/1000\n",
      "1155/1155 [==============================] - 2s 2ms/step - loss: 4182.9702 - mae: 34.3108 - mse: 4182.9702 - accuracy: 0.2126 - val_loss: 2740.7283 - val_mae: 26.3039 - val_mse: 2740.7283 - val_accuracy: 6.4977e-04\n",
      "Epoch 619/1000\n",
      "1155/1155 [==============================] - 2s 2ms/step - loss: 4205.6074 - mae: 34.4746 - mse: 4205.6074 - accuracy: 0.2146 - val_loss: 3260.2605 - val_mae: 27.3559 - val_mse: 3260.2605 - val_accuracy: 0.0101\n",
      "Epoch 620/1000\n",
      "1155/1155 [==============================] - 2s 1ms/step - loss: 4270.8765 - mae: 34.6759 - mse: 4270.8765 - accuracy: 0.2114 - val_loss: 2864.7822 - val_mae: 25.6992 - val_mse: 2864.7822 - val_accuracy: 0.0054\n",
      "Epoch 621/1000\n",
      "1155/1155 [==============================] - 2s 1ms/step - loss: 4336.5771 - mae: 34.6217 - mse: 4336.5771 - accuracy: 0.2128 - val_loss: 2723.5444 - val_mae: 24.2859 - val_mse: 2723.5444 - val_accuracy: 0.0155\n",
      "Epoch 622/1000\n",
      "1155/1155 [==============================] - 2s 1ms/step - loss: 4116.9136 - mae: 34.2355 - mse: 4116.9136 - accuracy: 0.2134 - val_loss: 2916.3638 - val_mae: 24.8007 - val_mse: 2916.3638 - val_accuracy: 0.0207\n",
      "Epoch 623/1000\n",
      "1155/1155 [==============================] - 2s 1ms/step - loss: 4359.3701 - mae: 34.8296 - mse: 4359.3701 - accuracy: 0.2137 - val_loss: 2970.3394 - val_mae: 25.0600 - val_mse: 2970.3394 - val_accuracy: 0.0236\n",
      "Epoch 624/1000\n",
      "1155/1155 [==============================] - 2s 2ms/step - loss: 4205.8506 - mae: 34.5586 - mse: 4205.8506 - accuracy: 0.2123 - val_loss: 3443.3125 - val_mae: 28.2225 - val_mse: 3443.3125 - val_accuracy: 0.0438\n",
      "Epoch 625/1000\n",
      "1155/1155 [==============================] - 2s 2ms/step - loss: 4202.1597 - mae: 34.6109 - mse: 4202.1597 - accuracy: 0.2117 - val_loss: 2734.1814 - val_mae: 26.0610 - val_mse: 2734.1814 - val_accuracy: 6.4977e-04\n",
      "Epoch 626/1000\n",
      "1155/1155 [==============================] - 2s 1ms/step - loss: 4255.7544 - mae: 34.7864 - mse: 4255.7544 - accuracy: 0.2130 - val_loss: 2740.1487 - val_mae: 25.2902 - val_mse: 2740.1487 - val_accuracy: 0.0031\n",
      "Epoch 627/1000\n",
      "1155/1155 [==============================] - 2s 2ms/step - loss: 4309.6196 - mae: 34.5058 - mse: 4309.6196 - accuracy: 0.2135 - val_loss: 2759.6741 - val_mae: 24.4565 - val_mse: 2759.6741 - val_accuracy: 0.0155\n",
      "Epoch 628/1000\n",
      "1155/1155 [==============================] - 2s 1ms/step - loss: 4334.4297 - mae: 34.7766 - mse: 4334.4297 - accuracy: 0.2129 - val_loss: 2722.5642 - val_mae: 25.9162 - val_mse: 2722.5642 - val_accuracy: 4.3318e-04\n",
      "Epoch 629/1000\n",
      "1155/1155 [==============================] - 2s 1ms/step - loss: 4211.7969 - mae: 34.4321 - mse: 4211.7969 - accuracy: 0.2131 - val_loss: 3060.9858 - val_mae: 26.6401 - val_mse: 3060.9858 - val_accuracy: 0.0027\n",
      "Epoch 630/1000\n",
      "1155/1155 [==============================] - 2s 1ms/step - loss: 4202.0361 - mae: 34.5308 - mse: 4202.0361 - accuracy: 0.2118 - val_loss: 3072.2734 - val_mae: 25.8962 - val_mse: 3072.2734 - val_accuracy: 0.0154\n",
      "Epoch 631/1000\n",
      "1155/1155 [==============================] - 2s 1ms/step - loss: 4312.6030 - mae: 34.6443 - mse: 4312.6030 - accuracy: 0.2128 - val_loss: 2743.4392 - val_mae: 25.9173 - val_mse: 2743.4392 - val_accuracy: 0.0024\n",
      "Epoch 632/1000\n",
      "1155/1155 [==============================] - 2s 2ms/step - loss: 4101.1074 - mae: 34.0644 - mse: 4101.1074 - accuracy: 0.2128 - val_loss: 2864.1741 - val_mae: 26.6268 - val_mse: 2864.1741 - val_accuracy: 0.0013\n",
      "Epoch 633/1000\n",
      "1155/1155 [==============================] - 2s 2ms/step - loss: 4211.2939 - mae: 34.5268 - mse: 4211.2939 - accuracy: 0.2147 - val_loss: 2874.4709 - val_mae: 26.3276 - val_mse: 2874.4709 - val_accuracy: 0.0022\n",
      "Epoch 634/1000\n",
      "1155/1155 [==============================] - 2s 2ms/step - loss: 4204.8022 - mae: 34.6534 - mse: 4204.8022 - accuracy: 0.2130 - val_loss: 2875.9231 - val_mae: 25.5590 - val_mse: 2875.9231 - val_accuracy: 0.0056\n",
      "Epoch 635/1000\n",
      "1155/1155 [==============================] - 2s 2ms/step - loss: 4266.3359 - mae: 34.5531 - mse: 4266.3359 - accuracy: 0.2100 - val_loss: 2740.2432 - val_mae: 26.0868 - val_mse: 2740.2432 - val_accuracy: 0.0069\n",
      "Epoch 636/1000\n",
      "1155/1155 [==============================] - 2s 1ms/step - loss: 4277.1162 - mae: 34.7522 - mse: 4277.1162 - accuracy: 0.2114 - val_loss: 3030.2842 - val_mae: 26.6736 - val_mse: 3030.2842 - val_accuracy: 0.0015\n",
      "Epoch 637/1000\n",
      "1155/1155 [==============================] - 2s 2ms/step - loss: 4347.9590 - mae: 34.8180 - mse: 4347.9590 - accuracy: 0.2108 - val_loss: 2800.9810 - val_mae: 24.8027 - val_mse: 2800.9810 - val_accuracy: 0.0084\n",
      "Epoch 638/1000\n",
      "1155/1155 [==============================] - 2s 1ms/step - loss: 4339.3164 - mae: 34.5620 - mse: 4339.3164 - accuracy: 0.2156 - val_loss: 2852.8274 - val_mae: 24.4485 - val_mse: 2852.8274 - val_accuracy: 0.0548\n",
      "Epoch 639/1000\n",
      "1155/1155 [==============================] - 2s 1ms/step - loss: 4245.7910 - mae: 34.6977 - mse: 4245.7910 - accuracy: 0.2106 - val_loss: 3180.5410 - val_mae: 26.5183 - val_mse: 3180.5410 - val_accuracy: 0.0062\n",
      "Epoch 640/1000\n",
      "1155/1155 [==============================] - 2s 2ms/step - loss: 4064.0823 - mae: 34.0260 - mse: 4064.0823 - accuracy: 0.2131 - val_loss: 2933.7100 - val_mae: 27.1406 - val_mse: 2933.7100 - val_accuracy: 0.0015\n",
      "Epoch 641/1000\n",
      "1155/1155 [==============================] - 2s 1ms/step - loss: 4282.6797 - mae: 34.9076 - mse: 4282.6797 - accuracy: 0.2117 - val_loss: 2943.7310 - val_mae: 25.9314 - val_mse: 2943.7310 - val_accuracy: 0.0026\n",
      "Epoch 642/1000\n",
      "1155/1155 [==============================] - 2s 1ms/step - loss: 4278.9707 - mae: 34.5897 - mse: 4278.9707 - accuracy: 0.2144 - val_loss: 2777.2197 - val_mae: 26.7283 - val_mse: 2777.2197 - val_accuracy: 0.0000e+00\n",
      "Epoch 643/1000\n",
      "1155/1155 [==============================] - 2s 2ms/step - loss: 4074.1589 - mae: 34.2222 - mse: 4074.1589 - accuracy: 0.2136 - val_loss: 3219.7080 - val_mae: 28.2038 - val_mse: 3219.7080 - val_accuracy: 0.0055\n",
      "Epoch 644/1000\n",
      "1155/1155 [==============================] - 2s 1ms/step - loss: 4223.0225 - mae: 34.4783 - mse: 4223.0225 - accuracy: 0.2136 - val_loss: 2808.9504 - val_mae: 25.0129 - val_mse: 2808.9504 - val_accuracy: 0.0040\n",
      "Epoch 645/1000\n",
      "1155/1155 [==============================] - 2s 1ms/step - loss: 4195.2441 - mae: 34.5194 - mse: 4195.2441 - accuracy: 0.2136 - val_loss: 2860.2673 - val_mae: 25.7487 - val_mse: 2860.2673 - val_accuracy: 0.0024\n",
      "Epoch 646/1000\n",
      "1155/1155 [==============================] - 2s 2ms/step - loss: 4129.4697 - mae: 34.4248 - mse: 4129.4697 - accuracy: 0.2100 - val_loss: 2771.6084 - val_mae: 25.4103 - val_mse: 2771.6084 - val_accuracy: 0.0024\n",
      "Epoch 647/1000\n",
      "1155/1155 [==============================] - 2s 1ms/step - loss: 4128.1279 - mae: 34.3881 - mse: 4128.1279 - accuracy: 0.2122 - val_loss: 2822.9651 - val_mae: 25.6909 - val_mse: 2822.9651 - val_accuracy: 0.0040\n",
      "Epoch 648/1000\n",
      "1155/1155 [==============================] - 2s 1ms/step - loss: 4309.1104 - mae: 34.6780 - mse: 4309.1104 - accuracy: 0.2127 - val_loss: 2868.1094 - val_mae: 26.2091 - val_mse: 2868.1094 - val_accuracy: 0.0015\n",
      "Epoch 649/1000\n",
      "1155/1155 [==============================] - 2s 1ms/step - loss: 4308.8765 - mae: 34.6415 - mse: 4308.8765 - accuracy: 0.2118 - val_loss: 2809.0845 - val_mae: 24.6852 - val_mse: 2809.0845 - val_accuracy: 0.0067\n",
      "Epoch 650/1000\n",
      "1155/1155 [==============================] - 2s 1ms/step - loss: 4221.4766 - mae: 34.4879 - mse: 4221.4766 - accuracy: 0.2135 - val_loss: 2809.3350 - val_mae: 24.2822 - val_mse: 2809.3350 - val_accuracy: 0.0091\n",
      "Epoch 651/1000\n",
      "1155/1155 [==============================] - 2s 2ms/step - loss: 4307.0845 - mae: 34.6892 - mse: 4307.0845 - accuracy: 0.2155 - val_loss: 3043.7546 - val_mae: 27.2344 - val_mse: 3043.7546 - val_accuracy: 3.2489e-04\n",
      "Epoch 652/1000\n",
      "1155/1155 [==============================] - 2s 1ms/step - loss: 4200.9761 - mae: 34.5314 - mse: 4200.9761 - accuracy: 0.2138 - val_loss: 2908.7744 - val_mae: 26.6340 - val_mse: 2908.7744 - val_accuracy: 8.6636e-04\n",
      "Epoch 653/1000\n",
      "1155/1155 [==============================] - 2s 1ms/step - loss: 4225.4199 - mae: 34.4771 - mse: 4225.4199 - accuracy: 0.2127 - val_loss: 2804.6377 - val_mae: 26.7239 - val_mse: 2804.6377 - val_accuracy: 4.3318e-04\n",
      "Epoch 654/1000\n",
      "1155/1155 [==============================] - 2s 2ms/step - loss: 4138.1396 - mae: 34.3685 - mse: 4138.1396 - accuracy: 0.2112 - val_loss: 2833.1621 - val_mae: 26.3193 - val_mse: 2833.1621 - val_accuracy: 9.7466e-04\n",
      "Epoch 655/1000\n",
      "1155/1155 [==============================] - 2s 1ms/step - loss: 4158.5562 - mae: 34.3464 - mse: 4158.5562 - accuracy: 0.2126 - val_loss: 2847.1045 - val_mae: 24.3923 - val_mse: 2847.1045 - val_accuracy: 0.0360\n",
      "Epoch 656/1000\n",
      "1155/1155 [==============================] - 2s 2ms/step - loss: 4169.6230 - mae: 34.3760 - mse: 4169.6230 - accuracy: 0.2122 - val_loss: 2943.2178 - val_mae: 26.8956 - val_mse: 2943.2178 - val_accuracy: 6.4977e-04\n",
      "Epoch 657/1000\n",
      "1155/1155 [==============================] - 2s 2ms/step - loss: 4013.0571 - mae: 34.0677 - mse: 4013.0571 - accuracy: 0.2128 - val_loss: 2753.5955 - val_mae: 24.8171 - val_mse: 2753.5955 - val_accuracy: 0.0149\n",
      "Epoch 658/1000\n",
      "1155/1155 [==============================] - 2s 1ms/step - loss: 4236.4990 - mae: 34.5374 - mse: 4236.4990 - accuracy: 0.2133 - val_loss: 2861.8201 - val_mae: 26.5986 - val_mse: 2861.8201 - val_accuracy: 0.0016\n",
      "Epoch 659/1000\n",
      "1155/1155 [==============================] - 2s 1ms/step - loss: 4302.7202 - mae: 34.7368 - mse: 4302.7202 - accuracy: 0.2115 - val_loss: 2761.2053 - val_mae: 24.7721 - val_mse: 2761.2053 - val_accuracy: 0.0089\n",
      "Epoch 660/1000\n",
      "1155/1155 [==============================] - 2s 1ms/step - loss: 4143.0161 - mae: 34.3580 - mse: 4143.0161 - accuracy: 0.2131 - val_loss: 2890.1333 - val_mae: 26.2417 - val_mse: 2890.1333 - val_accuracy: 0.0011\n",
      "Epoch 661/1000\n",
      "1155/1155 [==============================] - 2s 2ms/step - loss: 4214.0166 - mae: 34.4204 - mse: 4214.0166 - accuracy: 0.2134 - val_loss: 3060.8342 - val_mae: 25.9454 - val_mse: 3060.8342 - val_accuracy: 0.0080\n",
      "Epoch 662/1000\n",
      "1155/1155 [==============================] - 2s 1ms/step - loss: 4205.8027 - mae: 34.5622 - mse: 4205.8027 - accuracy: 0.2144 - val_loss: 2858.7917 - val_mae: 27.2795 - val_mse: 2858.7917 - val_accuracy: 4.3318e-04\n",
      "Epoch 663/1000\n",
      "1155/1155 [==============================] - 2s 1ms/step - loss: 4306.0166 - mae: 34.6596 - mse: 4306.0166 - accuracy: 0.2139 - val_loss: 2778.1292 - val_mae: 25.7269 - val_mse: 2778.1292 - val_accuracy: 0.0029\n",
      "Epoch 664/1000\n",
      "1155/1155 [==============================] - 2s 2ms/step - loss: 4207.8916 - mae: 34.2879 - mse: 4207.8916 - accuracy: 0.2142 - val_loss: 3121.5740 - val_mae: 27.5917 - val_mse: 3121.5740 - val_accuracy: 0.0018\n",
      "Epoch 665/1000\n",
      "1155/1155 [==============================] - 2s 1ms/step - loss: 4184.0874 - mae: 34.5539 - mse: 4184.0874 - accuracy: 0.2114 - val_loss: 2870.5732 - val_mae: 26.2295 - val_mse: 2870.5732 - val_accuracy: 4.3318e-04\n",
      "Epoch 666/1000\n",
      "1155/1155 [==============================] - 2s 1ms/step - loss: 4182.0283 - mae: 34.5777 - mse: 4182.0283 - accuracy: 0.2121 - val_loss: 2862.1223 - val_mae: 25.1876 - val_mse: 2862.1223 - val_accuracy: 0.0053\n",
      "Epoch 667/1000\n",
      "1155/1155 [==============================] - 2s 1ms/step - loss: 4146.4404 - mae: 34.2179 - mse: 4146.4404 - accuracy: 0.2141 - val_loss: 2849.2683 - val_mae: 25.7709 - val_mse: 2849.2683 - val_accuracy: 0.0029\n",
      "Epoch 668/1000\n",
      "1155/1155 [==============================] - 2s 2ms/step - loss: 4161.0400 - mae: 34.3404 - mse: 4161.0400 - accuracy: 0.2114 - val_loss: 2815.7183 - val_mae: 27.1051 - val_mse: 2815.7183 - val_accuracy: 1.0830e-04\n",
      "Epoch 669/1000\n",
      "1155/1155 [==============================] - 2s 2ms/step - loss: 4310.0742 - mae: 34.5839 - mse: 4310.0742 - accuracy: 0.2135 - val_loss: 2945.5269 - val_mae: 27.3271 - val_mse: 2945.5269 - val_accuracy: 3.2489e-04\n",
      "Epoch 670/1000\n",
      "1155/1155 [==============================] - 2s 2ms/step - loss: 4100.4858 - mae: 34.2215 - mse: 4100.4858 - accuracy: 0.2118 - val_loss: 2877.7976 - val_mae: 25.7812 - val_mse: 2877.7976 - val_accuracy: 0.0029\n",
      "Epoch 671/1000\n",
      "1155/1155 [==============================] - 2s 2ms/step - loss: 4089.4949 - mae: 34.0868 - mse: 4089.4949 - accuracy: 0.2143 - val_loss: 2853.1228 - val_mae: 25.2772 - val_mse: 2853.1228 - val_accuracy: 0.0210\n",
      "Epoch 672/1000\n",
      "1155/1155 [==============================] - 2s 2ms/step - loss: 4205.6309 - mae: 34.5567 - mse: 4205.6309 - accuracy: 0.2129 - val_loss: 2723.3616 - val_mae: 24.9034 - val_mse: 2723.3616 - val_accuracy: 0.0057\n",
      "Epoch 673/1000\n",
      "1155/1155 [==============================] - 2s 1ms/step - loss: 4321.9102 - mae: 34.8347 - mse: 4321.9102 - accuracy: 0.2141 - val_loss: 2802.3655 - val_mae: 26.0897 - val_mse: 2802.3655 - val_accuracy: 0.0022\n",
      "Epoch 674/1000\n",
      "1155/1155 [==============================] - 2s 2ms/step - loss: 4074.6038 - mae: 34.1532 - mse: 4074.6038 - accuracy: 0.2131 - val_loss: 2799.2976 - val_mae: 24.8244 - val_mse: 2799.2976 - val_accuracy: 0.0063\n",
      "Epoch 675/1000\n",
      "1155/1155 [==============================] - 2s 1ms/step - loss: 4110.8833 - mae: 34.3275 - mse: 4110.8833 - accuracy: 0.2144 - val_loss: 3289.3447 - val_mae: 27.3236 - val_mse: 3289.3447 - val_accuracy: 0.0061\n",
      "Epoch 676/1000\n",
      "1155/1155 [==============================] - 2s 2ms/step - loss: 4109.3931 - mae: 34.3103 - mse: 4109.3931 - accuracy: 0.2127 - val_loss: 3002.3469 - val_mae: 26.5213 - val_mse: 3002.3469 - val_accuracy: 0.0022\n",
      "Epoch 677/1000\n",
      "1155/1155 [==============================] - 2s 1ms/step - loss: 4153.0498 - mae: 34.3786 - mse: 4153.0498 - accuracy: 0.2133 - val_loss: 2875.7637 - val_mae: 27.1381 - val_mse: 2875.7637 - val_accuracy: 5.4148e-04\n",
      "Epoch 678/1000\n",
      "1155/1155 [==============================] - 2s 2ms/step - loss: 4248.7681 - mae: 34.6557 - mse: 4248.7681 - accuracy: 0.2131 - val_loss: 2823.0752 - val_mae: 25.7002 - val_mse: 2823.0752 - val_accuracy: 0.0045\n",
      "Epoch 679/1000\n",
      "1155/1155 [==============================] - 2s 2ms/step - loss: 4188.9829 - mae: 34.2628 - mse: 4188.9829 - accuracy: 0.2122 - val_loss: 2822.2146 - val_mae: 25.7454 - val_mse: 2822.2146 - val_accuracy: 0.0021\n",
      "Epoch 680/1000\n",
      "1155/1155 [==============================] - 2s 2ms/step - loss: 4258.8794 - mae: 34.6575 - mse: 4258.8794 - accuracy: 0.2148 - val_loss: 2865.0532 - val_mae: 25.2723 - val_mse: 2865.0532 - val_accuracy: 0.0254\n",
      "Epoch 681/1000\n",
      "1155/1155 [==============================] - 2s 2ms/step - loss: 4070.9028 - mae: 34.3251 - mse: 4070.9028 - accuracy: 0.2119 - val_loss: 2821.7012 - val_mae: 26.6404 - val_mse: 2821.7012 - val_accuracy: 8.6636e-04\n",
      "Epoch 682/1000\n",
      "1155/1155 [==============================] - 2s 2ms/step - loss: 4170.2793 - mae: 34.3842 - mse: 4170.2793 - accuracy: 0.2113 - val_loss: 3056.7937 - val_mae: 26.9634 - val_mse: 3056.7937 - val_accuracy: 0.0021\n",
      "Epoch 683/1000\n",
      "1155/1155 [==============================] - 2s 2ms/step - loss: 4179.3384 - mae: 34.5183 - mse: 4179.3384 - accuracy: 0.2119 - val_loss: 2759.7751 - val_mae: 24.3109 - val_mse: 2759.7751 - val_accuracy: 0.0298\n",
      "Epoch 684/1000\n",
      "1155/1155 [==============================] - 2s 1ms/step - loss: 4230.8877 - mae: 34.5178 - mse: 4230.8877 - accuracy: 0.2133 - val_loss: 2703.1450 - val_mae: 24.3232 - val_mse: 2703.1450 - val_accuracy: 0.0032\n",
      "Epoch 685/1000\n",
      "1155/1155 [==============================] - 2s 2ms/step - loss: 4113.1733 - mae: 34.2138 - mse: 4113.1733 - accuracy: 0.2139 - val_loss: 2878.7341 - val_mae: 25.2958 - val_mse: 2878.7341 - val_accuracy: 0.0061\n",
      "Epoch 686/1000\n",
      "1155/1155 [==============================] - 2s 2ms/step - loss: 4218.9736 - mae: 34.4495 - mse: 4218.9736 - accuracy: 0.2122 - val_loss: 2782.9817 - val_mae: 26.6279 - val_mse: 2782.9817 - val_accuracy: 2.1659e-04\n",
      "Epoch 687/1000\n",
      "1155/1155 [==============================] - 2s 2ms/step - loss: 4201.0620 - mae: 34.3705 - mse: 4201.0620 - accuracy: 0.2137 - val_loss: 2872.9583 - val_mae: 26.8291 - val_mse: 2872.9583 - val_accuracy: 7.5807e-04\n",
      "Epoch 688/1000\n",
      "1155/1155 [==============================] - 2s 1ms/step - loss: 4161.3218 - mae: 34.2249 - mse: 4161.3218 - accuracy: 0.2118 - val_loss: 2705.8391 - val_mae: 23.3914 - val_mse: 2705.8391 - val_accuracy: 0.0492\n",
      "Epoch 689/1000\n",
      "1155/1155 [==============================] - 2s 2ms/step - loss: 4055.3901 - mae: 34.0860 - mse: 4055.3901 - accuracy: 0.2139 - val_loss: 2727.2224 - val_mae: 23.2338 - val_mse: 2727.2224 - val_accuracy: 0.0334\n",
      "Epoch 690/1000\n",
      "1155/1155 [==============================] - 2s 2ms/step - loss: 4319.7905 - mae: 34.6843 - mse: 4319.7905 - accuracy: 0.2091 - val_loss: 2930.0530 - val_mae: 26.3500 - val_mse: 2930.0530 - val_accuracy: 0.0018\n",
      "Epoch 691/1000\n",
      "1155/1155 [==============================] - 2s 2ms/step - loss: 4172.3760 - mae: 34.3191 - mse: 4172.3760 - accuracy: 0.2120 - val_loss: 2707.7163 - val_mae: 23.7157 - val_mse: 2707.7163 - val_accuracy: 0.0238\n",
      "Epoch 692/1000\n",
      "1155/1155 [==============================] - 2s 2ms/step - loss: 4092.4246 - mae: 34.2186 - mse: 4092.4246 - accuracy: 0.2124 - val_loss: 2792.8757 - val_mae: 24.4490 - val_mse: 2792.8757 - val_accuracy: 0.0180\n",
      "Epoch 693/1000\n",
      "1155/1155 [==============================] - 2s 2ms/step - loss: 4242.9048 - mae: 34.4999 - mse: 4242.9048 - accuracy: 0.2136 - val_loss: 2906.5391 - val_mae: 26.7490 - val_mse: 2906.5391 - val_accuracy: 5.4148e-04\n",
      "Epoch 694/1000\n",
      "1155/1155 [==============================] - 2s 2ms/step - loss: 4309.9648 - mae: 34.7867 - mse: 4309.9648 - accuracy: 0.2146 - val_loss: 3019.5388 - val_mae: 26.1984 - val_mse: 3019.5388 - val_accuracy: 0.0050\n",
      "Epoch 695/1000\n",
      "1155/1155 [==============================] - 2s 1ms/step - loss: 4041.8335 - mae: 34.0283 - mse: 4041.8335 - accuracy: 0.2125 - val_loss: 2875.4258 - val_mae: 27.4923 - val_mse: 2875.4258 - val_accuracy: 3.2489e-04\n",
      "Epoch 696/1000\n",
      "1155/1155 [==============================] - 2s 2ms/step - loss: 4195.0522 - mae: 34.3481 - mse: 4195.0522 - accuracy: 0.2137 - val_loss: 2824.5259 - val_mae: 27.0869 - val_mse: 2824.5259 - val_accuracy: 6.4977e-04\n",
      "Epoch 697/1000\n",
      "1155/1155 [==============================] - 2s 2ms/step - loss: 4206.9844 - mae: 34.2728 - mse: 4206.9844 - accuracy: 0.2139 - val_loss: 2795.5105 - val_mae: 26.3576 - val_mse: 2795.5105 - val_accuracy: 0.0022\n",
      "Epoch 698/1000\n",
      "1155/1155 [==============================] - 2s 2ms/step - loss: 4162.8574 - mae: 34.3337 - mse: 4162.8574 - accuracy: 0.2111 - val_loss: 2903.2312 - val_mae: 27.4450 - val_mse: 2903.2312 - val_accuracy: 5.4148e-04\n",
      "Epoch 699/1000\n",
      "1155/1155 [==============================] - 2s 2ms/step - loss: 4272.9375 - mae: 34.5414 - mse: 4272.9375 - accuracy: 0.2112 - val_loss: 2836.9788 - val_mae: 25.8725 - val_mse: 2836.9788 - val_accuracy: 0.0011\n",
      "Epoch 700/1000\n",
      "1155/1155 [==============================] - 2s 2ms/step - loss: 4171.2920 - mae: 34.4813 - mse: 4171.2920 - accuracy: 0.2137 - val_loss: 2868.6953 - val_mae: 25.5221 - val_mse: 2868.6953 - val_accuracy: 0.0207\n",
      "Epoch 701/1000\n",
      "1155/1155 [==============================] - 2s 2ms/step - loss: 4120.4531 - mae: 34.2136 - mse: 4120.4531 - accuracy: 0.2137 - val_loss: 2765.1729 - val_mae: 25.9084 - val_mse: 2765.1729 - val_accuracy: 0.0011\n",
      "Epoch 702/1000\n",
      "1155/1155 [==============================] - 2s 2ms/step - loss: 4111.6133 - mae: 34.3919 - mse: 4111.6133 - accuracy: 0.2138 - val_loss: 2747.3240 - val_mae: 24.2346 - val_mse: 2747.3240 - val_accuracy: 0.0040\n",
      "Epoch 703/1000\n",
      "1155/1155 [==============================] - 2s 1ms/step - loss: 4140.3071 - mae: 34.1804 - mse: 4140.3071 - accuracy: 0.2143 - val_loss: 2711.0564 - val_mae: 25.8168 - val_mse: 2711.0564 - val_accuracy: 0.0049\n",
      "Epoch 704/1000\n",
      "1155/1155 [==============================] - 2s 2ms/step - loss: 4171.9600 - mae: 34.2898 - mse: 4171.9600 - accuracy: 0.2136 - val_loss: 3096.8630 - val_mae: 26.1319 - val_mse: 3096.8630 - val_accuracy: 0.0373\n",
      "Epoch 705/1000\n",
      "1155/1155 [==============================] - 2s 2ms/step - loss: 4082.5945 - mae: 34.1770 - mse: 4082.5945 - accuracy: 0.2131 - val_loss: 3051.9495 - val_mae: 25.4778 - val_mse: 3051.9495 - val_accuracy: 0.0273\n",
      "Epoch 706/1000\n",
      "1155/1155 [==============================] - 2s 1ms/step - loss: 4172.2339 - mae: 34.4109 - mse: 4172.2339 - accuracy: 0.2120 - val_loss: 2815.6709 - val_mae: 26.7965 - val_mse: 2815.6709 - val_accuracy: 1.0830e-04\n",
      "Epoch 707/1000\n",
      "1155/1155 [==============================] - 2s 2ms/step - loss: 4286.7725 - mae: 34.6799 - mse: 4286.7725 - accuracy: 0.2142 - val_loss: 3108.6272 - val_mae: 28.0461 - val_mse: 3108.6272 - val_accuracy: 3.2489e-04\n",
      "Epoch 708/1000\n",
      "1155/1155 [==============================] - 2s 2ms/step - loss: 4121.2246 - mae: 34.3132 - mse: 4121.2246 - accuracy: 0.2115 - val_loss: 2871.0029 - val_mae: 26.3016 - val_mse: 2871.0029 - val_accuracy: 0.0016\n",
      "Epoch 709/1000\n",
      "1155/1155 [==============================] - 2s 2ms/step - loss: 4164.3369 - mae: 34.3596 - mse: 4164.3369 - accuracy: 0.2138 - val_loss: 3029.3037 - val_mae: 26.9710 - val_mse: 3029.3037 - val_accuracy: 8.6636e-04\n",
      "Epoch 710/1000\n",
      "1155/1155 [==============================] - 2s 2ms/step - loss: 4165.3154 - mae: 34.2947 - mse: 4165.3154 - accuracy: 0.2114 - val_loss: 2990.3943 - val_mae: 27.3536 - val_mse: 2990.3943 - val_accuracy: 0.0017\n",
      "Epoch 711/1000\n",
      "1155/1155 [==============================] - 2s 2ms/step - loss: 4211.9731 - mae: 34.3803 - mse: 4211.9731 - accuracy: 0.2137 - val_loss: 2778.7866 - val_mae: 25.4893 - val_mse: 2778.7866 - val_accuracy: 0.0024\n",
      "Epoch 712/1000\n",
      "1155/1155 [==============================] - 2s 1ms/step - loss: 4316.9170 - mae: 34.6092 - mse: 4316.9170 - accuracy: 0.2137 - val_loss: 2875.1516 - val_mae: 26.5896 - val_mse: 2875.1516 - val_accuracy: 0.0013\n",
      "Epoch 713/1000\n",
      "1155/1155 [==============================] - 2s 2ms/step - loss: 4074.3218 - mae: 34.1947 - mse: 4074.3218 - accuracy: 0.2161 - val_loss: 2741.6497 - val_mae: 25.4876 - val_mse: 2741.6497 - val_accuracy: 0.0023\n",
      "Epoch 714/1000\n",
      "1155/1155 [==============================] - 2s 2ms/step - loss: 4144.8599 - mae: 34.3938 - mse: 4144.8599 - accuracy: 0.2128 - val_loss: 2729.9570 - val_mae: 24.3461 - val_mse: 2729.9570 - val_accuracy: 0.0071\n",
      "Epoch 715/1000\n",
      "1155/1155 [==============================] - 2s 2ms/step - loss: 4330.7256 - mae: 34.6111 - mse: 4330.7256 - accuracy: 0.2152 - val_loss: 2759.9121 - val_mae: 25.5128 - val_mse: 2759.9121 - val_accuracy: 0.0016\n",
      "Epoch 716/1000\n",
      "1155/1155 [==============================] - 2s 2ms/step - loss: 4174.2798 - mae: 34.5458 - mse: 4174.2798 - accuracy: 0.2123 - val_loss: 2813.1458 - val_mae: 25.8439 - val_mse: 2813.1458 - val_accuracy: 0.0017\n",
      "Epoch 717/1000\n",
      "1155/1155 [==============================] - 2s 2ms/step - loss: 4164.5615 - mae: 34.3491 - mse: 4164.5615 - accuracy: 0.2145 - val_loss: 2901.0042 - val_mae: 27.3753 - val_mse: 2901.0042 - val_accuracy: 9.7466e-04\n",
      "Epoch 718/1000\n",
      "1155/1155 [==============================] - 2s 2ms/step - loss: 4142.4150 - mae: 34.2688 - mse: 4142.4150 - accuracy: 0.2155 - val_loss: 2926.2839 - val_mae: 25.9034 - val_mse: 2926.2839 - val_accuracy: 0.0063\n",
      "Epoch 719/1000\n",
      "1155/1155 [==============================] - 2s 2ms/step - loss: 3965.8804 - mae: 34.0286 - mse: 3965.8804 - accuracy: 0.2133 - val_loss: 2902.7578 - val_mae: 25.8619 - val_mse: 2902.7578 - val_accuracy: 0.0050\n",
      "Epoch 720/1000\n",
      "1155/1155 [==============================] - 2s 2ms/step - loss: 3994.4363 - mae: 34.0779 - mse: 3994.4363 - accuracy: 0.2110 - val_loss: 2839.9509 - val_mae: 26.0851 - val_mse: 2839.9509 - val_accuracy: 0.0028\n",
      "Epoch 721/1000\n",
      "1155/1155 [==============================] - 2s 2ms/step - loss: 4111.6343 - mae: 34.1551 - mse: 4111.6343 - accuracy: 0.2126 - val_loss: 2913.9883 - val_mae: 25.0735 - val_mse: 2913.9883 - val_accuracy: 0.0586\n",
      "Epoch 722/1000\n",
      "1155/1155 [==============================] - 2s 1ms/step - loss: 4125.6445 - mae: 34.1208 - mse: 4125.6445 - accuracy: 0.2134 - val_loss: 3044.1685 - val_mae: 26.0210 - val_mse: 3044.1685 - val_accuracy: 0.0065\n",
      "Epoch 723/1000\n",
      "1155/1155 [==============================] - 2s 1ms/step - loss: 4089.6543 - mae: 34.2838 - mse: 4089.6543 - accuracy: 0.2127 - val_loss: 2787.0166 - val_mae: 25.3219 - val_mse: 2787.0166 - val_accuracy: 0.0054\n",
      "Epoch 724/1000\n",
      "1155/1155 [==============================] - 2s 2ms/step - loss: 4206.8447 - mae: 34.3102 - mse: 4206.8447 - accuracy: 0.2131 - val_loss: 2925.0720 - val_mae: 25.0606 - val_mse: 2925.0720 - val_accuracy: 0.0356\n",
      "Epoch 725/1000\n",
      "1155/1155 [==============================] - 2s 2ms/step - loss: 4079.8489 - mae: 34.1011 - mse: 4079.8489 - accuracy: 0.2140 - val_loss: 2813.1282 - val_mae: 25.7050 - val_mse: 2813.1282 - val_accuracy: 7.5807e-04\n",
      "Epoch 726/1000\n",
      "1155/1155 [==============================] - 2s 2ms/step - loss: 3989.2441 - mae: 33.9198 - mse: 3989.2441 - accuracy: 0.2132 - val_loss: 2873.2441 - val_mae: 26.3320 - val_mse: 2873.2441 - val_accuracy: 0.0016\n",
      "Epoch 727/1000\n",
      "1155/1155 [==============================] - 2s 2ms/step - loss: 4188.7837 - mae: 34.0332 - mse: 4188.7837 - accuracy: 0.2171 - val_loss: 2836.5598 - val_mae: 27.5152 - val_mse: 2836.5598 - val_accuracy: 0.0000e+00\n",
      "Epoch 728/1000\n",
      "1155/1155 [==============================] - 2s 2ms/step - loss: 4208.7383 - mae: 34.0862 - mse: 4208.7383 - accuracy: 0.2129 - val_loss: 2865.7012 - val_mae: 25.2018 - val_mse: 2865.7012 - val_accuracy: 0.0028\n",
      "Epoch 729/1000\n",
      "1155/1155 [==============================] - 2s 2ms/step - loss: 4121.8481 - mae: 33.6615 - mse: 4121.8481 - accuracy: 0.2174 - val_loss: 2736.4861 - val_mae: 25.4127 - val_mse: 2736.4861 - val_accuracy: 0.0019\n",
      "Epoch 730/1000\n",
      "1155/1155 [==============================] - 2s 2ms/step - loss: 4001.4998 - mae: 33.7037 - mse: 4001.4998 - accuracy: 0.2149 - val_loss: 3191.8066 - val_mae: 27.1209 - val_mse: 3191.8066 - val_accuracy: 0.0022\n",
      "Epoch 731/1000\n",
      "1155/1155 [==============================] - 2s 2ms/step - loss: 4142.0386 - mae: 33.9224 - mse: 4142.0386 - accuracy: 0.2148 - val_loss: 2716.4338 - val_mae: 23.7818 - val_mse: 2716.4338 - val_accuracy: 0.0374\n",
      "Epoch 732/1000\n",
      "1155/1155 [==============================] - 2s 2ms/step - loss: 4010.7815 - mae: 33.8332 - mse: 4010.7815 - accuracy: 0.2151 - val_loss: 2723.9170 - val_mae: 24.2181 - val_mse: 2723.9170 - val_accuracy: 0.0068\n",
      "Epoch 733/1000\n",
      "1155/1155 [==============================] - 2s 2ms/step - loss: 4111.2754 - mae: 33.8840 - mse: 4111.2754 - accuracy: 0.2144 - val_loss: 2793.0049 - val_mae: 25.2324 - val_mse: 2793.0049 - val_accuracy: 0.0064\n",
      "Epoch 734/1000\n",
      "1155/1155 [==============================] - 2s 2ms/step - loss: 4008.1809 - mae: 33.6493 - mse: 4008.1809 - accuracy: 0.2153 - val_loss: 2774.1223 - val_mae: 25.2633 - val_mse: 2774.1223 - val_accuracy: 0.0029\n",
      "Epoch 735/1000\n",
      "1155/1155 [==============================] - 2s 2ms/step - loss: 4183.6729 - mae: 34.0864 - mse: 4183.6729 - accuracy: 0.2135 - val_loss: 2753.6589 - val_mae: 26.1310 - val_mse: 2753.6589 - val_accuracy: 6.4977e-04\n",
      "Epoch 736/1000\n",
      "1155/1155 [==============================] - 2s 2ms/step - loss: 4107.6367 - mae: 33.8212 - mse: 4107.6367 - accuracy: 0.2162 - val_loss: 2782.6870 - val_mae: 24.4505 - val_mse: 2782.6870 - val_accuracy: 0.0240\n",
      "Epoch 737/1000\n",
      "1155/1155 [==============================] - 2s 2ms/step - loss: 4087.5068 - mae: 33.7232 - mse: 4087.5068 - accuracy: 0.2137 - val_loss: 2786.9058 - val_mae: 25.0080 - val_mse: 2786.9058 - val_accuracy: 0.0057\n",
      "Epoch 738/1000\n",
      "1155/1155 [==============================] - 2s 2ms/step - loss: 4169.8975 - mae: 34.0369 - mse: 4169.8975 - accuracy: 0.2163 - val_loss: 2691.4819 - val_mae: 23.4279 - val_mse: 2691.4819 - val_accuracy: 0.0306\n",
      "Epoch 739/1000\n",
      "1155/1155 [==============================] - 2s 2ms/step - loss: 4113.2388 - mae: 33.8909 - mse: 4113.2388 - accuracy: 0.2130 - val_loss: 3067.1099 - val_mae: 25.3733 - val_mse: 3067.1099 - val_accuracy: 0.0147\n",
      "Epoch 740/1000\n",
      "1155/1155 [==============================] - 2s 2ms/step - loss: 4109.5166 - mae: 34.0293 - mse: 4109.5166 - accuracy: 0.2154 - val_loss: 3073.3599 - val_mae: 26.0391 - val_mse: 3073.3599 - val_accuracy: 0.0264\n",
      "Epoch 741/1000\n",
      "1155/1155 [==============================] - 2s 2ms/step - loss: 4131.2979 - mae: 33.8799 - mse: 4131.2979 - accuracy: 0.2140 - val_loss: 2892.9688 - val_mae: 24.7916 - val_mse: 2892.9688 - val_accuracy: 0.0122\n",
      "Epoch 742/1000\n",
      "1155/1155 [==============================] - 2s 2ms/step - loss: 4016.8010 - mae: 33.6858 - mse: 4016.8010 - accuracy: 0.2160 - val_loss: 3082.8215 - val_mae: 26.6193 - val_mse: 3082.8215 - val_accuracy: 0.0258\n",
      "Epoch 743/1000\n",
      "1155/1155 [==============================] - 2s 2ms/step - loss: 4100.0586 - mae: 33.8994 - mse: 4100.0586 - accuracy: 0.2129 - val_loss: 2845.0574 - val_mae: 25.0740 - val_mse: 2845.0574 - val_accuracy: 0.0036\n",
      "Epoch 744/1000\n",
      "1155/1155 [==============================] - 2s 2ms/step - loss: 4149.9595 - mae: 34.0681 - mse: 4149.9595 - accuracy: 0.2115 - val_loss: 3054.5557 - val_mae: 26.1605 - val_mse: 3054.5557 - val_accuracy: 0.0040\n",
      "Epoch 745/1000\n",
      "1155/1155 [==============================] - 2s 2ms/step - loss: 4205.1606 - mae: 34.0064 - mse: 4205.1606 - accuracy: 0.2146 - val_loss: 2850.2771 - val_mae: 24.6811 - val_mse: 2850.2771 - val_accuracy: 0.0161\n",
      "Epoch 746/1000\n",
      "1155/1155 [==============================] - 2s 2ms/step - loss: 4059.6709 - mae: 33.7061 - mse: 4059.6709 - accuracy: 0.2153 - val_loss: 2777.5337 - val_mae: 25.4510 - val_mse: 2777.5337 - val_accuracy: 0.0019\n",
      "Epoch 747/1000\n",
      "1155/1155 [==============================] - 2s 2ms/step - loss: 4149.0342 - mae: 33.9273 - mse: 4149.0342 - accuracy: 0.2138 - val_loss: 2695.3076 - val_mae: 24.3266 - val_mse: 2695.3076 - val_accuracy: 0.0220\n",
      "Epoch 748/1000\n",
      "1155/1155 [==============================] - 2s 2ms/step - loss: 4186.3311 - mae: 34.1625 - mse: 4186.3311 - accuracy: 0.2151 - val_loss: 2757.5552 - val_mae: 22.9531 - val_mse: 2757.5552 - val_accuracy: 0.1863\n",
      "Epoch 749/1000\n",
      "1155/1155 [==============================] - 2s 2ms/step - loss: 4105.1475 - mae: 33.8598 - mse: 4105.1475 - accuracy: 0.2145 - val_loss: 2798.9932 - val_mae: 25.1436 - val_mse: 2798.9932 - val_accuracy: 0.0057\n",
      "Epoch 750/1000\n",
      "1155/1155 [==============================] - 2s 2ms/step - loss: 4019.8457 - mae: 33.8155 - mse: 4019.8457 - accuracy: 0.2153 - val_loss: 2708.7322 - val_mae: 24.5926 - val_mse: 2708.7322 - val_accuracy: 0.0091\n",
      "Epoch 751/1000\n",
      "1155/1155 [==============================] - 2s 2ms/step - loss: 4109.7563 - mae: 33.9190 - mse: 4109.7563 - accuracy: 0.2138 - val_loss: 2724.4375 - val_mae: 25.8624 - val_mse: 2724.4375 - val_accuracy: 2.1659e-04\n",
      "Epoch 752/1000\n",
      "1155/1155 [==============================] - 2s 2ms/step - loss: 4134.5410 - mae: 33.8707 - mse: 4134.5410 - accuracy: 0.2166 - val_loss: 2828.4661 - val_mae: 25.0308 - val_mse: 2828.4661 - val_accuracy: 0.0065\n",
      "Epoch 753/1000\n",
      "1155/1155 [==============================] - 2s 2ms/step - loss: 4206.7183 - mae: 34.2150 - mse: 4206.7183 - accuracy: 0.2152 - val_loss: 2781.8530 - val_mae: 26.3976 - val_mse: 2781.8530 - val_accuracy: 9.7466e-04\n",
      "Epoch 754/1000\n",
      "1155/1155 [==============================] - 2s 2ms/step - loss: 4096.2681 - mae: 33.9880 - mse: 4096.2681 - accuracy: 0.2130 - val_loss: 2887.2505 - val_mae: 25.5226 - val_mse: 2887.2505 - val_accuracy: 0.0167\n",
      "Epoch 755/1000\n",
      "1155/1155 [==============================] - 2s 2ms/step - loss: 4149.7104 - mae: 34.0552 - mse: 4149.7104 - accuracy: 0.2146 - val_loss: 2880.5176 - val_mae: 24.6767 - val_mse: 2880.5176 - val_accuracy: 0.0530\n",
      "Epoch 756/1000\n",
      "1155/1155 [==============================] - 2s 2ms/step - loss: 4135.4043 - mae: 34.0411 - mse: 4135.4043 - accuracy: 0.2150 - val_loss: 2800.8875 - val_mae: 26.9870 - val_mse: 2800.8875 - val_accuracy: 4.3318e-04\n",
      "Epoch 757/1000\n",
      "1155/1155 [==============================] - 2s 2ms/step - loss: 3995.3723 - mae: 33.7015 - mse: 3995.3723 - accuracy: 0.2140 - val_loss: 3118.2747 - val_mae: 25.6919 - val_mse: 3118.2747 - val_accuracy: 0.0209\n",
      "Epoch 758/1000\n",
      "1155/1155 [==============================] - 2s 2ms/step - loss: 4113.7295 - mae: 33.9146 - mse: 4113.7295 - accuracy: 0.2170 - val_loss: 2821.5193 - val_mae: 25.3627 - val_mse: 2821.5193 - val_accuracy: 0.0028\n",
      "Epoch 759/1000\n",
      "1155/1155 [==============================] - 2s 2ms/step - loss: 4108.5576 - mae: 34.0996 - mse: 4108.5576 - accuracy: 0.2149 - val_loss: 3059.3884 - val_mae: 25.5026 - val_mse: 3059.3884 - val_accuracy: 0.0149\n",
      "Epoch 760/1000\n",
      "1155/1155 [==============================] - 2s 2ms/step - loss: 4172.0991 - mae: 34.1947 - mse: 4172.0991 - accuracy: 0.2153 - val_loss: 2990.5913 - val_mae: 26.2818 - val_mse: 2990.5913 - val_accuracy: 0.0027\n",
      "Epoch 761/1000\n",
      "1155/1155 [==============================] - 2s 2ms/step - loss: 4112.2490 - mae: 33.8621 - mse: 4112.2490 - accuracy: 0.2144 - val_loss: 2713.0767 - val_mae: 25.4571 - val_mse: 2713.0767 - val_accuracy: 0.0017\n",
      "Epoch 762/1000\n",
      "1155/1155 [==============================] - 2s 2ms/step - loss: 4162.0850 - mae: 34.0674 - mse: 4162.0850 - accuracy: 0.2157 - val_loss: 2823.6426 - val_mae: 25.9820 - val_mse: 2823.6426 - val_accuracy: 0.0022\n",
      "Epoch 763/1000\n",
      "1155/1155 [==============================] - 2s 2ms/step - loss: 3915.9160 - mae: 33.5227 - mse: 3915.9160 - accuracy: 0.2127 - val_loss: 2835.0239 - val_mae: 25.1119 - val_mse: 2835.0239 - val_accuracy: 0.0053\n",
      "Epoch 764/1000\n",
      "1155/1155 [==============================] - 2s 2ms/step - loss: 4033.6050 - mae: 33.8303 - mse: 4033.6050 - accuracy: 0.2130 - val_loss: 2854.6040 - val_mae: 24.2872 - val_mse: 2854.6040 - val_accuracy: 0.0432\n",
      "Epoch 765/1000\n",
      "1155/1155 [==============================] - 2s 2ms/step - loss: 4078.4683 - mae: 33.8726 - mse: 4078.4683 - accuracy: 0.2137 - val_loss: 2906.8928 - val_mae: 24.9584 - val_mse: 2906.8928 - val_accuracy: 0.0270\n",
      "Epoch 766/1000\n",
      "1155/1155 [==============================] - 2s 2ms/step - loss: 4160.1523 - mae: 34.1421 - mse: 4160.1523 - accuracy: 0.2127 - val_loss: 2888.6296 - val_mae: 25.2501 - val_mse: 2888.6296 - val_accuracy: 0.0145\n",
      "Epoch 767/1000\n",
      "1155/1155 [==============================] - 2s 2ms/step - loss: 3991.0264 - mae: 33.6575 - mse: 3991.0264 - accuracy: 0.2148 - val_loss: 2744.9382 - val_mae: 24.2236 - val_mse: 2744.9382 - val_accuracy: 0.0329\n",
      "Epoch 768/1000\n",
      "1155/1155 [==============================] - 2s 2ms/step - loss: 3953.3469 - mae: 33.6856 - mse: 3953.3469 - accuracy: 0.2152 - val_loss: 2739.1707 - val_mae: 26.5942 - val_mse: 2739.1707 - val_accuracy: 2.1659e-04\n",
      "Epoch 769/1000\n",
      "1155/1155 [==============================] - 2s 2ms/step - loss: 4044.8149 - mae: 33.7673 - mse: 4044.8149 - accuracy: 0.2159 - val_loss: 2745.1819 - val_mae: 24.5909 - val_mse: 2745.1819 - val_accuracy: 0.0044\n",
      "Epoch 770/1000\n",
      "1155/1155 [==============================] - 2s 2ms/step - loss: 4138.6650 - mae: 34.1669 - mse: 4138.6650 - accuracy: 0.2143 - val_loss: 2815.3906 - val_mae: 25.9686 - val_mse: 2815.3906 - val_accuracy: 0.0017\n",
      "Epoch 771/1000\n",
      "1155/1155 [==============================] - 2s 2ms/step - loss: 4104.2959 - mae: 34.0476 - mse: 4104.2959 - accuracy: 0.2141 - val_loss: 2958.1411 - val_mae: 24.6290 - val_mse: 2958.1411 - val_accuracy: 0.0256\n",
      "Epoch 772/1000\n",
      "1155/1155 [==============================] - 2s 2ms/step - loss: 4111.2715 - mae: 34.1246 - mse: 4111.2715 - accuracy: 0.2155 - val_loss: 2923.2412 - val_mae: 25.0050 - val_mse: 2923.2412 - val_accuracy: 0.0073\n",
      "Epoch 773/1000\n",
      "1155/1155 [==============================] - 2s 2ms/step - loss: 4072.6560 - mae: 33.9391 - mse: 4072.6560 - accuracy: 0.2144 - val_loss: 3069.2720 - val_mae: 24.5002 - val_mse: 3069.2720 - val_accuracy: 0.0551\n",
      "Epoch 774/1000\n",
      "1155/1155 [==============================] - 2s 2ms/step - loss: 4055.0732 - mae: 33.8820 - mse: 4055.0732 - accuracy: 0.2133 - val_loss: 2720.3726 - val_mae: 24.2535 - val_mse: 2720.3726 - val_accuracy: 0.0067\n",
      "Epoch 775/1000\n",
      "1155/1155 [==============================] - 2s 2ms/step - loss: 3961.7886 - mae: 33.5051 - mse: 3961.7886 - accuracy: 0.2140 - val_loss: 2858.4751 - val_mae: 24.9475 - val_mse: 2858.4751 - val_accuracy: 0.0156\n",
      "Epoch 776/1000\n",
      "1155/1155 [==============================] - 2s 2ms/step - loss: 4037.1738 - mae: 33.8618 - mse: 4037.1738 - accuracy: 0.2160 - val_loss: 2694.0471 - val_mae: 24.4413 - val_mse: 2694.0471 - val_accuracy: 0.0025\n",
      "Epoch 777/1000\n",
      "1155/1155 [==============================] - 2s 1ms/step - loss: 4213.6064 - mae: 34.2277 - mse: 4213.6064 - accuracy: 0.2153 - val_loss: 3158.3823 - val_mae: 26.4236 - val_mse: 3158.3823 - val_accuracy: 0.0187\n",
      "Epoch 778/1000\n",
      "1155/1155 [==============================] - 2s 2ms/step - loss: 4015.5251 - mae: 33.8164 - mse: 4015.5251 - accuracy: 0.2151 - val_loss: 2777.2249 - val_mae: 27.1252 - val_mse: 2777.2249 - val_accuracy: 1.0830e-04\n",
      "Epoch 779/1000\n",
      "1155/1155 [==============================] - 2s 2ms/step - loss: 4088.6772 - mae: 34.0744 - mse: 4088.6772 - accuracy: 0.2138 - val_loss: 2816.2668 - val_mae: 27.0906 - val_mse: 2816.2668 - val_accuracy: 4.3318e-04\n",
      "Epoch 780/1000\n",
      "1155/1155 [==============================] - 2s 2ms/step - loss: 4192.8862 - mae: 34.0761 - mse: 4192.8862 - accuracy: 0.2122 - val_loss: 2930.8555 - val_mae: 24.3011 - val_mse: 2930.8555 - val_accuracy: 0.0638\n",
      "Epoch 781/1000\n",
      "1155/1155 [==============================] - 2s 2ms/step - loss: 4108.7837 - mae: 34.1069 - mse: 4108.7837 - accuracy: 0.2154 - val_loss: 2888.5984 - val_mae: 27.0666 - val_mse: 2888.5984 - val_accuracy: 9.7466e-04\n",
      "Epoch 782/1000\n",
      "1155/1155 [==============================] - 2s 2ms/step - loss: 3969.3828 - mae: 33.6211 - mse: 3969.3828 - accuracy: 0.2145 - val_loss: 2965.2917 - val_mae: 26.8164 - val_mse: 2965.2917 - val_accuracy: 5.4148e-04\n",
      "Epoch 783/1000\n",
      "1155/1155 [==============================] - 2s 2ms/step - loss: 4068.8386 - mae: 34.0674 - mse: 4068.8386 - accuracy: 0.2134 - val_loss: 3044.5488 - val_mae: 28.2891 - val_mse: 3044.5488 - val_accuracy: 5.4148e-04\n",
      "Epoch 784/1000\n",
      "1155/1155 [==============================] - 2s 2ms/step - loss: 4128.1855 - mae: 34.1139 - mse: 4128.1855 - accuracy: 0.2138 - val_loss: 2850.8667 - val_mae: 24.8821 - val_mse: 2850.8667 - val_accuracy: 0.0349\n",
      "Epoch 785/1000\n",
      "1155/1155 [==============================] - 2s 2ms/step - loss: 4059.1626 - mae: 33.9333 - mse: 4059.1626 - accuracy: 0.2147 - val_loss: 2784.5498 - val_mae: 25.4747 - val_mse: 2784.5498 - val_accuracy: 0.0024\n",
      "Epoch 786/1000\n",
      "1155/1155 [==============================] - 2s 2ms/step - loss: 4100.4048 - mae: 34.0138 - mse: 4100.4048 - accuracy: 0.2135 - val_loss: 2648.4597 - val_mae: 23.7432 - val_mse: 2648.4597 - val_accuracy: 0.0066\n",
      "Epoch 787/1000\n",
      "1155/1155 [==============================] - 2s 2ms/step - loss: 4288.2822 - mae: 34.4629 - mse: 4288.2822 - accuracy: 0.2147 - val_loss: 2816.1946 - val_mae: 23.7492 - val_mse: 2816.1946 - val_accuracy: 0.0527\n",
      "Epoch 788/1000\n",
      "1155/1155 [==============================] - 2s 2ms/step - loss: 3997.6462 - mae: 33.6808 - mse: 3997.6462 - accuracy: 0.2159 - val_loss: 2674.4727 - val_mae: 24.9852 - val_mse: 2674.4727 - val_accuracy: 0.0025\n",
      "Epoch 789/1000\n",
      "1155/1155 [==============================] - 2s 2ms/step - loss: 4296.9302 - mae: 34.4031 - mse: 4296.9302 - accuracy: 0.2125 - val_loss: 2793.0620 - val_mae: 25.9450 - val_mse: 2793.0620 - val_accuracy: 0.0015\n",
      "Epoch 790/1000\n",
      "1155/1155 [==============================] - 2s 2ms/step - loss: 3946.1484 - mae: 33.4158 - mse: 3946.1484 - accuracy: 0.2158 - val_loss: 2791.3906 - val_mae: 26.8180 - val_mse: 2791.3906 - val_accuracy: 0.0017\n",
      "Epoch 791/1000\n",
      "1155/1155 [==============================] - 2s 2ms/step - loss: 3973.6289 - mae: 33.9800 - mse: 3973.6289 - accuracy: 0.2121 - val_loss: 2691.1877 - val_mae: 24.5759 - val_mse: 2691.1877 - val_accuracy: 0.0047\n",
      "Epoch 792/1000\n",
      "1155/1155 [==============================] - 2s 2ms/step - loss: 4057.9392 - mae: 34.0510 - mse: 4057.9392 - accuracy: 0.2150 - val_loss: 2731.6082 - val_mae: 24.9350 - val_mse: 2731.6082 - val_accuracy: 0.0026\n",
      "Epoch 793/1000\n",
      "1155/1155 [==============================] - 2s 2ms/step - loss: 4073.4922 - mae: 33.9097 - mse: 4073.4922 - accuracy: 0.2161 - val_loss: 2767.7539 - val_mae: 24.5503 - val_mse: 2767.7539 - val_accuracy: 0.0092\n",
      "Epoch 794/1000\n",
      "1155/1155 [==============================] - 2s 2ms/step - loss: 4052.9534 - mae: 33.8674 - mse: 4052.9534 - accuracy: 0.2155 - val_loss: 2719.3872 - val_mae: 25.0801 - val_mse: 2719.3872 - val_accuracy: 0.0023\n",
      "Epoch 795/1000\n",
      "1155/1155 [==============================] - 2s 2ms/step - loss: 4091.2224 - mae: 34.1086 - mse: 4091.2224 - accuracy: 0.2140 - val_loss: 2835.2395 - val_mae: 26.1051 - val_mse: 2835.2395 - val_accuracy: 0.0015\n",
      "Epoch 796/1000\n",
      "1155/1155 [==============================] - 2s 2ms/step - loss: 4097.0645 - mae: 33.9780 - mse: 4097.0645 - accuracy: 0.2145 - val_loss: 2728.8518 - val_mae: 23.7914 - val_mse: 2728.8518 - val_accuracy: 0.0566\n",
      "Epoch 797/1000\n",
      "1155/1155 [==============================] - 2s 2ms/step - loss: 4047.1548 - mae: 33.8834 - mse: 4047.1548 - accuracy: 0.2165 - val_loss: 2719.3518 - val_mae: 27.4167 - val_mse: 2719.3518 - val_accuracy: 1.0830e-04\n",
      "Epoch 798/1000\n",
      "1155/1155 [==============================] - 2s 2ms/step - loss: 4097.8228 - mae: 34.0915 - mse: 4097.8228 - accuracy: 0.2138 - val_loss: 2749.4626 - val_mae: 25.7303 - val_mse: 2749.4626 - val_accuracy: 0.0019\n",
      "Epoch 799/1000\n",
      "1155/1155 [==============================] - 2s 2ms/step - loss: 4042.5947 - mae: 33.8415 - mse: 4042.5947 - accuracy: 0.2169 - val_loss: 2903.1816 - val_mae: 25.1960 - val_mse: 2903.1816 - val_accuracy: 0.0453\n",
      "Epoch 800/1000\n",
      "1155/1155 [==============================] - 2s 2ms/step - loss: 4133.0894 - mae: 34.0861 - mse: 4133.0894 - accuracy: 0.2135 - val_loss: 2726.4658 - val_mae: 26.0213 - val_mse: 2726.4658 - val_accuracy: 0.0018\n",
      "Epoch 801/1000\n",
      "1155/1155 [==============================] - 2s 2ms/step - loss: 3973.3633 - mae: 33.7208 - mse: 3973.3633 - accuracy: 0.2151 - val_loss: 2863.6172 - val_mae: 25.8008 - val_mse: 2863.6172 - val_accuracy: 0.0064\n",
      "Epoch 802/1000\n",
      "1155/1155 [==============================] - 2s 2ms/step - loss: 4213.5415 - mae: 34.4778 - mse: 4213.5415 - accuracy: 0.2115 - val_loss: 2938.1299 - val_mae: 26.9261 - val_mse: 2938.1299 - val_accuracy: 0.0016\n",
      "Epoch 803/1000\n",
      "1155/1155 [==============================] - 2s 2ms/step - loss: 4155.5757 - mae: 34.2929 - mse: 4155.5757 - accuracy: 0.2152 - val_loss: 2817.6155 - val_mae: 25.2856 - val_mse: 2817.6155 - val_accuracy: 0.0370\n",
      "Epoch 804/1000\n",
      "1155/1155 [==============================] - 2s 2ms/step - loss: 3977.7876 - mae: 33.7618 - mse: 3977.7876 - accuracy: 0.2137 - val_loss: 2680.7253 - val_mae: 26.0214 - val_mse: 2680.7253 - val_accuracy: 7.5807e-04\n",
      "Epoch 805/1000\n",
      "1155/1155 [==============================] - 2s 1ms/step - loss: 4048.7490 - mae: 33.9333 - mse: 4048.7490 - accuracy: 0.2152 - val_loss: 2637.2471 - val_mae: 23.8825 - val_mse: 2637.2471 - val_accuracy: 0.0315\n",
      "Epoch 806/1000\n",
      "1155/1155 [==============================] - 2s 1ms/step - loss: 3930.0544 - mae: 33.5679 - mse: 3930.0544 - accuracy: 0.2146 - val_loss: 2755.1667 - val_mae: 25.1901 - val_mse: 2755.1667 - val_accuracy: 0.0024\n",
      "Epoch 807/1000\n",
      "1155/1155 [==============================] - 2s 2ms/step - loss: 4065.4600 - mae: 33.8618 - mse: 4065.4600 - accuracy: 0.2146 - val_loss: 2695.7239 - val_mae: 23.8138 - val_mse: 2695.7239 - val_accuracy: 0.0157\n",
      "Epoch 808/1000\n",
      "1155/1155 [==============================] - 2s 2ms/step - loss: 4019.1248 - mae: 33.8806 - mse: 4019.1248 - accuracy: 0.2163 - val_loss: 2648.4031 - val_mae: 24.2278 - val_mse: 2648.4031 - val_accuracy: 0.0047\n",
      "Epoch 809/1000\n",
      "1155/1155 [==============================] - 2s 2ms/step - loss: 4070.0391 - mae: 33.9012 - mse: 4070.0391 - accuracy: 0.2128 - val_loss: 2750.8013 - val_mae: 24.5220 - val_mse: 2750.8013 - val_accuracy: 0.0041\n",
      "Epoch 810/1000\n",
      "1155/1155 [==============================] - 2s 2ms/step - loss: 4019.3608 - mae: 33.9468 - mse: 4019.3608 - accuracy: 0.2123 - val_loss: 2835.7585 - val_mae: 27.3190 - val_mse: 2835.7585 - val_accuracy: 8.6636e-04\n",
      "Epoch 811/1000\n",
      "1155/1155 [==============================] - 2s 2ms/step - loss: 4027.9846 - mae: 33.8075 - mse: 4027.9846 - accuracy: 0.2172 - val_loss: 2718.8345 - val_mae: 25.8913 - val_mse: 2718.8345 - val_accuracy: 0.0041\n",
      "Epoch 812/1000\n",
      "1155/1155 [==============================] - 2s 2ms/step - loss: 4000.2583 - mae: 33.8327 - mse: 4000.2583 - accuracy: 0.2164 - val_loss: 2724.4402 - val_mae: 24.9108 - val_mse: 2724.4402 - val_accuracy: 0.0030\n",
      "Epoch 813/1000\n",
      "1155/1155 [==============================] - 2s 2ms/step - loss: 3996.7612 - mae: 33.6360 - mse: 3996.7612 - accuracy: 0.2169 - val_loss: 2684.6472 - val_mae: 23.4620 - val_mse: 2684.6472 - val_accuracy: 0.0166\n",
      "Epoch 814/1000\n",
      "1155/1155 [==============================] - 2s 2ms/step - loss: 4139.4312 - mae: 34.1108 - mse: 4139.4312 - accuracy: 0.2131 - val_loss: 2695.4346 - val_mae: 25.1675 - val_mse: 2695.4346 - val_accuracy: 0.0026\n",
      "Epoch 815/1000\n",
      "1155/1155 [==============================] - 2s 1ms/step - loss: 4056.4902 - mae: 34.0872 - mse: 4056.4902 - accuracy: 0.2142 - val_loss: 2925.4739 - val_mae: 27.5457 - val_mse: 2925.4739 - val_accuracy: 4.3318e-04\n",
      "Epoch 816/1000\n",
      "1155/1155 [==============================] - 2s 2ms/step - loss: 4125.6338 - mae: 34.0549 - mse: 4125.6338 - accuracy: 0.2147 - val_loss: 3076.4607 - val_mae: 27.8174 - val_mse: 3076.4607 - val_accuracy: 5.4148e-04\n",
      "Epoch 817/1000\n",
      "1155/1155 [==============================] - 2s 2ms/step - loss: 4096.9565 - mae: 34.0538 - mse: 4096.9565 - accuracy: 0.2144 - val_loss: 2694.5820 - val_mae: 25.6134 - val_mse: 2694.5820 - val_accuracy: 0.0021\n",
      "Epoch 818/1000\n",
      "1155/1155 [==============================] - 2s 2ms/step - loss: 4051.9038 - mae: 33.8821 - mse: 4051.9038 - accuracy: 0.2150 - val_loss: 2812.7776 - val_mae: 23.6728 - val_mse: 2812.7776 - val_accuracy: 0.0831\n",
      "Epoch 819/1000\n",
      "1155/1155 [==============================] - 2s 2ms/step - loss: 4090.9231 - mae: 34.1642 - mse: 4090.9231 - accuracy: 0.2142 - val_loss: 3093.2605 - val_mae: 26.0994 - val_mse: 3093.2605 - val_accuracy: 0.0162\n",
      "Epoch 820/1000\n",
      "1155/1155 [==============================] - 2s 2ms/step - loss: 4069.7185 - mae: 33.7559 - mse: 4069.7185 - accuracy: 0.2138 - val_loss: 2744.1074 - val_mae: 25.7622 - val_mse: 2744.1074 - val_accuracy: 0.0011\n",
      "Epoch 821/1000\n",
      "1155/1155 [==============================] - 2s 2ms/step - loss: 4155.6987 - mae: 34.2138 - mse: 4155.6987 - accuracy: 0.2143 - val_loss: 2874.6438 - val_mae: 26.1938 - val_mse: 2874.6438 - val_accuracy: 0.0014\n",
      "Epoch 822/1000\n",
      "1155/1155 [==============================] - 2s 2ms/step - loss: 4039.2300 - mae: 33.9970 - mse: 4039.2300 - accuracy: 0.2170 - val_loss: 2776.2095 - val_mae: 24.3583 - val_mse: 2776.2095 - val_accuracy: 0.0261\n",
      "Epoch 823/1000\n",
      "1155/1155 [==============================] - 2s 2ms/step - loss: 4057.6824 - mae: 33.8069 - mse: 4057.6824 - accuracy: 0.2151 - val_loss: 3021.6880 - val_mae: 26.9908 - val_mse: 3021.6880 - val_accuracy: 0.0014\n",
      "Epoch 824/1000\n",
      "1155/1155 [==============================] - 2s 2ms/step - loss: 4129.9316 - mae: 34.0999 - mse: 4129.9316 - accuracy: 0.2162 - val_loss: 2686.2068 - val_mae: 25.9796 - val_mse: 2686.2068 - val_accuracy: 0.0014\n",
      "Epoch 825/1000\n",
      "1155/1155 [==============================] - 2s 2ms/step - loss: 4215.6201 - mae: 34.4252 - mse: 4215.6201 - accuracy: 0.2160 - val_loss: 2710.9697 - val_mae: 25.5220 - val_mse: 2710.9697 - val_accuracy: 0.0016\n",
      "Epoch 826/1000\n",
      "1155/1155 [==============================] - 2s 2ms/step - loss: 4075.9517 - mae: 34.0572 - mse: 4075.9517 - accuracy: 0.2152 - val_loss: 2712.4602 - val_mae: 23.0822 - val_mse: 2712.4602 - val_accuracy: 0.0497\n",
      "Epoch 827/1000\n",
      "1155/1155 [==============================] - 2s 2ms/step - loss: 4090.4497 - mae: 34.1116 - mse: 4090.4497 - accuracy: 0.2162 - val_loss: 2767.3369 - val_mae: 25.2499 - val_mse: 2767.3369 - val_accuracy: 0.0048\n",
      "Epoch 828/1000\n",
      "1155/1155 [==============================] - 2s 2ms/step - loss: 4178.3413 - mae: 34.3121 - mse: 4178.3413 - accuracy: 0.2147 - val_loss: 2779.7002 - val_mae: 26.7693 - val_mse: 2779.7002 - val_accuracy: 0.0013\n",
      "Epoch 829/1000\n",
      "1155/1155 [==============================] - 2s 2ms/step - loss: 4058.7742 - mae: 33.9902 - mse: 4058.7742 - accuracy: 0.2135 - val_loss: 2809.7234 - val_mae: 25.0309 - val_mse: 2809.7234 - val_accuracy: 0.0352\n",
      "Epoch 830/1000\n",
      "1155/1155 [==============================] - 2s 2ms/step - loss: 4020.4800 - mae: 33.9220 - mse: 4020.4800 - accuracy: 0.2134 - val_loss: 2759.0361 - val_mae: 26.0223 - val_mse: 2759.0361 - val_accuracy: 0.0014\n",
      "Epoch 831/1000\n",
      "1155/1155 [==============================] - 2s 2ms/step - loss: 4059.9714 - mae: 34.0345 - mse: 4059.9714 - accuracy: 0.2127 - val_loss: 2673.7515 - val_mae: 24.3506 - val_mse: 2673.7515 - val_accuracy: 0.0027\n",
      "Epoch 832/1000\n",
      "1155/1155 [==============================] - 2s 2ms/step - loss: 4093.7498 - mae: 33.9283 - mse: 4093.7498 - accuracy: 0.2160 - val_loss: 2932.6340 - val_mae: 26.1765 - val_mse: 2932.6340 - val_accuracy: 0.0120\n",
      "Epoch 833/1000\n",
      "1155/1155 [==============================] - 2s 2ms/step - loss: 4087.3750 - mae: 33.8722 - mse: 4087.3750 - accuracy: 0.2135 - val_loss: 2716.6333 - val_mae: 25.5346 - val_mse: 2716.6333 - val_accuracy: 7.5807e-04\n",
      "Epoch 834/1000\n",
      "1155/1155 [==============================] - 2s 2ms/step - loss: 4058.2925 - mae: 34.1112 - mse: 4058.2925 - accuracy: 0.2131 - val_loss: 2840.2524 - val_mae: 26.5829 - val_mse: 2840.2524 - val_accuracy: 0.0018\n",
      "Epoch 835/1000\n",
      "1155/1155 [==============================] - 2s 2ms/step - loss: 4125.3364 - mae: 34.0306 - mse: 4125.3364 - accuracy: 0.2146 - val_loss: 2800.0078 - val_mae: 25.9282 - val_mse: 2800.0078 - val_accuracy: 0.0017\n",
      "Epoch 836/1000\n",
      "1155/1155 [==============================] - 2s 2ms/step - loss: 4157.8760 - mae: 34.1386 - mse: 4157.8760 - accuracy: 0.2159 - val_loss: 3156.0569 - val_mae: 26.9595 - val_mse: 3156.0569 - val_accuracy: 0.0036\n",
      "Epoch 837/1000\n",
      "1155/1155 [==============================] - 2s 2ms/step - loss: 4109.5645 - mae: 33.9978 - mse: 4109.5645 - accuracy: 0.2142 - val_loss: 2689.5579 - val_mae: 23.5660 - val_mse: 2689.5579 - val_accuracy: 0.0152\n",
      "Epoch 838/1000\n",
      "1155/1155 [==============================] - 2s 2ms/step - loss: 4024.3022 - mae: 33.7983 - mse: 4024.3022 - accuracy: 0.2142 - val_loss: 2634.1987 - val_mae: 23.6493 - val_mse: 2634.1987 - val_accuracy: 0.0125\n",
      "Epoch 839/1000\n",
      "1155/1155 [==============================] - 2s 2ms/step - loss: 4073.5688 - mae: 33.9944 - mse: 4073.5688 - accuracy: 0.2154 - val_loss: 2736.6143 - val_mae: 22.9896 - val_mse: 2736.6143 - val_accuracy: 0.2048\n",
      "Epoch 840/1000\n",
      "1155/1155 [==============================] - 2s 2ms/step - loss: 4148.5913 - mae: 34.2388 - mse: 4148.5913 - accuracy: 0.2149 - val_loss: 2771.3491 - val_mae: 25.7027 - val_mse: 2771.3491 - val_accuracy: 0.0035\n",
      "Epoch 841/1000\n",
      "1155/1155 [==============================] - 2s 2ms/step - loss: 3966.9272 - mae: 33.9429 - mse: 3966.9272 - accuracy: 0.2131 - val_loss: 2904.6003 - val_mae: 26.7420 - val_mse: 2904.6003 - val_accuracy: 0.0014\n",
      "Epoch 842/1000\n",
      "1155/1155 [==============================] - 2s 2ms/step - loss: 4116.9741 - mae: 34.1319 - mse: 4116.9741 - accuracy: 0.2145 - val_loss: 2842.5034 - val_mae: 23.7436 - val_mse: 2842.5034 - val_accuracy: 0.0663\n",
      "Epoch 843/1000\n",
      "1155/1155 [==============================] - 2s 2ms/step - loss: 4086.8496 - mae: 34.1111 - mse: 4086.8496 - accuracy: 0.2182 - val_loss: 3033.7976 - val_mae: 27.2489 - val_mse: 3033.7976 - val_accuracy: 0.0014\n",
      "Epoch 844/1000\n",
      "1155/1155 [==============================] - 2s 1ms/step - loss: 4093.3486 - mae: 34.1829 - mse: 4093.3486 - accuracy: 0.2147 - val_loss: 2869.3389 - val_mae: 26.3700 - val_mse: 2869.3389 - val_accuracy: 0.0019\n",
      "Epoch 845/1000\n",
      "1155/1155 [==============================] - 2s 2ms/step - loss: 4056.4829 - mae: 34.0886 - mse: 4056.4829 - accuracy: 0.2160 - val_loss: 2907.7561 - val_mae: 25.1764 - val_mse: 2907.7561 - val_accuracy: 0.0115\n",
      "Epoch 846/1000\n",
      "1155/1155 [==============================] - 2s 2ms/step - loss: 4051.9885 - mae: 33.8524 - mse: 4051.9885 - accuracy: 0.2156 - val_loss: 2697.8774 - val_mae: 23.9194 - val_mse: 2697.8774 - val_accuracy: 0.0140\n",
      "Epoch 847/1000\n",
      "1155/1155 [==============================] - 2s 2ms/step - loss: 4066.9878 - mae: 34.0951 - mse: 4066.9878 - accuracy: 0.2143 - val_loss: 2755.7231 - val_mae: 24.4801 - val_mse: 2755.7231 - val_accuracy: 0.0341\n",
      "Epoch 848/1000\n",
      "1155/1155 [==============================] - 2s 2ms/step - loss: 4098.9253 - mae: 33.9925 - mse: 4098.9253 - accuracy: 0.2150 - val_loss: 2790.3999 - val_mae: 25.7911 - val_mse: 2790.3999 - val_accuracy: 0.0022\n",
      "Epoch 849/1000\n",
      "1155/1155 [==============================] - 2s 2ms/step - loss: 4087.3682 - mae: 34.0616 - mse: 4087.3682 - accuracy: 0.2156 - val_loss: 2749.3015 - val_mae: 24.7171 - val_mse: 2749.3015 - val_accuracy: 0.0026\n",
      "Epoch 850/1000\n",
      "1155/1155 [==============================] - 2s 2ms/step - loss: 4053.2134 - mae: 34.0583 - mse: 4053.2134 - accuracy: 0.2147 - val_loss: 2981.2458 - val_mae: 26.2818 - val_mse: 2981.2458 - val_accuracy: 0.0051\n",
      "Epoch 851/1000\n",
      "1155/1155 [==============================] - 2s 2ms/step - loss: 4169.7812 - mae: 34.3776 - mse: 4169.7812 - accuracy: 0.2150 - val_loss: 2991.3950 - val_mae: 26.4312 - val_mse: 2991.3950 - val_accuracy: 0.0021\n",
      "Epoch 852/1000\n",
      "1155/1155 [==============================] - 2s 1ms/step - loss: 4033.5049 - mae: 33.9889 - mse: 4033.5049 - accuracy: 0.2152 - val_loss: 2888.6980 - val_mae: 29.2356 - val_mse: 2888.6980 - val_accuracy: 0.0000e+00\n",
      "Epoch 853/1000\n",
      "1155/1155 [==============================] - 2s 1ms/step - loss: 3883.1853 - mae: 33.7184 - mse: 3883.1853 - accuracy: 0.2149 - val_loss: 2844.0205 - val_mae: 26.5780 - val_mse: 2844.0205 - val_accuracy: 1.0830e-04\n",
      "Epoch 854/1000\n",
      "1155/1155 [==============================] - 2s 1ms/step - loss: 3991.6606 - mae: 33.8611 - mse: 3991.6606 - accuracy: 0.2162 - val_loss: 2681.3867 - val_mae: 26.2917 - val_mse: 2681.3867 - val_accuracy: 6.4977e-04\n",
      "Epoch 855/1000\n",
      "1155/1155 [==============================] - 2s 1ms/step - loss: 4032.6697 - mae: 33.9465 - mse: 4032.6697 - accuracy: 0.2147 - val_loss: 2721.5623 - val_mae: 25.1309 - val_mse: 2721.5623 - val_accuracy: 0.0173\n",
      "Epoch 856/1000\n",
      "1155/1155 [==============================] - 2s 2ms/step - loss: 4134.0825 - mae: 34.3557 - mse: 4134.0825 - accuracy: 0.2142 - val_loss: 2960.5210 - val_mae: 26.8249 - val_mse: 2960.5210 - val_accuracy: 0.0011\n",
      "Epoch 857/1000\n",
      "1155/1155 [==============================] - 2s 2ms/step - loss: 4090.1685 - mae: 34.0431 - mse: 4090.1685 - accuracy: 0.2148 - val_loss: 2921.7112 - val_mae: 25.7308 - val_mse: 2921.7112 - val_accuracy: 0.0032\n",
      "Epoch 858/1000\n",
      "1155/1155 [==============================] - 2s 1ms/step - loss: 3898.0918 - mae: 33.6832 - mse: 3898.0918 - accuracy: 0.2148 - val_loss: 2869.6091 - val_mae: 25.9572 - val_mse: 2869.6091 - val_accuracy: 0.0091\n",
      "Epoch 859/1000\n",
      "1155/1155 [==============================] - 2s 2ms/step - loss: 4094.3455 - mae: 34.2561 - mse: 4094.3455 - accuracy: 0.2137 - val_loss: 2904.0625 - val_mae: 26.5754 - val_mse: 2904.0625 - val_accuracy: 0.0029\n",
      "Epoch 860/1000\n",
      "1155/1155 [==============================] - 2s 1ms/step - loss: 3874.8645 - mae: 33.5802 - mse: 3874.8645 - accuracy: 0.2169 - val_loss: 2671.9463 - val_mae: 24.4615 - val_mse: 2671.9463 - val_accuracy: 0.0055\n",
      "Epoch 861/1000\n",
      "1155/1155 [==============================] - 2s 1ms/step - loss: 3958.2188 - mae: 33.8047 - mse: 3958.2188 - accuracy: 0.2143 - val_loss: 2786.7090 - val_mae: 25.6465 - val_mse: 2786.7090 - val_accuracy: 0.0013\n",
      "Epoch 862/1000\n",
      "1155/1155 [==============================] - 2s 1ms/step - loss: 4121.2407 - mae: 34.3825 - mse: 4121.2407 - accuracy: 0.2132 - val_loss: 2863.9248 - val_mae: 24.8294 - val_mse: 2863.9248 - val_accuracy: 0.0241\n",
      "Epoch 863/1000\n",
      "1155/1155 [==============================] - 2s 1ms/step - loss: 3914.0947 - mae: 33.5164 - mse: 3914.0947 - accuracy: 0.2146 - val_loss: 2928.2153 - val_mae: 26.0059 - val_mse: 2928.2153 - val_accuracy: 0.0090\n",
      "Epoch 864/1000\n",
      "1155/1155 [==============================] - 2s 1ms/step - loss: 4021.7588 - mae: 33.8012 - mse: 4021.7588 - accuracy: 0.2146 - val_loss: 2747.3792 - val_mae: 26.0191 - val_mse: 2747.3792 - val_accuracy: 4.3318e-04\n",
      "Epoch 865/1000\n",
      "1155/1155 [==============================] - 2s 1ms/step - loss: 4079.8762 - mae: 33.8941 - mse: 4079.8762 - accuracy: 0.2149 - val_loss: 2771.3867 - val_mae: 24.9479 - val_mse: 2771.3867 - val_accuracy: 0.0034\n",
      "Epoch 866/1000\n",
      "1155/1155 [==============================] - 2s 1ms/step - loss: 3987.6887 - mae: 33.8953 - mse: 3987.6887 - accuracy: 0.2156 - val_loss: 2808.5537 - val_mae: 25.5286 - val_mse: 2808.5537 - val_accuracy: 0.0021\n",
      "Epoch 867/1000\n",
      "1155/1155 [==============================] - 2s 1ms/step - loss: 4077.4868 - mae: 33.8844 - mse: 4077.4868 - accuracy: 0.2150 - val_loss: 2785.1924 - val_mae: 27.3905 - val_mse: 2785.1924 - val_accuracy: 3.2489e-04\n",
      "Epoch 868/1000\n",
      "1155/1155 [==============================] - 2s 1ms/step - loss: 4059.7393 - mae: 34.1359 - mse: 4059.7393 - accuracy: 0.2150 - val_loss: 3142.6221 - val_mae: 26.7436 - val_mse: 3142.6221 - val_accuracy: 0.0027\n",
      "Epoch 869/1000\n",
      "1155/1155 [==============================] - 2s 1ms/step - loss: 3966.0757 - mae: 33.8960 - mse: 3966.0757 - accuracy: 0.2149 - val_loss: 2687.4290 - val_mae: 25.5666 - val_mse: 2687.4290 - val_accuracy: 0.0054\n",
      "Epoch 870/1000\n",
      "1155/1155 [==============================] - 2s 1ms/step - loss: 4170.2935 - mae: 34.2973 - mse: 4170.2935 - accuracy: 0.2148 - val_loss: 2907.1274 - val_mae: 25.6766 - val_mse: 2907.1274 - val_accuracy: 0.0029\n",
      "Epoch 871/1000\n",
      "1155/1155 [==============================] - 2s 1ms/step - loss: 3923.0972 - mae: 33.7442 - mse: 3923.0972 - accuracy: 0.2144 - val_loss: 2950.1626 - val_mae: 26.6656 - val_mse: 2950.1626 - val_accuracy: 0.0038\n",
      "Epoch 872/1000\n",
      "1155/1155 [==============================] - 2s 1ms/step - loss: 4117.1343 - mae: 34.3170 - mse: 4117.1343 - accuracy: 0.2150 - val_loss: 2831.3191 - val_mae: 25.7204 - val_mse: 2831.3191 - val_accuracy: 0.0030\n",
      "Epoch 873/1000\n",
      "1155/1155 [==============================] - 2s 1ms/step - loss: 3961.3359 - mae: 33.7605 - mse: 3961.3359 - accuracy: 0.2146 - val_loss: 3045.2371 - val_mae: 25.4438 - val_mse: 3045.2371 - val_accuracy: 0.0728\n",
      "Epoch 874/1000\n",
      "1155/1155 [==============================] - 2s 1ms/step - loss: 4035.5627 - mae: 33.9583 - mse: 4035.5627 - accuracy: 0.2131 - val_loss: 2820.1904 - val_mae: 25.4390 - val_mse: 2820.1904 - val_accuracy: 0.0055\n",
      "Epoch 875/1000\n",
      "1155/1155 [==============================] - 2s 1ms/step - loss: 4058.9985 - mae: 33.9879 - mse: 4058.9985 - accuracy: 0.2156 - val_loss: 2820.1877 - val_mae: 25.2158 - val_mse: 2820.1877 - val_accuracy: 0.0043\n",
      "Epoch 876/1000\n",
      "1155/1155 [==============================] - 2s 1ms/step - loss: 4104.3936 - mae: 34.0880 - mse: 4104.3936 - accuracy: 0.2137 - val_loss: 3091.8325 - val_mae: 24.9308 - val_mse: 3091.8325 - val_accuracy: 0.0308\n",
      "Epoch 877/1000\n",
      "1155/1155 [==============================] - 2s 1ms/step - loss: 4024.1340 - mae: 33.7786 - mse: 4024.1340 - accuracy: 0.2166 - val_loss: 2755.5071 - val_mae: 24.9941 - val_mse: 2755.5071 - val_accuracy: 0.0042\n",
      "Epoch 878/1000\n",
      "1155/1155 [==============================] - 2s 1ms/step - loss: 4007.4050 - mae: 33.9837 - mse: 4007.4050 - accuracy: 0.2147 - val_loss: 2703.4993 - val_mae: 24.9935 - val_mse: 2703.4993 - val_accuracy: 0.0023\n",
      "Epoch 879/1000\n",
      "1155/1155 [==============================] - 2s 1ms/step - loss: 3895.1602 - mae: 33.5837 - mse: 3895.1602 - accuracy: 0.2153 - val_loss: 3001.4412 - val_mae: 27.5216 - val_mse: 3001.4412 - val_accuracy: 0.0013\n",
      "Epoch 880/1000\n",
      "1155/1155 [==============================] - 2s 1ms/step - loss: 4040.4966 - mae: 33.9559 - mse: 4040.4966 - accuracy: 0.2138 - val_loss: 2680.6985 - val_mae: 26.1447 - val_mse: 2680.6985 - val_accuracy: 2.1659e-04\n",
      "Epoch 881/1000\n",
      "1155/1155 [==============================] - 2s 1ms/step - loss: 4039.8867 - mae: 34.1125 - mse: 4039.8867 - accuracy: 0.2152 - val_loss: 2696.9607 - val_mae: 25.5162 - val_mse: 2696.9607 - val_accuracy: 0.0022\n",
      "Epoch 882/1000\n",
      "1155/1155 [==============================] - 2s 1ms/step - loss: 4034.6482 - mae: 33.9540 - mse: 4034.6482 - accuracy: 0.2157 - val_loss: 2829.6997 - val_mae: 26.2165 - val_mse: 2829.6997 - val_accuracy: 0.0023\n",
      "Epoch 883/1000\n",
      "1155/1155 [==============================] - 2s 1ms/step - loss: 4062.7566 - mae: 34.0876 - mse: 4062.7566 - accuracy: 0.2110 - val_loss: 2893.5129 - val_mae: 26.5797 - val_mse: 2893.5129 - val_accuracy: 6.4977e-04\n",
      "Epoch 884/1000\n",
      "1155/1155 [==============================] - 2s 1ms/step - loss: 4011.0457 - mae: 34.0075 - mse: 4011.0457 - accuracy: 0.2147 - val_loss: 2781.5632 - val_mae: 24.1847 - val_mse: 2781.5632 - val_accuracy: 0.0222\n",
      "Epoch 885/1000\n",
      "1155/1155 [==============================] - 2s 1ms/step - loss: 4062.6887 - mae: 34.1344 - mse: 4062.6887 - accuracy: 0.2159 - val_loss: 2783.9746 - val_mae: 25.3435 - val_mse: 2783.9746 - val_accuracy: 0.0028\n",
      "Epoch 886/1000\n",
      "1155/1155 [==============================] - 2s 1ms/step - loss: 4131.9160 - mae: 34.1812 - mse: 4131.9160 - accuracy: 0.2142 - val_loss: 2945.2908 - val_mae: 26.3635 - val_mse: 2945.2908 - val_accuracy: 0.0015\n",
      "Epoch 887/1000\n",
      "1155/1155 [==============================] - 2s 1ms/step - loss: 4060.2380 - mae: 34.2283 - mse: 4060.2380 - accuracy: 0.2161 - val_loss: 2820.7302 - val_mae: 27.1751 - val_mse: 2820.7302 - val_accuracy: 4.3318e-04\n",
      "Epoch 888/1000\n",
      "1155/1155 [==============================] - 2s 1ms/step - loss: 4115.5493 - mae: 34.2102 - mse: 4115.5493 - accuracy: 0.2150 - val_loss: 2694.3696 - val_mae: 25.4352 - val_mse: 2694.3696 - val_accuracy: 8.6636e-04\n",
      "Epoch 889/1000\n",
      "1155/1155 [==============================] - 2s 1ms/step - loss: 3959.5359 - mae: 33.7807 - mse: 3959.5359 - accuracy: 0.2148 - val_loss: 2702.7834 - val_mae: 24.4098 - val_mse: 2702.7834 - val_accuracy: 0.0050\n",
      "Epoch 890/1000\n",
      "1155/1155 [==============================] - 2s 1ms/step - loss: 3963.6738 - mae: 33.8639 - mse: 3963.6738 - accuracy: 0.2138 - val_loss: 3016.7817 - val_mae: 25.3344 - val_mse: 3016.7817 - val_accuracy: 0.0522\n",
      "Epoch 891/1000\n",
      "1155/1155 [==============================] - 2s 1ms/step - loss: 4028.4724 - mae: 33.9565 - mse: 4028.4724 - accuracy: 0.2140 - val_loss: 2701.7363 - val_mae: 26.2153 - val_mse: 2701.7363 - val_accuracy: 0.0022\n",
      "Epoch 892/1000\n",
      "1155/1155 [==============================] - 2s 1ms/step - loss: 4047.1882 - mae: 34.1049 - mse: 4047.1882 - accuracy: 0.2156 - val_loss: 2740.1826 - val_mae: 24.6992 - val_mse: 2740.1826 - val_accuracy: 0.0152\n",
      "Epoch 893/1000\n",
      "1155/1155 [==============================] - 2s 1ms/step - loss: 3988.1343 - mae: 34.1242 - mse: 3988.1343 - accuracy: 0.2126 - val_loss: 2697.9631 - val_mae: 25.7758 - val_mse: 2697.9631 - val_accuracy: 8.6636e-04\n",
      "Epoch 894/1000\n",
      "1155/1155 [==============================] - 2s 1ms/step - loss: 3950.9368 - mae: 33.8053 - mse: 3950.9368 - accuracy: 0.2148 - val_loss: 2629.9724 - val_mae: 24.0436 - val_mse: 2629.9724 - val_accuracy: 0.0026\n",
      "Epoch 895/1000\n",
      "1155/1155 [==============================] - 2s 1ms/step - loss: 4000.1416 - mae: 34.0771 - mse: 4000.1416 - accuracy: 0.2156 - val_loss: 2870.8940 - val_mae: 26.4882 - val_mse: 2870.8940 - val_accuracy: 0.0014\n",
      "Epoch 896/1000\n",
      "1155/1155 [==============================] - 2s 1ms/step - loss: 3935.9934 - mae: 33.9678 - mse: 3935.9934 - accuracy: 0.2148 - val_loss: 2874.3176 - val_mae: 27.3156 - val_mse: 2874.3176 - val_accuracy: 4.3318e-04\n",
      "Epoch 897/1000\n",
      "1155/1155 [==============================] - 2s 1ms/step - loss: 3900.5317 - mae: 33.7245 - mse: 3900.5317 - accuracy: 0.2144 - val_loss: 2777.7898 - val_mae: 25.6493 - val_mse: 2777.7898 - val_accuracy: 0.0025\n",
      "Epoch 898/1000\n",
      "1155/1155 [==============================] - 2s 1ms/step - loss: 4018.0127 - mae: 33.7884 - mse: 4018.0127 - accuracy: 0.2150 - val_loss: 2905.7114 - val_mae: 25.0869 - val_mse: 2905.7114 - val_accuracy: 0.0049\n",
      "Epoch 899/1000\n",
      "1155/1155 [==============================] - 2s 1ms/step - loss: 3986.3823 - mae: 33.9626 - mse: 3986.3823 - accuracy: 0.2136 - val_loss: 2718.9512 - val_mae: 25.2209 - val_mse: 2718.9512 - val_accuracy: 0.0099\n",
      "Epoch 900/1000\n",
      "1155/1155 [==============================] - 2s 1ms/step - loss: 4035.9419 - mae: 34.1489 - mse: 4035.9419 - accuracy: 0.2155 - val_loss: 2839.2095 - val_mae: 25.9057 - val_mse: 2839.2095 - val_accuracy: 0.0012\n",
      "Epoch 901/1000\n",
      "1155/1155 [==============================] - 2s 1ms/step - loss: 3934.6350 - mae: 33.8718 - mse: 3934.6350 - accuracy: 0.2144 - val_loss: 2725.6172 - val_mae: 25.0028 - val_mse: 2725.6172 - val_accuracy: 0.0051\n",
      "Epoch 902/1000\n",
      "1155/1155 [==============================] - 2s 1ms/step - loss: 3936.0034 - mae: 33.7971 - mse: 3936.0034 - accuracy: 0.2133 - val_loss: 2774.0386 - val_mae: 26.7217 - val_mse: 2774.0386 - val_accuracy: 1.0830e-04\n",
      "Epoch 903/1000\n",
      "1155/1155 [==============================] - 2s 1ms/step - loss: 4123.0288 - mae: 34.2432 - mse: 4123.0288 - accuracy: 0.2151 - val_loss: 2940.8281 - val_mae: 27.6086 - val_mse: 2940.8281 - val_accuracy: 0.0000e+00\n",
      "Epoch 904/1000\n",
      "1155/1155 [==============================] - 2s 1ms/step - loss: 4088.2007 - mae: 34.1954 - mse: 4088.2007 - accuracy: 0.2151 - val_loss: 2918.7637 - val_mae: 25.2817 - val_mse: 2918.7637 - val_accuracy: 0.0054\n",
      "Epoch 905/1000\n",
      "1155/1155 [==============================] - 2s 1ms/step - loss: 4040.3774 - mae: 34.0941 - mse: 4040.3774 - accuracy: 0.2143 - val_loss: 2656.6514 - val_mae: 25.2632 - val_mse: 2656.6514 - val_accuracy: 0.0080\n",
      "Epoch 906/1000\n",
      "1155/1155 [==============================] - 2s 1ms/step - loss: 4023.0410 - mae: 33.9924 - mse: 4023.0410 - accuracy: 0.2148 - val_loss: 2729.1541 - val_mae: 27.1675 - val_mse: 2729.1541 - val_accuracy: 0.0000e+00\n",
      "Epoch 907/1000\n",
      "1155/1155 [==============================] - 2s 1ms/step - loss: 3992.7693 - mae: 33.9443 - mse: 3992.7693 - accuracy: 0.2145 - val_loss: 3060.2546 - val_mae: 27.6529 - val_mse: 3060.2546 - val_accuracy: 0.0013\n",
      "Epoch 908/1000\n",
      "1155/1155 [==============================] - 2s 1ms/step - loss: 3940.3291 - mae: 33.8285 - mse: 3940.3291 - accuracy: 0.2164 - val_loss: 2663.8926 - val_mae: 23.1093 - val_mse: 2663.8926 - val_accuracy: 0.0304\n",
      "Epoch 909/1000\n",
      "1155/1155 [==============================] - 2s 1ms/step - loss: 3911.4482 - mae: 33.5440 - mse: 3911.4482 - accuracy: 0.2122 - val_loss: 3024.1028 - val_mae: 26.7762 - val_mse: 3024.1028 - val_accuracy: 0.0015\n",
      "Epoch 910/1000\n",
      "1155/1155 [==============================] - 2s 1ms/step - loss: 3878.7539 - mae: 33.8728 - mse: 3878.7539 - accuracy: 0.2136 - val_loss: 2914.6272 - val_mae: 26.9352 - val_mse: 2914.6272 - val_accuracy: 8.6636e-04\n",
      "Epoch 911/1000\n",
      "1155/1155 [==============================] - 2s 1ms/step - loss: 4000.7590 - mae: 33.8799 - mse: 4000.7590 - accuracy: 0.2138 - val_loss: 2842.1992 - val_mae: 24.2564 - val_mse: 2842.1992 - val_accuracy: 0.0376\n",
      "Epoch 912/1000\n",
      "1155/1155 [==============================] - 2s 1ms/step - loss: 4124.5156 - mae: 34.1597 - mse: 4124.5156 - accuracy: 0.2145 - val_loss: 2845.8425 - val_mae: 25.7416 - val_mse: 2845.8425 - val_accuracy: 0.0035\n",
      "Epoch 913/1000\n",
      "1155/1155 [==============================] - 2s 1ms/step - loss: 3996.8032 - mae: 34.0347 - mse: 3996.8032 - accuracy: 0.2133 - val_loss: 2720.7595 - val_mae: 23.4164 - val_mse: 2720.7595 - val_accuracy: 0.0422\n",
      "Epoch 914/1000\n",
      "1155/1155 [==============================] - 2s 1ms/step - loss: 4003.9453 - mae: 33.8047 - mse: 4003.9453 - accuracy: 0.2146 - val_loss: 2757.7412 - val_mae: 25.7479 - val_mse: 2757.7412 - val_accuracy: 0.0022\n",
      "Epoch 915/1000\n",
      "1155/1155 [==============================] - 2s 1ms/step - loss: 4110.3032 - mae: 34.2758 - mse: 4110.3032 - accuracy: 0.2124 - val_loss: 2738.3987 - val_mae: 25.4058 - val_mse: 2738.3987 - val_accuracy: 0.0027\n",
      "Epoch 916/1000\n",
      "1155/1155 [==============================] - 2s 1ms/step - loss: 3991.3613 - mae: 33.8359 - mse: 3991.3613 - accuracy: 0.2144 - val_loss: 2831.4924 - val_mae: 26.5444 - val_mse: 2831.4924 - val_accuracy: 5.4148e-04\n",
      "Epoch 917/1000\n",
      "1155/1155 [==============================] - 2s 1ms/step - loss: 3976.2620 - mae: 33.7905 - mse: 3976.2620 - accuracy: 0.2141 - val_loss: 2795.7278 - val_mae: 25.7156 - val_mse: 2795.7278 - val_accuracy: 0.0013\n",
      "Epoch 918/1000\n",
      "1155/1155 [==============================] - 2s 1ms/step - loss: 4132.2310 - mae: 34.1684 - mse: 4132.2310 - accuracy: 0.2150 - val_loss: 2668.2358 - val_mae: 24.4802 - val_mse: 2668.2358 - val_accuracy: 0.0056\n",
      "Epoch 919/1000\n",
      "1155/1155 [==============================] - 2s 1ms/step - loss: 3944.2944 - mae: 33.7669 - mse: 3944.2944 - accuracy: 0.2177 - val_loss: 2998.3740 - val_mae: 27.5936 - val_mse: 2998.3740 - val_accuracy: 8.6636e-04\n",
      "Epoch 920/1000\n",
      "1155/1155 [==============================] - 2s 1ms/step - loss: 4015.1882 - mae: 33.9574 - mse: 4015.1882 - accuracy: 0.2145 - val_loss: 2737.9990 - val_mae: 24.7074 - val_mse: 2737.9990 - val_accuracy: 0.0252\n",
      "Epoch 921/1000\n",
      "1155/1155 [==============================] - 2s 1ms/step - loss: 4045.1008 - mae: 33.9700 - mse: 4045.1008 - accuracy: 0.2142 - val_loss: 3015.1929 - val_mae: 25.1689 - val_mse: 3015.1929 - val_accuracy: 0.0166\n",
      "Epoch 922/1000\n",
      "1155/1155 [==============================] - 2s 1ms/step - loss: 3909.8225 - mae: 33.7702 - mse: 3909.8225 - accuracy: 0.2144 - val_loss: 2805.3247 - val_mae: 26.4041 - val_mse: 2805.3247 - val_accuracy: 0.0011\n",
      "Epoch 923/1000\n",
      "1155/1155 [==============================] - 2s 1ms/step - loss: 4039.4543 - mae: 33.9144 - mse: 4039.4543 - accuracy: 0.2159 - val_loss: 2674.3008 - val_mae: 25.7251 - val_mse: 2674.3008 - val_accuracy: 0.0012\n",
      "Epoch 924/1000\n",
      "1155/1155 [==============================] - 2s 1ms/step - loss: 3997.8208 - mae: 33.8611 - mse: 3997.8208 - accuracy: 0.2142 - val_loss: 2762.9875 - val_mae: 25.9204 - val_mse: 2762.9875 - val_accuracy: 3.2489e-04\n",
      "Epoch 925/1000\n",
      "1155/1155 [==============================] - 2s 1ms/step - loss: 4039.0476 - mae: 34.1773 - mse: 4039.0476 - accuracy: 0.2137 - val_loss: 2855.5183 - val_mae: 25.9727 - val_mse: 2855.5183 - val_accuracy: 0.0100\n",
      "Epoch 926/1000\n",
      "1155/1155 [==============================] - 2s 1ms/step - loss: 3907.1421 - mae: 33.5692 - mse: 3907.1421 - accuracy: 0.2157 - val_loss: 2925.1157 - val_mae: 26.2424 - val_mse: 2925.1157 - val_accuracy: 0.0013\n",
      "Epoch 927/1000\n",
      "1155/1155 [==============================] - 2s 1ms/step - loss: 3996.2219 - mae: 34.0128 - mse: 3996.2219 - accuracy: 0.2144 - val_loss: 2762.9722 - val_mae: 25.0469 - val_mse: 2762.9722 - val_accuracy: 0.0069\n",
      "Epoch 928/1000\n",
      "1155/1155 [==============================] - 2s 1ms/step - loss: 4026.9297 - mae: 34.1201 - mse: 4026.9297 - accuracy: 0.2165 - val_loss: 2758.7917 - val_mae: 24.9794 - val_mse: 2758.7917 - val_accuracy: 0.0047\n",
      "Epoch 929/1000\n",
      "1155/1155 [==============================] - 2s 1ms/step - loss: 3967.8467 - mae: 33.7364 - mse: 3967.8467 - accuracy: 0.2164 - val_loss: 2722.0566 - val_mae: 25.4113 - val_mse: 2722.0566 - val_accuracy: 0.0014\n",
      "Epoch 930/1000\n",
      "1155/1155 [==============================] - 2s 1ms/step - loss: 4019.6394 - mae: 33.8950 - mse: 4019.6394 - accuracy: 0.2131 - val_loss: 2723.7842 - val_mae: 25.0624 - val_mse: 2723.7842 - val_accuracy: 0.0048\n",
      "Epoch 931/1000\n",
      "1155/1155 [==============================] - 2s 1ms/step - loss: 3976.4763 - mae: 33.8347 - mse: 3976.4763 - accuracy: 0.2143 - val_loss: 2637.7378 - val_mae: 23.5444 - val_mse: 2637.7378 - val_accuracy: 0.0115\n",
      "Epoch 932/1000\n",
      "1155/1155 [==============================] - 2s 1ms/step - loss: 4061.4734 - mae: 34.0552 - mse: 4061.4734 - accuracy: 0.2141 - val_loss: 2875.2581 - val_mae: 26.5663 - val_mse: 2875.2581 - val_accuracy: 6.4977e-04\n",
      "Epoch 933/1000\n",
      "1155/1155 [==============================] - 2s 1ms/step - loss: 3925.0869 - mae: 33.9079 - mse: 3925.0869 - accuracy: 0.2134 - val_loss: 2898.6641 - val_mae: 27.3296 - val_mse: 2898.6641 - val_accuracy: 0.0016\n",
      "Epoch 934/1000\n",
      "1155/1155 [==============================] - 2s 1ms/step - loss: 3906.5403 - mae: 33.7393 - mse: 3906.5403 - accuracy: 0.2109 - val_loss: 2750.1331 - val_mae: 26.0603 - val_mse: 2750.1331 - val_accuracy: 7.5807e-04\n",
      "Epoch 935/1000\n",
      "1155/1155 [==============================] - 2s 1ms/step - loss: 4011.4041 - mae: 33.8543 - mse: 4011.4041 - accuracy: 0.2170 - val_loss: 2776.3582 - val_mae: 23.7392 - val_mse: 2776.3582 - val_accuracy: 0.0451\n",
      "Epoch 936/1000\n",
      "1155/1155 [==============================] - 2s 1ms/step - loss: 3963.3911 - mae: 33.8699 - mse: 3963.3911 - accuracy: 0.2146 - val_loss: 2712.0828 - val_mae: 23.9175 - val_mse: 2712.0828 - val_accuracy: 0.0133\n",
      "Epoch 937/1000\n",
      "1155/1155 [==============================] - 2s 2ms/step - loss: 4182.3516 - mae: 34.2124 - mse: 4182.3516 - accuracy: 0.2131 - val_loss: 2669.3926 - val_mae: 26.0517 - val_mse: 2669.3926 - val_accuracy: 0.0013\n",
      "Epoch 938/1000\n",
      "1155/1155 [==============================] - 2s 1ms/step - loss: 3938.6824 - mae: 33.5729 - mse: 3938.6824 - accuracy: 0.2146 - val_loss: 2653.6575 - val_mae: 24.1224 - val_mse: 2653.6575 - val_accuracy: 0.0103\n",
      "Epoch 939/1000\n",
      "1155/1155 [==============================] - 2s 2ms/step - loss: 3988.7991 - mae: 33.7395 - mse: 3988.7991 - accuracy: 0.2160 - val_loss: 2662.8818 - val_mae: 23.9380 - val_mse: 2662.8818 - val_accuracy: 0.0489\n",
      "Epoch 940/1000\n",
      "1155/1155 [==============================] - 2s 2ms/step - loss: 3943.2500 - mae: 33.8014 - mse: 3943.2500 - accuracy: 0.2158 - val_loss: 3094.6597 - val_mae: 25.9915 - val_mse: 3094.6597 - val_accuracy: 0.0071\n",
      "Epoch 941/1000\n",
      "1155/1155 [==============================] - 2s 1ms/step - loss: 4061.3599 - mae: 33.9175 - mse: 4061.3599 - accuracy: 0.2143 - val_loss: 2953.3223 - val_mae: 23.5550 - val_mse: 2953.3223 - val_accuracy: 0.2212\n",
      "Epoch 942/1000\n",
      "1155/1155 [==============================] - 2s 2ms/step - loss: 3982.0483 - mae: 33.8658 - mse: 3982.0483 - accuracy: 0.2144 - val_loss: 3108.6943 - val_mae: 25.6397 - val_mse: 3108.6943 - val_accuracy: 0.0334\n",
      "Epoch 943/1000\n",
      "1155/1155 [==============================] - 2s 2ms/step - loss: 3958.9246 - mae: 33.8435 - mse: 3958.9246 - accuracy: 0.2176 - val_loss: 2885.2175 - val_mae: 24.9480 - val_mse: 2885.2175 - val_accuracy: 0.0065\n",
      "Epoch 944/1000\n",
      "1155/1155 [==============================] - 2s 2ms/step - loss: 3909.0400 - mae: 33.8230 - mse: 3909.0400 - accuracy: 0.2163 - val_loss: 2704.2729 - val_mae: 25.6386 - val_mse: 2704.2729 - val_accuracy: 0.0018\n",
      "Epoch 945/1000\n",
      "1155/1155 [==============================] - 2s 2ms/step - loss: 4014.1821 - mae: 33.8303 - mse: 4014.1821 - accuracy: 0.2144 - val_loss: 2944.3425 - val_mae: 25.1429 - val_mse: 2944.3425 - val_accuracy: 0.0066\n",
      "Epoch 946/1000\n",
      "1155/1155 [==============================] - 2s 2ms/step - loss: 3976.8596 - mae: 33.7958 - mse: 3976.8596 - accuracy: 0.2137 - val_loss: 3008.8132 - val_mae: 25.2254 - val_mse: 3008.8132 - val_accuracy: 0.0105\n",
      "Epoch 947/1000\n",
      "1155/1155 [==============================] - 2s 2ms/step - loss: 4012.3054 - mae: 33.9780 - mse: 4012.3054 - accuracy: 0.2158 - val_loss: 2838.0701 - val_mae: 25.2873 - val_mse: 2838.0701 - val_accuracy: 0.0041\n",
      "Epoch 948/1000\n",
      "1155/1155 [==============================] - 2s 2ms/step - loss: 4010.4504 - mae: 34.0605 - mse: 4010.4504 - accuracy: 0.2131 - val_loss: 2672.2913 - val_mae: 24.3308 - val_mse: 2672.2913 - val_accuracy: 0.0068\n",
      "Epoch 949/1000\n",
      "1155/1155 [==============================] - 2s 2ms/step - loss: 4030.9031 - mae: 33.9674 - mse: 4030.9031 - accuracy: 0.2152 - val_loss: 2833.5696 - val_mae: 26.1354 - val_mse: 2833.5696 - val_accuracy: 9.7466e-04\n",
      "Epoch 950/1000\n",
      "1155/1155 [==============================] - 2s 2ms/step - loss: 4082.8567 - mae: 34.0717 - mse: 4082.8567 - accuracy: 0.2148 - val_loss: 2765.4395 - val_mae: 25.3502 - val_mse: 2765.4395 - val_accuracy: 0.0015\n",
      "Epoch 951/1000\n",
      "1155/1155 [==============================] - 2s 2ms/step - loss: 4060.6824 - mae: 34.0827 - mse: 4060.6824 - accuracy: 0.2150 - val_loss: 3121.5881 - val_mae: 27.3671 - val_mse: 3121.5881 - val_accuracy: 0.0015\n",
      "Epoch 952/1000\n",
      "1155/1155 [==============================] - 2s 2ms/step - loss: 4085.8628 - mae: 34.0142 - mse: 4085.8628 - accuracy: 0.2128 - val_loss: 3157.0413 - val_mae: 28.6055 - val_mse: 3157.0413 - val_accuracy: 8.6636e-04\n",
      "Epoch 953/1000\n",
      "1155/1155 [==============================] - 2s 2ms/step - loss: 4028.0334 - mae: 33.9257 - mse: 4028.0334 - accuracy: 0.2152 - val_loss: 2736.0830 - val_mae: 23.3852 - val_mse: 2736.0830 - val_accuracy: 0.1279\n",
      "Epoch 954/1000\n",
      "1155/1155 [==============================] - 2s 2ms/step - loss: 3894.3994 - mae: 33.6838 - mse: 3894.3994 - accuracy: 0.2146 - val_loss: 2717.2756 - val_mae: 24.5521 - val_mse: 2717.2756 - val_accuracy: 0.0329\n",
      "Epoch 955/1000\n",
      "1155/1155 [==============================] - 2s 2ms/step - loss: 3915.8540 - mae: 33.7233 - mse: 3915.8540 - accuracy: 0.2166 - val_loss: 2862.6040 - val_mae: 27.7256 - val_mse: 2862.6040 - val_accuracy: 0.0011\n",
      "Epoch 956/1000\n",
      "1155/1155 [==============================] - 2s 2ms/step - loss: 4041.0261 - mae: 33.8871 - mse: 4041.0261 - accuracy: 0.2139 - val_loss: 2948.9724 - val_mae: 26.0216 - val_mse: 2948.9724 - val_accuracy: 0.0037\n",
      "Epoch 957/1000\n",
      "1155/1155 [==============================] - 2s 2ms/step - loss: 4011.9634 - mae: 34.0529 - mse: 4011.9634 - accuracy: 0.2161 - val_loss: 2866.7568 - val_mae: 25.5005 - val_mse: 2866.7568 - val_accuracy: 0.0034\n",
      "Epoch 958/1000\n",
      "1155/1155 [==============================] - 2s 2ms/step - loss: 3989.3970 - mae: 33.9234 - mse: 3989.3970 - accuracy: 0.2183 - val_loss: 2640.3022 - val_mae: 24.4227 - val_mse: 2640.3022 - val_accuracy: 0.0027\n",
      "Epoch 959/1000\n",
      "1155/1155 [==============================] - 2s 2ms/step - loss: 4029.0425 - mae: 34.0643 - mse: 4029.0425 - accuracy: 0.2167 - val_loss: 2835.7014 - val_mae: 26.6097 - val_mse: 2835.7014 - val_accuracy: 5.4148e-04\n",
      "Epoch 960/1000\n",
      "1155/1155 [==============================] - 2s 2ms/step - loss: 3940.5024 - mae: 33.7953 - mse: 3940.5024 - accuracy: 0.2148 - val_loss: 2888.3330 - val_mae: 26.3798 - val_mse: 2888.3330 - val_accuracy: 0.0026\n",
      "Epoch 961/1000\n",
      "1155/1155 [==============================] - 2s 2ms/step - loss: 4065.7893 - mae: 34.2095 - mse: 4065.7893 - accuracy: 0.2137 - val_loss: 2748.1436 - val_mae: 24.9146 - val_mse: 2748.1436 - val_accuracy: 0.0019\n",
      "Epoch 962/1000\n",
      "1155/1155 [==============================] - 2s 2ms/step - loss: 4045.6780 - mae: 34.0132 - mse: 4045.6780 - accuracy: 0.2163 - val_loss: 2945.4956 - val_mae: 25.5795 - val_mse: 2945.4956 - val_accuracy: 0.0120\n",
      "Epoch 963/1000\n",
      "1155/1155 [==============================] - 2s 2ms/step - loss: 3923.2222 - mae: 33.6735 - mse: 3923.2222 - accuracy: 0.2159 - val_loss: 2973.2966 - val_mae: 26.3829 - val_mse: 2973.2966 - val_accuracy: 0.0041\n",
      "Epoch 964/1000\n",
      "1155/1155 [==============================] - 2s 2ms/step - loss: 3992.3459 - mae: 33.8781 - mse: 3992.3459 - accuracy: 0.2162 - val_loss: 2648.6746 - val_mae: 24.9013 - val_mse: 2648.6746 - val_accuracy: 0.0050\n",
      "Epoch 965/1000\n",
      "1155/1155 [==============================] - 2s 2ms/step - loss: 3923.9465 - mae: 33.7151 - mse: 3923.9465 - accuracy: 0.2156 - val_loss: 2849.5059 - val_mae: 28.5003 - val_mse: 2849.5059 - val_accuracy: 1.0830e-04\n",
      "Epoch 966/1000\n",
      "1155/1155 [==============================] - 2s 2ms/step - loss: 4015.8562 - mae: 33.9189 - mse: 4015.8562 - accuracy: 0.2145 - val_loss: 2797.1199 - val_mae: 26.3779 - val_mse: 2797.1199 - val_accuracy: 2.1659e-04\n",
      "Epoch 967/1000\n",
      "1155/1155 [==============================] - 2s 2ms/step - loss: 4008.5076 - mae: 33.9210 - mse: 4008.5076 - accuracy: 0.2163 - val_loss: 2753.0120 - val_mae: 26.3703 - val_mse: 2753.0120 - val_accuracy: 0.0014\n",
      "Epoch 968/1000\n",
      "1155/1155 [==============================] - 2s 2ms/step - loss: 3923.5706 - mae: 33.7981 - mse: 3923.5706 - accuracy: 0.2147 - val_loss: 2862.6926 - val_mae: 26.7441 - val_mse: 2862.6926 - val_accuracy: 9.7466e-04\n",
      "Epoch 969/1000\n",
      "1155/1155 [==============================] - 2s 2ms/step - loss: 3919.3809 - mae: 33.8512 - mse: 3919.3809 - accuracy: 0.2150 - val_loss: 2706.7483 - val_mae: 25.2833 - val_mse: 2706.7483 - val_accuracy: 0.0042\n",
      "Epoch 970/1000\n",
      "1155/1155 [==============================] - 2s 2ms/step - loss: 3918.2944 - mae: 33.6815 - mse: 3918.2944 - accuracy: 0.2151 - val_loss: 2857.3787 - val_mae: 25.8586 - val_mse: 2857.3787 - val_accuracy: 0.0018\n",
      "Epoch 971/1000\n",
      "1155/1155 [==============================] - 2s 2ms/step - loss: 3983.3108 - mae: 34.0820 - mse: 3983.3108 - accuracy: 0.2152 - val_loss: 2996.9177 - val_mae: 26.4434 - val_mse: 2996.9177 - val_accuracy: 0.0025\n",
      "Epoch 972/1000\n",
      "1155/1155 [==============================] - 2s 2ms/step - loss: 3944.6418 - mae: 33.8166 - mse: 3944.6418 - accuracy: 0.2154 - val_loss: 2744.1340 - val_mae: 26.8583 - val_mse: 2744.1340 - val_accuracy: 6.4977e-04\n",
      "Epoch 973/1000\n",
      "1155/1155 [==============================] - 2s 2ms/step - loss: 4013.6846 - mae: 33.9843 - mse: 4013.6846 - accuracy: 0.2133 - val_loss: 2884.7422 - val_mae: 26.0408 - val_mse: 2884.7422 - val_accuracy: 0.0037\n",
      "Epoch 974/1000\n",
      "1155/1155 [==============================] - 2s 2ms/step - loss: 4000.4509 - mae: 33.9220 - mse: 4000.4509 - accuracy: 0.2152 - val_loss: 2741.9651 - val_mae: 25.7330 - val_mse: 2741.9651 - val_accuracy: 0.0032\n",
      "Epoch 975/1000\n",
      "1155/1155 [==============================] - 2s 2ms/step - loss: 3843.4844 - mae: 33.5278 - mse: 3843.4844 - accuracy: 0.2156 - val_loss: 2767.7695 - val_mae: 24.7488 - val_mse: 2767.7695 - val_accuracy: 0.0113\n",
      "Epoch 976/1000\n",
      "1155/1155 [==============================] - 2s 2ms/step - loss: 4017.5557 - mae: 33.8014 - mse: 4017.5557 - accuracy: 0.2146 - val_loss: 2683.6575 - val_mae: 24.1100 - val_mse: 2683.6575 - val_accuracy: 0.0057\n",
      "Epoch 977/1000\n",
      "1155/1155 [==============================] - 2s 2ms/step - loss: 3884.4893 - mae: 33.6515 - mse: 3884.4893 - accuracy: 0.2165 - val_loss: 2758.0786 - val_mae: 26.1504 - val_mse: 2758.0786 - val_accuracy: 6.4977e-04\n",
      "Epoch 978/1000\n",
      "1155/1155 [==============================] - 2s 2ms/step - loss: 3910.2434 - mae: 33.8320 - mse: 3910.2434 - accuracy: 0.2145 - val_loss: 2871.0964 - val_mae: 25.8656 - val_mse: 2871.0964 - val_accuracy: 0.0045\n",
      "Epoch 979/1000\n",
      "1155/1155 [==============================] - 2s 2ms/step - loss: 3902.7908 - mae: 33.6873 - mse: 3902.7908 - accuracy: 0.2161 - val_loss: 3011.4023 - val_mae: 26.7752 - val_mse: 3011.4023 - val_accuracy: 0.0025\n",
      "Epoch 980/1000\n",
      "1155/1155 [==============================] - 2s 2ms/step - loss: 3932.4473 - mae: 33.7921 - mse: 3932.4473 - accuracy: 0.2154 - val_loss: 2680.7219 - val_mae: 23.7959 - val_mse: 2680.7219 - val_accuracy: 0.0192\n",
      "Epoch 981/1000\n",
      "1155/1155 [==============================] - 2s 2ms/step - loss: 4013.9666 - mae: 34.0055 - mse: 4013.9666 - accuracy: 0.2124 - val_loss: 2762.4250 - val_mae: 25.5159 - val_mse: 2762.4250 - val_accuracy: 0.0027\n",
      "Epoch 982/1000\n",
      "1155/1155 [==============================] - 2s 2ms/step - loss: 4049.8499 - mae: 34.0226 - mse: 4049.8499 - accuracy: 0.2153 - val_loss: 2681.6292 - val_mae: 23.4654 - val_mse: 2681.6292 - val_accuracy: 0.0237\n",
      "Epoch 983/1000\n",
      "1155/1155 [==============================] - 2s 2ms/step - loss: 3840.9963 - mae: 33.8396 - mse: 3840.9963 - accuracy: 0.2155 - val_loss: 2737.6089 - val_mae: 23.8477 - val_mse: 2737.6089 - val_accuracy: 0.0801\n",
      "Epoch 984/1000\n",
      "1155/1155 [==============================] - 2s 2ms/step - loss: 3887.9900 - mae: 33.6477 - mse: 3887.9900 - accuracy: 0.2153 - val_loss: 2791.3909 - val_mae: 23.9902 - val_mse: 2791.3909 - val_accuracy: 0.0235\n",
      "Epoch 985/1000\n",
      "1155/1155 [==============================] - 2s 2ms/step - loss: 3990.0469 - mae: 33.8028 - mse: 3990.0469 - accuracy: 0.2158 - val_loss: 2905.9795 - val_mae: 25.2971 - val_mse: 2905.9795 - val_accuracy: 0.0025\n",
      "Epoch 986/1000\n",
      "1155/1155 [==============================] - 2s 2ms/step - loss: 3910.8406 - mae: 33.7165 - mse: 3910.8406 - accuracy: 0.2159 - val_loss: 2654.2644 - val_mae: 22.9848 - val_mse: 2654.2644 - val_accuracy: 0.1120\n",
      "Epoch 987/1000\n",
      "1155/1155 [==============================] - 2s 2ms/step - loss: 3934.1121 - mae: 33.7054 - mse: 3934.1121 - accuracy: 0.2151 - val_loss: 2654.7183 - val_mae: 25.0596 - val_mse: 2654.7183 - val_accuracy: 0.0011\n",
      "Epoch 988/1000\n",
      "1155/1155 [==============================] - 2s 2ms/step - loss: 3924.4902 - mae: 34.0148 - mse: 3924.4902 - accuracy: 0.2169 - val_loss: 2750.5872 - val_mae: 24.3500 - val_mse: 2750.5872 - val_accuracy: 0.0106\n",
      "Epoch 989/1000\n",
      "1155/1155 [==============================] - 2s 2ms/step - loss: 4127.6206 - mae: 34.1109 - mse: 4127.6206 - accuracy: 0.2148 - val_loss: 2719.2227 - val_mae: 24.4286 - val_mse: 2719.2227 - val_accuracy: 0.0138\n",
      "Epoch 990/1000\n",
      "1155/1155 [==============================] - 2s 2ms/step - loss: 3988.0544 - mae: 33.9691 - mse: 3988.0544 - accuracy: 0.2145 - val_loss: 2882.1328 - val_mae: 26.5232 - val_mse: 2882.1328 - val_accuracy: 0.0015\n",
      "Epoch 991/1000\n",
      "1155/1155 [==============================] - 2s 2ms/step - loss: 3994.1646 - mae: 33.8433 - mse: 3994.1646 - accuracy: 0.2156 - val_loss: 2751.7966 - val_mae: 24.8350 - val_mse: 2751.7966 - val_accuracy: 0.0121\n",
      "Epoch 992/1000\n",
      "1155/1155 [==============================] - 2s 2ms/step - loss: 3903.3359 - mae: 33.7424 - mse: 3903.3359 - accuracy: 0.2152 - val_loss: 2618.8687 - val_mae: 24.9734 - val_mse: 2618.8687 - val_accuracy: 0.0017\n",
      "Epoch 993/1000\n",
      "1155/1155 [==============================] - 2s 2ms/step - loss: 3902.5479 - mae: 33.7252 - mse: 3902.5479 - accuracy: 0.2148 - val_loss: 2645.1567 - val_mae: 24.4940 - val_mse: 2645.1567 - val_accuracy: 0.0021\n",
      "Epoch 994/1000\n",
      "1155/1155 [==============================] - 2s 2ms/step - loss: 3912.0088 - mae: 33.8122 - mse: 3912.0088 - accuracy: 0.2140 - val_loss: 2862.4014 - val_mae: 26.1516 - val_mse: 2862.4014 - val_accuracy: 0.0030\n",
      "Epoch 995/1000\n",
      "1155/1155 [==============================] - 2s 2ms/step - loss: 4126.4014 - mae: 34.2746 - mse: 4126.4014 - accuracy: 0.2154 - val_loss: 2804.5325 - val_mae: 25.4626 - val_mse: 2804.5325 - val_accuracy: 0.0015\n",
      "Epoch 996/1000\n",
      "1155/1155 [==============================] - 2s 2ms/step - loss: 3866.7407 - mae: 33.6264 - mse: 3866.7407 - accuracy: 0.2180 - val_loss: 2861.1721 - val_mae: 26.4867 - val_mse: 2861.1721 - val_accuracy: 0.0086\n",
      "Epoch 997/1000\n",
      "1155/1155 [==============================] - 2s 2ms/step - loss: 3908.2317 - mae: 33.6078 - mse: 3908.2317 - accuracy: 0.2163 - val_loss: 2892.6448 - val_mae: 26.4901 - val_mse: 2892.6448 - val_accuracy: 0.0024\n",
      "Epoch 998/1000\n",
      "1155/1155 [==============================] - 2s 2ms/step - loss: 3997.0117 - mae: 33.9008 - mse: 3997.0117 - accuracy: 0.2157 - val_loss: 3000.4668 - val_mae: 28.7137 - val_mse: 3000.4668 - val_accuracy: 1.0830e-04\n",
      "Epoch 999/1000\n",
      "1155/1155 [==============================] - 2s 2ms/step - loss: 4024.3870 - mae: 33.8783 - mse: 4024.3870 - accuracy: 0.2160 - val_loss: 2845.7659 - val_mae: 24.9138 - val_mse: 2845.7659 - val_accuracy: 0.0113\n",
      "Epoch 1000/1000\n",
      "1155/1155 [==============================] - 2s 2ms/step - loss: 3914.4595 - mae: 33.8125 - mse: 3914.4595 - accuracy: 0.2139 - val_loss: 2600.3608 - val_mae: 23.2611 - val_mse: 2600.3608 - val_accuracy: 0.0209\n"
     ]
    }
   ],
   "source": [
    "model_bc = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.InputLayer(input_shape=55),\n",
    "    #ak.MultiCategoryEncoding(encoding=['int','int','int','int','none','none','none','none','none',\n",
    "    #                                   'none','none','none','none','none','int','int','int','int',\n",
    "    #                                   'int','none','int','none','none','int','int','none','none',\n",
    "    #                                   'int','int','int','int','none','none','int','none','none',\n",
    "    #                                   'none','int','int','int','int','int','int','none','none',\n",
    "    #                                   'int','int','int','int','int','int','int','int']),\n",
    "    normalizer_BC, \n",
    "    tf.keras.layers.Dense(1024, activation='linear'),\n",
    "    tf.keras.layers.ReLU(),\n",
    "    tf.keras.layers.Dropout(0.5),\n",
    "    tf.keras.layers.Dense(32, activation='linear'),\n",
    "    tf.keras.layers.ReLU(),\n",
    "    tf.keras.layers.Dropout(0.5),\n",
    "    tf.keras.layers.Dense(1)\n",
    "])\n",
    "\n",
    "model_bc.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.001), \n",
    "                loss=\"mse\", \n",
    "                metrics=[\"mae\", \"mse\", 'accuracy'])\n",
    "\n",
    "history_bc = model_bc.fit(x=x_train_bc, y=y_train_bc, epochs=1000, callbacks=[early_stop], validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "296/296 [==============================] - 0s 554us/step - loss: 2663.3662 - mae: 22.8274 - mse: 2663.3662 - accuracy: 0.0204\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[2663.3662109375, 22.82735252380371, 2663.3662109375, 0.020408162847161293]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_bc.evaluate(x_val_bc, y_val_bc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Make predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Do some more stuff"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Evaluate the model based on the validation data\n",
    "\n",
    "mse_a = mean_squared_error(y_val_a, model_a.predict(x_val_a))\n",
    "print(\"MSE for A: \", mse_a)\n",
    "mse_b = mean_squared_error(y_val_b, model_b.predict(x_val_b))\n",
    "print(\"MSE for B: \", mse_b)\n",
    "mse_c = mean_squared_error(y_val_c, model_c.predict(x_val_c))\n",
    "print(\"MSE for C: \", mse_c)\n",
    "print(\"Mean MSE: \", (mse_a + mse_b + mse_c) / 3)\n",
    "\n",
    "# Evaluate the predictions\n",
    "\n",
    "score_a = model_a.score(x_val_a, y_val_a)\n",
    "score_b = model_b.score(x_val_b, y_val_b)\n",
    "score_c = model_c.score(x_val_c, y_val_c)\n",
    "\n",
    "print(\"Score A: \", score_a)\n",
    "print(\"Score B: \", score_b)\n",
    "print(\"Score C: \", score_c)\n",
    "print('')\n",
    "\n",
    "# Get feature importance scores\n",
    "models = [(model_a, 'A'), (model_b, 'B'), (model_c, 'C')]\n",
    "for model in models:\n",
    "\n",
    "    feature_importance_scores = model[0].feature_importances_\n",
    "\n",
    "# Create a DataFrame to associate features with their importance scores\n",
    "    feature_importance_df1 = pd.DataFrame({'Feature': x_train_a.columns, 'Importance': feature_importance_scores})\n",
    "\n",
    "# Sort features by importance in descending order\n",
    "    feature_importance_df1 = feature_importance_df1.sort_values(by='Importance', ascending=False)\n",
    "\n",
    "# Print or visualize the feature importance scores\n",
    "    \n",
    "    print(f'Model {model[1]}')\n",
    "    print(feature_importance_df1.head(10))\n",
    "    print('')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_pred = y_pred\n",
    "\n",
    "test = pd.read_csv('../data/test.csv')\n",
    "test['prediction'] = y_test_pred\n",
    "sample_submission = pd.read_csv('../data/sample_submission.csv')\n",
    "submission = sample_submission[['id']].merge(test[['id', 'prediction']], on='id', how='left')\n",
    "submission.to_csv('submissions/submission.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
