{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import xgboost as xgb\n",
    "from sklearn.ensemble import HistGradientBoostingRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning, message=\"is_sparse is deprecated\")\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning, module=\"xgboost\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_estimated_a = pd.read_parquet('../data/A/X_train_estimated.parquet')\n",
    "X_train_estimated_b = pd.read_parquet('../data/B/X_train_estimated.parquet')\n",
    "X_train_estimated_c = pd.read_parquet('../data/C/X_train_estimated.parquet')\n",
    "\n",
    "X_train_observed_a = pd.read_parquet('../data/A/X_train_observed.parquet')\n",
    "X_train_observed_b = pd.read_parquet('../data/B/X_train_observed.parquet')\n",
    "X_train_observed_c = pd.read_parquet('../data/C/X_train_observed.parquet')\n",
    "\n",
    "X_test_estimated_a = pd.read_parquet('../data/A/X_test_estimated.parquet')\n",
    "X_test_estimated_b = pd.read_parquet('../data/B/X_test_estimated.parquet')\n",
    "X_test_estimated_c = pd.read_parquet('../data/C/X_test_estimated.parquet')\n",
    "\n",
    "train_targets_a = pd.read_parquet('../data/A/train_targets.parquet')\n",
    "train_targets_b = pd.read_parquet('../data/B/train_targets.parquet')\n",
    "train_targets_c = pd.read_parquet('../data/C/train_targets.parquet')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data clean up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Data set A, B and C clean up\n",
    "\n",
    "def data_clean_up(x_train_est, x_train_observe, y_train):\n",
    "\n",
    "  if 'date_calc' in x_train_est.columns:\n",
    "    x_train_est.drop(columns=\"date_calc\", inplace=True)\n",
    "\n",
    "  x_train = pd.concat([x_train_observe, x_train_est])\n",
    "\n",
    "  # Group the rows into blocks of 4 and apply the aggregation function\n",
    "  agg_func = {col: 'mean' for col in x_train.columns[1:]}\n",
    "  X_train_downscaled = x_train.groupby(x_train.index // 4).agg({**{'date_forecast': 'first'}, **agg_func})\n",
    "\n",
    "  y_train.dropna(inplace=True)\n",
    "  combined_data = pd.merge(X_train_downscaled, y_train, left_on='date_forecast', right_on='time')\n",
    "  y_train = combined_data['pv_measurement']\n",
    "\n",
    "  if 'date_forecast' and 'time' and 'pv_measurement' in combined_data.columns:\n",
    "    combined_data.drop(columns=\"date_forecast\", inplace=True)\n",
    "    combined_data.drop(columns=\"time\", inplace=True)\n",
    "    combined_data.drop(columns=\"pv_measurement\", inplace=True)\n",
    "\n",
    "  return combined_data, y_train\n",
    "\n",
    "x_train_a, y_train_a = data_clean_up(X_train_estimated_a, X_train_observed_a, train_targets_a)\n",
    "x_train_b, y_train_b = data_clean_up(X_train_estimated_b, X_train_observed_b, train_targets_b)\n",
    "x_train_c, y_train_c = data_clean_up(X_train_estimated_c, X_train_observed_c, train_targets_c)\n",
    "\n",
    "\n",
    "def data_clean_up_test(x_test_est):\n",
    "\n",
    "  # Group the rows into blocks of 4 and apply the aggregation function\n",
    "  agg_func = {col: 'mean' for col in x_test_est.columns[1:]}\n",
    "  X_test_downscaled = x_test_est.groupby(x_test_est.index // 4).agg({**{'date_forecast': 'first'}, **agg_func})\n",
    "\n",
    "  if 'date_forecast' in X_test_downscaled.columns:\n",
    "    X_test_downscaled.drop(columns=\"date_forecast\", inplace=True)\n",
    "\n",
    "  return X_test_downscaled"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Do something"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_a1 = xgb.XGBRegressor(objective='reg:squarederror', random_state=42)\n",
    "model_b1 = xgb.XGBRegressor(objective='reg:squarederror', random_state=42)\n",
    "model_c1 = xgb.XGBRegressor(objective='reg:squarederror', random_state=42)\n",
    "\n",
    "model_a1.fit(x_train_a, y_train_a)\n",
    "model_b1.fit(x_train_b, y_train_b)\n",
    "model_c1.fit(x_train_c, y_train_c)\n",
    "\n",
    "model_a2 = HistGradientBoostingRegressor()\n",
    "model_b2 = HistGradientBoostingRegressor()\n",
    "model_c2 = HistGradientBoostingRegressor()\n",
    "\n",
    "model_a2.fit(x_train_a, y_train_a)\n",
    "model_b2.fit(x_train_b, y_train_b)\n",
    "model_c2.fit(x_train_c, y_train_c)\n",
    "\n",
    "X_test_estimated_a = data_clean_up_test(X_test_estimated_a)\n",
    "X_test_estimated_b = data_clean_up_test(X_test_estimated_b)\n",
    "X_test_estimated_c = data_clean_up_test(X_test_estimated_c)\n",
    "\n",
    "y_pred_a1 = model_a1.predict(X_test_estimated_a)\n",
    "y_pred_b1 = model_b1.predict(X_test_estimated_b)\n",
    "y_pred_c1= model_c1.predict(X_test_estimated_c)\n",
    "\n",
    "y_pred_a2 = model_a2.predict(X_test_estimated_a)\n",
    "y_pred_b2 = model_b2.predict(X_test_estimated_b)\n",
    "y_pred_c2= model_c2.predict(X_test_estimated_c)\n",
    "\n",
    "y_pred_xgb = np.concatenate((y_pred_a1, y_pred_b1, y_pred_c1), axis=0)\n",
    "y_pred_hgb = np.concatenate((y_pred_a2, y_pred_b2, y_pred_c2), axis=0)\n",
    "average_preds = (y_pred_xgb + y_pred_hgb) / 2.0\n",
    "\n",
    "\n",
    "# # Load and preprocess your data\n",
    "# X_train_a, y_train_a = data_clean_up(X_train_estimated_a, X_train_observed_a, train_targets_a)\n",
    "# X_train_b, y_train_b = data_clean_up(X_train_estimated_b, X_train_observed_b, train_targets_b)\n",
    "# X_train_c, y_train_c = data_clean_up(X_train_estimated_c, X_train_observed_c, train_targets_c)\n",
    "\n",
    "# def cv_stack(X_train, y_train):\n",
    "#     # Define the number of folds for cross-validation\n",
    "#     n_splits = 5  # Adjust as needed\n",
    "\n",
    "#     # Initialize arrays to store cross-validation predictions\n",
    "#     cv_preds = np.zeros((len(y_train), n_splits))\n",
    "\n",
    "#     # Create a KFold splitter\n",
    "#     kf = KFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
    "\n",
    "#     # Train base models and generate cross-validation predictions\n",
    "#     for i, (train_idx, valid_idx) in enumerate(kf.split(X_train)):\n",
    "#         print(\"train_idx:\", train_idx)\n",
    "#         print(\"valid_idx:\", valid_idx)\n",
    "#         X_tr, X_val = X_train[train_idx], X_train[valid_idx]\n",
    "#         y_tr, y_val = y_train[train_idx], y_train[valid_idx]\n",
    "        \n",
    "#         # Train base regression models (e.g., HistGradientBoostingRegressor, XGBRegressor) on X_tr and y_tr\n",
    "        \n",
    "#         # Generate predictions from base models on the validation subset\n",
    "#         hist_gb_model = HistGradientBoostingRegressor()\n",
    "#         hist_gb_model.fit(X_tr, y_tr)\n",
    "#         xgb_model = xgb.XGBRegressor()\n",
    "#         xgb_model.fit(X_tr, y_tr)\n",
    "        \n",
    "#         cv_preds[valid_idx, i] = (hist_gb_model.predict(X_val) + xgb_model.predict(X_val)) / 2  # Use an average for stacking\n",
    "\n",
    "#     return cv_preds\n",
    "\n",
    "# # Generate cross-validation predictions for the training dataset\n",
    "# cv_preds_a = cv_stack(X_train_a, y_train_a)\n",
    "# cv_preds_b = cv_stack(X_train_b, y_train_b)\n",
    "# cv_preds_c = cv_stack(X_train_c, y_train_c)\n",
    "\n",
    "# # Combine cross-validation predictions into a new dataset\n",
    "# stacked_data_a = cv_preds_a.mean(axis=1).reshape(-1, 1)  # Use an average for stacking\n",
    "# stacked_data_b = cv_preds_b.mean(axis=1).reshape(-1, 1)\n",
    "# stacked_data_c = cv_preds_c.mean(axis=1).reshape(-1, 1)\n",
    "\n",
    "# # Train a meta-model (e.g., linear regression) on the stacked data\n",
    "# meta_model_a = LinearRegression()\n",
    "# meta_model_a.fit(stacked_data_a, y_train_a)\n",
    "\n",
    "# meta_model_b = LinearRegression()\n",
    "# meta_model_b.fit(stacked_data_b, y_train_b)\n",
    "\n",
    "# meta_model_c = LinearRegression()\n",
    "# meta_model_c.fit(stacked_data_c, y_train_c)\n",
    "\n",
    "# # Make final predictions on the entire training dataset\n",
    "# final_predictions_a = meta_model_a.predict(X_test_estimated_a)\n",
    "# final_predictions_b = meta_model_b.predict(X_test_estimated_b)\n",
    "# final_predictions_c = meta_model_c.predict(X_test_estimated_c)\n",
    "\n",
    "# # Evaluate the stacked ensemble model (e.g., using mean squared error)\n",
    "# mse = np.mean_squared_error(y_train, final_predictions_a)\n",
    "# print(f\"Stacked Ensemble MSE A: {mse}\")\n",
    "\n",
    "# mse = np.mean_squared_error(y_train, final_predictions_b)\n",
    "# print(f\"Stacked Ensemble MSE B: {mse}\")\n",
    "\n",
    "# mse = np.mean_squared_error(y_train, final_predictions_c)\n",
    "# print(f\"Stacked Ensemble MSE C: {mse}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Make predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Do some more stuff"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_pred = average_preds\n",
    "\n",
    "test = pd.read_csv('../data/test.csv')\n",
    "test['prediction'] = y_test_pred\n",
    "sample_submission = pd.read_csv('../data/sample_submission.csv')\n",
    "submission = sample_submission[['id']].merge(test[['id', 'prediction']], on='id', how='left')\n",
    "submission.to_csv('submission.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
