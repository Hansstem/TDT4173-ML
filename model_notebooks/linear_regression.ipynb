{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Automatically reloads newest versions of imports if functions in any python files used are changed\n",
    "# %autoreload\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.interpolate import interp1d\n",
    "from sklearn.linear_model import LinearRegression\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_estimated_a = pd.read_parquet('../data/A/X_train_estimated.parquet')\n",
    "X_train_estimated_b = pd.read_parquet('../data/B/X_train_estimated.parquet')\n",
    "X_train_estimated_c = pd.read_parquet('../data/C/X_train_estimated.parquet')\n",
    "\n",
    "X_train_observed_a = pd.read_parquet('../data/A/X_train_observed.parquet')\n",
    "X_train_observed_b = pd.read_parquet('../data/B/X_train_observed.parquet')\n",
    "X_train_observed_c = pd.read_parquet('../data/C/X_train_observed.parquet')\n",
    "\n",
    "X_test_estimated_a = pd.read_parquet('../data/A/X_test_estimated.parquet')\n",
    "X_test_estimated_b = pd.read_parquet('../data/B/X_test_estimated.parquet')\n",
    "X_test_estimated_c = pd.read_parquet('../data/C/X_test_estimated.parquet')\n",
    "\n",
    "train_targets_a = pd.read_parquet('../data/A/train_targets.parquet')\n",
    "train_targets_b = pd.read_parquet('../data/B/train_targets.parquet')\n",
    "train_targets_c = pd.read_parquet('../data/C/train_targets.parquet')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data clean up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine the datasets 'a', 'b', and 'c'\n",
    "if 'date_calc' in X_train_estimated_a.columns:\n",
    "  X_train_estimated_a.drop(columns=\"date_calc\", inplace=True)\n",
    "\n",
    "X_train = pd.concat([X_train_observed_a, X_train_estimated_a])\n",
    "# X_train\n",
    "print(X_train_estimated_a.shape)\n",
    "print(X_train_observed_a.shape)\n",
    "print(train_targets_a.shape)\n",
    "print(X_train.index.shape)\n",
    "agg_func = {col: 'mean' for col in X_train.columns[1:]}\n",
    "\n",
    "\n",
    "# Group the rows into blocks of 4 and apply the aggregation function\n",
    "X_train_downscaled = X_train.groupby(X_train.index // 4).agg({**{'date_forecast': 'first'}, **agg_func})\n",
    "# Reset the index to make it a regular DataFrame with a new index\n",
    "X_train_downscaled.reset_index(drop=True, inplace=True)\n",
    "combined_data = pd.merge(X_train_downscaled, train_targets_a, left_on='date_forecast', right_on='time')\n",
    "y_train = combined_data['pv_measurement']\n",
    "combined_data.drop(columns=\"ceiling_height_agl:m\", inplace=True)\n",
    "\n",
    "# if 'date_forecast' and 'time' and 'pv_measurement' in combined_data.columns:\n",
    "  # combined_data.drop(columns=\"date_forecast\", inplace=True)\n",
    "  # combined_data.drop(columns=\"time\", inplace=True)\n",
    "  # combined_data.drop(columns=\"pv_measurement\", inplace=True)\n",
    "\n",
    "# x_train = combined_data.dropna(inplace=True)\n",
    "print(combined_data.shape)\n",
    "print(y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Do feature selection etc."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(17576, 46)\n",
      "(118669, 46)\n",
      "(34085, 2)\n",
      "(136245,)\n",
      "(29667, 47)\n",
      "0         0.00\n",
      "1         0.00\n",
      "2         0.00\n",
      "3         0.00\n",
      "4        19.36\n",
      "         ...  \n",
      "29662     0.00\n",
      "29663     0.00\n",
      "29664     0.00\n",
      "29665     0.00\n",
      "29666     0.00\n",
      "Name: pv_measurement, Length: 29667, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# model_a = LinearRegression()\n",
    "# model_a.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Make predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model_a.predict(X_test_estimated_a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_pred = y_pred\n",
    "\n",
    "test = pd.read_csv('../data/test.csv')\n",
    "test['prediction'] = y_test_pred\n",
    "sample_submission = pd.read_csv('sample_submission.csv')\n",
    "submission = sample_submission[['id']].merge(test[['id', 'prediction']], on='id', how='left')\n",
    "submission.to_csv('submission.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
