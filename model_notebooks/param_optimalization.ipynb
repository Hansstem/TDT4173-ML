{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "import warnings\n",
    "import data_func.read_data as read_data\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning, module=\"xgboost\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframes = read_data.get_training_data()\n",
    "X_frames_train = dataframes[0]\n",
    "Y_frames_train = dataframes[1]\n",
    "X_frames_test = read_data.get_test_data()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data clean up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29667\n",
      "29667\n",
      "720\n"
     ]
    }
   ],
   "source": [
    "# making shure that target values line up with x_values\n",
    "\n",
    "def data_allign(x_train, y_train):\n",
    "\n",
    "  y_train.dropna(inplace=True)\n",
    "  combined_data = pd.merge(x_train, y_train, left_on='date_forecast', right_on='time')\n",
    "  y_train = combined_data['pv_measurement']\n",
    "\n",
    "  if 'time' and 'pv_measurement' in combined_data.columns:\n",
    "    combined_data.drop(columns=['time', 'pv_measurement'], inplace=True)\n",
    "    \n",
    "  return combined_data, y_train\n",
    "\n",
    "import data_func.aggregation as data_agg\n",
    "\n",
    "for i in range(len(X_frames_train)):\n",
    "    X_frames_train[i] = data_agg.gen_agg(X_frames_train[i], 'mean')\n",
    "    X_frames_train[i], Y_frames_train[i] = data_allign(X_frames_train[i], Y_frames_train[i])\n",
    "\n",
    "\n",
    "for j in range(len(X_frames_test)):\n",
    "    X_frames_test[j] = data_agg.gen_agg(X_frames_test[j], 'mean')\n",
    "\n",
    "print(len(X_frames_train[0]))\n",
    "print(len(Y_frames_train[0]))\n",
    "print(len(X_frames_test[0]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import data_func.timeseasonality as DTS\n",
    "for i in range(len(X_frames_train)):\n",
    "    X_frames_train[i] = DTS.append_seasonal_columns(X_frames_train[i])\n",
    "    X_frames_train[i].drop(columns=['date_forecast'], inplace=True)\n",
    "\n",
    "for i in range(len(X_frames_test)):\n",
    "    X_frames_test[i] = DTS.append_seasonal_columns(X_frames_test[i])\n",
    "    X_frames_test[i].drop(columns=['date_forecast'], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyperparameter optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-10-17 18:25:41,094] A new study created in memory with name: no-name-a06ccc76-c7af-4cb2-ab43-603af035aa65\n",
      "[I 2023-10-17 18:25:59,361] Trial 0 finished with value: 2368.194074049965 and parameters: {'n_estimators': 690, 'max_depth': 9, 'learning_rate': 0.05335673602208645, 'subsample': 0.932804582895975, 'colsample_bytree': 0.9885642849465077}. Best is trial 0 with value: 2368.194074049965.\n",
      "[I 2023-10-17 18:26:07,832] Trial 1 finished with value: 2319.427506832132 and parameters: {'n_estimators': 356, 'max_depth': 8, 'learning_rate': 0.076614824667391, 'subsample': 0.610845042291492, 'colsample_bytree': 0.7956039908084882}. Best is trial 1 with value: 2319.427506832132.\n",
      "[I 2023-10-17 18:26:17,960] Trial 2 finished with value: 2429.05450275033 and parameters: {'n_estimators': 547, 'max_depth': 8, 'learning_rate': 0.018712167851818416, 'subsample': 0.7154168576917876, 'colsample_bytree': 0.9401711777169734}. Best is trial 1 with value: 2319.427506832132.\n",
      "[I 2023-10-17 18:26:19,887] Trial 3 finished with value: 2603.783894823702 and parameters: {'n_estimators': 267, 'max_depth': 6, 'learning_rate': 0.032220804366143205, 'subsample': 0.9867650690019776, 'colsample_bytree': 0.5186270546216765}. Best is trial 1 with value: 2319.427506832132.\n",
      "[I 2023-10-17 18:26:22,265] Trial 4 finished with value: 2797.154667538076 and parameters: {'n_estimators': 566, 'max_depth': 4, 'learning_rate': 0.12069706313965901, 'subsample': 0.5093116020036043, 'colsample_bytree': 0.9001622590074717}. Best is trial 1 with value: 2319.427506832132.\n",
      "[I 2023-10-17 18:26:24,938] Trial 5 finished with value: 2609.9856386498263 and parameters: {'n_estimators': 572, 'max_depth': 4, 'learning_rate': 0.14660253860297123, 'subsample': 0.8382695514005198, 'colsample_bytree': 0.9524766045312285}. Best is trial 1 with value: 2319.427506832132.\n",
      "[I 2023-10-17 18:26:25,956] Trial 6 finished with value: 3094.629179882628 and parameters: {'n_estimators': 137, 'max_depth': 5, 'learning_rate': 0.021521168811054554, 'subsample': 0.5748921823023614, 'colsample_bytree': 0.9559698674861041}. Best is trial 1 with value: 2319.427506832132.\n",
      "[I 2023-10-17 18:26:27,047] Trial 7 finished with value: 2809.865749679682 and parameters: {'n_estimators': 274, 'max_depth': 4, 'learning_rate': 0.06143683236364264, 'subsample': 0.6277016020100772, 'colsample_bytree': 0.6679590701927122}. Best is trial 1 with value: 2319.427506832132.\n",
      "[I 2023-10-17 18:26:44,055] Trial 8 finished with value: 2485.7568564323547 and parameters: {'n_estimators': 709, 'max_depth': 9, 'learning_rate': 0.12636379944203047, 'subsample': 0.6560981082946724, 'colsample_bytree': 0.9411463268385263}. Best is trial 1 with value: 2319.427506832132.\n",
      "[I 2023-10-17 18:26:44,859] Trial 9 finished with value: 2843.048927943052 and parameters: {'n_estimators': 139, 'max_depth': 5, 'learning_rate': 0.26804971548176704, 'subsample': 0.7355199040933744, 'colsample_bytree': 0.5309172833605037}. Best is trial 1 with value: 2319.427506832132.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best hyperparameters: {'n_estimators': 356, 'max_depth': 8, 'learning_rate': 0.076614824667391, 'subsample': 0.610845042291492, 'colsample_bytree': 0.7956039908084882}\n"
     ]
    }
   ],
   "source": [
    "import optuna\n",
    "import xgboost as xgb # Change to model to optimize\n",
    "\n",
    "# Split the data into training and validation sets\n",
    "x_train_a, x_val_a, y_train_a, y_val_a = train_test_split(X_frames_train[0], Y_frames_train[0], test_size=0.17, random_state=None)\n",
    "x_train_b, x_val_b, y_train_b, y_val_b = train_test_split(X_frames_train[1], Y_frames_train[1], test_size=0.17, random_state=None)\n",
    "x_train_c, x_val_c, y_train_c, y_val_c = train_test_split(X_frames_train[2], Y_frames_train[2], test_size=0.17, random_state=None)\n",
    "\n",
    "\n",
    "def objective(trial):\n",
    "\n",
    "  params = {\n",
    "        'n_estimators': trial.suggest_int('n_estimators', 100, 1000),\n",
    "        'max_depth': trial.suggest_int('max_depth', 3, 10),\n",
    "        'learning_rate': trial.suggest_float('learning_rate', 0.01, 0.3, log=True),\n",
    "        'subsample': trial.suggest_float('subsample', 0.5, 1),\n",
    "        'colsample_bytree': trial.suggest_float('colsample_bytree', 0.5, 1),\n",
    "    }\n",
    "\n",
    "  model_c = xgb.XGBRegressor(**params) # Change to model to optimize\n",
    "  model_c.fit(x_train_c, y_train_c)\n",
    "\n",
    "  # Make predictions on the validation set\n",
    "  y_pred = model_c.predict(x_val_c)\n",
    "\n",
    "  # Calculate the Mean Squared Error (MSE) as the metric to optimize\n",
    "  mse = mean_squared_error(y_val_c, y_pred)\n",
    "\n",
    "  return mse\n",
    "\n",
    "study = optuna.create_study(direction='minimize')\n",
    "study.optimize(objective, n_trials=10)\n",
    "\n",
    "best = study.best_params\n",
    "# Print the best hyperparameters found\n",
    "print(\"Best hyperparameters:\", best)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
