{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from catboost import CatBoostRegressor\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "This script has functionality for reading .parquet files as a pandas DataFrame\n",
    "Date: 10/10/2023\n",
    "Auth: Peter\n",
    "\"\"\"\n",
    "import pandas as pd\n",
    "from typing import List\n",
    "import os\n",
    "\n",
    "folder = '../../data/'\n",
    "A = folder + 'A/'\n",
    "B = folder + 'B/'\n",
    "C = folder + 'C/'\n",
    "\n",
    "XTRO = 'X_train_observed.parquet'\n",
    "XTRE = 'X_train_estimated.parquet'\n",
    "XTEE = 'X_test_estimated.parquet'\n",
    "Y = 'train_targets.parquet'\n",
    "\n",
    "relative_filepaths = {\"A\": A, \"B\": B, \"C\": C}\n",
    "\n",
    "def get_df_from_parquet(filepath: str) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Returns DataFrame when given filepath to .parquet file\n",
    "    \"\"\"\n",
    "    return pd.read_parquet(filepath)\n",
    "\n",
    "def merge_x(xo_path, xe_path):\n",
    "    xo = get_df_from_parquet(xo_path)\n",
    "    xe = get_df_from_parquet(xe_path)\n",
    "    xo['estimated'] = 0\n",
    "    xe['estimated'] = 1\n",
    "    xo['estimation_calc_forecast_difference'] = 0\n",
    "    time_diff = []\n",
    "    for i in range(len(xe)):\n",
    "        time_diff.append(abs((xe['date_forecast'].iloc[i] - xe['date_calc'].iloc[i]).seconds))\n",
    "    xe['estimation_calc_forecast_difference'] = time_diff\n",
    "\n",
    "    if 'date_calc' in xe.columns:\n",
    "         xe.drop(columns=['date_calc'], inplace=True)\n",
    "    x_train = pd.concat([xo, xe])\n",
    "    return x_train\n",
    "\n",
    "def append_x_y(x_list, y_list, merge, path):\n",
    "    if merge:\n",
    "        x_list.append(merge_x(path+XTRO, path+XTRE))\n",
    "    else: \n",
    "        x_list.append(get_df_from_parquet(path+XTRO)) #appending observed X train\n",
    "        x_list.append(get_df_from_parquet(path+XTRE)) #appendeing estimated X train\n",
    "    y_list.append(get_df_from_parquet(path+Y)) # appending target Y\n",
    "\n",
    "def get_training_data(location: str or list = None, merge: bool = True) -> List[List[pd.DataFrame]]:\n",
    "    \"\"\"\n",
    "    Returns tuple with merged x_train data for given location(s) in a list and corresponding list of targets\n",
    "\n",
    "    OR if none given, returns all locations x_train_merged per location \n",
    "    \n",
    "    **in order A, B, C <----------NB!** or order given. \n",
    "\n",
    "    RETURNS: List[List[x_train: pd.DataFrame], List[y_target: pd.DataFrame]]\n",
    "\n",
    "    NOTE: If merge = False the list returned is [x_train_observed_A, x_train_estimated_A,...]\n",
    "    \"\"\"\n",
    "    ### dealing with current working directory for relative paths ###\n",
    "    cwd_old = os.getcwd()\n",
    "    file_loc = os.path.abspath(__file__)\n",
    "    cwd_new = os.path.dirname(file_loc)\n",
    "    os.chdir(cwd_new)\n",
    "    \n",
    "    x_train_list = []\n",
    "    y_target_list = []\n",
    "    \n",
    "    if location == None: \n",
    "        for i in relative_filepaths:\n",
    "            path = relative_filepaths[i]\n",
    "            append_x_y(x_train_list, y_target_list, merge, path)\n",
    "    \n",
    "    elif type(location) == str:\n",
    "        try:\n",
    "            path = relative_filepaths[location] \n",
    "            append_x_y(x_train_list, y_target_list, merge, path)\n",
    "        except Exception as e:\n",
    "            print(f'\\nProbaly no matching location for passed string: {location}')\n",
    "            raise Exception(e)\n",
    "        \n",
    "    \n",
    "    elif type(location) == list:\n",
    "        for loc in location: \n",
    "            try: \n",
    "                path = relative_filepaths[loc]\n",
    "                append_x_y(x_train_list, y_target_list, merge, path)\n",
    "            except Exception as e:\n",
    "                print(f'\\nProbaly no matching location for passed strings:{location}')\n",
    "                raise Exception(e)\n",
    "    \n",
    "    os.chdir(cwd_old)\n",
    "    ### returning working directory ###\n",
    "    return [x_train_list, y_target_list]\n",
    "\n",
    "def get_test_data(location: str or list = None) -> List[pd.DataFrame]:\n",
    "    \"\"\"\n",
    "    Returns list with x_test data for given location(s) in a list\n",
    "\n",
    "    OR if none given, returns all locations x_testper location \n",
    "    \n",
    "    **in order A, B, C <----------NB!** or order given. \n",
    "\n",
    "    RETURNS: List[x_test: pd.DataFrame]\n",
    "    \"\"\"\n",
    "    ### dealing with current working directory for relative paths ###\n",
    "    cwd_old = os.getcwd()\n",
    "    file_loc = os.path.abspath(__file__)\n",
    "    cwd_new = os.path.dirname(file_loc)\n",
    "    os.chdir(cwd_new)\n",
    "    \n",
    "    x_list = []\n",
    "    \n",
    "    if location == None: \n",
    "        for i in relative_filepaths:\n",
    "            path = relative_filepaths[i]\n",
    "            xt = get_df_from_parquet(path+XTEE)\n",
    "            xt['estimated'] = 1\n",
    "            time_diff = []\n",
    "            for i in range(len(xt)):\n",
    "                time_diff.append(abs((xt['date_forecast'].iloc[i] - xt['date_calc'].iloc[i]).seconds))\n",
    "            xt['estimation_calc_forecast_difference'] = time_diff\n",
    "            x_list.append(xt)\n",
    "    \n",
    "    elif type(location) == str:\n",
    "        try:\n",
    "            path = relative_filepaths[location] \n",
    "            x_list.append(get_df_from_parquet(path+XTEE))\n",
    "        except Exception as e:\n",
    "            print(f'\\nProbaly no matching location for passed string: {location}')\n",
    "            raise Exception(e)\n",
    "        \n",
    "    \n",
    "    elif type(location) == list:\n",
    "        for loc in location: \n",
    "            try: \n",
    "                path = relative_filepaths[loc]\n",
    "                x_list.append(get_df_from_parquet(path+XTEE))\n",
    "            except Exception as e:\n",
    "                print(f'\\nProbaly no matching location for passed strings:{location}')\n",
    "                raise Exception(e)\n",
    "    \n",
    "    os.chdir(cwd_old)\n",
    "    for x in x_list:\n",
    "        if 'date_calc' in x:\n",
    "            x.drop(columns=['date_calc'], inplace=True)\n",
    "    ### returning working directory ###\n",
    "    return x_list\n",
    "\n",
    "dataframes = get_training_data()\n",
    "X_frames_train = dataframes[0]\n",
    "Y_frames_train = dataframes[1]\n",
    "X_frames_test = get_test_data()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "XTRA = X_frames_train[0]\n",
    "XTRB = X_frames_train[1]\n",
    "XTRC = X_frames_train[2]\n",
    "\n",
    "YA = Y_frames_train[0]\n",
    "YB = Y_frames_train[1]\n",
    "YC = Y_frames_train[2]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"A: \\n\", len(XTRA))\n",
    "ind = XTRA[(XTRA['date_forecast'] == pd.to_datetime('2022-10-21 00:00:00'))].index\n",
    "print(ind)\n",
    "XTRA = XTRA.drop(ind).reset_index(drop=True)\n",
    "print(len(XTRA))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"B: \\n\", len(XTRB))\n",
    "ind = XTRB[(XTRB['date_forecast'] == pd.to_datetime('2022-05-02 21:00:00'))].index\n",
    "print(ind)\n",
    "XTRB = XTRB.drop(ind).reset_index(drop=True)\n",
    "print(len(XTRB))\n",
    "\n",
    "print(\"C: \\n\",len(XTRC))\n",
    "ind = XTRC[(XTRC['date_forecast'] == pd.to_datetime('2022-04-25 21:00:00'))].index\n",
    "print(ind)\n",
    "XTRC = XTRC.drop(ind).reset_index(drop=True)\n",
    "print(len(XTRC))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data clean up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fix_y_holes(y: pd.DataFrame) -> pd.DataFrame:\n",
    "    Y = y\n",
    "    drop_val = None\n",
    "    index_dropper = []\n",
    "    for i in range(1, len(Y)-4): # Since we match on 4 consecutive values.\n",
    "        if Y['pv_measurement'].iloc[i] != 0:\n",
    "            if (Y['pv_measurement'].iloc[i] == Y['pv_measurement'].iloc[i+1] and Y['pv_measurement'].iloc[i+1] == Y['pv_measurement'].iloc[i+2] and Y['pv_measurement'].iloc[i+2] == Y['pv_measurement'].iloc[i+3]):\n",
    "                drop_val = Y['pv_measurement'].iloc[i]\n",
    "        if Y['pv_measurement'].iloc[i] == drop_val:\n",
    "            index_dropper.append(i)\n",
    "        else:\n",
    "            if drop_val != None:\n",
    "                drop_val = None\n",
    "    print(index_dropper)\n",
    "    return Y.drop(index_dropper)\n",
    "    \n",
    "import matplotlib.pylab as plt\n",
    "fig, axs = plt.subplots(6, 1, figsize=(20, 10), sharex=True)\n",
    "YA[['time', 'pv_measurement']].set_index('time').plot(ax=axs[0], title='Target A', color='red')\n",
    "YB[['time', 'pv_measurement']].set_index('time').plot(ax=axs[1], title='Target B', color='red')\n",
    "YC[['time', 'pv_measurement']].set_index('time').plot(ax=axs[2], title='Target C', color='red')\n",
    "\n",
    "\n",
    "YA = fix_y_holes(YA)\n",
    "YB = fix_y_holes(YB)\n",
    "YC = fix_y_holes(YC)\n",
    "\n",
    "YA[['time', 'pv_measurement']].set_index('time').plot(ax=axs[3], title='Target A Clean', color='blue')\n",
    "YB[['time', 'pv_measurement']].set_index('time').plot(ax=axs[4], title='Target B Clean', color='blue')\n",
    "YC[['time', 'pv_measurement']].set_index('time').plot(ax=axs[5], title='Target C Clean', color='blue')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Aggregation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Making sure that target values line up with x_values\n",
    "\n",
    "agg_types = ['count', \n",
    "             'sum',\n",
    "             'mean',\n",
    "             'median',\n",
    "             'min',\n",
    "             'max',\n",
    "             'mode',\n",
    "             'std',\n",
    "             'var']\n",
    "\n",
    "def stocastic_median(x_list):\n",
    "    s = np.median(x_list)\n",
    "    return int(s)\n",
    "\n",
    "\n",
    "def gen_agg(df: pd.DataFrame, agg_type, batch_size: int = 4, merge_on = 'first') -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Pass dataframe WITH date_forecast value and choose aggregation type by passing string to 'agg_type'\n",
    "\n",
    "        - count -> Number of non-null observations\n",
    "        - sum -> Sum of values\n",
    "        - mean -> Mean of values\n",
    "        - median -> Arithmetic median of values, e.g. middle of ordered dataset\n",
    "        - min -> Minimum\n",
    "        - max -> Maximum\n",
    "        - std -> Standard deviation\n",
    "        - var -> Variance\n",
    "\n",
    "        Also possible to pass aggregation function directly f.eks. np.mean\n",
    "    \"\"\"\n",
    "    agg_func = {col: agg_type for col in df.columns[1:]} # [1:] assumes 'date_forecast' is first\n",
    "    return df.groupby(df.index // batch_size).agg({**{'date_forecast': merge_on}, **agg_func})\n",
    "\n",
    "categorical_col = ['dew_or_rime:idx', 'precip_type_5min:idx', 'is_day:idx', 'is_in_shadow:idx']\n",
    "\n",
    "def aggregate_correct_x(x: pd.DataFrame) -> pd.DataFrame:\n",
    "   '''\n",
    "   Takes a given dataframe and returns an aggregated dataframe based on selected categorical functions. \n",
    "   Assumes grouping of 4.\n",
    "   '''\n",
    "   categorical = x[[\"date_forecast\"] + categorical_col]\n",
    "   mean = x.drop(columns=categorical_col)\n",
    "\n",
    "   categorical = gen_agg(categorical, agg_type=stocastic_median, merge_on = 'first')\n",
    "   mean = gen_agg(mean, \"mean\", merge_on = 'first')\n",
    "\n",
    "   return pd.merge(categorical, mean, on=\"date_forecast\")\n",
    "\n",
    "def data_allign(x_train, y_train):\n",
    "\n",
    "  y_train.dropna(inplace=True)\n",
    "  x_train = aggregate_correct_x(x_train)\n",
    "  combined_data = pd.merge(x_train, y_train, left_on='date_forecast', right_on='time')\n",
    "  y_train = combined_data['pv_measurement']\n",
    "\n",
    "  if 'time' and 'pv_measurement' in combined_data.columns:\n",
    "    combined_data.drop(columns=['time', 'pv_measurement'], inplace=True)\n",
    "    \n",
    "  return combined_data, y_train\n",
    "\n",
    "X_train = [XTRA, XTRB, XTRC]\n",
    "Y_train = [YA, YB, YC]\n",
    "\n",
    "for i in range(len(X_train)):\n",
    "    X_train[i], Y_train[i] = data_allign(X_train[i], Y_train[i])\n",
    "\n",
    "for j in range(len(X_frames_test)):\n",
    "    X_frames_test[j] = aggregate_correct_x(X_frames_test[j])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Verify length matches\n",
    "for x in range(len(X_train)):\n",
    "    print(\"x,y: \", len(X_train[x]), len(Y_train[x]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train[0].tail()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Timeseasonality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List\n",
    "\n",
    "## We now need functions for assigning daily and YEARly cycles (described in datanalysis docu on Peter branch)\n",
    "# plus 2 avoids 0 and negative values but we ignore this here since it allready normalises the data\n",
    "DAY = 24*60*60\n",
    "YEAR = (365.2425)*DAY\n",
    "SHIFT = 0 #possible to shift oscilation to avoid 0 and or negative values.\n",
    "\n",
    "# Conversion datetime -> unix_time\n",
    "def get_unixtime(datetime: pd.Series) -> pd.Series:\n",
    "    unixtime = (datetime - pd.Timestamp(\"1970-01-01\")) // pd.Timedelta('1s')\n",
    "    return unixtime\n",
    "\n",
    "# functions for creating seasonality:\n",
    "def sinus_day(unix_time):\n",
    "    return SHIFT + np.sin(unix_time * (2 * np.pi / DAY)) # since it is seconds since 1.1.1970 we divide by seconds in a DAY to get seasonal changes throughout the dat\n",
    "\n",
    "def sinus_year(unix_time):\n",
    "    return SHIFT + np.sin(unix_time * (2 * np.pi / YEAR))\n",
    "\n",
    "def cosinus_day(unix_time):\n",
    "    return SHIFT + np.cos(unix_time * (2 * np.pi / DAY))\n",
    "\n",
    "def cosinus_year(unix_time):\n",
    "    return SHIFT + np.cos(unix_time * (2 * np.pi / YEAR))\n",
    "\n",
    "# function for returning two series with the daily cycles (sine and cosine)\n",
    "def get_daycycle(unixtime: pd.Series) -> List[pd.Series]:\n",
    "    sinus_daytime = unixtime.apply(sinus_day)\n",
    "    sinus_daytime = sinus_daytime.rename('sinus_day') \n",
    "    cosinus_daytime = unixtime.apply(cosinus_day)\n",
    "    cosinus_daytime = cosinus_daytime.rename('cosinus_day')\n",
    "    return [sinus_daytime, cosinus_daytime]\n",
    "\n",
    "# Function for returning two series with the yearly cycles\n",
    "def get_yearcycle(unixtime: pd.Series) -> List[pd.Series]:\n",
    "    sinus_yeartime = unixtime.apply(sinus_year)\n",
    "    sinus_yeartime = sinus_yeartime.rename('sinus_year')\n",
    "    cosinus_yeartime = unixtime.apply(cosinus_year)\n",
    "    cosinus_yeartime = cosinus_yeartime.rename('cosinus_year')\n",
    "    return [sinus_yeartime, cosinus_yeartime]\n",
    "\n",
    "def append_seasonal_columns(df: pd.DataFrame, time_column: str = 'date_forecast') -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    returns joined Dataframe with seasonal data. Does not drop time_column\n",
    "    \"\"\"\n",
    "    # check that time column exists\n",
    "    if time_column not in df.columns: \n",
    "        raise Exception(f\"The timecolumn passed: {time_column}, is not part of the dataset passed.\")\n",
    "    \n",
    "    if not np.issubdtype(df[time_column], np.datetime64):\n",
    "        raise Exception(f'Passed timecolumn must be of numpy datetime64. Passed type is {df[time_column].dtype()}')\n",
    "    \n",
    "    unixtime = get_unixtime(df[time_column])\n",
    "    day_sin, day_cos = get_daycycle(unixtime)\n",
    "    year_sin, year_cos = get_yearcycle(unixtime)\n",
    "    df = df.join([day_sin, day_cos, year_sin, year_cos])\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### One-Hot-Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def one_hot_encode(df: pd.DataFrame, col_list: [str]):\n",
    "  for col in col_list:\n",
    "    column_to_encode = df[col]\n",
    "    df_encoded = pd.get_dummies(column_to_encode, prefix=col) # Convert categorical variable into dummy/indicator variables\n",
    "    df.drop(col, axis=1, inplace=True)\n",
    "    df_encoded_binary = df_encoded.astype(int) # Convert to binary from boolean\n",
    "    df = pd.concat([df, df_encoded_binary], axis=1) # Concatenate dataframes\n",
    "  return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Date forecast columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def date_forecast_columns(df: pd.DataFrame):\n",
    "\n",
    "  date_forecast = df['date_forecast']\n",
    "  \n",
    "  df['year'] = date_forecast.dt.year\n",
    "  df['month'] = date_forecast.dt.month\n",
    "  df['day'] = date_forecast.dt.day\n",
    "  df['hours'] = date_forecast.dt.hour\n",
    "  df['day_of_week'] = date_forecast.dt.dayofweek\n",
    "  df['day_of_year'] = date_forecast.dt.dayofyear\n",
    "  df['week_of_year'] = date_forecast.dt.isocalendar().week\n",
    "\n",
    "  return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def more_features(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    # Convert the 'date_forecast' to datetime and set it as index\n",
    "    df['date_forecast'] = pd.to_datetime(df['date_forecast'])\n",
    "    df.set_index('date_forecast', inplace=True)\n",
    "    df.sort_index(inplace=True)\n",
    "\n",
    "    # Now apply the rolling function\n",
    "    df['max_air_density_3h'] = df['air_density_2m:kgm3'].rolling('3h').max()\n",
    "    df['min_air_density_3h'] = df['air_density_2m:kgm3'].rolling('3h').min()\n",
    "    df['total_solar_rad_1h'] = df['direct_rad_1h:J'] + df['diffuse_rad_1h:J']\n",
    "    df['total_wind_speed_10m'] = (df['wind_speed_u_10m:ms']**2 + df['wind_speed_v_10m:ms']**2)**0.5\n",
    "    df['total_snow_1h'] = df[['fresh_snow_1h:cm', 'snow_melt_10min:mm']].sum(axis=1)\n",
    "    df['pressure_variation_3h'] = df['sfc_pressure:hPa'].diff(periods=3)\n",
    "\n",
    "    return df\n",
    "\n",
    "for i in range(len(X_train)):\n",
    "    X_train[i] = append_seasonal_columns(X_train[i])\n",
    "    X_train[i] = date_forecast_columns(X_train[i])\n",
    "    X_train[i] = more_features(X_train[i])\n",
    "\n",
    "for i in range(len(X_frames_test)):\n",
    "    X_frames_test[i] = append_seasonal_columns(X_frames_test[i])\n",
    "    X_frames_test[i] = date_forecast_columns(X_frames_test[i])    \n",
    "    X_frames_test[i] = more_features(X_frames_test[i])\n",
    " \n",
    "\n",
    "# THIS SECTION CAN ONLY WORK IF THE PREVIOUS AGGREGATION IS DONE INDIVIDUALLY FOR CATEGORICAL DATA\n",
    "\n",
    "def fix_categorical(train: pd.DataFrame, test: pd.DataFrame):\n",
    "    temp = pd.concat([train, test], ignore_index=True)\n",
    "    index_train = temp[(temp['date_forecast'] < test['date_forecast'].iloc[0])].index\n",
    "    return temp.drop(index_train)\n",
    "\n",
    "OH_columns = ['dew_or_rime:idx', 'precip_type_5min:idx']\n",
    "\n",
    "for i in range(len(X_frames_test)):\n",
    "    X_train[i] = one_hot_encode(X_train[i],OH_columns)\n",
    "    X_frames_test[i] = one_hot_encode(X_frames_test[i], OH_columns)\n",
    "    X_frames_test[i] = fix_categorical(X_train[i], X_frames_test[i])\n",
    "    # kommenter dusse=\n",
    "    # X_train[i].drop(columns=['date_forecast'], inplace=True)\n",
    "    # X_frames_test[i].drop(columns=['date_forecast'], inplace=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show null values for all training sets\n",
    "\n",
    "count_a = X_train[0].isna().sum()\n",
    "count_b = X_train[1].isna().sum()\n",
    "count_c = X_train[2].isna().sum()\n",
    "\n",
    "count_a.rename(\"A\", inplace=True)\n",
    "count_b.rename(\"B\", inplace=True)\n",
    "count_c.rename(\"C\", inplace=True)\n",
    "\n",
    "df = pd.merge(count_a, count_b, left_index=True, right_index=True)\n",
    "df = pd.merge(df, count_c, left_index=True, right_index=True)\n",
    "\n",
    "df[(df['A'] != 0) | (df['B'] != 0) | (df['C'] != 0)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show null values for all test sets\n",
    "\n",
    "count_a = X_frames_test[0].isna().sum()\n",
    "count_b = X_frames_test[1].isna().sum()\n",
    "count_c = X_frames_test[2].isna().sum()\n",
    "\n",
    "count_a.rename(\"A\", inplace=True)\n",
    "count_b.rename(\"B\", inplace=True)\n",
    "count_c.rename(\"C\", inplace=True)\n",
    "\n",
    "df = pd.merge(count_a, count_b, left_index=True, right_index=True)\n",
    "df = pd.merge(df, count_c, left_index=True, right_index=True)\n",
    "\n",
    "df[(df['A'] != 0) | (df['B'] != 0) | (df['C'] != 0)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removes nan or fills it\n",
    "values = {\"ceiling_height_agl:m\": 20000, \"cloud_base_agl:m\": 20000}\n",
    "\n",
    "for i in range(len(X_train)):\n",
    "    X_train[i].drop(columns=['snow_density:kgm3', 'elevation:m', 'year'], inplace=True)\n",
    "    X_frames_test[i].drop(columns=['snow_density:kgm3', 'elevation:m', 'year'], inplace=True)\n",
    "    X_train[i].fillna(value=values, inplace=True)\n",
    "    X_frames_test[i].fillna(value=values, inplace=True)\n",
    "    X_frames_test[i].fillna(0, inplace=True) # fills remaining NaN vals with 0, (specifically for one-hot encoded columns with NaN)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print(X_train[0]['estimated'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def combine_features(df, listOfFeaturesToCombine):\n",
    "    for features in listOfFeaturesToCombine:\n",
    "        new_col_name = features[0] + '_mean'\n",
    "        df[new_col_name] = df[features].mean(axis=1)\n",
    "    return df\n",
    "\n",
    "listOfFeaturesToCombine = [['msl_pressure:hPa', 'pressure_100m:hPa', 'pressure_50m:hPa', 'sfc_pressure:hPa'],\n",
    "                            [\"diffuse_rad:W\", \"direct_rad:W\"], \n",
    "                           ['effective_cloud_cover:p', 'total_cloud_cover:p']\n",
    "                    ]\n",
    "for i in range(len(X_train)):\n",
    "    X_train[i] = combine_features(X_train[i], listOfFeaturesToCombine)\n",
    "    X_frames_test[i] = combine_features(X_frames_test[i], listOfFeaturesToCombine)\n",
    "X_train[0].describe().transpose()\n",
    "\n",
    "# top_10_worst_features = ['precip_type_5min:idx_5', 'wind_speed_w_1000hPa:ms', 'dew_or_rime:idx_-1', 'precip_type_5min:idx_2', 'dew_or_rime:idx_1', 'snow_drift:idx', 'dew_or_rime:idx_0', 'prob_rime:p', 'precip_type_5min:idx_3', 'fresh_snow_1h:cm',\n",
    "#                          'fresh_snow_3h:cm', 'snow_melt_10min:mm', 'fresh_snow_6h:cm', 'snow_depth:cm', 'precip_type_5min:idx_1',\n",
    "#                          'rain_water:kgm2', 'fresh_snow_12h:cm']\n",
    "# top_5_worst_features = ['snow_drift:idx', 'dew_or_rime:idx_-1', 'dew_or_rime:idx_0', 'precip_type_5min:idx_5', 'precip_type_5min:idx_2', \n",
    "#                         'wind_speed_u_10m:ms', 'wind_speed_w_1000hPa:ms','wind_speed_v_10m:ms'\n",
    "#                         ]\n",
    "# for i in range(len(X_train)):\n",
    "#     X_train[i].drop(columns=top_5_worst_features, inplace=True)\n",
    "#     X_frames_test[i].drop(columns=top_5_worst_features, inplace=True)\n",
    "\n",
    "# for i in range(len(X_train)):\n",
    "#     X_train[i].drop(columns=top_10_worst_features, inplace=True)\n",
    "#     X_frames_test[i].drop(columns=top_10_worst_features, inplace=True)\n",
    "\n",
    "\n",
    "# for i in range(len(X_train)):\n",
    "#     X_train[i]['diffuse_rad:W_mean_prev_hour'] = X_train[i]['diffuse_rad:W_mean'].shift(1)\n",
    "#     X_train[i]['diffuse_rad_1h:J_mean_prev_hour'] = X_train[i]['diffuse_rad_1h:J_mean'].shift(1)\n",
    "#     X_frames_test[i]['diffuse_rad:W_mean_prev_hour'] = X_frames_test[i]['diffuse_rad:W_mean'].shift(1)\n",
    "#     X_frames_test[i]['diffuse_rad_1h:J_mean_prev_hour'] = X_frames_test[i]['diffuse_rad_1h:J_mean'].shift(1)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_frames_test[0].columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into training and validation sets\n",
    "\n",
    "x_train_a, x_val_a, y_train_a, y_val_a = train_test_split(X_train[0], Y_train[0], test_size=0.17, random_state=42)\n",
    "x_train_b, x_val_b, y_train_b, y_val_b = train_test_split(X_train[1], Y_train[1], test_size=0.17, random_state=42)\n",
    "x_train_c, x_val_c, y_train_c, y_val_c = train_test_split(X_train[2], Y_train[2], test_size=0.17, random_state=42)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Catboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "# Use params from hyperparameter tuning using optuna\n",
    "params_a = {'random_state': 42, 'learning_rate': 0.039975576144155645, 'depth': 9, 'subsample': 0.4504678933801176, 'colsample_bylevel': 0.9773225861097778, 'min_data_in_leaf': 90}\n",
    "params_b = {'random_state': 42, 'learning_rate': 0.023765834908014156, 'depth': 10, 'subsample': 0.8298593330195755, 'colsample_bylevel': 0.6060393047650714, 'min_data_in_leaf': 61}\n",
    "params_c = {'random_state': 42, 'learning_rate': 0.060183973978509046, 'depth': 10, 'subsample': 0.28819995411353627, 'colsample_bylevel': 0.39818319507473743, 'min_data_in_leaf': 77}\n",
    "\n",
    "# # Hypertuned params, but worse :(\n",
    "# params_a = {'random_state': 42, 'learning_rate': 0.09566223811599815, 'depth': 7, 'subsample': 0.960801961471582, 'colsample_bylevel': 0.6043383106745279, 'min_data_in_leaf': 78}\n",
    "# params_b = {'random_state': 42, 'learning_rate': 0.04250298579274471, 'depth': 10, 'subsample': 0.5902141253689043, 'colsample_bylevel': 0.4702544263427683, 'min_data_in_leaf': 87}\n",
    "# params_c = {'random_state': 42, 'learning_rate': 0.008810167623455675, 'depth': 10, 'subsample': 0.8621321557173095, 'colsample_bylevel': 0.6774949043850594, 'min_data_in_leaf': 25}\n",
    "\n",
    "model_a = CatBoostRegressor(**params_a)\n",
    "model_b = CatBoostRegressor(**params_b)\n",
    "model_c = CatBoostRegressor(**params_c)\n",
    "\n",
    "\n",
    "model_a.fit(x_train_a, y_train_a)\n",
    "model_b.fit(x_train_b, y_train_b)\n",
    "model_c.fit(x_train_c, y_train_c)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### AutoGluon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from autogluon.tabular import TabularDataset, TabularPredictor\n",
    "\n",
    "joined_a = pd.merge(X_train[0], Y_train[0], left_index=True, right_index=True)\n",
    "train_a = TabularDataset(joined_a)\n",
    "predictor = TabularPredictor(label=\"pv_measurement\", eval_metric='mae').fit(train_data=train_a, presets='medium_quality', time_limit=300) #, presets='good_quality', time_limit=3600)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "joined_b = pd.merge(X_train[1], Y_train[1], left_index=True, right_index=True)\n",
    "train_b = TabularDataset(joined_b)\n",
    "predictor_b = TabularPredictor(label=\"pv_measurement\", eval_metric=\"mae\").fit(train_data=train_b,  presets='medium_quality', time_limit=300)#, presets='good_quality', time_limit=3600)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "joined_c = pd.merge(X_train[2], Y_train[2], left_index=True, right_index=True)\n",
    "train_c = TabularDataset(joined_c)\n",
    "predictor_c = TabularPredictor(label=\"pv_measurement\", eval_metric=\"mae\").fit(train_data=train_c, presets='medium_quality', time_limit=300)#, presets='good_quality', time_limit=3600)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the model based on the validation data\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "mse_a = mean_squared_error(y_val_a, y_val_a_pred)\n",
    "print(\"MSE for A: \", mse_a)\n",
    "mse_b = mean_squared_error(y_val_b, y_val_b_pred)\n",
    "print(\"MSE for B: \", mse_b)\n",
    "mse_c = mean_squared_error(y_val_c, y_val_c_pred)\n",
    "print(\"MSE for C: \", mse_c)\n",
    "print(\"Mean MSE: \", (mse_a + mse_b + mse_c) / 3)\n",
    "\n",
    "# Evaluate the predictions\n",
    "\n",
    "score_a = model_a.score(x_val_a, y_val_a)\n",
    "score_b = model_b.score(x_val_b, y_val_b)\n",
    "#score_c = model_c.score(x_val_c, y_val_c)\n",
    "\n",
    "print(\"Score A: \", score_a)\n",
    "print(\"Score B: \", score_b)\n",
    "#print(\"Score C: \", score_c)\n",
    "print('')\n",
    "\n",
    "#Mean MSE:  41875.359992707075\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mae_a = mean_absolute_error(y_val_a, y_val_a_pred)\n",
    "print(\"MAE for A: \", mae_a)\n",
    "mae_b = mean_absolute_error(y_val_b, y_val_b_pred)\n",
    "print(\"MAE for B: \", mae_b)\n",
    "mae_c = mean_absolute_error(y_val_c, y_val_c_pred)\n",
    "print(\"MAE for C: \", mae_c)\n",
    "print('total MAE: ', (mae_a + mae_b + mae_c))\n",
    "print('mean MAE: ', (mae_a + mae_b + mae_c) / 3)\n",
    "\n",
    "# MAE for A:  153.7542843577413\n",
    "# MAE for B:  22.167841037841136\n",
    "# MAE for C:  16.982720853153175\n",
    "# total MAE:  192.90484624873562\n",
    "# mean MAE:  64.30161541624521\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature importance catboost\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "feature_importance = model_a.get_feature_importance()\n",
    "# Create a DataFrame to store feature names and their importance scores\n",
    "importance_df = pd.DataFrame({'Feature': x_train_a.columns, 'Importance': feature_importance})\n",
    "\n",
    "# Sort the DataFrame by importance scores in descending order\n",
    "importance_df = importance_df.sort_values(by='Importance', ascending=False)\n",
    "\n",
    "# Create a bar plot to visualize feature importance\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.barh(importance_df['Feature'], importance_df['Importance'], color='skyblue')\n",
    "plt.xlabel('Importance')\n",
    "plt.ylabel('Feature')\n",
    "plt.title('Feature Importance')\n",
    "plt.gca().invert_yaxis()  # Invert the y-axis to display the most important features at the top\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Make predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model on the entire training data\n",
    "\n",
    "y_pred_cat_a = model_a.predict(X_frames_test[0]) * X_frames_test[0]['is_day:idx']\n",
    "y_pred_cat_b = model_b.predict(X_frames_test[1]) * X_frames_test[1]['is_day:idx']\n",
    "y_pred_cat_c = model_c.predict(X_frames_test[2]) * X_frames_test[2]['is_day:idx']\n",
    "\n",
    "y_pred_ag_a = predictor.predict(X_frames_test[0]) * X_frames_test[0]['is_day:idx']\n",
    "y_pred_ag_b = predictor_b.predict(X_frames_test[1]) * X_frames_test[1]['is_day:idx']\n",
    "y_pred_ag_c = predictor_c.predict(X_frames_test[2]) * X_frames_test[2]['is_day:idx']\n",
    "\n",
    "\n",
    "y_pred_cat = np.concatenate((y_pred_cat_a, y_pred_cat_b, y_pred_cat_c), axis=0)\n",
    "y_pred_ag = np.concatenate((y_pred_ag_a, y_pred_ag_b, y_pred_ag_c), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(y_pred_cat))\n",
    "print(len(y_pred_ag))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(y_pred_cat)):\n",
    "    if y_pred_cat[i] < 10: \n",
    "        y_pred_cat[i] = 0\n",
    "    if y_pred_ag[i] < 10:\n",
    "        y_pred_ag[i] = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Combine predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "mean_of_predictions = (y_pred_cat + y_pred_ag) / 2\n",
    "y_pred = mean_of_predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_pred = y_pred\n",
    "\n",
    "test = pd.read_csv('../data/test.csv')\n",
    "test['prediction'] = y_test_pred\n",
    "sample_submission = pd.read_csv('../data/sample_submission.csv')\n",
    "submission = sample_submission[['id']].merge(test[['id', 'prediction']], on='id', how='left')\n",
    "submission.to_csv('submissions/submission_cat_and_ag.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_submission = pd.read_csv('./submissions/submission_cat_148LESSSSGO.csv')\n",
    "second_best_sub = pd.read_csv('./submissions/submission_cat.csv')\n",
    "\n",
    "print(y_pred.shape)\n",
    "print(best_submission['prediction'].shape)\n",
    "plt.figure(figsize=(20,12))\n",
    "\n",
    "plt.plot(second_best_sub, 'g')\n",
    "plt.plot(best_submission['prediction'], 'r.')\n",
    "plt.xlabel(\"id\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dist = best_submission['prediction'] - second_best_sub['prediction']\n",
    "\n",
    "plt.figure(figsize=(20,12))\n",
    "plt.plot(dist)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
